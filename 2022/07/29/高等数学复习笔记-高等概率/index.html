

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=dark>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/logo.png">
  <link rel="icon" href="/img/logo.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Hailey">
  <meta name="keywords" content="Notebook">
  
    <meta name="description" content="基于 ChiuFai WONG 教授的课件进行高等概率零碎知识的整理；">
<meta property="og:type" content="article">
<meta property="og:title" content="【笔记】高等数学复习笔记-高等概率">
<meta property="og:url" content="http://achlier.github.io/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87/index.html">
<meta property="og:site_name" content="Borderland">
<meta property="og:description" content="基于 ChiuFai WONG 教授的课件进行高等概率零碎知识的整理；">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://achlier.github.io/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87/pic4-3.jpg">
<meta property="og:image" content="http://achlier.github.io/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87/pic4-1.jpg">
<meta property="og:image" content="http://achlier.github.io/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87/pic4-2.jpg">
<meta property="article:published_time" content="2022-07-29T02:36:04.000Z">
<meta property="article:modified_time" content="2022-07-29T19:59:59.182Z">
<meta property="article:author" content="Hailey">
<meta property="article:tag" content="Advanced Probability">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://achlier.github.io/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87/pic4-3.jpg">
  
  
  
  <title>【笔记】高等数学复习笔记-高等概率 - Borderland</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"achlier.github.io","root":"/","version":"1.9.0","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":false,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Achlier&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="【笔记】高等数学复习笔记-高等概率"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-07-29 10:36" pubdate>
          July 29, 2022 am
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          4.3k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          36 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">【笔记】高等数学复习笔记-高等概率</h1>
            
            <div class="markdown-body">
              
              <blockquote>
<p>基于 ChiuFai WONG 教授的课件进行高等概率零碎知识的整理；</p>
</blockquote>
<span id="more"></span>
<h2 id="随机事件和概率"><a href="#随机事件和概率" class="headerlink" title="随机事件和概率"></a>随机事件和概率</h2><h3 id="运算律"><a href="#运算律" class="headerlink" title="运算律"></a>运算律</h3><ol>
<li>交换律：$A\bigcup B=B\bigcup A,A\bigcap B=B\bigcap A$</li>
<li>结合律：$(A\bigcup B)\bigcup C=A\bigcup (B\bigcup C)$</li>
<li>分配律：$(A\bigcap B)\bigcap C=A\bigcap (B\bigcap C)$</li>
</ol>
<h3 id="德-centerdot-摩根律"><a href="#德-centerdot-摩根律" class="headerlink" title="德$\centerdot $摩根律"></a>德$\centerdot $摩根律</h3><ol>
<li>$\overline{A\bigcup B}=\bar{A}\bigcap \bar{B}$</li>
<li>$\overline{A\bigcap B}=\bar{A}\bigcup \bar{B}$</li>
</ol>
<blockquote>
<p>并的补等于补的交，交的补等于补的并</p>
</blockquote>
<h3 id="概率的基本公式"><a href="#概率的基本公式" class="headerlink" title="概率的基本公式"></a>概率的基本公式</h3><h4 id="全概率公式-Total-Probability-Theorem"><a href="#全概率公式-Total-Probability-Theorem" class="headerlink" title="全概率公式 Total Probability Theorem"></a>全概率公式 Total Probability Theorem</h4><p>If</p>
<script type="math/tex; mode=display">
E_1\cup E_2\cup ...\cup E_n=\Omega\quad and\quad E_i\cap E_j=\varnothing\quad for\quad i\ne j</script><p>by using the fact that the events $A\cap E_i,i=1,2,…,n$ are  mutually exclusive, we obtain</p>
<script type="math/tex; mode=display">
P(A)=\sum_i P(A|E_i)P(E_i)</script><h4 id="Bayes-Theorem"><a href="#Bayes-Theorem" class="headerlink" title="Bayes Theorem"></a>Bayes Theorem</h4><p>Let $\{E_i\}_{i\in I}$ be a finite or countable disjoint union of $\Omega$, and suppose $P(A) &gt; 0$. Then</p>
<script type="math/tex; mode=display">
P(E_n|A)=\frac{P(A\cap E_n)}{P(A)}=\frac{P(A|E_n)P(E_n)}{\sum_i P(A|E_i)P(E_i)}</script><h2 id="随机变量及其概率分布"><a href="#随机变量及其概率分布" class="headerlink" title="随机变量及其概率分布"></a>随机变量及其概率分布</h2><h3 id="Expected-Value"><a href="#Expected-Value" class="headerlink" title="Expected Value"></a>Expected Value</h3><p>In general,  if $g’’(x)&gt;0(or g’’(x)&lt;0)$ for all $x$, then $g(E[x])\le E<a href="\text{or}\ g(E[x]">g(x)</a>\ge E[g(x)])$</p>
<h3 id="Variance"><a href="#Variance" class="headerlink" title="Variance"></a>Variance</h3><script type="math/tex; mode=display">
Var(x)=E[(x-\mu)^2]=E[x^2]-E[x]^2</script><h3 id="Probability-Generating-Function"><a href="#Probability-Generating-Function" class="headerlink" title="Probability Generating Function"></a>Probability Generating Function</h3><script type="math/tex; mode=display">
P_X(z)=E(z^X)=p(0)+p(1)z+p(2)z^2+...</script><p>Clearly, $p(n)=\frac1{n!}\frac{d^n}{dz^n}P_X(z)\bigg|_{z=0}$ and $P_X(1)=p(0)+p(1)+p(2)+…=1$</p>
<p>Also $P’_X(1)=E[X],P’’_X(1)=E[X^2]-E[X],Var[x]=P’’_X(1)+P’_X(1)-P’_X(1)^2$</p>
<h3 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h3><script type="math/tex; mode=display">
f_{Y_1,Y_2}(y_1,y_2)=f_{x_1,x_2}(g_1^{-1}(y_1,y_2),g_2^{-1}(y_1,y_2))|J|</script><p>where $J$ is the Jacobian of $g^{-1}$</p>
<script type="math/tex; mode=display">
f_Z(Z)=\int_{-\infty}^{\infty}f_X(w)f_Y(Z-w)dw</script><h3 id="Law-of-Total-Expectation"><a href="#Law-of-Total-Expectation" class="headerlink" title="Law of Total Expectation"></a>Law of Total Expectation</h3><script type="math/tex; mode=display">
E[X]=\sum_yE[X|Y=y]P(Y=y)</script><script type="math/tex; mode=display">
Var(X|Y)=E[X^2|Y]-E[X|Y]^2</script><script type="math/tex; mode=display">
Var[X]=E[X^2]-E[X]^2=E[Var(X|Y)]+Var(E[X|Y])</script><h3 id="Bivariate-normal-distribution"><a href="#Bivariate-normal-distribution" class="headerlink" title="Bivariate normal distribution"></a>Bivariate normal distribution</h3><script type="math/tex; mode=display">
f_{X, Y}(x, y)=\frac{1}{2 \pi \sigma_{X} \sigma_{Y} \sqrt{1-\rho^{2}}} e^{-\frac{1}{2\left(1-\rho^{2}\right)}\left[\left(\frac{x-\mu_{X}}{\sigma_{X}}\right)^{2}-2 \rho\left(\frac{x-\mu_{X}}{\sigma_{X}}\right)\left(\frac{y-\mu_{Y}}{\sigma_{Y}}\right)+\left(\frac{y-\mu_{Y}}{\sigma_{Y}}\right)^{2}\right]}</script><p>$f_{X|Y}(x|y)$ is normally distributed with mean $E[X|Y=y]=\mu_x+\rho \sigma_x\frac{y-\mu_Y}{\sigma_Y}$ </p>
<p>and variance $Var[X|Y=y]=(1-\rho^2)\sigma_x^2$.</p>
<h3 id="Moment-generating-function"><a href="#Moment-generating-function" class="headerlink" title="Moment generating function"></a>Moment generating function</h3><script type="math/tex; mode=display">
M_{X}(t)=E\left[e^{t x}\right]=\left\{\begin{array}{cl}
\sum_{x} e^{t x} p(x) & \text { if } X \text { is discrete with probability mass function } p(x) \\
\int_{-\infty}^{\infty} e^{t x} f(x) d x & \text { if } X \text { is continuous with probability density function } f_{X}(x)
\end{array}\right.</script><p>Hence</p>
<script type="math/tex; mode=display">
E[X^k]=\frac{d^k}{dt^k}M_X(t)\bigg|_{t=0}</script><p>Furthermore,</p>
<script type="math/tex; mode=display">
\begin{array}{c}
\left.\frac{d}{d t} \ln M_{X}(t)\right|_{t=0}=\left.\frac{M_{X}^{\prime}(t)}{M_{X}(t)}\right|_{t=0}=E[X] \text { and } \\
\left.\frac{d^{2}}{d t^{2}} \ln M_{X}(t)\right|_{t=0}=\left.\frac{d}{d t}\left(\frac{M_{X}^{\prime}(t)}{M_{X}(t)}\right)\right|_{t=0}=\left.\frac{M_{X}(t) M_{X}^{\prime \prime}(t)-M_{X}^{\prime}(t)^{2}}{M_{X}^{2}(t)}\right|_{t=0}=\operatorname{Var}[X]
\end{array}</script><p>the joint moment generating function,</p>
<script type="math/tex; mode=display">
M\left(t_{1}, \cdots, t_{n}\right)=E\left[e^{t_{1} X_{1}+\cdots+t_{n} X_{n}}\right]</script><p>如果 $ \mathbb{E}\left[|\xi|^{n}\right]&lt;\infty$ ,我们就说 $\xi$ 是 $n$ 次可积的, 或者说有 $n$  阶矩. 高阶矩的存在蕴含着低阶矩的存在. 存在蕴含一阶矩存在. 距的存在性实际上依赖于 $\xi$ 的分布函数的尾部大小, $\mathbb{P}(|\xi|&gt;x)$ 作为 $x$ 的函数称为是尾部, 尾部总是一个无穷小量, 可积性非常依赖于尾部的阶. 例如 $\mathbb{E}\left[\left.|\xi\right|^{n}\right]&lt;\infty $ 蕴含着</p>
<script type="math/tex; mode=display">
\lim _{x \rightarrow \infty}|x|^{n} \mathbb{P}(|\xi|>x)=0</script><h3 id="Convergence-of-Random-Variables"><a href="#Convergence-of-Random-Variables" class="headerlink" title="Convergence of Random Variables"></a>Convergence of Random Variables</h3><p><img src="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87/pic4-3.jpg" srcset="/img/loading.gif" lazyload alt></p>
<p>In this figure, the stronger types of convergence are on top and, as we move to the bottom, the convergence becomes weaker.</p>
<h4 id="Convergence-in-Distribution"><a href="#Convergence-in-Distribution" class="headerlink" title="Convergence in Distribution"></a><strong>Convergence in Distribution</strong></h4><script type="math/tex; mode=display">
\lim _{n \rightarrow \infty} F_{X_{n}}(x)=F_{X}(x)</script><p>Also</p>
<script type="math/tex; mode=display">
\lim _{n \rightarrow \infty} p_{X_{n}}(x)=p_{X}(x)</script><p><strong>Central Limit Theorem</strong></p>
<p>Let $Z_{1}, Z_{2}, \cdots$ be a sequence of random variables having distribution functions $F_{Z_{n}}$ and moment generating functions $M_{Z_{n}}, n \geq 1$ , and let $Z$ be a random variable having distribution function $F_{Z}$ and moment generating function $M_{Z}$. If  $M_{Z_{n}}(t) \rightarrow M_{Z}(t) $ for all $t$, then $F_{Z_{n}}(t) \rightarrow F_{Z}(t)$ for all $t$ at which $F_{Z}(t) $ is continuous.</p>
<script type="math/tex; mode=display">
P\left(\frac{X_{1}+\cdots+X_{n}-n \mu}{\sigma \sqrt{n}} \leq a\right)=P\left(\frac{\bar{X}-\mu}{\sigma / \sqrt{n}} \leq a\right) \rightarrow \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{a} e^{-\frac{x^{2}}{2}} d x \text { as } n \rightarrow \infty</script><h4 id="Convergence-in-Probability"><a href="#Convergence-in-Probability" class="headerlink" title="Convergence in Probability"></a><strong>Convergence in Probability</strong></h4><script type="math/tex; mode=display">
\lim _{n \rightarrow \infty} P\left(\left|X_{n}-X\right| \geq \varepsilon\right)=0 \text {, for all } \varepsilon>0</script><p><strong>Markov’s inequality</strong></p>
<script type="math/tex; mode=display">
P(X \geq a) \leq \frac{E[X]}{a}</script><p>Proof</p>
<p>For $a&gt;0$ , define an event $A=\{X \geq a\}$ and $I_{A}$ an indicator for $A$ , that is</p>
<script type="math/tex; mode=display">
I_{A}=\left\{\begin{array}{ll}1 & \text { if } A \text { occurs }(X \geq a) \\ 0 & \text { if } A^{c} \text { occurs }(X<a)\end{array}\right.</script><p>Note that, since $X \geq 0, I_{A} \leq \frac{X}{a}$ and taking expectations of the preceding  inequality yields</p>
<script type="math/tex; mode=display">
P(X \geq a)=P(A)=E\left[I_{A}\right] \leq \frac{E[X]}{a}</script><p><strong>Chebyshev’s inequality</strong></p>
<script type="math/tex; mode=display">
P(|X-\mu| \geq k) \leq \frac{\sigma^{2}}{k^{2}}</script><p><strong>Weak Law of Large Numbers</strong></p>
<script type="math/tex; mode=display">
\lim _{n \rightarrow \infty} P(|\bar{X}-\mu| \geq \varepsilon)\leq \frac{\sigma^{2}}{n\varepsilon^{2}}=0</script><h4 id="Convergence-in-the-r-th-Mean"><a href="#Convergence-in-the-r-th-Mean" class="headerlink" title="Convergence in the r-th Mean"></a><strong>Convergence in the r-th Mean</strong></h4><script type="math/tex; mode=display">
\lim _{n \rightarrow \infty} E\left(\left|X_{n}-X\right|^{r}\right)=0</script><h4 id="Almost-Sure-Convergence"><a href="#Almost-Sure-Convergence" class="headerlink" title="Almost Sure Convergence"></a><strong>Almost Sure Convergence</strong></h4><script type="math/tex; mode=display">
P\left(\omega \in \Omega: \lim _{n \rightarrow \infty} X_{n}(\omega)=X(\omega)\right)=1</script><p>Also</p>
<script type="math/tex; mode=display">
\mathbb{P}\left(\lim \sup \left\{\left|X_{n}-X\right|>\varepsilon\right\}\right)=0</script><p>由 Borel-Cantelli 推出</p>
<script type="math/tex; mode=display">
\sum_{n=1}^{\infty} P\left(\left|X_{n}-X\right| \geq \varepsilon\right)<\infty</script><h2 id="Special-distributions"><a href="#Special-distributions" class="headerlink" title="Special distributions"></a>Special distributions</h2><h3 id="Discrete-random-variables"><a href="#Discrete-random-variables" class="headerlink" title="Discrete random variables"></a><strong>Discrete random variables</strong></h3><ol>
<li><h4 id="Bernoulli-p"><a href="#Bernoulli-p" class="headerlink" title="Bernoulli $(p)$"></a>Bernoulli $(p)$</h4><p>Description: $X$ indicates whether a trial that results in a success with probability $p$ is a success or not.</p>
<p>Probability mass function: $p_{X}(k)=P(X=k)=\left\{\begin{array}{cc}p &amp; \text { for } k=1 \ 1-p &amp; \text { for } k=0 \ 0 &amp; \text { otherwise }\end{array}\right.$</p>
<p>Mean: $E[X]=p$</p>
<p>Variance: $\operatorname{Var}[X]=p(1-p)$</p>
<p>Moment generating function: $M_{X}(t)=1-p+p e^{t}$</p>
</li>
<li><h4 id="Binomial-n-p"><a href="#Binomial-n-p" class="headerlink" title="Binomial$(n, p)$"></a>Binomial$(n, p)$</h4><p>Description: $X$ represents the number of successes in $n$ independent trials when each trial is a success with probability $p$.</p>
<p>Probability mass function: $p_{X}(k)=P(X=k)=\left\{\begin{array}{cc}\left(\begin{array}{l}n \ k\end{array}\right) p^{k}(1-p)^{n-k} &amp; \text { for } k=0,1, \cdots, n \ 0 &amp; \text { otherwise }\end{array}\right.$</p>
<p>Mean: $E[X]=n p$</p>
<p>Variance: $\operatorname{Var}[X]=n p(1-p)$</p>
<p>Moment generating function: $M_{X}(t)=\left(1-p+p e^{t}\right)^{n}$</p>
<p>Properties:</p>
<ul>
<li><p>Binomial$(1, p)$=Binomial$(p)$</p>
</li>
<li><p>Sum of $n$ independent Binomial$(p)$ random variables is Binomial$(n, p)$</p>
</li>
<li><p>For Binomial tree model : $E[S_n]=S_0(pu+(1-p)d)^n$，$E[S_n^2]=S_0^2(pu^2+(1-p)d^2)^n$</p>
<p><img src="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87/pic4-1.jpg" srcset="/img/loading.gif" lazyload alt></p>
</li>
</ul>
</li>
</ol>
<ol>
<li><h4 id="Geometric-p"><a href="#Geometric-p" class="headerlink" title="Geometric $(p)$"></a>Geometric $(p)$</h4><p>Description: $X$ is the number of trials needed to obtain a success when each trial is independently a success with probability $p$.</p>
<p>Probability mass function: $p_{X}(k)=P(X=k)=\left\{\begin{array}{cc}p(1-p)^{k-1} &amp; \text { for } k=1,2, \cdots \ 0 &amp; \text { otherwise }\end{array}\right.$</p>
<p>Cumulative distribution function: $P(X&gt;n)=(1-p)^n$</p>
<p>Mean: $E[X]=\frac{1}{p}$</p>
<p>Variance: $\operatorname{Var}[X]=\frac{1-p}{p^{2}}$</p>
<p>Moment generating function: $M_{X}(t)=\frac{p e^{t}}{1-(1-p) e^{t}}$</p>
<p>Properties:</p>
<ul>
<li>Geometric distribution is memoryless. That means that if you intend to repeat an experiment until the first success, then, given that the first success has not yet occurred, the conditional probability distribution of the number of additional trials does not depend on how many failures have been observed.</li>
<li>Discrete analogue of Exponential random variable.</li>
</ul>
</li>
<li><h4 id="Negative-Binomial-r-p"><a href="#Negative-Binomial-r-p" class="headerlink" title="Negative Binomial $(r, p)$"></a>Negative Binomial $(r, p)$</h4><p>Description: $X$ is the number of trials needed to obtain a total of $r$ successes when each trial is independently a success with probability $p$.</p>
<p>Probability mass function: $p_{X}(k)=P(X=k)=\left\{\begin{array}{cc}\left(\begin{array}{c}k-1 \ r-1\end{array}\right) p^{r}(1-p)^{k-r} &amp; \text { for } k=r, r+1, \cdots \ 0 &amp; \text { otherwise }\end{array}\right.$</p>
<p>Mean: $E[X]=\frac{r}{p}$</p>
<p>Variance: $\operatorname{Var}[X]=r \frac{1-p}{p^{2}}$</p>
<p>Moment generating function: $M_{X}(t)=\left(\frac{p e^{t}}{1-(1-p) e^{t}}\right)^{r}$</p>
<p>Properties:</p>
<ul>
<li>Negative Binomial$(1, p)$=Geometric$(p)$</li>
<li>Sum of $r$ independent Geometric $(p)$ random variables is Negative Binomial$(r, p)$</li>
<li>Discrete analogue of Gamma random variable</li>
<li>$P(X&gt;n)=P(Y&lt;r)$ for $Y$ a binomial random variable with parameters $n$ and $p$.</li>
</ul>
</li>
<li><h4 id="Poisson-lambda"><a href="#Poisson-lambda" class="headerlink" title="Poisson$(\lambda)$"></a>Poisson$(\lambda)$</h4><p>Description: $X$ is used to model the number of events that occur in many trials that has a small probability of occurrence.</p>
<p>Probability mass function: $p_{X}(k)=P(X=k)=\left\{\begin{array}{cc}e^{-\lambda} \frac{\lambda^{k}}{k !} &amp; \text { for } k=0,1, \cdots \ 0 &amp; \text { otherwise }\end{array}\right.$</p>
<p>Mean: $E[X]=\lambda$</p>
<p>Variance: $\operatorname{Var}[X]=\lambda$</p>
<p>Moment generating function: $M_{X}(t)=e^{\lambda\left(e^{t}-1\right)}$</p>
<p>Properties:</p>
<ul>
<li>A Poisson random variable $X$ with parameter $\lambda=n p$ provides a good approximation to a Poisson$(n, p)$ random variable when $n$ is large and $p$ is small.</li>
<li>If events are occurring one at a time in a random manner for which (a) the number of events that occur in disjoint time intervals is independent and (b) the probability of an event occurring in any small time interval is approximately $\lambda$ times the length of the interval, then the number of events in an interval of length $t$ will be a Poisson $(\lambda t)$ random variable.</li>
</ul>
</li>
<li><h4 id="Hypergeometric-n-N-m"><a href="#Hypergeometric-n-N-m" class="headerlink" title="Hypergeometric $(n, N, m)$"></a>Hypergeometric $(n, N, m)$</h4><p>Description: $X$ is the number of white balls in a random sample of $n$ balls chosen without replacement from an urn of $N$ balls of which $m$ are white.</p>
<p>Probability mass function: $p_{X}(k)=P(X=k)=\left\{\begin{array}{cc}\frac{\left(\begin{array}{c}m \ k\end{array}\right)\left(\begin{array}{c}N-m \ n-k\end{array}\right)}{\left(\begin{array}{c}N \ n\end{array}\right)} &amp; \text { for } k=0,1, \cdots \ 0 &amp; \text { otherwise }\end{array}\right.$</p>
<p>The preceding uses the convention that $\left(\begin{array}{l}r \ j\end{array}\right)=0$ if either $j<0$ or $j>r$.</0$></p>
<p>Mean: $E[X]=n \frac{m}{N}$</p>
<p>Variance: $\operatorname{Var}[X]=n \frac{m}{N}\left(1-\frac{m}{N}\right)\left(\frac{N-n}{N-1}\right)$</p>
<p>Property:</p>
<ul>
<li>If each ball were replaced before the next selection, then $X$ would be a Binomial$(n, p)$ random variable.</li>
</ul>
</li>
</ol>
<h3 id="Continuous-random-variables"><a href="#Continuous-random-variables" class="headerlink" title="Continuous random variables"></a><strong>Continuous random variables</strong></h3><ol>
<li><h4 id="Uniform-a-b"><a href="#Uniform-a-b" class="headerlink" title="Uniform $(a, b)$"></a>Uniform $(a, b)$</h4><p>Description: $X$ is equally likely to be near each value in the interval $(a, b)$.</p>
<p>Probability density function: $f_{X}(x)=\left\{\begin{array}{cl}\frac{1}{b-a} &amp; a&lt;x&lt;b \ 0 &amp; \text { otherwise }\end{array}\right.$</p>
<p>Mean: $E[X]=\frac{a+b}{2}$</p>
<p>Variance: $\operatorname{Var}[X]=\frac{(b-a)^{2}}{12}$</p>
<p>Moment generating function: $M_{X}(t)=\left\{\begin{array}{cc}\frac{e^{b t}-e^{a t}}{t(b-a)} &amp; t \neq 0 \ 1 &amp; t=0\end{array}\right.$</p>
</li>
<li><h4 id="Exponential-lambda"><a href="#Exponential-lambda" class="headerlink" title="Exponential $(\lambda)$"></a>Exponential $(\lambda)$</h4><p>Description: $X$ is the waiting time until an event occurs when events are always occurring at a rate $\lambda&gt;0$.</p>
<p>Probability density function: $f_{X}(x)=\left\{\begin{array}{cc}\lambda e^{-\lambda x} &amp; x\ge0 \ 0 &amp; \text { otherwise }\end{array}\right.$</p>
<p>Cumulative density function: $F_X(x)=\left\{\begin{array}{cc}1-e^{-\lambda x} &amp; x\ge0 \ 0 &amp; \text { otherwise }\end{array}\right.$</p>
<p>Mean: $E[X]=\frac{1}{\lambda}$</p>
<p>Variance: $\operatorname{Var}[X]=\frac{1}{\lambda^{2}}$</p>
<p>Moment generating function: $M_{X}(t)=\frac{\lambda}{\lambda-t}$ for $\lambda&gt;t$</p>
<p>Properties:</p>
<ul>
<li>$X$ is memoryless, in that the remaining life of an item whose life distribution is Exponential $(\lambda)$ is also Exponential $(\lambda)$, no matter what the current age of the item is.</li>
<li>Continuous analogue of Geometric random variable.</li>
</ul>
</li>
<li><h4 id="Gamma-alpha-lambda"><a href="#Gamma-alpha-lambda" class="headerlink" title="Gamma$(\alpha, \lambda)$"></a>Gamma$(\alpha, \lambda)$</h4><p>Description: When $\alpha=n, X$ is the waiting time until $n$ events occur when events are always occurring at a rate $\lambda&gt;0$.</p>
<p>Probability density function: $f_{X}(x)=\left\{\begin{array}{cc}\frac{\lambda e^{-\lambda x}(\lambda x)^{\alpha-1}}{\Gamma(\alpha)} &amp; x&gt;0 \ 0 &amp; \text { otherwise }\end{array}\right.$ where $\Gamma(\alpha)=\int_{0}^{\infty} e^{-x} x^{\alpha-1} d x$ is called the Gamma function.</p>
<p>Using integration by parts, $\Gamma(\alpha)=(\alpha-1)\Gamma(\alpha-1), \Gamma(n)=(n-1)!$</p>
<p>Mean: $E[X]=\frac{\alpha}{\lambda}$</p>
<p>Variance: $\operatorname{Var}[X]=\frac{\alpha}{\lambda^{2}}$</p>
<p>Moment generating function: $M_{X}(t)=\left(\frac{\lambda}{\lambda-t}\right)^{\alpha}$ for $\lambda&gt;t$</p>
<p>Properties:</p>
<ul>
<li>Gamma$(1, \lambda)$=Gamma$(\lambda)$</li>
<li>If the random variables are independent, then the sum of a Gamma$\left(\alpha_{1}, \lambda\right)$ and a Gamma $\left(\alpha_{2}, \lambda\right)$ is a Gamma$\left(\alpha_{1}+\alpha_{2}, \lambda\right)$</li>
<li>The sum of $n$ independent and identically distributed exponentials with parameter $\lambda$ is a Gamma$(n, \lambda)$</li>
<li>$P\left(S_{n} \leq t\right)=P(N(t) \geq n)$, where $S_{n}$ has Gamma distribution with parameter $(n, \lambda)$ and $N(t)$ is Po isson with mean $\lambda t$.</li>
</ul>
<p><img src="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87/pic4-2.jpg" srcset="/img/loading.gif" lazyload alt></p>
</li>
<li><h4 id="Normal-left-mu-sigma-2-right"><a href="#Normal-left-mu-sigma-2-right" class="headerlink" title="Normal$\left(\mu, \sigma^{2}\right)$"></a>Normal$\left(\mu, \sigma^{2}\right)$</h4><p>Description: In many real applications, a certain random variable of interest is a sum of a large number of independent random variables. We are often able to use the Central Limit Theorem to justify using the normal distribution.</p>
<p>Probability density function: $f_{X}(x)=\frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}$</p>
<p>Mean: $E[X]=\mu$</p>
<p>Variance: $\operatorname{Var}[X]=\sigma^{2}$</p>
<p>Moment generating function: $M_{X}(t)=e^{\mu+\frac{1}{2} \sigma^{2} r^{2}}$</p>
<p>Properties:</p>
<ul>
<li>When $\mu=0, \sigma=1, X$ is called a standard nomal. If $X$ is Normal$\left(\mu, \sigma^{2}\right), Z=\frac{X-\mu}{\sigma}$ is standard normal.</li>
<li>Sum of independent normal random variables is also normal.</li>
<li>An important result is the Central Limit Theorem, which states that the distribution of the sum of $n$ independent and identically distributed random variables becomes normal as $n$ goes to infinity, for any distribution of these random variables that has a finite mean and variance.</li>
<li>Zero covariance of 2 nomal random variables implies these 2 variables are independent.</li>
</ul>
</li>
<li><h4 id="Lognormal-left-mu-sigma-2-right"><a href="#Lognormal-left-mu-sigma-2-right" class="headerlink" title="Lognormal$\left(\mu, \sigma^{2}\right)$"></a>Lognormal$\left(\mu, \sigma^{2}\right)$</h4><p>Description: Lognormal random variable is often used as the distribution of the ratio of the price of security at the end of one day to its price at the end of the prior day.</p>
<p>Probability density function: $f_{X}(x)=\left\{\begin{array}{cl}\frac{1}{x \sigma \sqrt{2 \pi}} e^{-\frac{(\ln x-\mu)^{2}}{2 \sigma^{2}}} &amp; \text { if } x&gt;0 \ 0 &amp; \text { otherwise }\end{array}\right.$</p>
<p>Mean: $E[X]=e^{\mu+\frac{1}{2} \sigma^{2}}$</p>
<p>Variance: $\operatorname{Var}[X]=e^{2 \mu+\sigma^{2}}\left(e^{\sigma^{2}}-1\right)$</p>
<p>Median: $x_{0.5}=e^{\mu}$</p>
<p>Properties: $X$ is a lognormal random variable with parameters $\left(\mu, \sigma^{2}\right)$ if $Y=\ln X$ is a normal random variable with parameters $\left(\mu, \sigma^{2}\right)$, that is, lognormal $\rightarrow X=e^{Y \leftarrow \text { mamal }}$</p>
</li>
<li><h4 id="Beta-a-b"><a href="#Beta-a-b" class="headerlink" title="Beta$(a, b)$"></a>Beta$(a, b)$</h4><p>Description: The $i$-th smallest of $n$ independent uniform $(0,1)$ random variables is a Beta$(i, n-i+1)$ random variable.</p>
<p>Probability density function: $f_{X}(x)=\left\{\begin{array}{cl}\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} x^{a-1}(1-x)^{b-1} &amp; 0&lt;x&lt;1 \ 0 &amp; \text { otherwise }\end{array}\right.$ where $\Gamma$ is Gamma function.</p>
<p>Mean: $E[X]=\frac{a}{a+b}$</p>
<p>Variance: $\operatorname{Var}[Y]=\frac{a b}{(a+b)^{2}(a+b+1)}$</p>
<p>Properties: Beta$(1,1)$ and Uniform $(0,1)$ are identical.</p>
</li>
</ol>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Math/" class="category-chain-item">Math</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Advanced-Probability/">#Advanced Probability</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>【笔记】高等数学复习笔记-高等概率</div>
      <div>http://achlier.github.io/2022/07/29/高等数学复习笔记-高等概率/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Hailey</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>July 29, 2022</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>Licensed under</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/" title="【笔记】高等数学复习笔记-随机过程">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">【笔记】高等数学复习笔记-随机过程</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/" title="【笔记】高等数学复习笔记-微分方程">
                        <span class="hidden-mobile">【笔记】高等数学复习笔记-微分方程</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;Table of Contents</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>






  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.0/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
