<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>【笔记】金融市场知识要点</title>
    <link href="/2022/09/19/%E9%87%91%E8%9E%8D%E5%B8%82%E5%9C%BA%E7%9F%A5%E8%AF%86%E8%A6%81%E7%82%B9/"/>
    <url>/2022/09/19/%E9%87%91%E8%9E%8D%E5%B8%82%E5%9C%BA%E7%9F%A5%E8%AF%86%E8%A6%81%E7%82%B9/</url>
    
    <content type="html"><![CDATA[<blockquote><p>由于过去的学习的主要是书本知识，并没有实战经验。因此在网上累积了一些金融市场上的定义助于更快熟悉工作节奏。</p></blockquote><span id="more"></span><h2 id="股票市场知识要点"><a href="#股票市场知识要点" class="headerlink" title="股票市场知识要点"></a>股票市场知识要点</h2><ol><li><p>板块介绍</p><ul><li><p><strong>主板</strong>对发行人（企业）的营业期限、股本大小、盈利水平、最低市值等方面的要求标准较高，上市企业多为大型成熟企业，具有较大的资本规模以及稳定的盈利能力</p></li><li><p><strong>中小板</strong>是相对于主板而言规模较小的企业</p></li><li><p><strong>创业板</strong>大多从事高科技业务，具有较高的成长性，但往往成立时间较短规模较小，业绩也不实出，但有很大的成长空间</p></li><li><p><strong>科创板</strong>是独立于现有主板市场的新设板块，主要针对新技术、新能源、高端制造、环保、生物医药等新兴领域，相比较其他三个板块，科创板允许企业在未实现利润的情况下上市</p></li></ul></li><li><p>股票代码</p><ul><li><p>沪市主板上市公司 60开头</p></li><li><p>深市主板上市公司 000开头或者有些001</p></li><li><p>深市中小板上市公司 002，003开头</p></li><li><p>创业板上市公司 300开头</p></li><li><p>科创板上市公司 688开头</p></li></ul></li><li><p>股票种类</p><ul><li><p>A股：人民币普通股票，实行T+1交割制度，有涨跌幅10%20%30%的限制</p></li><li><p>B股：人民币特种股票，以外币认购和买卖，沪市B股以美元计价，深市B股以港元计价，实行T+3交割制度，有涨跌幅10%的限制</p></li><li><p>H股：注册地在内地，上市地在香港的中资企业股票。为实物股，使用港元交易，实行T+0交割制度，无涨跌幅限制</p></li></ul></li><li><p>交易时段</p><ul><li><p>9:15-9:25 集合竞价，开始报价，9:20前报价可以撤销，系统收集所有人的买卖报价后统一按照“价格优先，时间优先”的原则集中撮合，成交额最大的交易，对应价格即为开盘价。</p></li><li><p>9:30-11:30，13:00-14:57 连续竞价</p></li><li><p>14:57-15:00 尾盘集合竞价，系统收集所有人的买卖报价后统一按照“价格优先，时间优先”的原则集中撮合，成交额最大的交易，对应价格即为收盘价。</p></li></ul></li><li><p>涨跌幅限制</p><ul><li><p>对于沪深主板，深市中小板，每个交易日，单只普通股票的股价较上一交易日收盘价的涨跌幅度不得超过10%；ST（Special Treatment) 开头的股票复牌后涨跌幅不得超过5%；新股上市首日，最高涨跌幅限制为44%。</p></li><li><p>对于科创板和创业板的股票，每个交易日单只股票的股价较上一交易日的收盘价的涨跌幅度不得超过20%；新股上市前五日不设涨跌幅。</p></li></ul></li><li><p>走势信息</p><ul><li><p>最新：当前该股价格</p></li><li><p>涨幅：（现价-昨收）/昨收*100%</p></li><li><p>涨跌：现价-昨收</p></li><li><p>涨速：（现价- N分钟前的价格）*100%/N分钟前的价格</p></li><li><p>均价：当前时刻今天的成交均价</p></li><li><p>除权（XR）：是指股票的发行公司依一定比例分配股票给股东，作为股票股利，此时增加公司的总股数并导致股价下跌</p><ul><li>前复权：将除权前的K线向下移动，维持股价趋势的连续性</li><li>后复权：将除权后的K线向上移动，但这种方式会导致与实际股价差异较大</li><li>填权：股票在除权后上涨回了原先的价格</li></ul></li><li><p>除息：在股票发放分红之前，股票中所含的实际价值减少，需要对价格进行回归调整</p></li><li><p>单边市/涨跌停板单边无连续报价：收市前5分钟内出现只有停板价位的买入（卖出）申报、没有停板价位的卖出（买入）申报，或者一有卖出（买入）申报就成交，但未打开停板价位的情况</p></li><li><p>顶背离：K线图呈现股价不断上涨，但是各项指标不断下跌的现象</p></li><li><p>底背离：K线图呈现股价不断下跌，但是各项指标在不断向上抬高的现象</p></li></ul></li><li><p>市场专业术语</p><ul><li><p>IPO（Initial Public Offering，首次公开募股）：一家企业第一次将它的股份向公众出售，俗称上市</p></li><li><p>蓝筹股（Blue Chips）：长期稳定增长的，大型的传统工业股及金融股</p></li><li><p>红筹股（Red Chips）：在中国境外注册成立，在香港上市，主要业务在中国大陆的股票</p></li><li><p>基本面：公司层面，是公司经营的基本状况，包括主营业务、财务状況、盈利水平、管理架构等；国家层面，是影响公司发展前景的宏观经济运行情况，包括银行利率 财政政策、汇率波动等</p></li><li><p>技术面：股价波动后形成的各类技术指标 ，走势形态以及K线组合等</p></li><li><p>市现率：每股市价/每股现金流量</p></li><li><p>市销率（PS）：每股市价/每股销售收入，公司市值/公司主营业务收入，在国内二级股票市场不常用</p></li><li><p>市净率（PB）：每股市价/每股净资产，评估投资风险</p></li><li><p>市盈率（PE，Price Earning Ratio ）：公司市值/公司净利润，每股市价/每股收益，评估投资一个公司需要多少年才能回本，但净利润的水分可能大</p></li><li><p>净资产收益率（ROE，Return On Equity）：公司净利润/公司净资产，每股收益/每股净资产，反映单位资金一年下来能赚多少钱</p></li><li><p>换手率/周转率：成交量/发行总股数*100%，是反映市场交投活跃程度最重要的指标之一</p></li><li><p>牛市：多头市场，股市价格的总趋势不断走高，大涨小跌，买入者多于卖出者，新资金不断涌入，供大于求</p></li><li><p>熊市：空头市场，股市价格的总趋势不断走低，大跌小涨。中国股市没有做空机制，要避免盲目抄底</p></li><li><p>牛皮市：在某段时间内，股市整体价格变化不大，成交量小，是买卖双方势均力敌的表现</p></li><li><p>委比（The Committee ）：（委买手数-委卖手数）/（委买手数+委卖手数）*100%，是某一时刻买卖盘相对强度指标</p></li><li><p>量比：（现成交总手数/现累积开市时间（分））/过去五日平均每分钟成交量，是衡量相对成交量的指标</p></li><li><p>外盘：即主动性买盘，买方主动以高于或等于当前价格购买股票，一般用红色标记</p></li><li><p>内盘：即主动性卖盘，买家主动买进大量抛售的股票数量</p></li><li><p>盘口：看盘观察交易动向的俗称</p></li><li><p>总手：到目前为止该股的总成交量</p></li><li><p>现手：刚成交的一笔交易的手数</p></li><li><p>配股：向原股东以低于市价的某一特定价格，出售一定数量新发行股票。本质上属于一种融资行为</p></li></ul></li><li><p>影响股价的因素</p><ul><li><p>1938年Williams 和 Gordon 提出了公司（股票）价值估计的股票贴现模型（Dividend Discount Model ）</p><script type="math/tex; mode=display">V=\sum_{t=1}^\infty\frac{D_t}{（1+k)^t}</script></li><li><p>alpha收益：买入被低估的股票的收益</p></li><li><p>beta收益：基本面本身上涨的收益</p></li></ul></li><li><p>市场策略</p><ul><li>低位吸筹/炸单：伏大量买单，然后通过少量的卖单诱导股价下跌。即便是有一定经验的投资者在遇到利空加上放量下跌的情况时，也会忍不住卖出手中股票。这样庄家就能轻松的以一个比较低的成本，吸收足够控盘的筹码。简单来说就是庄家利用恐慌情绪大幅打压股价，引起市场震荡，趁机在低位吸纳逃跑散户所卖出的股票的建仓手法。主要适用于受关注度比较小的股票</li></ul></li></ol><h2 id="期货市场知识要点"><a href="#期货市场知识要点" class="headerlink" title="期货市场知识要点"></a>期货市场知识要点</h2><ol><li><p>股指期货代码</p><ul><li><p>沪深300股指期货 IF（金融，制造业等周期性股票）</p></li><li><p>上证50指数 IH（金融）</p></li><li><p>中证500 IC（中盘股，行业分布均匀，单一行业权重不超过10%）</p></li></ul></li><li><p>交易市场术语</p><ul><li><p>基差：现货价格-期货价格</p></li><li><p>期货贴水/升水：在某一特定地点和特定时间内，某一特定商品的期货价格高于（低于）现货价格称为期货升水（贴水）</p></li><li><p>正向市场：正常情况下，期货价格高于现货价格</p></li><li><p>方向市场：正常情况下，期货价格低于现货价格</p></li><li><p>牛市：处于价格上涨期间的市场</p></li><li><p>熊市：处于价格下跌期间的市场</p></li><li><p>当日结算价：当日成交价格按照成交量的加权平均价</p></li><li><p>申买/卖量：当日交易系统中未成交的最高（低）价位申请买入（卖出）的下单数量</p></li><li><p>集合竞价最大成交量原则：高于竞价产生的价格的买入申报全部成交，低于竞价产生的价格的卖出申报全部成交;等于集合竞价产生的价格的买入或卖出申报，根据买入申报量和卖出申报量的多少，按少的一方的申报量成交</p></li><li><p>风险准备金：由交易所设立，用于为维护期货市场正常运转提供财务担保和弥补因交易所不可预测风险带来的亏损的资金</p></li></ul></li></ol><h2 id="基金市场知识要点"><a href="#基金市场知识要点" class="headerlink" title="基金市场知识要点"></a>基金市场知识要点</h2><ol><li><p>基金种类</p><ul><li>封闭式基金：不可赎回只能转让，即场内交易</li><li>开放式基金：随时赎回不可转让，即场外交易</li><li>ETF（交易型开放式指数基金）：可以在二级市场交易，随时买进卖出</li><li>LOF（交易型开放式基金）：投资标的更多样，比ETF申赎门槛低</li><li>分级基金/结构型基金：大多为指数基金，其通过对基金收益或净资产的分解，形成两级或多级风险收益表现有一定差异化基金份额的基金品种</li><li>保本基金：大多为混合基金，基金将大部分资产从事固定收益投资，而达到保本的作用。在保本期限内申购或赎回并不承诺保本</li><li>量化基金：大多为混合基金或股票基金，采用量化投资的方法去管理基金</li></ul></li><li><p>基金交易种类</p><ul><li>认购：在基金成立前的募集期内，投资者申请购买基金份额的行为</li><li>申购：基金成立后，投资者申请购买基金份额的行为</li><li>赎回：将基金份额兑换成现金的行为</li><li>转换：投资者将所持有的某只基金的基金份额转换成另一只基金的基金份额的行为。转换的两只基金必须都是同一基金管理人管理的、在同一注册登记机构处注册登记的基金。基金份额的转换常会收取一定的转换费用，但与赎回基金份额后再进行基金申购相比，基金转换业务的时间成本和交易费用都较低</li></ul></li><li><p>基金交易规则</p><ul><li><p>T日，即指交易日，以股市收市时间15:00为界，每天申购赎回一定要在当日下午15:00前操作，超过15:00就是下一个交易日的申请了。</p></li><li><p>基金交易一般为T日申请，T+1日确认，QDII基金(即投资海外市场的基金）由于全球交易所开市时间的时差所以是T+2日确认。如果在非交易日，比如周末购买或者赎回基金都会顺延到交易日。</p></li></ul></li></ol>]]></content>
    
    
    <categories>
      
      <category>Financial Market</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Stock</tag>
      
      <tag>Futures</tag>
      
      <tag>Fund</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】ubuntu下vim的基本用法</title>
    <link href="/2022/09/17/ubuntu%E4%B8%8Bvim%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/"/>
    <url>/2022/09/17/ubuntu%E4%B8%8Bvim%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<blockquote><p>由于租了一台Ubuntu系统的云服务器来搭梯子，不免要用到vi来修改文档内容，此处为了方便查找特意从网上摘录了操作方便查找。</p></blockquote><span id="more"></span><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>vim 自带基础教程：在任意一台装有vim的机器上，命令行中输入 <code>vimtutor</code>  然后就可以看到教程了。</p><p>当想要对一个文件进行改写or阅读时只有输入 <code>vi 文件路径</code> 或者 <code>vim 文件路径</code> 就可以了。</p><h2 id="三种模式"><a href="#三种模式" class="headerlink" title="三种模式"></a>三种模式</h2><p>vim有3个模式：<strong>命令模式（Command/Normal）、插入模式（Insert）、末行模式（Last line mode）</strong>。</p><ul><li>命令模式：<code>vi</code> 后初始模式，可以移动光标、删除字符等。按 <code>i/a/o</code> 进入插入模式。按 : 进入末行模式。</li><li><p>插入模式：在此模式下可以输入字符，按 <code>ESC</code> 将回到命令模式。</p></li><li><p>末行模式：以在最底一行输入命令。</p></li></ul><h2 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h2><h4 id="简单地移动的命令"><a href="#简单地移动的命令" class="headerlink" title="简单地移动的命令"></a>简单地移动的命令</h4><ul><li><p><code>h/j/k/l</code> → 移动光标，同等于 (←↓↑→)</p></li><li><p><code>空格键</code> → 向右、Backspace → 向左</p></li><li><p><code>Enter</code> → 移动到下一行首、<code>-</code> → 移动到上一行首。</p></li><li><p><code>w</code> → 到下一个单词的开头。</p></li><li><p><code>e</code> → 到下一个单词的结尾。</p><blockquote><p>如果你认为单词是由默认方式，那么就用小写的e和w。默认上来说，一个单词由字母，数字和下划线组成；如果你认为单词是由blank字符分隔符，那么你需要使用大写的E和W。</p></blockquote></li><li><p><code>0</code> → 数字零，到行头</p></li><li><code>^</code> → 到本行第一个不是blank字符的位置（所谓blank字符就是空格，tab，换行，回车等）</li><li><code>$</code> → 到本行行尾</li><li><code>g_</code> → 到本行最后一个不是blank字符的位置。</li><li><code>gg</code> → 到第一行</li><li><code>n+</code> → 向下跳n行</li><li><code>n-</code> → 向上跳n行</li><li><code>3G</code> → 到第 3 行</li><li><code>G</code> → 到最后一行</li></ul><h4 id="删除与拷贝的命令"><a href="#删除与拷贝的命令" class="headerlink" title="删除与拷贝的命令"></a>删除与拷贝的命令</h4><ul><li><code>x</code> → 删当前光标所在的一个字符</li><li><code>dd</code> → 删除当前行，并把删除的行存到剪贴板里</li><li><code>yy</code> → 拷贝当前行 相当行于 <code>ddP</code></li><li><code>p</code> → 粘贴剪贴板到当前位置之后</li><li><code>P</code> → 粘贴剪贴板到当前位置之前</li><li><code>J</code> → 合并光标所在行及下一行为一行</li></ul><h4 id="搜索的命令"><a href="#搜索的命令" class="headerlink" title="搜索的命令"></a>搜索的命令</h4><ul><li><code>f</code> 和 <code>F</code> 加上字符 → 移动光标到下（上）一个字符</li><li><p><code>t</code> 和 <code>T</code> 加上字符 → 移动到选定字符前的第一个字符</p></li><li><p><code>/</code> 或者 ？加字符串 → 向下（上）搜索字符串，如果搜索出多个匹配，可按n键到下一个</p></li><li><code>%</code> → 匹配光标当前所在的括号向对应反括号移动，包括 <code>(</code>, <code>&#123;</code>, <code>[</code></li><li><code>*</code> 和 <code>#</code> → 匹配光标当前所在的单词，移动光标到下一个（或上一个）匹配单词（*是下一个，#是上一个）</li><li><code>n</code> → 向下搜索前一个搜素动作</li><li><code>N</code> → 向上搜索前一个搜索动作</li></ul><h4 id="重复的命令"><a href="#重复的命令" class="headerlink" title="重复的命令"></a>重复的命令</h4><ul><li><code>u</code> → undo</li><li><code>ctrl r</code> → redo</li><li><code>.</code> → 重复上个操作</li></ul><h4 id="会进入插入模式的命令"><a href="#会进入插入模式的命令" class="headerlink" title="会进入插入模式的命令"></a>会进入插入模式的命令</h4><ul><li><code>i</code> → 在当前光标位置的左边添加文本</li><li><code>I</code> → 在当前行的开始处添加文本(非空字符的行首)</li><li><code>a</code> → 在当前光标位置的右边添加文本</li><li><code>A</code> → 在当前行的末尾位置添加文本</li><li><code>o</code> → 在当前行的下面新建一行</li><li><code>O</code> →  在当前行的上面新建一行</li><li><code>cw</code> → 替换从光标所在位置后到一个单词结尾的字符</li></ul><h4 id="进入了奇怪的模式"><a href="#进入了奇怪的模式" class="headerlink" title="进入了奇怪的模式"></a>进入了奇怪的模式</h4><ul><li><code>R</code> → 替换(覆盖)当前光标位置及后面的若干文本(进入替换模式)</li></ul><h2 id="末行模式"><a href="#末行模式" class="headerlink" title="末行模式"></a>末行模式</h2><h4 id="文件的打开与推出与保存"><a href="#文件的打开与推出与保存" class="headerlink" title="文件的打开与推出与保存"></a>文件的打开与推出与保存</h4><ul><li><code>:w</code> → 存盘</li><li><code>:q</code> → 退出</li><li><code>:x</code>， <code>ZZ</code> 或 <code>:wq</code> → 保存并退出 </li><li><code>:q!</code> → 退出不保存 <code>:qa!</code> 强行退出所有的正在编辑的文件，就算别的文件有更改。</li><li><code>:e 文件路径</code> → 打开一个文件</li><li><code>:w 文件路径</code> → 保存至文件路径</li><li><code>:saveas 文件路径</code> → 另存至文件路径</li><li><code>:bn</code> 或 <code>:n</code> 和 <code>:bp</code> 或 <code>:p</code> → 你可以同时打开很多文件，使用这两个命令来切换下一个或上一个文件。</li></ul><h4 id="替换的命令"><a href="#替换的命令" class="headerlink" title="替换的命令"></a>替换的命令</h4><ul><li><code>:s/old/new</code> → 用new替换行中首次出现的old</li><li><code>:s/old/new/g</code> → 用new替换行中所有的old</li><li><code>:n,m s/old/new/g</code> → 用new替换从n到m行里所有的old</li><li><code>:%s/old/new/g</code> → 用new替换当前文件里所有的old</li></ul><h4 id="其他功能"><a href="#其他功能" class="headerlink" title="其他功能"></a>其他功能</h4><ul><li><code>:set  nu</code>  → 显示行号</li><li><code>:set nonu</code>  → 取消显示行号</li></ul><h2 id="更多玩法"><a href="#更多玩法" class="headerlink" title="更多玩法"></a>更多玩法</h2><p>命令前加上数字，可以令你的操作更加便捷</p><ul><li><code>100idesu [ESC]</code> → 输入100次 idesu</li><li><code>3fa</code> → 在当前行查找第三个出现的a</li><li><code>nyy</code> → 将当前行向下n行复制到缓冲区</li></ul><p>或者利用命令的结合，很多命令都可以如下来干：</p><figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs xquery">&lt;<span class="hljs-keyword">start</span><span class="hljs-built_in"> position</span>&gt;<span class="language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">command</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">end</span> <span class="hljs-attr">position</span>&gt;</span></span><br></code></pre></td></tr></table></figure><p>例如</p><ul><li><code>yw</code> → 复制从光标开始到词尾的字符</li><li><code>nyw</code> → 复制从光标开始的n个单词</li><li><code>y^</code> → 复制从光标到行首的内容</li><li><p><code>y$</code> → 复制从光标到行尾的内容</p></li><li><p><code>0y$</code> → 从行头开始拷贝到本行最后一个字符</p></li><li><code>dt&quot;</code> → 删除所有的内容，直到遇到双引号</li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="https://blog.csdn.net/niushuai666/article/details/7275406">Vim简明教程【CoolShell】</a></p><p><a href="https://blog.csdn.net/lvdepeng123/article/details/79669874">ubuntu下vi/vim 的基本用法</a></p>]]></content>
    
    
    <categories>
      
      <category>【Other】</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Vim</tag>
      
      <tag>Ubuntu</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【课程】吴恩达机器学习课程(三)</title>
    <link href="/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_3/"/>
    <url>/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_3/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于吴恩达机器学习 - Machine Learning Specialization <a href="https://www.coursera.org/specializations/machine-learning-introduction">课程</a> 的笔记第三部分；非监督学习与推荐系统；</p></blockquote><span id="more"></span><h1 id="Course-3-Unsupervised-Learning-Recommenders-Reinforcement-Learning"><a href="#Course-3-Unsupervised-Learning-Recommenders-Reinforcement-Learning" class="headerlink" title="Course 3 : Unsupervised Learning, Recommenders, Reinforcement Learning"></a>Course 3 : Unsupervised Learning, Recommenders, Reinforcement Learning</h1><p>In the third course of the Machine Learning Specialization, you will:</p><ul><li>Use unsupervised learning techniques for unsupervised learning: including clustering and anomaly detection</li><li>Build recommender systems with a collaborative filtering approach and a content-based deep learning method</li><li>Build a deep reinforcement learning model.</li></ul><h2 id="Week-8-Unsupervised-Learning"><a href="#Week-8-Unsupervised-Learning" class="headerlink" title="Week 8 : Unsupervised Learning"></a>Week 8 : Unsupervised Learning</h2><h3 id="13-Clustering"><a href="#13-Clustering" class="headerlink" title="13. Clustering"></a>13. Clustering</h3><h4 id="13-1-Introduction"><a href="#13-1-Introduction" class="headerlink" title="13.1 Introduction"></a>13.1 Introduction</h4><p>在一个典型的监督学习中，我们有一个带标签的训练集，我们的目标是找到能够区分正样本和负样本的决策边界。与此不同的是，在非监督学习中，我们的数据没有附带任何标签，我们拿到的数据就是这样的：</p><p><img src="/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_3/pic13-1.jpg" alt></p><p>也就是说，在非监督学习中，我们需要将一系列无标签的训练数据，输入到一个算法中。我们可能需要某种算法帮助我们寻找一种结构。图上的数据看起来可以分成两个分开的点集（称为簇），一个能够找到特定点集的算法，就被称为聚类算法。</p><h4 id="13-2-Means-Algorithm"><a href="#13-2-Means-Algorithm" class="headerlink" title="13.2 Means Algorithm"></a>13.2 Means Algorithm</h4><p><strong>K-均值</strong> 是一个迭代算法，假设我们想要将数据聚类成 $K$ 个组，其方法为:</p><ol><li><p>首先随机选择$K$个随机的点，称为<strong>聚类中心</strong>（<strong>cluster centroids</strong>）</p></li><li><p>对于数据集中的每一个数据，按照距离$K$个中心点的距离，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类</p></li><li><p>计算每一个组的平均值</p></li><li>将该组所关联的中心点移动到平均值的位置</li><li>重复步骤2-4直至中心点不再变化。</li></ol><h5 id="【Python-代码】"><a href="#【Python-代码】" class="headerlink" title="【Python 代码】"></a>【Python 代码】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">random_init</span>(<span class="hljs-params">data, k</span>):<br>    <span class="hljs-keyword">return</span> data.sample(k).values<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">combine_data_C</span>(<span class="hljs-params">data, C</span>):<br>    data_with_c = data.copy()<br>    data_with_c[<span class="hljs-string">&#x27;C&#x27;</span>] = C<br>    <span class="hljs-keyword">return</span> data_with_c<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">nearst_cluster</span>(<span class="hljs-params">x, centroids</span>):<br>    distances = np.apply_along_axis(func1d=np.linalg.norm, axis=<span class="hljs-number">1</span>, arr=centroids - x)<br>    <span class="hljs-keyword">return</span> np.argmin(distances)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">assign_cluster</span>(<span class="hljs-params">data, centroids</span>):<br>    <span class="hljs-keyword">return</span> np.apply_along_axis(<span class="hljs-keyword">lambda</span> x: nearst_cluster(x, centroids), axis=<span class="hljs-number">1</span>, arr=data.values)<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">new_centroids</span>(<span class="hljs-params">data, C</span>):<br>    data_with_c = combine_data_C(data, C)<br>    <span class="hljs-keyword">return</span> data_with_c.groupby(<span class="hljs-string">&#x27;C&#x27;</span>, as_index=<span class="hljs-literal">False</span>).mean().sort_values(by=<span class="hljs-string">&#x27;C&#x27;</span>).drop(<span class="hljs-string">&#x27;C&#x27;</span>, axis=<span class="hljs-number">1</span>).values<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cost</span>(<span class="hljs-params">data, centroids, C</span>):<br>    m = data.shape[<span class="hljs-number">0</span>]<br>    data_belong_C = centroids[C]<br>    distances = np.apply_along_axis(func1d=np.linalg.norm, axis=<span class="hljs-number">1</span>, arr=data.values-data_belong_C)<br>    <span class="hljs-keyword">return</span> distances.<span class="hljs-built_in">sum</span>()/m<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">k_means_iter</span>(<span class="hljs-params">data, k, epoch=<span class="hljs-number">100</span>, tol=<span class="hljs-number">0.0001</span></span>):<br>    centroids=random_init(data, k)<br>    cost_epoch = []<br>    <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>        C = assign_cluster(data, centroids)<br>        centroids = new_centroids(data, C)<br>        cost_epoch.append(cost(data, centroids, C))<br>        <br>        <span class="hljs-keyword">if</span> i&gt;<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> np.<span class="hljs-built_in">abs</span>(cost_epoch[-<span class="hljs-number">1</span>] - cost_epoch[-<span class="hljs-number">2</span>]) / cost_epoch[-<span class="hljs-number">1</span>] &lt; tol:<br>            <span class="hljs-keyword">break</span>;<br>            <br>        <span class="hljs-keyword">return</span> C, centroids, cost_epoch[-<span class="hljs-number">1</span>]<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">k_means</span>(<span class="hljs-params">data, k, epoch=<span class="hljs-number">100</span>, n_init=<span class="hljs-number">10</span></span>):<br>    tries = np.array([k_means_iter(data, k, epoch) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_init)])<br>    least_cost_idx = np.argmin(tries[:, -<span class="hljs-number">1</span>])<br>    <br>    <span class="hljs-keyword">return</span> tries[least_cost_idx]<br></code></pre></td></tr></table></figure><h5 id="【Sklearn-Kmeans】"><a href="#【Sklearn-Kmeans】" class="headerlink" title="【Sklearn Kmeans】"></a>【Sklearn Kmeans】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> KMeans<br><br>sk_kmeans = KMeans(n_clusters=<span class="hljs-number">3</span>)<br>sk_kmeans.fit(data2)<br>sk_C = sk_kmeans.predict(data2)<br>data_with_C = combine_data_C(data2, sk_C)<br></code></pre></td></tr></table></figure><h4 id="13-3-Optimization-Objective"><a href="#13-3-Optimization-Objective" class="headerlink" title="13.3 Optimization Objective"></a>13.3 Optimization Objective</h4><p>K-均值最小化问题，是要最小化所有的数据点与其所关联的聚类中心点之间的距离之和，因此 K-均值的代价函数（又称<strong>畸变函数</strong> <strong>Distortion function</strong>）为：</p><script type="math/tex; mode=display">J(c^{(1)},...,c^{(m)},μ_1,...,μ_K)=\dfrac {1}{m}\sum^{m}_{i=1}\left\| X^{(i)}-\mu_{c^{(i)}}\right\| ^{2}</script><ul><li>$μ^1$,$μ^2$,…,$μ^k$ 表示聚类中心</li><li>$c^{(1)}$,$c^{(2)}$,…,$c^{(m)}$ 存储与第 $i$ 个实例数据最近的聚类中心的索引</li><li>$\mu_{c^{(i)}}$代表与$x^{(i)}$最近的聚类中心点</li></ul><h4 id="13-4-Random-Initialization"><a href="#13-4-Random-Initialization" class="headerlink" title="13.4 Random Initialization"></a>13.4 Random Initialization</h4><p><strong>K-均值</strong>的一个问题在于，它有可能会停留在一个局部最小值处，而这取决于初始化的情况。为了解决这个问题，我们通常需要多次运行<strong>K-均值</strong>算法，每一次都重新进行随机初始化，最后再比较多次运行<strong>K-均值</strong>的结果，选择代价函数最小的结果。</p><p>这种方法在$K$较小的时候（2 to 10）还是可行的，但是如果$K$较大，这么做也可能不会有明显地改善。</p><h4 id="13-5-Choosing-the-Number-of-Clusters"><a href="#13-5-Choosing-the-Number-of-Clusters" class="headerlink" title="13.5 Choosing the Number of Clusters"></a>13.5 Choosing the Number of Clusters</h4><p>没有所谓最好的选择聚类数的方法，通常是需要根据不同的问题，人工进行选择的。选择的时候思考我们运用<strong>K-均值</strong>算法聚类的动机是什么，然后选择能最好服务于该目的标聚类数。</p><p>当人们在讨论选择聚类数目的方法时，有一个可能会谈及的方法叫作“肘部法则”。关于“肘部法则”，我们所需要做的是改变$K$值，也就是聚类类别数目的总数，然后计算成本函数或者计算畸变函数$J$。随着聚类数目的变大，如果畸变函数下降的速度突然减缓时（在图上表现得像一个凸出的肘部），就应该选择变缓前的最后一个值作为数目。</p><h4 id="13-6-其他参考资料"><a href="#13-6-其他参考资料" class="headerlink" title="13.6 其他参考资料"></a>13.6 其他参考资料</h4><h5 id="1-相似度-距离计算方法总结"><a href="#1-相似度-距离计算方法总结" class="headerlink" title="1.相似度/距离计算方法总结"></a>1.相似度/距离计算方法总结</h5><ol><li><p>闵可夫斯基距离 <strong>Minkowski</strong>（其中欧式距离：$p=2$) :</p><script type="math/tex; mode=display">\operatorname{dist}(X, Y)=\left(\sum_{i=1}^{n}\left|x_{i}-y_{i}\right|^{p}\right)^{\frac{1}{p}}</script></li><li><p>杰卡德相似系数 <strong>Jaccard</strong>：</p><script type="math/tex; mode=display">J(A,B)=\frac{\left| A\cap B \right|}{\left|A\cup B \right|}</script></li><li><p>余弦相似度 <strong>cosine similarity</strong>：$n$维向量$x$和$y$的夹角记做$\theta$，根据余弦定理，其余弦值为：</p><script type="math/tex; mode=display">\cos (\theta)=\frac{x^{T} y}{|x| \cdot|y|}=\frac{\sum_{i=1}^{n} x_{i} y_{i}}{\sqrt{\sum_{i=1}^{n} x_{i}^{2}} \sqrt{\sum_{i=1}^{n} y_{i}^{2}}}</script></li><li><p><strong>Pearson</strong> 皮尔逊相关系数：</p><script type="math/tex; mode=display">\rho_{X Y}=\frac{\operatorname{cov}(X, Y)}{\sigma_{X} \sigma_{Y}}=\frac{E\left[\left(X-\mu_{X}\right)\left(Y-\mu_{Y}\right)\right]}{\sigma_{X} \sigma_{Y}}=\frac{\sum_{i=1}^{n}\left(x-\mu_{X}\right)\left(y-\mu_{Y}\right)}{\sqrt{\sum_{i=1}^{n}\left(x-\mu_{X}\right)^{2}} \sqrt{\sum_{i=1}^{n}\left(y-\mu_{Y}\right)^{2}}}</script><p>Pearson相关系数即将$x$、$y$坐标向量各自平移到原点后的夹角余弦。</p></li></ol><h5 id="2-聚类的衡量指标"><a href="#2-聚类的衡量指标" class="headerlink" title="2.聚类的衡量指标"></a>2.聚类的衡量指标</h5><ol><li><p>均一性：$p$</p><p>类似于精确率，一个簇中只包含一个类别的样本，则满足均一性。其实也可以认为就是正确率(每个聚簇中正确分类的样本数占该聚簇总样本数的比例和)</p></li><li><p>完整性：$r$</p><p>类似于召回率，同类别样本被归类到相同簇中，则满足完整性;每个聚簇中正确分类的样本数占该 类型的总样本数比例的和</p></li><li><p><strong>V-measure</strong>:</p><p>均一性和完整性的加权平均 </p><script type="math/tex; mode=display">V=\frac{\left(1+\beta^{2}\right) * p r}{\beta^{2} * p+r}</script></li><li><p>轮廓系数 : $s$</p><p>簇内不相似度: 计算样本$i$到同簇其它样本的平均距离为$a(i)$，应尽可能小。</p><p>簇间不相似度: 计算样本$i$到其它簇$C_j$的所有样本的平均距离$b_{ij}$，应尽可能大。</p><p>轮廓系数：$s(i)$值越接近1表示样本$i$聚类越合理，越接近-1，表示样本$i$应该分类到 另外的簇中，近似为0，表示样本$i$应该在边界上;所有样本的$s(i)$的均值被成为聚类结果的轮廓系数。 </p><script type="math/tex; mode=display">s(i) = \frac{b(i)-a(i)}{max\{a(i),b(i)\}}</script></li><li><p>调兰德指数 : <strong>ARI</strong> </p><p>$a_i$为实际上是 $i$ 这个组，并且聚类成了 $i$ 组的数量</p><p>$n_{ij}$为实际是 $i$ 组，被聚类成了 $j$ 组的数量</p><script type="math/tex; mode=display">A R I=\frac{\sum_{i j}\left(\begin{array}{c}n_{i j} \\ 2\end{array}\right)-\left[\sum_{i}\left(\begin{array}{c}a_{i} \\ 2\end{array}\right) \sum_{j}\left(\begin{array}{c}b_{j} \\ 2\end{array}\right)\right] /\left(\begin{array}{c}n \\ 2\end{array}\right)}{\frac{1}{2}\left[\sum_{i}\left(\begin{array}{c}a_{i} \\ 2\end{array}\right)+\sum_{j}\left(\begin{array}{c}b_{j} \\ 2\end{array}\right)\right]-\left[\sum_{i}\left(\begin{array}{c}a_{i} \\ 2\end{array}\right) \sum_{j}\left(\begin{array}{c}b_{j} \\ 2\end{array}\right)\right] /\left(\begin{array}{c}n \\ 2\end{array}\right)}</script></li></ol><h4 id="13-7-K-means-in-Image-Compression"><a href="#13-7-K-means-in-Image-Compression" class="headerlink" title="13.7 K-means in Image Compression"></a>13.7 K-means in Image Compression</h4><p><img src="/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_3/pic13-2.png" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> skimage <span class="hljs-keyword">import</span> io<br><br>pic = io.imread(<span class="hljs-string">&#x27;./pic13-2.png&#x27;</span>) / <span class="hljs-number">255</span><br>io.imshow(pic) <span class="hljs-comment"># (128, 128, 3)</span><br>data = pic.reshape(<span class="hljs-number">128</span>*<span class="hljs-number">128</span>, <span class="hljs-number">3</span>)<br><br>C, centroids, cost_ = k_means(pd.DataFrame(data), <span class="hljs-number">16</span>, epoch=<span class="hljs-number">10</span>, n_init=<span class="hljs-number">3</span>)<br>compressed_pic = centroids[C].reshape((<span class="hljs-number">128</span>,<span class="hljs-number">128</span>,<span class="hljs-number">3</span>))<br>fig, ax = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>ax[<span class="hljs-number">0</span>].imshow(pic)<br>ax[<span class="hljs-number">1</span>].imshow(compressed_pic)<br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_3/pic13-3.jpg" alt></p><h5 id="【Sklearn-Kmeans】-1"><a href="#【Sklearn-Kmeans】-1" class="headerlink" title="【Sklearn Kmeans】"></a>【Sklearn Kmeans】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> KMeans<br><br>model = KMeans(n_clusters=<span class="hljs-number">16</span>, n_init=<span class="hljs-number">100</span>, n_jobs=-<span class="hljs-number">1</span>)<br>model.fit(data)<br>centroids = model.cluster_centers_<br>C = model.predict(data)<br>compressed_pic = centroids[C].reshape((<span class="hljs-number">128</span>,<span class="hljs-number">128</span>,<span class="hljs-number">3</span>))<br>fig, ax = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>ax[<span class="hljs-number">0</span>].imshow(pic)<br>ax[<span class="hljs-number">1</span>].imshow(compressed_pic)<br>plt.show()<br></code></pre></td></tr></table></figure><h3 id="14-Dimensionality-Reduction"><a href="#14-Dimensionality-Reduction" class="headerlink" title="14. Dimensionality Reduction"></a>14. Dimensionality Reduction</h3><h4 id="14-1-Motivation"><a href="#14-1-Motivation" class="headerlink" title="14.1 Motivation"></a>14.1 Motivation</h4><p>有几个不同的原因使我们可能需要做降维。一是数据压缩，它让我们加快我们的学习算法。二是数据可视化，在许多及其学习问题中，如果我们能将数据可视化，我们便能寻找到一个更好的解决方案，降维可以帮助我们。</p><h4 id="14-2-Principal-Component-Analysis-Problem-Formulation"><a href="#14-2-Principal-Component-Analysis-Problem-Formulation" class="headerlink" title="14.2 Principal Component Analysis Problem Formulation"></a>14.2 Principal Component Analysis Problem Formulation</h4><p>主成分分析(<strong>PCA</strong>)是最常见的降维算法。在<strong>PCA</strong>中，我们要做的是找到一个方向向量（<strong>Vector direction</strong>），当我们把所有的数据都投射到该向量上时，我们希望投射平均均方误差能尽可能地小。方向向量是一个经过原点的向量，而投射误差是从特征向量向该方向向量作垂线的长度。</p><p>主成分分析与线性回归是两种不同的算法。主成分分析最小化的是垂直到向量方向的<strong>投射</strong>误差（<strong>Projected Error</strong>），而线性回归尝试的是最小化 竖直方向的<strong>预测</strong>误差。线性回归的目的是预测结果，而主成分分析不作任何预测。</p><p><strong>PCA</strong>技术的一大好处是对数据进行降维的处理。我们可以对新求出的“主元”向量的重要性进行排序，根据需要取前面最重要的部分，将后面的维数省去，可以达到降维从而简化模型或是对数据进行压缩的效果。同时最大程度的保持了原有数据的信息。</p><p><strong>PCA</strong>技术的一个很大的优点是，它是完全无参数限制的。在<strong>PCA</strong>的计算过程中完全不需要人为的设定参数或是根据任何经验模型对计算进行干预，最后的结果只与数据相关，与用户是独立的。</p><p>但是，这一点同时也可以看作是缺点。如果用户对观测对象有一定的先验知识，掌握了数据的一些特征，却无法通过参数化等方法对处理过程进行干预，可能会得不到预期的效果，效率也不高。</p><h4 id="14-3-Principal-Component-Analysis-Algorithm"><a href="#14-3-Principal-Component-Analysis-Algorithm" class="headerlink" title="14.3 Principal Component Analysis Algorithm"></a>14.3 Principal Component Analysis Algorithm</h4><p><strong>PCA</strong> 从$n$维减少到$k$维的例子：</p><ul><li><p>第一步是均值归一化。我们需要计算出特征的均值，然后令 $x_j= x_j-μ_j$。如果特征是在不同的数量级上，我们还需要将其除以标准差 $σ^2$。</p></li><li><p>第二步是计算<strong>协方差矩阵</strong>（<strong>covariance matrix</strong>）$Σ$：</p><script type="math/tex; mode=display">\sum=\dfrac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}</script></li><li><p>第三步是计算协方差矩阵$Σ$的<strong>特征向量</strong>（<strong>eigenvectors</strong>）$U$。如果我们希望将数据从$n$维降至$k$维，我们只需要从$U$中选取前$k$个向量，获得一个$n×k$维度的矩阵，我们用$U_{reduce}$表示，然后通过如下计算获得要求的新特征向量$z^{(i)}$:</p><script type="math/tex; mode=display">z^{(i)}=U^{T}_{reduce}*x^{(i)}</script><p>其中$x$是$n×1$维的，因此结果为$k×1$维度。</p></li></ul><h4 id="14-4-Choosing-The-Number-Of-Principal-Components"><a href="#14-4-Choosing-The-Number-Of-Principal-Components" class="headerlink" title="14.4 Choosing The Number Of Principal Components"></a>14.4 Choosing The Number Of Principal Components</h4><p>我们希望在平均均方误差与训练集方差的比例尽可能小的情况下选择尽可能小的$k$值。</p><p>如果我们希望这个比例小于1%，就意味着原本数据的偏差有99%都保留下来了，如果我们选择保留95%的偏差，便能非常显著地降低模型中特征的维度了。</p><p>我们可以先令$k=1$，然后进行主要成分分析，获得$U_{reduce}$和$z$，然后计算比例是否小于1%。如果不是的话再令$k=2$，如此类推，直到找到可以使得比例小于1%的最小$k$ 值</p><p>在求<strong>svd奇异值分解</strong>时我们有式子</p><script type="math/tex; mode=display">\Sigma=USV^{T}</script><blockquote><p>其中 $UU^T=I$，更多相关见 <a href="https://blog.csdn.net/qq_42722197/article/details/120858115">连接</a></p></blockquote><p>其中的$S$是一个$n×n$的矩阵，只有对角线上有值，而其它单元都是0，我们可以使用这个矩阵来计算平均均方误差与训练集方差的比例：</p><script type="math/tex; mode=display">\dfrac {\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{\left( i\right) }-x^{\left( i\right) }_{approx}\right\| ^{2}}{\dfrac {1}{m}\sum^{m}_{i=1}\left\| x^{(i)}\right\| ^{2}}=1-\dfrac {\Sigma^{k}_{i=1}S_{ii}}{\Sigma^{m}_{i=1}S_{ii}}\leq 1\%</script><p>在压缩过数据后，我们可以采用如下方法来近似地获得原有的特征：<script type="math/tex">x^{\left( i\right) }_{approx}=U_{reduce}z^{(i)}</script></p><h5 id="【Python-代码】-1"><a href="#【Python-代码】-1" class="headerlink" title="【Python 代码】"></a>【Python 代码】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">covariance_matrix</span>(<span class="hljs-params">X</span>):<br>    m = X.shape[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">return</span> (X.T @ X) / m<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">PCA</span>(<span class="hljs-params">X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        X ndarray(m, n)</span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">        U ndarray(n, n): principle components</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <br>    X_norm = normalize(X)<br>    Sigma = covariance_matrix(X_norm)<br>    U, S, V = np.linalg.svd(Sigma)<br>    <br>    <span class="hljs-keyword">return</span> U, S, V<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">project_data</span>(<span class="hljs-params">X, U, k</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    projected n dim to k dim</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    m, n = X.shape<br>    <span class="hljs-keyword">if</span> k &gt; n:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;k should be lower dimension of n&#x27;</span>)<br>    <br>    <span class="hljs-keyword">return</span> X @ U[:, :k]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">recover_data</span>(<span class="hljs-params">Z, U</span>):<br>    m, n = Z.shape<br>    <span class="hljs-keyword">if</span> n &gt;= U.shape[<span class="hljs-number">0</span>]:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;Z dimension is upper than U, you should recover lower dimension to higher&#x27;</span>)<br>    <br>    <span class="hljs-keyword">return</span> Z @ U[:, :n].T<br><br><span class="hljs-comment"># 画投影</span><br>fig, (ax1, ax2, ax3) = plt.subplots(ncols=<span class="hljs-number">3</span>, figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">4</span>))<br>sns.rugplot(Z, ax=ax1)<br>ax1.set_title(<span class="hljs-string">&#x27;project dimension&#x27;</span>)<br>ax1.set_xlabel(<span class="hljs-string">&#x27;Z&#x27;</span>)<br><br>sns.regplot(<span class="hljs-string">&#x27;X1&#x27;</span>, <span class="hljs-string">&#x27;X2&#x27;</span>, data=pd.DataFrame(X_recover, columns=[<span class="hljs-string">&#x27;X1&#x27;</span>, <span class="hljs-string">&#x27;X2&#x27;</span>]),<br>           fit_reg=<span class="hljs-literal">False</span>, ax=ax2)<br>ax2.set_title(<span class="hljs-string">&#x27;2D projection from Z&#x27;</span>)<br><br>sns.regplot(<span class="hljs-string">&#x27;X1&#x27;</span>, <span class="hljs-string">&#x27;X2&#x27;</span>, data=pd.DataFrame(X_norm, columns=[<span class="hljs-string">&#x27;X1&#x27;</span>, <span class="hljs-string">&#x27;X2&#x27;</span>]),<br>           fit_reg=<span class="hljs-literal">False</span>, ax=ax3)<br>ax3.set_title(<span class="hljs-string">&#x27;Original dimension&#x27;</span>)<br><br>ax.plot([X_recover[:,<span class="hljs-number">0</span>], X_norm[:,<span class="hljs-number">0</span>]], [X_recover[:,<span class="hljs-number">1</span>], X_norm[:,<span class="hljs-number">1</span>]], <span class="hljs-string">&#x27;--&#x27;</span>)<br></code></pre></td></tr></table></figure><h5 id="【Sklearn-Kmeans】-2"><a href="#【Sklearn-Kmeans】-2" class="headerlink" title="【Sklearn Kmeans】"></a>【Sklearn Kmeans】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA <span class="hljs-keyword">as</span> sk_PCA<br><br>pca = sk_PCA(n_components=<span class="hljs-number">100</span>)<br>Z = pca.fit_transform(X)<br></code></pre></td></tr></table></figure><h4 id="14-5-Advice-for-Applying-PCA"><a href="#14-5-Advice-for-Applying-PCA" class="headerlink" title="14.5 Advice for Applying PCA"></a>14.5 Advice for Applying PCA</h4><p>一个常见错误使用主要成分分析的情况是，将其用于减少过拟合（减少了特征的数量）。这样做非常不好，不如尝试正则化处理。原因在于主要成分分析只是近似地丢弃掉一些特征，它并不考虑任何与结果变量有关的信息。因此如果你在监督学习中采用PCA可能会丢失非常重要的性质。然而当我们进行正则化处理时，会考虑到结果变量，不会丢掉重要的数据。</p><p>另一个常见的错误是，默认地将主要成分分析作为学习过程中的一部分，这虽然很多时候有效果，最好还是从所有原始特征开始，只在有必要的时候（算法运行太慢或者占用太多内存）才考虑采用主要成分分析。</p><h2 id="Week-9-Anomaly-Detection"><a href="#Week-9-Anomaly-Detection" class="headerlink" title="Week 9 : Anomaly Detection"></a>Week 9 : Anomaly Detection</h2><h3 id="15-Anomaly-Detection"><a href="#15-Anomaly-Detection" class="headerlink" title="15. Anomaly Detection"></a>15. Anomaly Detection</h3><h4 id="15-1-Problem-Motivation"><a href="#15-1-Problem-Motivation" class="headerlink" title="15.1 Problem Motivation"></a>15.1 Problem Motivation</h4><p>所谓的异常检测问题就是：我们希望知道这个新的数据是否有某种异常，它是否符合我们模型应该得到的结果。</p><p>我们所构建的模型应该能根据该测试数据的位置告诉我们其属于一组数据的可能性 $p(x)$。</p><p>这种方法称为密度估计，表达如下：</p><script type="math/tex; mode=display">if \quad p(x)\begin{cases}< \varepsilon & anomaly \\> =\varepsilon & normal\end{cases}</script><h4 id="15-2-Gaussian-Distribution"><a href="#15-2-Gaussian-Distribution" class="headerlink" title="15.2 Gaussian Distribution"></a>15.2 Gaussian Distribution</h4><p>回顾高斯分布的基本知识。</p><p>通常如果我们认为变量 $x$ 符合高斯分布 $x \sim N(\mu, \sigma^2)$则其概率密度函数为：</p><script type="math/tex; mode=display">p(x,\mu,\sigma^2)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)</script><p>我们可以利用已有的数据来预测总体中的$μ$和$σ^2$的计算方法如下：</p><script type="math/tex; mode=display">\mu=\frac{1}{m}\sum\limits_{i=1}^{m}x^{(i)}</script><script type="math/tex; mode=display">\sigma^2=\frac{1}{m}\sum\limits_{i=1}^{m}(x^{(i)}-\mu)^2</script><blockquote><p> 机器学习中对于方差我们通常只除以$m$而非统计学中的$(m-1)$</p></blockquote><h4 id="15-3-Algorithm"><a href="#15-3-Algorithm" class="headerlink" title="15.3 Algorithm"></a>15.3 Algorithm</h4><p>一旦我们获得了平均值和方差的估计值，给定新的一个训练实例，根据模型计算 $p(x)$：</p><script type="math/tex; mode=display">p(x)=\prod\limits_{j=1}^np(x_j;\mu_j,\sigma_j^2)=\prod\limits_{j=1}^1\frac{1}{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})</script><p>当$p(x) &lt; \varepsilon$时，为异常。</p><h5 id="【Python-代码】-2"><a href="#【Python-代码】-2" class="headerlink" title="【Python 代码】"></a>【Python 代码】</h5><p>单变量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">mu = X.mean(axis=<span class="hljs-number">0</span>)<br>sigma2 = ((X - mu)**<span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>) / X.shape[<span class="hljs-number">0</span>]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pdf</span>(<span class="hljs-params">x, mu, sigma2</span>):<br>    m, n = x[<span class="hljs-number">0</span>].shape<br>    ret = <span class="hljs-number">1</span> / np.power(<span class="hljs-number">2</span>*np.pi*sigma2, n/<span class="hljs-number">2</span>) * np.exp(-(x-mu)*(x-mu) / (<span class="hljs-number">2</span>*sigma2))<br>    ret = ret.prod(axis=<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span>  ret<br><br><span class="hljs-comment"># 画等高线</span><br>x, y = np.mgrid[<span class="hljs-number">0</span>:<span class="hljs-number">30</span>:<span class="hljs-number">0.01</span>, <span class="hljs-number">0</span>:<span class="hljs-number">30</span>:<span class="hljs-number">0.01</span>]<br>pos = np.dstack((x, y))<br>fig, ax = plt.subplots(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>))<br>ax.contourf(x, y, pdf(pos, mu, sigma2), cmap=<span class="hljs-string">&#x27;Blues&#x27;</span>)<br>ax.contour(x, y, pdf(pos, mu, sigma2), colors=<span class="hljs-string">&#x27;black&#x27;</span>)<br>ax.scatter(X[:, <span class="hljs-number">0</span>], X[:, <span class="hljs-number">1</span>])<br><br>plt.show()<br></code></pre></td></tr></table></figure><h4 id="15-4-Developing-and-Evaluating-an-Anomaly-Detection-System"><a href="#15-4-Developing-and-Evaluating-an-Anomaly-Detection-System" class="headerlink" title="15.4 Developing and Evaluating an Anomaly Detection System"></a>15.4 Developing and Evaluating an Anomaly Detection System</h4><p>异常检测算法是一个非监督学习算法，意味着我们无法根据结果变量 $ y$ 的值来告诉我们数据是否真的是异常的。我们需要另一种方法来帮助检验算法是否有效。当我们开发一个异常检测系统时，我们从带标记（异常或正常）的数据着手，我们从其中选择一部分正常数据用于构建训练集，然后用剩下的正常数据和异常数据混合的数据构成交叉检验集和测试集。</p><p>例如：我们有10000台正常引擎的数据，有20台异常引擎的数据。 我们这样分配数据：</p><p>6000台正常引擎的数据作为训练集</p><p>2000台正常引擎和10台异常引擎的数据作为交叉检验集</p><p>2000台正常引擎和10台异常引擎的数据作为测试集</p><p>具体的评价方法如下：</p><ol><li>根据测试集数据，我们估计特征的平均值和方差并构建$p(x)$函数</li><li>对交叉检验集，我们尝试使用不同的$\varepsilon$值作为阀值，并预测数据是否异常，根据$F1$值或者查准率与查全率的比例来选择 $\varepsilon$</li><li>选出 $\varepsilon$ 后，针对测试集进行预测，计算异常检验系统的$F1$值，或者查准率与查全率之比</li></ol><h4 id="15-5-Anomaly-Detection-vs-Supervised-Learning"><a href="#15-5-Anomaly-Detection-vs-Supervised-Learning" class="headerlink" title="15.5 Anomaly Detection vs. Supervised Learning"></a>15.5 Anomaly Detection vs. Supervised Learning</h4><p>之前我们构建的异常检测系统也使用了带标记的数据，与监督学习有些相似，下面的对比有助于选择采用监督学习还是异常检测：</p><p>两者比较：</p><div class="table-container"><table><thead><tr><th>异常检测</th><th>监督学习</th></tr></thead><tbody><tr><td>非常少量的正向类（异常数据 $y=1$）, 大量的负向类（$y=0$）</td><td>同时有大量的正向类和负向类</td></tr><tr><td>根据非常少量的正向类数据来训练算法。</td><td>有足够多的正向类实例，足够用于训练算法。</td></tr><tr><td>未来遇到的异常可能与已掌握的异常、非常的不同。</td><td>未来遇到的正向类实例可能与训练集中的非常近似。</td></tr><tr><td>例如： 欺诈行为检测 生产（例如飞机引擎）检测数据中心的计算机运行状况</td><td>例如：邮件过滤器 天气预报 肿瘤分类</td></tr></tbody></table></div><h4 id="15-6-Choosing-What-Features-to-Use"><a href="#15-6-Choosing-What-Features-to-Use" class="headerlink" title="15.6 Choosing What Features to Use"></a>15.6 Choosing What Features to Use</h4><p>异常检测假设特征符合高斯分布，如果数据的分布不是高斯分布，异常检测算法也能够工作，但是最好还是将数据转换成高斯分布，例如使用对数函数：$x= log(x+c)$，其中 $c$ 为非负常数； 或者 $x=x^c$，$c$为 0-1 之间的一个分数，等方法。</p><p>一个常见的问题是一些异常的数据可能也会有较高的$p(x)$值，因而被算法认为是正常的。这种情况下误差分析能够帮助我们，我们可以分析那些被算法错误预测为正常的数据，观察能否找出一些问题。我们可能能从问题中发现我们需要增加一些新的特征，增加这些新特征后获得的新算法能够帮助我们更好地进行异常检测。</p><h4 id="15-7-Multivariate-Gaussian-Distribution"><a href="#15-7-Multivariate-Gaussian-Distribution" class="headerlink" title="15.7 Multivariate Gaussian Distribution"></a>15.7 Multivariate Gaussian Distribution</h4><p>在多元高斯分布模型中，我们将构建特征的协方差矩阵，用所有的特征一起来计算 $p(x)$。</p><p>我们首先计算所有特征的平均值，然后再计算协方差矩阵：</p><script type="math/tex; mode=display">\mu=\frac{1}{m}\sum_{i=1}^mx^{(i)}</script><script type="math/tex; mode=display">\Sigma = \frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu)(x^{(i)}-\mu)^T=\frac{1}{m}(X-\mu)^T(X-\mu)</script><p>注:其中$\mu $ 是一个向量，其每一个单元都是原特征矩阵中一行数据的均值。最后我们计算多元高斯分布的$p\left( x \right)$:</p><script type="math/tex; mode=display">p(x)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}exp\left(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\right)</script><p>原高斯分布模型和多元高斯分布模型的比较：</p><div class="table-container"><table><thead><tr><th>原高斯分布模型</th><th>多元高斯分布模型</th></tr></thead><tbody><tr><td>不能捕捉特征之间的相关性 但可以通过将特征进行组合的方法来解决</td><td>自动捕捉特征之间的相关性</td></tr><tr><td>计算代价低，能适应大规模的特征</td><td>计算代价较高 训练集较小时也同样适用</td></tr><tr><td></td><td>必须要有 $m&gt;n$，不然的话协方差矩阵$\Sigma$不可逆的，通常需要 $m&gt;10n$ 另外特征冗余也会导致协方差矩阵不可逆</td></tr></tbody></table></div><p>原高斯分布模型被广泛使用着，如果特征之间在某种程度上存在相互关联的情况，我们可以通过构造新新特征的方法来捕捉这些相关性。</p><p>如果训练集不是太大，并且没有太多的特征，我们可以使用多元高斯分布模型。</p><h5 id="【Python-代码】-3"><a href="#【Python-代码】-3" class="headerlink" title="【Python 代码】"></a>【Python 代码】</h5><p>多变量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> stats<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> f1_score, classification_report<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">select_threshold</span>(<span class="hljs-params">X, Xval, yval</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    use CV data to find the best epsilon</span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">        e: best epslion with the highest F-score</span><br><span class="hljs-string">        f-score</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># create multivariate model using traing data</span><br>    mu = X.mean(axis=<span class="hljs-number">0</span>)<br>    cov = np.cov(X.T)<br>    multi_normal = stats.multivariate_normal(mu, cov)<br>    <br>    pval = multi_normal.pdf(Xval)<br>    epsilon = np.linspace(np.<span class="hljs-built_in">min</span>(pval), np.<span class="hljs-built_in">max</span>(pval), num=<span class="hljs-number">10000</span>)<br>    <br>    fs = []<br>    <span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> epsilon:<br>        y_pred = (pval &lt;= e).astype(<span class="hljs-string">&#x27;int&#x27;</span>)<br>        fs.append(f1_score(yval, y_pred))<br>        <br>    argmax_fs = np.argmax(fs)<br>    <br>    <span class="hljs-keyword">return</span> epsilon[argmax_fs], fs[argmax_fs]   <br><br>e, fs = select_threshold(X, Xval, yval)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Best epsilon: &#123;&#125;\nBest F-score on validation data: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(e, fs))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span> (X, Xval, e, Xtest, ytest):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">        multi_normal: multivariate normal model</span><br><span class="hljs-string">        y_pred: prediction of test data</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <br>    Xdata = np.concatenate((X, Xval), axis=<span class="hljs-number">0</span>)<br>    mu = Xdata.mean(axis=<span class="hljs-number">0</span>)<br>    cov = np.cov(Xdata.T)<br>    multi_normal = stats.multivariate_normal(mu, cov)<br>    <br>    pval = multi_normal.pdf(Xtest)<br>    y_pred = (pval &lt;= e).astype(<span class="hljs-string">&#x27;int&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(classification_report(ytest, y_pred))<br>    <br>    <span class="hljs-keyword">return</span> multi_normal, y_pred<br><br>data = pd.DataFrame(Xtest, columns=[<span class="hljs-string">&#x27;Latency&#x27;</span>, <span class="hljs-string">&#x27;Throughput&#x27;</span>])<br>data[<span class="hljs-string">&#x27;y_pred&#x27;</span>] = y_pred<br><br>fig, ax = plt.subplots(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>))<br>ax.contourf(x, y, multi_normal.pdf(pos), cmap=<span class="hljs-string">&#x27;Blues&#x27;</span>)<br>ax.contour(x, y, multi_normal.pdf(pos), colors=<span class="hljs-string">&#x27;black&#x27;</span>)<br>ax.scatter(Xtest[:, <span class="hljs-number">0</span>], Xtest[:, <span class="hljs-number">1</span>], c=<span class="hljs-string">&#x27;b&#x27;</span>, s=<span class="hljs-number">10</span>)<br><br>anamoly_data = data[data[<span class="hljs-string">&#x27;y_pred&#x27;</span>] == <span class="hljs-number">1</span>]<br>ax.scatter(anamoly_data[<span class="hljs-string">&#x27;Latency&#x27;</span>], anamoly_data[<span class="hljs-string">&#x27;Throughput&#x27;</span>], marker=<span class="hljs-string">&#x27;x&#x27;</span>, s=<span class="hljs-number">50</span>)<br><br>plt.show()<br></code></pre></td></tr></table></figure><blockquote><p>from sklearn.model_selection import train_test_split 自动分成两部分</p></blockquote><h3 id="16-Recommender-Systems"><a href="#16-Recommender-Systems" class="headerlink" title="16. Recommender Systems"></a>16. Recommender Systems</h3><p>此部分在 <a href="https://achlier.github.io/2022/03/08/Recommender-System_Classical-RS/">Recommender System:Classical RS</a> 有更详细的笔记，在此忽略。</p><h2 id="Week-10-Large-Scale-Machine-Learning"><a href="#Week-10-Large-Scale-Machine-Learning" class="headerlink" title="Week 10 : Large Scale Machine Learning"></a>Week 10 : Large Scale Machine Learning</h2><h3 id="17-Gradient-Descent-with-Large-Database"><a href="#17-Gradient-Descent-with-Large-Database" class="headerlink" title="17. Gradient Descent with Large Database"></a>17. Gradient Descent with Large Database</h3><h4 id="17-1-Stochastic-Gradient-Descent"><a href="#17-1-Stochastic-Gradient-Descent" class="headerlink" title="17.1 Stochastic Gradient Descent"></a>17.1 Stochastic Gradient Descent</h4><p>如果我们一定需要一个大规模的训练集，我们可以尝试使用随机梯度下降法来代替批量梯度下降法。</p><p>在随机梯度下降法中，我们定义代价函数为一个单一训练实例的代价：</p><script type="math/tex; mode=display">\operatorname{cost}\left(\theta,\left(x^{(i)}, y^{(i)}\right)\right)=\frac{1}{2}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}</script><p><strong>随机</strong>梯度下降算法为：首先对训练集随机“洗牌”，然后：</p><p> <strong>Repeat</strong> (usually anywhere between1-10){</p><p>  <strong>for</strong> $i = 1:m${</p><p>​        $\theta:=\theta_{j}-\alpha\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}$      </p><p>​        (<strong>for</strong> $j=0:n$)</p><p> ​    }<br> }</p><p>随机梯度下降算法在每一次计算之后便更新参数 $\theta $ ，而不需要首先将所有的训练集求和，在梯度下降算法还没有完成一次迭代时，随机梯度下降算法便已经走出了很远。但是这样的算法存在的问题是，不是每一步都是朝着”正确”的方向迈出的。因此算法虽然会逐渐走向全局最小值的位置，但是可能无法站到那个最小值的那一点，而是在最小值点附近徘徊。</p><h4 id="17-2-Mini-Batch-Gradient-Descent"><a href="#17-2-Mini-Batch-Gradient-Descent" class="headerlink" title="17.2 Mini-Batch Gradient Descent"></a>17.2 Mini-Batch Gradient Descent</h4><p>小批量梯度下降算法是介于批量梯度下降算法和随机梯度下降算法之间的算法，每计算常数$b$次训练实例，便更新一次参数  $\theta $ 。</p><p> <strong>Repeat</strong> {</p><p> <strong>for</strong> $i = 1:m${</p><p>​        $\theta:=\theta_{j}-\alpha \frac{1}{b} \sum_{k=i}^{i+b-1}\left(h_{\theta}\left(x^{(k)}\right)-y^{(k)}\right) x_{j}^{(k)}$      </p><p>​       (<strong>for</strong> $j=0:n$)</p><p>​      $ i +=10 $   </p><p> ​     }<br> }</p><p>通常我们会令 $b$ 在 2-100 之间。这样做的好处在于，我们可以用向量化的方式来循环 $b$个训练实例，如果我们用的线性代数函数库比较好，能够支持平行处理，那么算法的总体表现将不受影响（与随机梯度下降相同）。</p><h4 id="17-3-Stochastic-Gradient-Descent-Convergence"><a href="#17-3-Stochastic-Gradient-Descent-Convergence" class="headerlink" title="17.3 Stochastic Gradient Descent Convergence"></a>17.3 Stochastic Gradient Descent Convergence</h4><p>在随机梯度下降中，我们在每一次更新 $\theta $ <strong>之前</strong>都计算一次代价，然后每$x$次迭代后，求出这$x$次对训练实例计算代价的平均值，然后绘制这些平均值与$x$次迭代的次数之间的函数图表。</p><p>当我们绘制图表时，可能会得到一个颠簸不平但是不会明显减少的函数图像。我们可以增加$\alpha$来使得函数更加平缓，也许便能看出下降的趋势了；对于函数图表仍然是颠簸不平且不下降的，那么我们的模型本身可能存在一些错误。</p><p>如果我们得到的曲线不断地上升，那么我们可能会需要选择一个较小的学习率$\alpha$。我们也可以令学习率随着迭代次数的增加而减小，例如令：</p><script type="math/tex; mode=display">\alpha=\frac{\text { const } 1}{\text { IterationNumber }+\text { const } 2}</script><h4 id="17-4-Online-Learning"><a href="#17-4-Online-Learning" class="headerlink" title="17.4 Online Learning"></a>17.4 Online Learning</h4><p>今天，许多大型网站或者许多大型网络公司，使用不同版本的在线学习机制算法，从大批的涌入又离开网站的用户身上进行学习。特别要提及的是，如果有一个由连续的用户流引发的连续的数据流进入你的网站，你能做的是使用一个在线学习机制，从数据流中学习用户的偏好，然后使用这些信息来优化一些关于网站的决策。在线学习算法指的是对数据流而非离线的静态数据集的学习。许多在线网站都有持续不断的用户流，对于每一个用户，网站希望能在不将数据存储到数据库中便顺利地进行算法学习。</p><p>在线学习的算法与随机梯度下降算法有些类似，我们对单一的实例进行学习，而非对一个提前定义的训练集进行循环。一旦对一个数据的学习完成了，我们便可以丢弃该数据，不需要再存储它了。这种方式的好处在于，我们的算法可以很好的适应用户的倾向性，算法可以针对用户的当前行为不断地更新模型以适应该用户。每次交互事件并不只产生一个数据集，例如，我们一次给用户提供3个物流选项，用户选择2项，我们实际上可以获得3个新的训练实例，因而我们的算法可以一次从3个实例中学习并更新模型。</p><h4 id="17-5-Map-Reduce-and-Data-Parallelism"><a href="#17-5-Map-Reduce-and-Data-Parallelism" class="headerlink" title="17.5 Map Reduce and Data Parallelism"></a>17.5 Map Reduce and Data Parallelism</h4><p>映射化简和数据并行对于大规模机器学习问题而言是非常重要的概念。之前提到，如果我们用批量梯度下降算法来求解大规模数据集的最优解，我们需要对整个训练集进行循环，计算偏导数和代价，再求和，计算代价非常大。如果我们能够将我们的数据集分配给不多台计算机，让每一台计算机处理数据集的一个子集，然后我们将计所的结果汇总在求和。这样的方法叫做映射简化。</p><p>具体而言，如果任何学习算法能够表达为，对训练集的函数的求和，那么便能将这个任务分配给多台计算机（或者同一台计算机的不同<strong>CPU</strong> 核心），以达到加速处理的目的。</p><h2 id="Week-11-Application-Example-Photo-OCR"><a href="#Week-11-Application-Example-Photo-OCR" class="headerlink" title="Week 11 : Application Example : Photo OCR"></a>Week 11 : Application Example : Photo OCR</h2><h3 id="18-Photo-OCR"><a href="#18-Photo-OCR" class="headerlink" title="18. Photo OCR"></a>18. Photo OCR</h3><h4 id="18-1-Problem-Description-and-Pipeline"><a href="#18-1-Problem-Description-and-Pipeline" class="headerlink" title="18.1 Problem Description and Pipeline"></a>18.1 Problem Description and Pipeline</h4><p>图像文字识别应用所作的事是，从一张给定的图片中识别文字。这比从一份扫描文档中识别文字要复杂的多。</p><p>为了完成这样的工作，需要采取如下步骤：</p><ol><li><p>文字侦测（<strong>Text detection</strong>）——将图片上的文字与其他环境对象分离开来</p></li><li><p>字符切分（<strong>Character segmentation</strong>）——将文字分割成一个个单一的字符</p></li><li><p>字符分类（<strong>Character classification</strong>）——确定每一个字符是什么</p></li></ol><h4 id="18-2-Sliding-Windows"><a href="#18-2-Sliding-Windows" class="headerlink" title="18.2 Sliding Windows"></a>18.2 Sliding Windows</h4><p>滑动窗口是一项用来从图像中抽取对象的技术。假使我们需要在一张图片中识别行人，首先要做的是用许多固定尺寸的图片来训练一个能够准确识别行人的模型。然后我们用之前训练识别行人的模型时所采用的图片尺寸在我们要进行行人识别的图片上进行剪裁，然后将剪裁得到的切片交给模型，让模型判断是否为行人，然后在图片上滑动剪裁区域重新进行剪裁，将新剪裁的切片也交给模型进行判断，如此循环直至将图片全部检测完。然后，我们按比例放大剪裁的区域，以新的尺寸对图片进行剪裁，将新剪裁的切片按比例缩小至模型所采纳的尺寸，交给模型进行判断，如此循环。</p><p>滑动窗口技术也被用于文字识别，首先训练模型能够区分字符与非字符，然后，运用滑动窗口技术识别字符，一旦完成了字符的识别，我们将识别得出的区域进行一些扩展，然后将重叠的区域进行合并。接着我们以宽高比作为过滤条件，过滤掉高度比宽度更大的区域（认为单词的长度通常比高度要大）。</p><p>最后一个阶段是字符分类阶段，利用神经网络、支持向量机或者逻辑回归算法训练一个分类器即可。</p><h4 id="18-3-Getting-Lots-of-Data-and-Artificial-Data"><a href="#18-3-Getting-Lots-of-Data-and-Artificial-Data" class="headerlink" title="18.3 Getting Lots of Data and Artificial Data"></a>18.3 Getting Lots of Data and Artificial Data</h4><p>如果我们的模型是低方差的，那么获得更多的数据用于训练模型，是能够有更好的效果的。问题在于，我们怎样获得数据，数据不总是可以直接获得的，我们有可能需要人工地创造一些数据。</p><p>以我们的文字识别应用为例，我们可以字体网站下载各种字体，然后利用这些不同的字体配上各种不同的随机背景图片创造出一些用于训练的实例，这让我们能够获得一个无限大的训练集。这是从零开始创造实例。</p><p>另一种方法是，利用已有的数据，然后对其进行修改，例如将已有的字符图片进行一些扭曲、旋转、模糊处理。只要我们认为实际数据有可能和经过这样处理后的数据类似，我们便可以用这样的方法来创造大量的数据。</p><p>有关获得更多数据的几种方法：</p><pre><code class="hljs">1. 人工数据合成2. 手动收集、标记数据3. 众包</code></pre><h4 id="18-4-Ceiling-Analysis-What-Part-of-the-Pipeline-to-Work-on-Next"><a href="#18-4-Ceiling-Analysis-What-Part-of-the-Pipeline-to-Work-on-Next" class="headerlink" title="18.4 Ceiling Analysis_ What Part of the Pipeline to Work on Next"></a>18.4 Ceiling Analysis_ What Part of the Pipeline to Work on Next</h4><p>在机器学习的应用中，我们通常需要通过几个步骤才能进行最终的预测，我们如何能够知道哪一部分最值得我们花时间和精力去改善呢？这个问题可以通过上限分析来回答。</p><p>流程图中每一部分的输出都是下一部分的输入，上限分析中，我们选取一部分，手工提供100%正确的输出结果，然后看应用的整体效果提升了多少。假使我们的例子中总体效果为72%的正确率。</p><p>如果我们令文字侦测部分输出的结果100%正确，发现系统的总体效果从72%提高到了89%。这意味着我们很可能会希望投入时间精力来提高我们的文字侦测部分。</p><p>接着我们手动选择数据，让字符切分输出的结果100%正确，发现系统的总体效果只提升了1%，这意味着，我们的字符切分部分可能已经足够好了。</p><p>最后我们手工选择数据，让字符分类输出的结果100%正确，系统的总体效果又提升了10%，这意味着我们可能也会应该投入更多的时间和精力来提高应用的总体表现。</p><h3 id="19-致谢"><a href="#19-致谢" class="headerlink" title="19. 致谢"></a>19. 致谢</h3><p>至此《机器学习》的课程就全部结束了。非常感谢 Dr. Andrew Ng 带我入了 Machine Learning 这个大坑，让我接触到了许多大学课程所学不到的知识。同时这门课程的内容确实非常适合没有基础的小白入门，它甚至包含了一些数学基础复习。并且课后的练习让在课上没有完全听懂的我得以抓住每节课的知识点，在课后理解复习。令人欣喜的是这门课同时还传授了许多构建模型实战运用的技巧，虽然在几年前第一次听这门课时并没有太过注意，但当现在的我已经有足够的基础做过一些研究后，才发现这些技巧和经验是十分可贵的！最后再次感谢教授耐心的指导和精彩的教学，以及每节课上的灿烂笑容！</p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【课程】吴恩达机器学习课程(二)</title>
    <link href="/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_2/"/>
    <url>/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于吴恩达机器学习 - Machine Learning Specialization <a href="https://www.coursera.org/specializations/machine-learning-introduction">课程</a> 的笔记第二部分；神经网络与支持向量机；</p></blockquote><span id="more"></span><h1 id="Course-2-Advanced-Learning-Algorithms"><a href="#Course-2-Advanced-Learning-Algorithms" class="headerlink" title="Course 2 : Advanced Learning Algorithms"></a>Course 2 : Advanced Learning Algorithms</h1><p>In the second course of the Machine Learning Specialization, you will:</p><ul><li>Build and train a neural network with TensorFlow to perform multi-class classification </li><li>Apply best practices for machine learning development so that your models generalize to data and tasks in the real world </li><li>Build and use decision trees and tree ensemble methods, including random forests and boosted trees</li></ul><h2 id="Week-4-Neural-Networks-Representation"><a href="#Week-4-Neural-Networks-Representation" class="headerlink" title="Week 4 : Neural Networks : Representation"></a>Week 4 : Neural Networks : Representation</h2><h3 id="8-Neural-Networks"><a href="#8-Neural-Networks" class="headerlink" title="8. Neural Networks"></a>8. Neural Networks</h3><h4 id="8-1-Non-linear-Hypotheses"><a href="#8-1-Non-linear-Hypotheses" class="headerlink" title="8.1 Non-linear Hypotheses"></a>8.1 Non-linear Hypotheses</h4><p>无论是线性回归还是逻辑回归都有这样一个缺点，即当特征太多时，计算的负荷会非常大。</p><p>假设我们希望训练一个模型来识别视觉对象（例如识别一张图片上是否是一辆汽车），我们采用的都是50x50像素的小图片，并且我们将所有的像素视为特征，则会有 2500个特征，如果我们要进一步将两两特征组合构成一个多项式模型，则会有约$2500^{2}/2$个（接近3百万个）特征。普通的逻辑回归模型，不能有效地处理这么多的特征，这时候我们需要神经网络。</p><h4 id="8-2-Neurons-and-the-Brain"><a href="#8-2-Neurons-and-the-Brain" class="headerlink" title="8.2 Neurons and the Brain"></a>8.2 Neurons and the Brain</h4><p>神经网络兴起于二十世纪八九十年代，应用得非常广泛。但由于各种原因，在90年代的后期应用减少了。而其中主要的原因是：神经网络是的计算量有些偏大。然而由于近些年计算机的运行速度变快，才足以真正运行起大规模的神经网络，这门技术又再次火爆了起来。正是由于这个原因和其他一些我们后面会讨论到的技术因素，如今的神经网络对于许多应用来说是最先进的技术。</p><h4 id="8-3-Model-Representation"><a href="#8-3-Model-Representation" class="headerlink" title="8.3 Model Representation"></a>8.3 Model Representation</h4><p>为了构建神经网络模型，我们需要首先思考大脑中的神经网络是怎样的？每一个神经元都可以被认为是一个处理单元/神经核（<strong>processing unit</strong>/<strong>Nucleus</strong>），它含有许多输入/树突（<strong>input</strong>/<strong>Dendrite</strong>），并且有一个输出/轴突（<strong>output</strong>/<strong>Axon</strong>）。神经网络是大量神经元相互链接并通过电脉冲来交流的一个网络。</p><p><img src="/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_2/pic8-1.jpg" alt></p><p>神经网络模型建立在很多神经元之上，每一个神经元又是一个个学习模型。这些神经元（也叫激活单元，<strong>activation unit</strong>）采纳一些特征作为输出，并且根据本身的模型提供一个输出在神经网络中，参数又可被成为权重（<strong>weight</strong>）。</p><p><img src="/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_2/pic8-2.jpg" alt></p><p>神经网络模型是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。下图为一个3层的神经网络，第一层成为输入层（<strong>Input Layer</strong>），最后一层称为输出层（<strong>Output Layer</strong>），中间一层成为隐藏层（<strong>Hidden Layers</strong>）。我们可以为每一层都增加一个偏差单位（<strong>bias unit</strong>）$x_0,a_0$</p><p>下面引入一些标记法来帮助描述模型：</p><ul><li>$a_{i}^{(j)}$ 代表第$j$ 层的第 $i$ 个激活单元。</li><li>$\theta ^{(j)}$代表从第 $j$ 层映射到第$ j+1$ 层时的权重的矩阵。</li></ul><p>对于上图所示的模型，激活单元和输出分别表达为</p><script type="math/tex; mode=display">\begin{aligned}a_{1}^{(2)}&=g\left(\Theta_{10}^{(1)} x_{0}+\Theta_{11}^{(1)} x_{1}+\Theta_{12}^{(1)} x_{2}+\Theta_{13}^{(1)} x_{3}\right) \\ a_{2}^{(2)}&=g\left(\Theta_{20}^{(1)} x_{0}+\Theta_{21}^{(1)} x_{1}+\Theta_{22}^{(1)} x_{2}+\Theta_{23}^{(1)} x_{3}\right) \\ a_{3}^{(2)}&=g\left(\Theta_{30}^{(1)} x_{0}+\Theta_{31}^{(1)} x_{1}+\Theta_{32}^{(1)} x_{2}+\Theta_{33}^{(1)} x_{3}\right) \\ h_{\Theta}(x)&=g\left(\Theta_{10}^{(2)} a_{0}^{(2)}+\Theta_{11}^{(2)} a_{1}^{(2)}+\Theta_{12}^{(2)} a_{2}^{(2)}+\Theta_{13}^{(2)} a_{3}^{(2)}\right)\end{aligned}</script><p>如果第 $j$ 层有 $s_j$ 个神经元，$j+1$ 层有 $s_{j+1}$ 个神经元，权重 $\Theta^{(j)}$ 的维度就是 $s_{j+1}\times(s_j+1)$</p><p>为了方便理解，我们令</p><ul><li><p>$z^{(j+1)}=\Theta^{(j)} \times a^{(j)}$</p></li><li><p>$a^{(j+1)}=g\left(z^{(j+1)}\right)$</p></li></ul><p>我们把这样从左到右的算法称为前向传播算法( <strong>FORWARD PROPAGATION</strong> )</p><h4 id="8-4-Examples-and-Intuitions"><a href="#8-4-Examples-and-Intuitions" class="headerlink" title="8.4 Examples and Intuitions"></a>8.4 Examples and Intuitions</h4><p>神经网络中，单层神经元（无中间层）的计算可用来表示逻辑运算，比如逻辑与(<strong>AND</strong>)、逻辑或(<strong>OR</strong>)。</p><h5 id="【Example-AND】"><a href="#【Example-AND】" class="headerlink" title="【Example AND】"></a>【Example AND】</h5><script type="math/tex; mode=display">h_{\Theta}(x)=g(-3+2x_1+2x_2)</script><p><strong>【Example OR】</strong></p><script type="math/tex; mode=display">h_{\Theta}(x)=g(-1+2x_1+2x_2)</script><h5 id="【Example-Not-x-1-】"><a href="#【Example-Not-x-1-】" class="headerlink" title="【Example Not $x_1$】"></a>【Example Not $x_1$】</h5><script type="math/tex; mode=display">h_{\Theta}(x)=g(1-2x_1)</script><p>逻辑异或(<strong>XOR</strong>)，逻辑异或非(<strong>XNOR</strong>)则需要两层神经元来计算。</p><p><img src="/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_2/pic8-3.jpg" alt></p><h5 id="【Example-XNOR】"><a href="#【Example-XNOR】" class="headerlink" title="【Example XNOR】"></a>【Example XNOR】</h5><script type="math/tex; mode=display">\text{XNOR}=( \text{x}_1\, \text{AND}\, \text{x}_2 )\, \text{OR} \left( \left( \text{NOT}\, \text{x}_1 \right) \text{AND} \left( \text{NOT}\, \text{x}_2 \right) \right)</script><p>第一层做 <strong>AND</strong> 判断，第二层做 <strong>OR</strong> 判断</p><h4 id="8-5-识别手写数字练习-逻辑回归与神经网络前向传播"><a href="#8-5-识别手写数字练习-逻辑回归与神经网络前向传播" class="headerlink" title="8.5 识别手写数字练习-逻辑回归与神经网络前向传播"></a>8.5 识别手写数字练习-逻辑回归与神经网络前向传播</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 数据</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-comment"># 画图</span><br><span class="hljs-keyword">import</span> matplotlib<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-comment"># 机器学习</span><br><span class="hljs-keyword">import</span> scipy.optimize <span class="hljs-keyword">as</span> opt<br><span class="hljs-keyword">from</span> scipy.io <span class="hljs-keyword">import</span> loadmat<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br></code></pre></td></tr></table></figure><h5 id="训练集"><a href="#训练集" class="headerlink" title="训练集"></a>训练集</h5><p>一共5000个训练数据，每个数据是一个表示20*20的灰度图像即400维，总的矩阵为5000*400</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">path, transpose=<span class="hljs-literal">True</span></span>):<br>    data = loadmat(path)<br>    X = data[<span class="hljs-string">&#x27;X&#x27;</span>] <span class="hljs-comment"># (5000, 400)</span><br>    y = data[<span class="hljs-string">&#x27;y&#x27;</span>] <span class="hljs-comment"># (5000, 1)</span><br>    y = y.reshape(y.shape[<span class="hljs-number">0</span>]) <span class="hljs-comment"># 从 (5000, 1) 到 (5000, )</span><br>    <span class="hljs-keyword">if</span> transpose:<br>        X = np.array([im.reshape((<span class="hljs-number">20</span>,<span class="hljs-number">20</span>)).T.reshape(<span class="hljs-number">400</span>) <span class="hljs-keyword">for</span> im <span class="hljs-keyword">in</span> X]) <br>        <span class="hljs-comment"># 对 X 进行转置</span><br>    <span class="hljs-keyword">return</span> X, y<br><br>raw_x, raw_y = load_data(<span class="hljs-string">&#x27;ex3data1.mat&#x27;</span>)<br></code></pre></td></tr></table></figure><h5 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_an_image</span>(<span class="hljs-params">image</span>):<br>    fig, ax = plt.subplots(figsize=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    ax.matshow(image.reshape((<span class="hljs-number">20</span>,<span class="hljs-number">20</span>)), cmap=matplotlib.cm.binary)<br>    plt.xticks(np.array([]))<br>    plt.yticks(np.array([]))<br>    plt.show()<br>    <br>pick_one = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">5000</span>)<br>plot_an_image(raw_x[pick_one, :])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;this should be &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(raw_y[pick_one]))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_100_image</span>(<span class="hljs-params">X</span>):<br>    sz = <span class="hljs-built_in">int</span>(np.sqrt(X.shape[<span class="hljs-number">1</span>])) <span class="hljs-comment"># size</span><br>    sample_idx = np.random.choice(np.arange(X.shape[<span class="hljs-number">0</span>]), <span class="hljs-number">100</span>)<br>    sample_images = X[sample_idx, :]<br>    <br>    fig, axs = plt.subplots(nrows=<span class="hljs-number">10</span>, ncols=<span class="hljs-number">10</span>, sharey=<span class="hljs-literal">True</span>, sharex=<span class="hljs-literal">True</span>, <br>                            figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">8</span>))<br>    <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>            axs[r, c].matshow(sample_images[<span class="hljs-number">10</span> * r + c].reshape((sz, sz)),<br>                              cmap=matplotlib.cm.binary)<br>    plt.xticks(np.array([]))<br>    plt.yticks(np.array([]))<br>    plt.show()    <br></code></pre></td></tr></table></figure><h5 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h5><p><img src="/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_2/向量化标签.png" alt></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">X = np.insert(raw_x, <span class="hljs-number">0</span>, np.ones(raw_x.shape[<span class="hljs-number">0</span>]), axis=<span class="hljs-number">1</span>) <span class="hljs-comment"># 偏差单位</span><br><br>y = []<br><span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">11</span>):<br>    y.append([<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> i==k <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> raw_y])<br>y = np.array([y[-<span class="hljs-number">1</span>]] + y[:-<span class="hljs-number">1</span>]) <span class="hljs-comment"># 把 10 放回首位</span><br></code></pre></td></tr></table></figure><h5 id="逻辑回归代价函数"><a href="#逻辑回归代价函数" class="headerlink" title="逻辑回归代价函数"></a>逻辑回归代价函数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">z</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-z))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cost</span>(<span class="hljs-params">theta, X, y</span>):<br>    first = y * np.log(sigmoid(X @ theta.T))<br>    second = (<span class="hljs-number">1</span> - y) * np.log(<span class="hljs-number">1</span> - sigmoid(X @ theta.T))<br>    <span class="hljs-keyword">return</span> -np.mean(first + second)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">regularized_cost</span>(<span class="hljs-params">theta, X, y, l</span>):<br>    reg = l / (<span class="hljs-number">2</span> * <span class="hljs-built_in">len</span>(X)) * (theta[<span class="hljs-number">1</span>:] ** <span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>()<br>    <span class="hljs-keyword">return</span> cost(theta, X, y) + reg<br></code></pre></td></tr></table></figure><h5 id="逻辑回归梯度函数"><a href="#逻辑回归梯度函数" class="headerlink" title="逻辑回归梯度函数"></a>逻辑回归梯度函数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient</span>(<span class="hljs-params">theta, X, y, l</span>):<br>    error = sigmoid(X@theta.T) - y<br>    grad = X.T @ error / <span class="hljs-built_in">len</span>(X)<br>    reg = theta * l / <span class="hljs-built_in">len</span>(X)<br>    reg[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">return</span> grad + reg<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">logistic_regression</span>(<span class="hljs-params">X, y, l=<span class="hljs-number">1</span></span>):<br>    theta = np.zeros(X.shape[<span class="hljs-number">1</span>])<br>    res = opt.minimize(fun = regularized_cost, x0=theta, args=(X, y, l), method=<span class="hljs-string">&#x27;TNC&#x27;</span>, jac=gradient, options=&#123;<span class="hljs-string">&#x27;disp&#x27;</span>: <span class="hljs-literal">True</span>&#125;)<br>    <span class="hljs-keyword">return</span> res.x<br></code></pre></td></tr></table></figure><h5 id="逻辑回归预测分析"><a href="#逻辑回归预测分析" class="headerlink" title="逻辑回归预测分析"></a>逻辑回归预测分析</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">theta, X</span>):<br>    prob = sigmoid(X @ theta)<br>    <span class="hljs-keyword">return</span> [<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> i &gt;= <span class="hljs-number">0.5</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> prob]<br><br><span class="hljs-comment"># 训练1维</span><br><br>theta_0 = logistic_regression(X, y[<span class="hljs-number">0</span>])<br>y_pred = predict(theta_0, X)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Accurary = &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(np.mean(y[<span class="hljs-number">0</span>] == y_pred)))<br><br><span class="hljs-comment"># 训练k维</span><br><br>theta_k = np.array([logistic_regression(X, y[k]) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)])<br><span class="hljs-comment"># theta_k.shape = (10, 401)</span><br>prob_matrix = sigmoid(X @ theta_k.T)<br>np.set_printoptions(suppress=<span class="hljs-literal">True</span>) <span class="hljs-comment"># 表示小数不需要以科学计数法的形式输出</span><br><br>y_pred = np.argmax(prob_matrix, axis=<span class="hljs-number">1</span>) <span class="hljs-comment"># 返回每行最大的列索引</span><br>y_pred = np.array([<span class="hljs-number">10</span> <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> y_pred])<br></code></pre></td></tr></table></figure><h5 id="神经网络向前传播"><a href="#神经网络向前传播" class="headerlink" title="神经网络向前传播"></a>神经网络向前传播</h5><p>练习题中已经给出了权重，所以我们只需要通过向前传播来预测</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_weight</span>(<span class="hljs-params">path</span>):<br>    data = loadmat(path)<br>    <span class="hljs-keyword">return</span> data[<span class="hljs-string">&#x27;Theta1&#x27;</span>], data[<span class="hljs-string">&#x27;Theta2&#x27;</span>]<br><br>theta1, theta2 = load_weight(<span class="hljs-string">&#x27;ex3weights.mat&#x27;</span>) <span class="hljs-comment"># (25, 401), (10, 26)</span><br><br>X, y = load_data(<span class="hljs-string">&#x27;ex3data1.mat&#x27;</span>, transpose=<span class="hljs-literal">False</span>)<br>X = np.insert(X, <span class="hljs-number">0</span>, np.ones(X.shape[<span class="hljs-number">0</span>]), axis=<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># 此处需要重新导入，因为练习中模型的输出 [0~9] 对应的是现实中的 [1~10]，并没有像我们前面一样更换位置。</span><br></code></pre></td></tr></table></figure><p>可以看出模型分为 输入层 中间层 和输出层，第一个阶段从 400 个变量转变为 25 个单元， 第二个阶段从 25+1 个变量转变为 10 个单元， 也是输出矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 输入层</span><br><br>a1 = X<br>z2 = a1 @ theta1.T<br>z2 = np.insert(z2, <span class="hljs-number">0</span>, np.ones(z2.shape[<span class="hljs-number">0</span>]), axis=<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># 第二层</span><br><br>a2 = sigmoid(z2)<br>z3 = a2 @ theta2.T<br><br><span class="hljs-comment"># 输出层</span><br><br>a3 = sigmoid(z3)<br><br><span class="hljs-comment"># 预测</span><br><br>y_pred = np.argmax(a3, axis=<span class="hljs-number">1</span>)+<span class="hljs-number">1</span><br>classification_report(y, y_pred)<br></code></pre></td></tr></table></figure><h2 id="Week-5-Neural-Networks-Learning"><a href="#Week-5-Neural-Networks-Learning" class="headerlink" title="Week 5 : Neural Networks : Learning"></a>Week 5 : Neural Networks : Learning</h2><h3 id="9-Cost-Function-and-Backpropagation"><a href="#9-Cost-Function-and-Backpropagation" class="headerlink" title="9.  Cost Function and Backpropagation"></a>9.  Cost Function and Backpropagation</h3><h4 id="9-1-Cost-Function"><a href="#9-1-Cost-Function" class="headerlink" title="9.1 Cost Function"></a>9.1 Cost Function</h4><p>首先引入一些便于稍后讨论的新标记方法：</p><ul><li>训练样本 $m$</li><li>输入 $x$ 和输出信号 $y$</li><li>$L$ 表示神经网络层数</li><li>$S_l$表示每层的<strong>neuron</strong>个数 ($S_L$表示输出层神经元个数)</li></ul><p>将神经网络的分类定义为两种情况：</p><ul><li>二类分类：$S_L=1, y=0\, or\, 1$表示哪一类；</li><li>$K$类分类：$S_L=k, y_i = 1$表示分到第$i$类；$(k&gt;3)$</li></ul><p>逻辑回归问题中我们的代价函数为：</p><script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}\left[\sum_{i=1}^{m} y^{(i)} \log h_{\theta}\left(x^{(i)}\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]+\frac{\lambda}{2 m} \sum_{j=1}^{n} \theta_{j}^{2}</script><p>在逻辑回归中，我们只有一个输出变量，又称标量（<strong>scalar</strong>），也只有一个因变量$y$，但是在神经网络中，我们可以有很多输出变量，我们的$h_\theta(x)$是一个维度为$K$的向量，并且我们训练集中的因变量也是同样维度的一个向量，因此我们的代价函数会比逻辑回归更加复杂一些</p><p>定义 $\left(h_{\Theta}(x)\right)_{i}=i^{t h} \text { output }$</p><script type="math/tex; mode=display">\begin{aligned} J(\Theta)=&-\frac{1}{m}\left[\sum_{i=1}^{m} \sum_{k=1}^{K} y_{k}^{(i)} \log \left(h_{\Theta}\left(x^{(i)}\right)\right)_{k}+\left(1-y_{k}^{(i)}\right) \log \left(1-\left(h_{\Theta}\left(x^{(i)}\right)\right)_{k}\right)\right] \\ &+\frac{\lambda}{2 m} \sum_{l=1}^{L-1} \sum_{i=1}^{s_{l}} \sum_{j=1}^{s_{l+1}}\left(\Theta_{j i}^{(l)}\right)^{2} \end{aligned}</script><p>正则化的一项是排除了每一层$\theta_0$后，每一层的$\theta$ 矩阵的和</p><h4 id="9-2-Backpropagation-Algorithm"><a href="#9-2-Backpropagation-Algorithm" class="headerlink" title="9.2 Backpropagation Algorithm"></a>9.2 Backpropagation Algorithm</h4><p><a href="https://blog.csdn.net/qq_29762941/article/details/80343185">详细推导</a></p><p>首先，我们定义 $\delta$ 来表示误差，则：$\delta_j^{(L)}=a_j^{(L)}-y_j$</p><p>我们利用这个误差值来计算前一层的误差：$\delta^{(i)}=\left(\Theta^{(i)}\right)^{T}\delta^{(i+1)}.\ast g’\left(z^{(i)}\right)$</p><blockquote><p>注意误差与导数之间是点乘</p></blockquote><p>其中 $g’(z^{(i)})$是 $S$ 形函数的导数: $g’(z^{(i)})=a^{(i)}\ast(1-a^{(i)})$</p><script type="math/tex; mode=display">\begin{aligned}g'(z)=\frac{e^{-z}}{(1+e^{-z})^2}=\frac{e^{-z}+1-1}{(1+e^{-z})^2}=\frac1{1+e^{-z}}-\frac1{(1+e^{-z})^2}=g(z)(1-g(z))\end{aligned}</script><p>我们有了所有的误差的表达式后，便可以计算代价函数的偏导数了，假设$λ=0$，即我们不做任何正则化处理时有：</p><script type="math/tex; mode=display">\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)=a_{j}^{(l)} \delta_{i}^{l+1}</script><h4 id="9-3-Backpropagation-Intuition"><a href="#9-3-Backpropagation-Intuition" class="headerlink" title="9.3 Backpropagation Intuition"></a>9.3 Backpropagation Intuition</h4><p>Formally，$\delta^{(l)}_{j}=\frac{\partial}{\partial z^{(l)}_{j}}\text{cost}$</p><p>其中</p><script type="math/tex; mode=display">\text{cost}(i)=-[y^{(i)}\log \left( h_\theta\left( x^{(i)} \right) \right)+\left( 1-y^{(i)} \right)\log \left( 1-h_\theta\left( x^{(i)} \right) \right)]</script><p>因此可求出</p><script type="math/tex; mode=display">\begin{aligned}\delta=\frac{\partial}{\partial z}\text{cost}(i)&=-y\frac1{a}a(1-a)-(1-y)\frac1{1-a}(-a)(1-a)\\&=-y(1-a)-(1-y)(-a)\\&=-y+ay+a-ay\\&=a-y\end{aligned}</script><p>因此 $\delta^{(l)}_{j}$ 又相当于是第 $l$ 层的第 $j$ 单元中得到的激活项的“误差”，即”正确“的 $a^{(l)}_{j}$ 与计算得到的 $a^{(l)}_{j}$ 的差</p><h5 id="【TensorFlow】"><a href="#【TensorFlow】" class="headerlink" title="【TensorFlow】"></a>【TensorFlow】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Sequential<br><span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Dense<br><br>model = Sequential(<br>    [<br>        Dense(<span class="hljs-number">3</span>, activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>, name = <span class="hljs-string">&#x27;layer1&#x27;</span>),<br>        Dense(<span class="hljs-number">1</span>, activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>, name = <span class="hljs-string">&#x27;layer2&#x27;</span>) <span class="hljs-comment"># activation可以换成softmax</span><br>     ]<br>)<br><br>model.<span class="hljs-built_in">compile</span>(<br>    loss = tf.keras.losses.BinaryCrossentropy(), <span class="hljs-comment"># 同时此处需要换成 SparseCategoricalCrossentropy</span><br>    optimizer = tf.keras.optimizers.Adam(learning_rate=<span class="hljs-number">0.01</span>),<br>)<br><br>model.fit(<br>    Xt,Yt,            <br>    epochs=<span class="hljs-number">10</span>,<br>)<br></code></pre></td></tr></table></figure><h4 id="9-4-Gradient-Checking"><a href="#9-4-Gradient-Checking" class="headerlink" title="9.4 Gradient Checking"></a>9.4 Gradient Checking</h4><p>当我们对一个较为复杂的模型（例如神经网络）使用梯度下降算法时，可能会存在一些不容易察觉的错误，意味着，虽然代价看上去在不断减小，但最终的结果可能并不是最优解。</p><p>为了避免这样的问题，我们采取一种叫做梯度的数值检验（<strong>Numerical Gradient Checking</strong>）方法。这种方法的思想是通过估计梯度值来检验我们计算的导数值是否真的是我们要求的。</p><p>对梯度的估计采用的方法是在代价函数上沿着切线的方向选择离两个非常近的点然后计算两个点的平均值用以估计梯度。即对于某个特定的 $\theta$，我们计算出在 $\theta$-$\varepsilon $ 处和 $\theta$+$\varepsilon $ 的代价值（$\varepsilon $是一个非常小的值，通常选取 0.001），然后求两个代价的平均，用以估计在 $\theta$ 处的代价值。</p><p>然后我们对通过反向传播方法计算出的偏导数进行检验。根据上面的算法，计算出的偏导数存储在矩阵 $D_{ij}^{(l)}$ 中。检验时，我们要将该矩阵展开成为向量，同时我们也将 $\theta$ 矩阵展开为向量，我们针对每一个 $\theta$ 都计算一个近似的梯度值，将这些值存储于一个近似梯度矩阵中，最终将得出的这个矩阵同 $D_{ij}^{(l)}$ 进行比较。</p><h4 id="9-5-Random-Initialization"><a href="#9-5-Random-Initialization" class="headerlink" title="9.5 Random Initialization"></a>9.5 Random Initialization</h4><p>任何优化算法都需要一些初始的参数。到目前为止我们都是初始所有参数为0，这样的初始方法对于逻辑回归来说是可行的，但是对于神经网络来说是不可行的。如果我们令所有的初始参数都为0，这将意味着我们第二层的所有激活单元都会有相同的值。因此，我们通常使用初始参数为正负ε之间的随机值</p><h4 id="9-6-Putting-It-Together"><a href="#9-6-Putting-It-Together" class="headerlink" title="9.6 Putting It Together"></a>9.6 Putting It Together</h4><p>小结一下使用神经网络时的步骤：</p><p>网络结构：</p><ul><li>首先要做的事是选择网络结构，即决定选择多少层以及决定每层分别有多少个单元。<ul><li>第一层的单元数即我们训练集的特征数量。</li><li>最后一层的单元数是我们训练集的结果的类的数量。</li><li>如果隐藏层数大于1，确保每个隐藏层的单元个数相同，通常情况下隐藏层单元的个数越多越好。</li><li>我们真正要决定的是隐藏层的层数和每个中间层的单元数。</li></ul></li></ul><p>训练神经网络：</p><ol><li><p>参数的随机初始化</p></li><li><p>利用正向传播方法计算所有的$h_{\theta}(x)$</p></li><li><p>编写计算代价函数 $J$ 的代码</p></li><li><p>利用反向传播方法计算所有偏导数</p></li><li><p>利用数值检验方法检验这些偏导数</p></li><li><p>使用优化算法来最小化代价函数</p></li></ol><h4 id="9-7-识别手写数字练习-神经网络逆向传播"><a href="#9-7-识别手写数字练习-神经网络逆向传播" class="headerlink" title="9.7 识别手写数字练习-神经网络逆向传播"></a>9.7 识别手写数字练习-神经网络逆向传播</h4><p>数据读取与画图和前面步骤类似，接着是将 [1~10] 的数变为 10 维向量的格式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">expend_y</span>(<span class="hljs-params">y</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    expend 5000*1 -&gt; 5000*10</span><br><span class="hljs-string">    y=2 -&gt; y=[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <br>    res = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> y:<br>        tmp = np.zeros(<span class="hljs-number">10</span>)<br>        tmp[i-<span class="hljs-number">1</span>] = <span class="hljs-number">1</span><br>        res.append(tmp)<br>    <span class="hljs-keyword">return</span> np.array(res)<br><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    与expand_y(y)结果一致</span><br><span class="hljs-string">    from sklearn.preprocessing import OneHotEncoder</span><br><span class="hljs-string">    encoder = OneHotEncoder(sparse=False)</span><br><span class="hljs-string">    y_onehot = encoder.fit_transform(y)</span><br><span class="hljs-string">    y_onehot.shape </span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <br>y = expend_y(y)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">serialize</span>(<span class="hljs-params">a, b</span>):<br>    <span class="hljs-keyword">return</span> np.concatenate((np.ravel(a), np.ravel(b))) <br><span class="hljs-comment"># 将两个 theta 合并</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">deserialize</span>(<span class="hljs-params">seq</span>):<br>    <span class="hljs-keyword">return</span> seq[ : <span class="hljs-number">25</span>*<span class="hljs-number">401</span>].reshape(<span class="hljs-number">25</span>, <span class="hljs-number">401</span>), seq[<span class="hljs-number">25</span>*<span class="hljs-number">401</span> : ].reshape(<span class="hljs-number">10</span>, <span class="hljs-number">26</span>) <br><span class="hljs-comment">#将两个 theta 分开</span><br></code></pre></td></tr></table></figure><h5 id="cost-funciton"><a href="#cost-funciton" class="headerlink" title="cost funciton"></a>cost funciton</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">z</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-z))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">feed_forward</span>(<span class="hljs-params">theta, X</span>):<br>    t1, t2 = deserialize(theta) <span class="hljs-comment"># t1:(25, 401) t2:(10, 26)</span><br>    a1 = X <span class="hljs-comment"># 5000*401</span><br>    <br>    z2 = a1 @ t1.T <span class="hljs-comment"># 5000*25</span><br>    a2 = np.insert(sigmoid(z2), <span class="hljs-number">0</span>, np.ones(z2.shape[<span class="hljs-number">0</span>]), axis=<span class="hljs-number">1</span>) <span class="hljs-comment"># 5000*26</span><br>    <br>    z3 = a2 @ t2.T <span class="hljs-comment"># 5000*10</span><br>    h = sigmoid(z3) <span class="hljs-comment"># 5000*10</span><br>    <span class="hljs-keyword">return</span> a1, z2, a2, z3, h<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cost</span>(<span class="hljs-params">theta, X, y</span>):<br>    h = feed_forward(theta, X)[-<span class="hljs-number">1</span>]<br>    tmp = -y * np.log(h) - (<span class="hljs-number">1</span>-y) * np.log(<span class="hljs-number">1</span>-h)<br>    <span class="hljs-keyword">return</span> tmp.<span class="hljs-built_in">sum</span>() / y.shape[<span class="hljs-number">0</span>]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">regularized_cost</span>(<span class="hljs-params">theta, X, y, l=<span class="hljs-number">1</span></span>):<br>    t1, t2 = deserialize(theta)<br>    m = X.shape[<span class="hljs-number">0</span>]<br>    <br>    reg1 = np.power(t1[:, <span class="hljs-number">1</span>:], <span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>() / (<span class="hljs-number">2</span> * m)<br>    reg2 = np.power(t2[:, <span class="hljs-number">1</span>:], <span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>() / (<span class="hljs-number">2</span> * m)<br>    <br>    <span class="hljs-keyword">return</span> cost(theta, X, y) + reg1 + reg2<br></code></pre></td></tr></table></figure><h5 id="Back-propagation"><a href="#Back-propagation" class="headerlink" title="Back propagation"></a>Back propagation</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid_gradient</span>(<span class="hljs-params">z</span>):<br>    <span class="hljs-keyword">return</span> sigmoid(z) * (<span class="hljs-number">1</span> - sigmoid(z))<br><span class="hljs-comment"># sigmoid 函数求导</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient</span>(<span class="hljs-params">theta, X, y</span>):<br>    t1, t2 = deserialize(theta)<br>    m = X.shape[<span class="hljs-number">0</span>]<br>    <br>    delta1 = np.zeros(t1.shape) <span class="hljs-comment"># 25*401</span><br>    delta2 = np.zeros(t2.shape) <span class="hljs-comment"># 10*26</span><br>    <br>    a1, z2, a2, z3, h = feed_forward(theta, X)<br>    <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m):<br>        a1i = a1[i] <span class="hljs-comment"># 1*401</span><br>        z2i = z2[i] <span class="hljs-comment"># 1*25</span><br>        a2i = a2[i] <span class="hljs-comment"># 1*26</span><br><br>        hi  = h[i]  <span class="hljs-comment"># 1*10</span><br>        yi  = y[i]  <span class="hljs-comment"># 1*10</span><br>        d3i = hi - yi <span class="hljs-comment"># 1*10，输出层的误差</span><br>        <br>        z2i = np.insert(z2i, <span class="hljs-number">0</span>, np.ones(<span class="hljs-number">1</span>))<br>        d2i = t2.T @ d3i * sigmoid_gradient(z2i) <span class="hljs-comment"># 1*26 隐藏层的误差</span><br>        <br>        <span class="hljs-comment"># careful with np vector transpose</span><br>        delta2 += np.matrix(d3i).T @ np.matrix(a2i)<br>        delta1 += np.matrix(d2i[<span class="hljs-number">1</span>:]).T @ np.matrix(a1i)<br>    <br>    <span class="hljs-keyword">return</span> serialize(delta1, delta2)<br><br>d1, d2 = deserialize(gradient(theta, X, y))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">regularized_gradient</span>(<span class="hljs-params">theta, X, y, l=<span class="hljs-number">1</span></span>):<br>    m = X.shape[<span class="hljs-number">0</span>]<br>    delta1, delta2 = deserialize(gradient(theta, X, y))<br>    delta1 /= m<br>    delta2 /= m<br>    <br>    t1, t2 = deserialize(theta)<br>    t1[:, <span class="hljs-number">0</span>] = <span class="hljs-number">0</span><br>    t2[:, <span class="hljs-number">0</span>] = <span class="hljs-number">0</span><br>    <br>    delta1 += l / m * t1<br>    delta2 += l / m * t2<br>    <br>    <span class="hljs-keyword">return</span> serialize(delta1, delta2)<br></code></pre></td></tr></table></figure><h5 id="梯度检查"><a href="#梯度检查" class="headerlink" title="梯度检查"></a>梯度检查</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">expand_array</span>(<span class="hljs-params">arr</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    replicate array into matrix</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    [1, 2, 3]</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    [[1, 2, 3],</span><br><span class="hljs-string">    [1, 2, 3],</span><br><span class="hljs-string">    [1, 2, 3]]</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <br>    <span class="hljs-keyword">return</span> np.array(np.matrix(np.ones(arr.shape[<span class="hljs-number">0</span>])).T @ np.matrix(arr))<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient_checking</span>(<span class="hljs-params">theta, X, y, epsilon, regularized=<span class="hljs-literal">False</span></span>):<br>    m = <span class="hljs-built_in">len</span>(theta)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">a_numeric_grad</span>(<span class="hljs-params">plus, minus, regularized=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-keyword">if</span> regularized:<br>            <span class="hljs-keyword">return</span> (regularized_cost(plus, X, y) - regularized_cost(minus, X, y)) / (epsilon*<span class="hljs-number">2</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> (cost(plus, X, y) - cost(minus, X, y)) / (epsilon*<span class="hljs-number">2</span>)<br>    <br>    theta_matrix = expand_array(theta)<br>    epsilon_matrix = np.identity(m) * epsilon <span class="hljs-comment"># identity单位矩阵</span><br>    plus_matrix = theta_matrix + epsilon_matrix<br>    minus_matrix = theta_matrix - epsilon_matrix<br>    <br>    approx_grad = np.array([a_numeric_grad(plus_matrix[i], minus_matrix[i], regularized) <br>                            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m)])<br>    analytic_grad = regularized_gradient(theta, X, y) <span class="hljs-keyword">if</span> regularized <span class="hljs-keyword">else</span> gradient(theta, X, y)<br>    diff = np.linalg.norm(approx_grad - analytic_grad) / np.linalg.norm(approx_grad + analytic_grad)<br>    <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;If your backpropagation implementation is correct,\nthe relative difference will be smaller than 10e-9 (assume epsilon=0.0001).\nRelative Difference: &#123;&#125;\n&#x27;</span>.<span class="hljs-built_in">format</span>(diff))<br></code></pre></td></tr></table></figure><h5 id="进行训练"><a href="#进行训练" class="headerlink" title="进行训练"></a>进行训练</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">random_init</span>(<span class="hljs-params">size</span>):<br>    <span class="hljs-keyword">return</span> np.random.uniform(-<span class="hljs-number">0.12</span>, <span class="hljs-number">0.12</span>, size)<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">nn_training</span>(<span class="hljs-params">theta, X, y</span>):<br>    init_theta = random_init(<span class="hljs-built_in">len</span>(theta))<br>    res = opt.minimize(fun=regularized_cost, x0 = init_theta,<br>                      args=(X, y, <span class="hljs-number">1</span>), method=<span class="hljs-string">&#x27;TNC&#x27;</span>,<br>                      jac=regularized_gradient,<br>                      options=&#123;<span class="hljs-string">&#x27;maxiter&#x27;</span>: <span class="hljs-number">400</span>&#125;)<br>    <span class="hljs-keyword">return</span> res<br>    <br>res = nn_training(theta, X, y)<br>final_theta = res.x<br></code></pre></td></tr></table></figure><h5 id="显示隐藏层"><a href="#显示隐藏层" class="headerlink" title="显示隐藏层"></a>显示隐藏层</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_hidden_layer</span>(<span class="hljs-params">theta</span>):<br>    t1, t2 = deserialize(theta)<br>    hidden_layer = t1[:, <span class="hljs-number">1</span>:]<br>    fig, ax_array = plt.subplots(nrows=<span class="hljs-number">5</span>, ncols=<span class="hljs-number">5</span>, sharey=<span class="hljs-literal">True</span>, sharex=<span class="hljs-literal">True</span>, figsize=(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))<br>    <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>            ax_array[r, c].matshow(hidden_layer[<span class="hljs-number">5</span>*r+c].reshape((<span class="hljs-number">20</span>,<span class="hljs-number">20</span>)), <br>                                  cmap=matplotlib.cm.binary)<br>            plt.xticks(np.array([]))<br>            plt.yticks(np.array([]))            <br>    plt.show()<br></code></pre></td></tr></table></figure><h2 id="Week-6-Advice-for-Applying-Machine-Learning"><a href="#Week-6-Advice-for-Applying-Machine-Learning" class="headerlink" title="Week 6 : Advice for Applying Machine Learning"></a>Week 6 : Advice for Applying Machine Learning</h2><h3 id="10-Evaluating-a-Learning-Algorithm"><a href="#10-Evaluating-a-Learning-Algorithm" class="headerlink" title="10. Evaluating a Learning Algorithm"></a>10. Evaluating a Learning Algorithm</h3><h4 id="10-1-Deciding-What-to-Try-Next"><a href="#10-1-Deciding-What-to-Try-Next" class="headerlink" title="10.1 Deciding What to Try Next"></a>10.1 Deciding What to Try Next</h4><p>使用预测房价的学习例子，假如你已经完成了正则化线性回归，也就是最小化代价函数$J$的值，在你得到学习参数以后，将假设函数放到一组新的房屋样本上进行测试，你发现在预测房价时产生了巨大的误差，现在你的问题是要想改进这个算法，接下来应该怎么办？</p><ul><li>获得更多的训练样本——通常是有效的，但代价较大，下面的方法也可能有效，可考虑先采用下面的几种方法。</li><li><p>尝试减少特征的数量</p></li><li><p>尝试获得更多的特征</p></li><li><p>尝试增加多项式特征</p></li><li><p>尝试减少正则化程度$\lambda$</p></li><li><p>尝试增加正则化程度$\lambda$</p></li></ul><p>我们不应该随机选择上面的某种方法来改进我们的算法，而是运用一些<strong>机器学习诊断法</strong>来帮助我们知道上面哪些方法对我们的算法是有效的。</p><h4 id="10-2-Evaluating-a-Hypothesis"><a href="#10-2-Evaluating-a-Hypothesis" class="headerlink" title="10.2 Evaluating a Hypothesis"></a>10.2 Evaluating a Hypothesis</h4><p>检验算法是否过拟合，我们可以将数据分成训练集和测试集，通常用70%的数据作为训练集，用剩下30%的数据作为测试集。很重要的一点是训练集和测试集均要含有各种类型的数据，通常我们要对数据进行“洗牌”，然后再分成训练集和测试集。使用训练集得到函数系数后对测试集进行预测，然后与真实值对比计算误差。</p><h4 id="10-3-Model-Selection-and-Train-Validation-Test-Sets"><a href="#10-3-Model-Selection-and-Train-Validation-Test-Sets" class="headerlink" title="10.3 Model Selection and Train_Validation_Test Sets"></a>10.3 Model Selection and Train_Validation_Test Sets</h4><p><strong>交叉验证集</strong> ：使用60%的数据作为训练集，使用 20%的数据作为交叉验证集，使用20%的数据作为测试集</p><p>模型选择的方法为：</p><ol><li><p>使用训练集训练出10个模型</p></li><li><p>用10个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值）</p></li><li><p>选取代价函数值最小的模型</p></li><li><p>用步骤3中选出的模型对测试集计算得出推广误差（代价函数的值）</p></li></ol><p>对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数，为了更好地作选择，可以把数据分为训练集、交叉验证集和测试集，针对不同隐藏层层数的神经网络训练神经网络，然后选择交叉验证集代价最小的神经网络。</p><h4 id="10-4-Diagnosing-Bias-vs-Variance"><a href="#10-4-Diagnosing-Bias-vs-Variance" class="headerlink" title="10.4 Diagnosing Bias vs. Variance"></a>10.4 Diagnosing Bias vs. Variance</h4><p>当你运行一个学习算法时，如果这个算法的表现不理想，那么多半是出现两种情况：要么是偏差比较大，要么是方差比较大。换句话说，出现的情况要么是欠拟合，要么是过拟合问题。</p><p>对于训练集，当 $d$ (<strong>degree of polynomial</strong>) 较小时，模型拟合程度更低，误差较大；随着 $d$ 的增长，拟合程度提高，误差减小。</p><p>对于交叉验证集，当 $d$ 较小时，模型拟合程度低，误差较大；但是随着 $d$ 的增长，误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。</p><ul><li><p>训练集误差和交叉验证集误差近似时：偏差/欠拟合</p></li><li><p>交叉验证集误差远大于训练集误差时：方差/过拟合</p></li></ul><h4 id="10-5-Regularization-and-Bias-Variance"><a href="#10-5-Regularization-and-Bias-Variance" class="headerlink" title="10.5 Regularization and Bias_Variance"></a>10.5 Regularization and Bias_Variance</h4><p>在我们在训练模型的过程中，一般会使用一些正则化方法来防止过拟合。但是我们可能会正则化的程度太高或太小了，即我们在选择λ的值时也需要思考与刚才选择多项式模型次数类似的问题。</p><p>我们选择一系列的想要测试的 $\lambda$ 值，通常是 0-10之间的呈现2倍关系的值（如：$0,0.01,0.02,0.04,0.08,0.15,0.32,0.64,1.28,2.56,5.12,10$ 共12个）。 我们同样把数据分为训练集、交叉验证集和测试集。</p><p>选择$\lambda$的方法为：</p><ol><li>使用训练集训练出12个不同程度正则化的模型</li><li>用12个模型分别对交叉验证集计算的出交叉验证误差</li><li>选择得出交叉验证误差最小的模型</li><li>运用步骤3中选出模型对测试集计算得出推广误差，我们也可以同时将训练集和交叉验证集模型的代价函数误差与λ的值绘制在一张图表上</li></ol><ul><li>当 $\lambda$ 较小时，训练集误差较小（过拟合）而交叉验证集误差较大</li><li>随着 $\lambda$ 的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加</li></ul><h4 id="10-6-Learning-Curves"><a href="#10-6-Learning-Curves" class="headerlink" title="10.6 Learning Curves"></a>10.6 Learning Curves</h4><p>我经常使用学习曲线来判断某一个学习算法是否处于偏差、方差问题。学习曲线是学习算法的一个很好的<strong>合理检验</strong>（<strong>sanity check</strong>）。学习曲线是将训练集误差和交叉验证集误差和训练集样本数量（$m$）的函数进行图表绘制。</p><ul><li><p>在高偏差/欠拟合的情况下，增加数据到训练集不一定能有帮助。</p></li><li><p>在高方差/过拟合的情况下，增加更多数据到训练集可能可以提高算法效果。</p></li></ul><h4 id="10-7-Deciding-What-to-Do-Next-Revisited"><a href="#10-7-Deciding-What-to-Do-Next-Revisited" class="headerlink" title="10.7 Deciding What to Do Next Revisited"></a>10.7 Deciding What to Do Next Revisited</h4><p>回顾 10.1 中提出的六种可选的下一步，让我们来看一看我们在什么情况下应该怎样选择：</p><ol><li><p>获得更多的训练样本——解决高方差</p></li><li><p>尝试减少特征的数量——解决高方差</p></li><li><p>尝试获得更多的特征——解决高偏差</p></li><li><p>尝试增加多项式特征——解决高偏差</p></li><li><p>尝试减少正则化程度λ——解决高偏差</p></li><li><p>尝试增加正则化程度λ——解决高方差</p></li></ol><h3 id="11-Machine-Learning-System-Design"><a href="#11-Machine-Learning-System-Design" class="headerlink" title="11. Machine Learning System Design"></a>11. Machine Learning System Design</h3><h4 id="11-1-Error-Analysis"><a href="#11-1-Error-Analysis" class="headerlink" title="11.1 Error Analysis"></a>11.1 Error Analysis</h4><p>构建一个学习算法的推荐方法为：</p><ol><li>从一个简单的能快速实现的算法开始，实现该算法并用交叉验证集数据测试这个算法</li><li>绘制学习曲线，决定是增加更多数据，或者添加更多特征，还是其他选择</li><li>进行<strong>误差分析</strong>：人工检查交叉验证集中我们算法中产生预测误差的样本，看看这些样本是否有某种系统化的趋势</li></ol><blockquote><p>注意，在交叉验证向量上来做误差分析</p></blockquote><h4 id="11-2-Error-Metrics-for-Skewed-Classes"><a href="#11-2-Error-Metrics-for-Skewed-Classes" class="headerlink" title="11.2 Error Metrics for Skewed Classes"></a>11.2 Error Metrics for Skewed Classes</h4><p>在前面的课程中提到了误差分析，以及设定误差度量值的重要性。那就是，设定某个实数来评估你的学习算法，并衡量它的表现，有了算法的评估和误差度量值。有一件重要的事情会对于你的学习算法造成非常微妙的影响，这件重要的事情就是<strong>偏斜类</strong>（<strong>skewed classes</strong>）的问题。类偏斜情况表现为我们的训练集中有非常多的同一种类的样本，只有很少或没有其他类的样本。这时我们有两个指标可以评判，分别是 <strong>精准度</strong>（<strong>Precision</strong>）和<strong>召回率</strong>（<strong>Recall</strong>）</p><p> 我们将算法预测的结果分成四种情况：</p><ol><li><strong>正确肯定</strong>（<strong>True Positive,TP</strong>）：预测为真，实际为真</li><li><strong>正确否定</strong>（<strong>True Negative,TN</strong>）：预测为假，实际为假</li><li><strong>错误肯定</strong>（<strong>False Positive,FP</strong>）：预测为真，实际为假</li><li><strong>错误否定</strong>（<strong>False Negative,FN</strong>）：预测为假，实际为真</li></ol><script type="math/tex; mode=display">\text{Precision rate}=\frac{TP}{(TP+FP)}</script><script type="math/tex; mode=display">\text{Recall rate}=\frac{TP}{(TP+FN)}</script><p><img src="/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_2/pic11-1.png" alt></p><h5 id="【Python-代码】"><a href="#【Python-代码】" class="headerlink" title="【Python 代码】"></a>【Python 代码】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">correct = [<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> a^b == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> (a,b) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, Y)]<br>accuracy = (<span class="hljs-built_in">sum</span>(correct) / <span class="hljs-built_in">len</span>(correct))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;accuracy = &#123;0:.0f&#125;%&#x27;</span>.<span class="hljs-built_in">format</span>(accuracy*<span class="hljs-number">100</span>))<br><br><span class="hljs-comment"># a^b : a和b中不同时存在的元素</span><br><br><span class="hljs-comment"># or</span><br><br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><br><span class="hljs-built_in">print</span>(classification_report(Y, predictions))<br><br><span class="hljs-comment"># precision查准率，recall召回率，f1-score调和平均数</span><br></code></pre></td></tr></table></figure><h4 id="11-3-Trading-Off-Precision-and-Recall"><a href="#11-3-Trading-Off-Precision-and-Recall" class="headerlink" title="11.3 Trading Off Precision and Recall"></a>11.3 Trading Off Precision and Recall</h4><p>如果我们希望只在非常确信的情况下预测为真，即我们希望更高的查准率，我们可以使用比0.5更大的阈值，如0.7，0.9。相反如果我们希望提高查全率，我们可以使用比0.5更小的阈值，如0.3。</p><p>而选择一个比较优秀的阈值可以通过计算<strong>F1 值</strong>（<strong>F1 Score</strong>）来判断</p><script type="math/tex; mode=display">2\frac{PR}{P+R}</script><h2 id="Week-7-Support-Vector-Machines"><a href="#Week-7-Support-Vector-Machines" class="headerlink" title="Week 7 : Support Vector Machines"></a>Week 7 : Support Vector Machines</h2><h3 id="12-Large-Margin-Classification"><a href="#12-Large-Margin-Classification" class="headerlink" title="12. Large Margin Classification"></a>12. Large Margin Classification</h3><h4 id="12-1-Optimization-Objective"><a href="#12-1-Optimization-Objective" class="headerlink" title="12.1 Optimization Objective"></a>12.1 Optimization Objective</h4><p>支持向量机(<strong>Support Vector Machine</strong>) 代价函数与逻辑回归相似，却更加强大</p><p>回顾之前逻辑回归的代价函数</p><script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}\left[\sum_{i=1}^{m} y^{(i)} \log h_{\theta}\left(x^{(i)}\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]+\frac{\lambda}{2 m} \sum_{j=1}^{n} \theta_{j}^{2}</script><p>这个式子括号中的函数可以分为两部分</p><script type="math/tex; mode=display">-y \log \frac{1}{1+e^{-\theta^{T} x}},\qquad-(1-y) \log \left(1-\frac{1}{1+e^{-\theta^{T} x}}\right)</script><p>当 $y=1$ 时只左边部分的值不为 0 ，当 $y=0$ 时则右边起作用，因此可得到以下两图。</p><p><img src="/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_2/pic12-1.png" alt></p><p>我们从这里开始建立支持向量机，新的代价函数将会以图中虚线的形式表现出，它是一条同逻辑回归非常相似的直线。这里采用这种表示方式可以在之后带来计算上的优势。</p><p>而对于代价函数本身，我们也有些许更变，</p><script type="math/tex; mode=display">\min _{\theta} C \sum_{i=1}^{m}\left[y^{(i)} \operatorname{cost}_{1}\left(\theta^{T} x^{(i)}\right)+\left(1-y^{(i)}\right) \operatorname{cost}_{0}\left(\theta^{T} x^{(i)}\right)\right]+\frac{1}{2} \sum_{i=1}^{n} \theta_{j}^{2}</script><p>其中 $cost_1,cost_2$ 是上图虚线采用的函数，同时我们去掉了 $\frac1m$ 改用乘以一个常量 $C$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sklearn.svm<br><br>svc1 = sklearn.svm.LinearSVC(C=<span class="hljs-number">1</span>, loss=<span class="hljs-string">&#x27;hinge&#x27;</span>, max_iter=<span class="hljs-number">20000</span>)<br>svc1.fit(data[[<span class="hljs-string">&#x27;X1&#x27;</span>, <span class="hljs-string">&#x27;X2&#x27;</span>]], data[<span class="hljs-string">&#x27;y&#x27;</span>])<br>svc1.score(data[[<span class="hljs-string">&#x27;X1&#x27;</span>, <span class="hljs-string">&#x27;X2&#x27;</span>]], data[<span class="hljs-string">&#x27;y&#x27;</span>])<br><br><span class="hljs-comment"># The confidence score for a sample is the signed distance of that sample to the hyperplane.</span><br>data[<span class="hljs-string">&#x27;SVM1 Confidence&#x27;</span>] = svc1.decision_function(data[[<span class="hljs-string">&#x27;X1&#x27;</span>, <span class="hljs-string">&#x27;X2&#x27;</span>]])<br><br>fig, ax = plt.subplots(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">6</span>))<br>ax.scatter(data[<span class="hljs-string">&#x27;X1&#x27;</span>], data[<span class="hljs-string">&#x27;X2&#x27;</span>], s=<span class="hljs-number">50</span>, c=data[<span class="hljs-string">&#x27;SVM1 Confidence&#x27;</span>], cmap=<span class="hljs-string">&#x27;seismic&#x27;</span>) <span class="hljs-comment"># 按照距离给定颜色</span><br>ax.set_title(<span class="hljs-string">&#x27;SVM(C=1) Decision Confidence&#x27;</span>)<br>ax.set_xlabel(<span class="hljs-string">&#x27;X1&#x27;</span>)<br>ax.set_ylabel(<span class="hljs-string">&#x27;X2&#x27;</span>)<br><br><span class="hljs-comment"># 决策边界, 使用等高线表示</span><br>x1 = np.arange(<span class="hljs-number">0</span>, <span class="hljs-number">4.5</span>, <span class="hljs-number">0.01</span>)<br>x2 = np.arange(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0.01</span>)<br>x1, x2 = np.meshgrid(x1, x2)<br>y_pred = np.array([svc1.predict(np.vstack((a, b)).T) <span class="hljs-keyword">for</span> (a, b) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(x1, x2)])<br>plt.contour(x1, x2, y_pred, colors=<span class="hljs-string">&#x27;g&#x27;</span>, linewidths=<span class="hljs-number">.5</span>)<br><br>plt.show()<br></code></pre></td></tr></table></figure><h4 id="12-2-Large-Margin-Intuition"><a href="#12-2-Large-Margin-Intuition" class="headerlink" title="12.2 Large Margin Intuition"></a>12.2 Large Margin Intuition</h4><p>人们有时将支持向量机看作是大间距分类器。这个可以从代价函数中的 $cost_1,cost_2$ 可以看出。</p><p>当我们有一个样本 $y=1$，只有在$z&gt;=1$时 (不仅仅是大于 0)，代价函数 $cost_1(z)$ 才等于0。这种做法相当于提高了函数的阈值，鼓励做出更精准的判断。</p><p>如果 $C$ 非常大，则最小化代价函数的时候，我们将会很希望找到一个使第一项为0的最优解。</p><p>因此代价函数也可以写成以下格式的优化问题</p><script type="math/tex; mode=display">\begin{aligned}&\min _{\theta} \frac{1}{2} \sum_{j=1}^{n} \theta_{j}^{2}\\s.t.\qquad &\theta^{T} x^{(i)} \geq 1 \text { if } y^{(i)}=1 \\&\theta^{T} x^{(i)} \leq-1  \text { if } y^{(i)}=0\end{aligned}</script><p><img src="/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_2/pic12-2.jpg" alt></p><p>从图中来看，分类器可以有很多种解 (紫，绿，黑)，但可以看出黑色线是最好的结果，因为它使得两个类有比较大的间距，而紫线和绿线离训练样本就非常近，在分离样本的时候就会比黑线表现差。因此，这个距离叫做支持向量机的间距，而这是支持向量机具有鲁棒性的原因，因为它努力用一个最大间距来分离样本。</p><h4 id="12-3-Mathematics-Behind-Large-Margin-Classification"><a href="#12-3-Mathematics-Behind-Large-Margin-Classification" class="headerlink" title="12.3 Mathematics Behind Large Margin Classification"></a>12.3 Mathematics Behind Large Margin Classification</h4><p>首先，我们可以通过 <a href="https://achlier.github.io/2021/02/15/Inner_product_and_Cross_Product/">之前的笔记</a> 复习一下关于向量内积的知识。</p><p>回顾之前的优化问题，如果假设 $n=2$ ，$\theta_0=0$，其中</p><script type="math/tex; mode=display">\sum_{j=1}^{n} \theta_{j}^{2}=\frac{1}{2}\left({\theta_1^2+\theta_2^2}\right)=\frac{1}{2}\left(\sqrt{\theta_1^2+\theta_2^2}\right)^2=\frac{1}{2}\left\| \theta \right\|^2</script><p>因此支持向量机做的全部事情，就是<strong>极小化参数向量</strong>$\theta$<strong>范数的平方，或者说长度的平方</strong>。</p><p><img src="/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_2/pic12-3.jpg" alt></p><p>图示中绿线为决策边界，而黑线就是向量$\theta$ ，$θ^Tx^{(i)}$ 相当于 $x^{(i)}$ 在向量$\theta$上的投影乘以向量 $\theta$ 的范数。我们可以将此转换为 $p^{(i)}\cdot{\left| \theta \right|}$。</p><script type="math/tex; mode=display">\begin{aligned}&\min _{\theta} \frac{1}{2} \sum_{j=1}^{n} \theta_{j}^{2}\\s.t.\qquad &p^{(i)}\cdot{\left\| \theta \right\|} \geq 1 \text { if } y^{(i)}=1 \\&p^{(i)}\cdot{\left\| \theta \right\|} \leq-1  \text { if } y^{(i)}=0\end{aligned}</script><p>为了让$\left| \theta \right|$尽量小并且满足约束条件，我们需要使$p^{(i)}$尽量大，即$x^{(i)}$ 在向量$\theta$上的投影尽量大，即$x^{(i)}$远离决策边界。</p><h4 id="12-4-Kernels"><a href="#12-4-Kernels" class="headerlink" title="12.4 Kernels"></a>12.4 Kernels</h4><p><img src="/2022/08/05/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_2/pic12-4.jpg" alt></p><p>我们之前讨论过可以使用高级数的多项式模型来解决无法用直线进行分隔的分类问题，而除此之外，我们还可以用核函数计算出新的特征然后进行训练。</p><p>给定一个训练样本$x$，我们利用$x$的各个特征与我们预先选定的<strong>地标</strong>(<strong>landmarks</strong>) $l^{(1)},l^{(2)},l^{(3)}$的近似程度来选取新的特征$f_1,f_2,f_3$。</p><script type="math/tex; mode=display">f_{1}=\operatorname{similarity}\left(x, l^{(1)}\right)=\exp \left(-\frac{\left\|x-l^{(1)}\right\|^{2}}{2 \sigma^{2}}\right)</script><p>上例中的 $\operatorname{similarity}(x,l^{(1)})$ 就是核函数，准确来说，这是一个<strong>高斯核函数</strong>(<strong>Gaussian Kernel</strong>)。 我们通常直接写成 $k(x,l^{(1)})$</p><ul><li>如果一个训练样本$x$与地标$l$之间的距离近似于0，则新特征 $f$近似于$e^{-0}=1$</li><li>如果一个训练样本$x$与地标$l$之间距离较远，则新特征$f$近似于$e^{-(一个较大的数)}=0$</li></ul><p>因此，当对新特征进行回归的时候，当系数都为正，越是靠近地标的值就越接近1</p><p>在高斯核函数之外我们还有其他一些选择，如：</p><ul><li><p>多项式核函数（<strong>Polynomial Kernel</strong>）</p></li><li><p>字符串核函数（<strong>String kernel</strong>）</p></li><li><p>卡方核函数（ <strong>chi-square kernel</strong>）</p></li><li><p>直方图交集核函数（<strong>histogram intersection kernel</strong>）</p></li><li>等…</li></ul><p>这些核函数的目标也都是根据训练集和地标之间的距离来构建新特征，这些核函数需要满足Mercer’s定理，才能被支持向量机的优化软件正确处理。</p><p>在具体实施过程中，当我们将核函数与<strong>SVM</strong>结合时，我们还需要对代价函数最后的正则化项进行些微调整，在计算$\sum_{j=1}^{n=m}\theta _{j}^{2}=\theta^{T}\theta $时，我们用$\theta^TM\theta$代替$\theta^T\theta$，其中$M$是根据我们选择的核函数而不同的一个矩阵。这样做的原因是为了简化计算。</p><p>理论上讲，我们也可以在逻辑回归中使用核函数，但是上面使用 $M$来简化计算的方法不适用与逻辑回归，因此计算将非常耗费时间。</p><h5 id="【参数-C-和-sigma-的影响】"><a href="#【参数-C-和-sigma-的影响】" class="headerlink" title="【参数$C$和$\sigma$的影响】"></a>【参数$C$和$\sigma$的影响】</h5><ul><li>$C=1/\lambda$</li><li>$C$ 较大时，相当于$\lambda$较小，可能会导致过拟合，高方差；</li><li>$C$ 较小时，相当于$\lambda$较大，可能会导致低拟合，高偏差；</li><li>$\sigma$较大时，可能会导致低方差，高偏差；</li><li>$\sigma$较小时，可能会导致低偏差，高方差。</li></ul><p><strong>下面是一些普遍使用的准则：</strong></p><p>$n$为特征数，$m$为训练样本数。</p><ul><li>如果相较于$m$而言，$n$要大许多，即训练集数据量不够支持我们训练一个复杂的非线性模型，我们选用逻辑回归模型或者不带核函数的支持向量机。</li><li>如果$n$较小，而且$m$大小中等，例如$n$在 1-1000 之间，而$m$在10-10000之间，使用高斯核函数的支持向量机。</li><li>如果$n$较小，而$m$较大，例如$n$在1-1000之间，而$m$大于50000，则使用支持向量机会非常慢，解决方案是创造、增加更多的特征，然后使用逻辑回归或不带核函数的支持向量机。</li></ul><p>值得一提的是，神经网络在以上三种情况下都可能会有较好的表现，但是训练神经网络可能非常慢，选择支持向量机的原因主要在于它的代价函数是凸函数，不存在局部最小值。</p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Neural Networks</tag>
      
      <tag>Support Vector Machines</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【课程】吴恩达机器学习课程(一)</title>
    <link href="/2022/08/03/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_1/"/>
    <url>/2022/08/03/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于吴恩达机器学习 - Machine Learning Specialization <a href="https://www.coursera.org/specializations/machine-learning-introduction">课程</a> 的笔记第一部分；基础部分；</p></blockquote><span id="more"></span><h1 id="Course-1-Supervised-Machine-Learning-Regression-and-Classification"><a href="#Course-1-Supervised-Machine-Learning-Regression-and-Classification" class="headerlink" title="Course 1 : Supervised Machine Learning: Regression and Classification"></a>Course 1 : Supervised Machine Learning: Regression and Classification</h1><p>In the first course of the Machine Learning Specialization, you will:</p><ul><li>Build machine learning models in Python using popular machine learning libraries NumPy and scikit-learn. </li><li>Build and train supervised machine learning models for prediction and binary classification tasks, including linear regression and logistic regression</li></ul><h2 id="Week-1-Introduction-to-Machine-Learning"><a href="#Week-1-Introduction-to-Machine-Learning" class="headerlink" title="Week 1 : Introduction to Machine Learning"></a>Week 1 : Introduction to Machine Learning</h2><h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><h4 id="1-1-监督学习-Supervised-Learning"><a href="#1-1-监督学习-Supervised-Learning" class="headerlink" title="1.1 监督学习 Supervised Learning"></a>1.1 监督学习 Supervised Learning</h4><ul><li>回归问题 - 连续输出</li><li>分类问题（支持向量机） - 离散输出</li></ul><h4 id="1-2-无监督学习-Unsupervised-Learning"><a href="#1-2-无监督学习-Unsupervised-Learning" class="headerlink" title="1.2 无监督学习 Unsupervised Learning"></a>1.2 无监督学习 Unsupervised Learning</h4><ul><li><p>聚类算法 - 把个体聚类到不同的类或不同类型的组</p><ul><li>谷歌新闻搜索非常多的新闻事件，自动地将同一主题的新闻事件聚类到一起</li><li>组织大型计算机集群，判断什么样的机器易于协同地工作，使数据中心工作得更高效</li><li>进行社交网络的分析，自动地将熟悉的人分在一起</li><li>通过检索消费者信息，自动地发现市场分类，并地把顾客划分到不同的细分市场中，更有效地在不同的细分市场一起进行销售产品</li><li>天文数据分析</li></ul></li><li><p>鸡尾酒会问题 cocktail party problem - 将两个说话的声音区分开来</p></li></ul><h3 id="2-Linear-Regression-with-One-Variable"><a href="#2-Linear-Regression-with-One-Variable" class="headerlink" title="2. Linear Regression with One Variable"></a>2. Linear Regression with One Variable</h3><h4 id="2-1-Model-Representation"><a href="#2-1-Model-Representation" class="headerlink" title="2.1 Model Representation"></a>2.1 Model Representation</h4><p>我们将要用来描述这个回归问题的标记如下:</p><ul><li>$m$ 代表训练集中实例的数量</li><li>$x$  代表特征/输入变量</li><li>$y$ 代表目标变量/输出变量</li><li>$\left( x,y \right)$ 代表训练集中的实例</li><li>$(x^{(i)},y^{(i)})$ 代表第$i$ 个观察实例</li><li>$h$  代表学习算法的解决方案或函数也称为假设（<strong>hypothesis</strong>）</li><li>$\theta_{0}$ 和 $\theta_{1}$ 代表需要训练的参数（<strong>parameters</strong>）</li></ul><p>因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题</p><script type="math/tex; mode=display">h_\theta ( x )=\theta_{0} + \theta_{1}x</script><h4 id="2-2-Cost-Function"><a href="#2-2-Cost-Function" class="headerlink" title="2.2 Cost Function"></a>2.2 Cost Function</h4><p>我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数。 即使得代价函数 $J$ 最小</p><script type="math/tex; mode=display">J \left( \theta_0, \theta_1 \right) = \frac{1}{2m}\sum\limits_{i=1}^m \left( h_{\theta}(x^{(i)})-y^{(i)} \right)^{2}</script><blockquote><p>此处 $\frac12$ 是为了在后面求导的时候能消去 2，方便运算</p></blockquote><p>此处采用 <strong>Squared error cost function</strong> 是因为，对于大多数问题，特别是回归问题，都是一个合理的选择。还有其他的代价函数也能很好地发挥作用，但 <strong>Squared error cost function</strong> 是解决回归问题最常用的手段了。</p><h5 id="【Python-代码】"><a href="#【Python-代码】" class="headerlink" title="【Python 代码】"></a>【Python 代码】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cost</span>(<span class="hljs-params">X, y, theta</span>):<br>    <br>    inner = np.power(((X * theta.T) - y), <span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>(inner) / (<span class="hljs-number">2</span> * <span class="hljs-built_in">len</span>(X))<br></code></pre></td></tr></table></figure><h4 id="2-3-Gradient-Descent-Intuition"><a href="#2-3-Gradient-Descent-Intuition" class="headerlink" title="2.3 Gradient Descent Intuition"></a>2.3 Gradient Descent Intuition</h4><p>梯度下降算法为</p><script type="math/tex; mode=display">\theta_{j}:=\theta_{j}-\alpha \frac{\partial }{\partial \theta_{j}}J\left(\theta \right)</script><p>在梯度下降法中，当我们接近局部最低点时，梯度下降法会自动采取更小的幅度，这是因为当我们接近局部最低点时，很显然在局部最低时导数等于零，所以当我们接近局部最低时，导数值会自动变得越来越小，所以梯度下降将自动采取较小的幅度，这就是梯度下降的做法。</p><p>其中 $\alpha$ 是学习率（<strong>learning rate</strong>），决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大。</p><ul><li>如果 $\alpha$ 太小，更新可能会很慢，它会需要很多步才能到达全局最低点</li><li>如果 $\alpha$ 太大，梯度下降法可能会越过最低点，会导致无法收敛，甚至发散。</li></ul><p>同时，当参数已经处于局部最低点时，梯度下降法将不会改变参数的值，这导致参数最终停留在局部最低而不是全局最优点。</p><blockquote><p>显然，在梯度下降的过程中要考虑合适的学习率与初始值，才能得到好的结果</p></blockquote><p>更深入的理解可以观看B站视频《图解机器学习的数学直觉》 中，图解微积分  <a href="https://www.bilibili.com/video/BV1iW411T781?p=36&amp;share_source=copy_pc">Jacobian</a> 和 [<a href="https://www.bilibili.com/video/BV1iW411T781?p=37">Jacobian matrix</a> 的部分</p><h4 id="2-4-Gradient-Descent-for-Linear-Regression"><a href="#2-4-Gradient-Descent-for-Linear-Regression" class="headerlink" title="2.4 Gradient Descent for Linear Regression"></a>2.4 Gradient Descent for Linear Regression</h4><p>对我们之前的线性回归问题运用梯度下降法，关键在于求出代价函数的导数，即：</p><script type="math/tex; mode=display">\frac{\partial }{\partial \theta _{j}}J(\theta _{0},\theta _{1})=\frac{\partial }{\partial \theta _{j}}\frac{1}{2m}\sum\limits_{i=1}^{m}{\left( h_{\theta }(x^{(i)})-y^{(i)} \right)}^{2}</script><ul><li><p>$j=0$  时：$\frac{\partial }{\partial \theta _{0}}J(\theta _{0},\theta _{1})=\frac{1}{m}\sum\limits_{i=1}^{m}{\left( h_{\theta }(x^{(i)})-y^{(i)} \right)}$</p></li><li><p>$j=1$  时：$\frac{\partial }{\partial \theta _{1}}J(\theta _{0},\theta _{1})=\frac{1}{m}\sum\limits_{i=1}^{m}{\left( \left( h_{\theta }(x^{(i)})-y^{(i)} \right)\cdot x^{(i)} \right)}$</p></li></ul><blockquote><p>此处采用的是<strong>批量梯度下降</strong> （batch gradient descent），即在梯度下降的每一步中，用到了所有的训练样本 （$m$) 来进行函数优化</p></blockquote><p>则算法改写成：</p><script type="math/tex; mode=display">\theta_{0}:=\theta_{0}-a\frac{1}{m}\sum\limits_{i=1}^{m}{ \left(h_{\theta }(x^{(i)})-y^{(i)} \right)}</script><script type="math/tex; mode=display">\theta_{1}:=\theta_{1}-a\frac{1}{m}\sum\limits_{i=1}^{m}{\left( \left(h_{\theta }(x^{(i)})-y^{(i)} \right)\cdot x^{(i)} \right)}</script><p><strong>线性回归的代价函数都是凸函数</strong>（convex function），因此不用担心仅仅得到局部最优的结果。</p><blockquote><p>注意，国内对凹凸函数的定义与国外相反，仅有经济学上是一致的，在这我们定义向下凸出的为凸函数。</p></blockquote><h5 id="【Python-代码】-1"><a href="#【Python-代码】-1" class="headerlink" title="【Python 代码】"></a>【Python 代码】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient</span>(<span class="hljs-params">X, Y, theta, alpha, iters</span>):<br>    <br>    parameters = <span class="hljs-built_in">int</span>(theta.shape[<span class="hljs-number">1</span>])<br>    cost = np.zeros(iters)<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(iters):<br>        error = X * theta.T - Y<br>        term = np.multiply(error, X)<br>        theta= theta - alpha / <span class="hljs-built_in">len</span>(X) * np.<span class="hljs-built_in">sum</span>(term,axis=<span class="hljs-number">0</span>)<br>        cost[i] = computeCost(X, Y, theta)<br>    <br>    <span class="hljs-keyword">return</span> theta, cost<br><span class="hljs-comment"># 在函数内赋值不会对 theta 做影响</span><br></code></pre></td></tr></table></figure><h5 id="【scikit-learn】"><a href="#【scikit-learn】" class="headerlink" title="【scikit-learn】"></a>【scikit-learn】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> linear_model<br><br>model = linear_model.LinearRegression()<br>model.fit(X, Y)<br><br>x = np.array(X[:, <span class="hljs-number">1</span>].A1)<br>y = model.predict(X).flatten()<br><br>fig, ax = plt.subplots(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">8</span>))<br>ax.plot(x, y, <span class="hljs-string">&#x27;r&#x27;</span>, label=<span class="hljs-string">&#x27;Prediction&#x27;</span>)<br>ax.scatter(data.Population, data.Profit, label=<span class="hljs-string">&#x27;Traning Data&#x27;</span>)<br>ax.legend(loc=<span class="hljs-number">2</span>)<br>ax.set_xlabel(<span class="hljs-string">&#x27;Population&#x27;</span>)<br>ax.set_ylabel(<span class="hljs-string">&#x27;Profit&#x27;</span>)<br>ax.set_title(<span class="hljs-string">&#x27;Predicted Profit vs. Population Size&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><h3 id="3-Linear-Algebra-Review"><a href="#3-Linear-Algebra-Review" class="headerlink" title="3. Linear Algebra Review"></a>3. Linear Algebra Review</h3><p>此部分由于过于基础可以参考 <a href="https://achlier.github.io/2022/07/28/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数单独的笔记 </a> 进行学习</p><h2 id="Week-2-linear-regression-with-multiple-variables"><a href="#Week-2-linear-regression-with-multiple-variables" class="headerlink" title="Week 2 : linear regression with multiple variables"></a>Week 2 : linear regression with multiple variables</h2><h3 id="4-Multivariate-Linear-Regression"><a href="#4-Multivariate-Linear-Regression" class="headerlink" title="4. Multivariate Linear Regression"></a>4. Multivariate Linear Regression</h3><h4 id="4-1-Multiple-Features"><a href="#4-1-Multiple-Features" class="headerlink" title="4.1 Multiple Features"></a>4.1 Multiple Features</h4><p>增添更多特征 $\left( x_{1},x_{2},…,x_{n} \right)$ 后，我们引入一系列新的注释：</p><ul><li>$n$ 代表特征的数量</li><li>${x^{\left( i \right)}}$代表第 $i$ 个训练实例，是特征矩阵中的第$i$行，是一个<strong>向量</strong>（<strong>vector</strong>）</li><li>$x_{j}^{\left( i \right)}$代表特征矩阵中第 $i$ 行的第 $j$ 个特征，也就是第 $i$ 个训练实例的第 $j$ 个特征</li><li>支持多变量的假设 $h$ 表示为：$h_{\theta}( x )=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}+…+\theta_{n}x_{n}$</li><li>因此公式可以简化为：$h_{\theta} ( x )=\theta^{T}X$</li></ul><h4 id="4-2-Gradient-Descent-for-Multiple-Variables"><a href="#4-2-Gradient-Descent-for-Multiple-Variables" class="headerlink" title="4.2 Gradient Descent for Multiple Variables"></a>4.2 Gradient Descent for Multiple Variables</h4><p>为了使得公式能够简化一些，引入$x_{0}=1$</p><p>多变量线性回归的批量梯度下降算法，当$n&gt;=1$时，</p><script type="math/tex; mode=display">\theta_j:=\theta_j-a\frac{1}{m}\sum\limits_{i=1}^{m}(h_{\theta }(x^{(i)})-y^{(i)})x_{j}^{(i)}</script><h5 id="【Python-代码】-2"><a href="#【Python-代码】-2" class="headerlink" title="【Python 代码】"></a>【Python 代码】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 画出拟合平面</span><br><span class="hljs-keyword">from</span> mpl_toolkits.mplot3d <span class="hljs-keyword">import</span> Axes3D<br><br>fig = plt.figure()<br>ax = Axes3D(fig)<br>X_ = np.arange(mins[<span class="hljs-number">0</span>], maxs[<span class="hljs-number">0</span>]+<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>Y_ = np.arange(mins[<span class="hljs-number">1</span>], maxs[<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>X_, Y_ = np.meshgrid(X_, Y_)<br>Z_ = theta[<span class="hljs-number">0</span>] + theta[<span class="hljs-number">1</span>] * X_ + theta[<span class="hljs-number">2</span>] * Y_<br><br><span class="hljs-comment"># 手动设置角度</span><br>ax.view_init(elev=<span class="hljs-number">25</span>, azim=<span class="hljs-number">125</span>)<br><br>ax.set_xlabel(<span class="hljs-string">&#x27;Size&#x27;</span>)<br>ax.set_ylabel(<span class="hljs-string">&#x27;Bedrooms&#x27;</span>)<br>ax.set_zlabel(<span class="hljs-string">&#x27;Price&#x27;</span>)<br><br>ax.plot_surface(X_, Y_, Z_, rstride=<span class="hljs-number">1</span>, cstride=<span class="hljs-number">1</span>, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br><br>ax.scatter(data_[:, <span class="hljs-number">0</span>], data_[:, <span class="hljs-number">1</span>], data_[:, <span class="hljs-number">2</span>])<br>plt.show()<br></code></pre></td></tr></table></figure><h4 id="4-3-Gradient-Descent-in-Practice-I-Feature-Scaling"><a href="#4-3-Gradient-Descent-in-Practice-I-Feature-Scaling" class="headerlink" title="4.3 Gradient Descent in Practice I - Feature Scaling"></a>4.3 Gradient Descent in Practice I - Feature Scaling</h4><p>在我们面对多维特征问题的时候，我们需要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛</p><p>考虑到我们设定 $x_0=1$ , 因此我们希望变量的值都在 $[-1,1]$ 左右</p><p>如果不采用 Feature Scaling ，而直接进行计算，可能会进入如下图红色路径需要多次迭代才能收敛的状态</p><p><img src="/2022/08/03/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_1/pic4-3.jpg" alt></p><h5 id="【Mean-normalization】"><a href="#【Mean-normalization】" class="headerlink" title="【Mean normalization】"></a>【Mean normalization】</h5><p>我们在对数据进行处理的时候可以直接除一个数，或者是使用均值归一化</p><script type="math/tex; mode=display">x_n=\frac{x_n-\mu_n}{s_n}</script><p>其中 $\mu_n$是平均值，$s_n$是标准差</p><h5 id="【Python-代码】-3"><a href="#【Python-代码】-3" class="headerlink" title="【Python 代码】"></a>【Python 代码】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">data_norm = (data - data.mean()) / data.std()<br><br><span class="hljs-comment"># or</span><br><br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><br>data_norm = scaler.fit_transform(data)<br><br><span class="hljs-comment"># 参数转化为缩放前</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">theta_transform</span>(<span class="hljs-params">theta, means, stds</span>):<br>    temp = means[:-<span class="hljs-number">1</span>] * theta[<span class="hljs-number">1</span>:] / stds[:-<span class="hljs-number">1</span>]<br>    theta[<span class="hljs-number">0</span>] = (theta[<span class="hljs-number">0</span>] - np.<span class="hljs-built_in">sum</span>(temp)) * stds[-<span class="hljs-number">1</span>] + means[-<span class="hljs-number">1</span>]<br>    theta[<span class="hljs-number">1</span>:] = theta[<span class="hljs-number">1</span>:] * stds[-<span class="hljs-number">1</span>] / stds[:-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">return</span> theta.reshape(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h4 id="4-4-Gradient-Descent-in-Practice-II-Learning-Rate"><a href="#4-4-Gradient-Descent-in-Practice-II-Learning-Rate" class="headerlink" title="4.4 Gradient Descent in Practice II - Learning Rate"></a>4.4 Gradient Descent in Practice II - Learning Rate</h4><p>梯度下降算法的每次迭代受到学习率的影响，如果学习率 $\alpha$ 过小，则达到收敛所需的迭代次数会非常高；如果学习率过 $\alpha$  大，每次迭代可能不会减小代价函数，反而会越过局部最小值导致无法收敛。我们可以通过观察迭代次数与 $J(\theta)$ 的关系来判断学习率取值的好坏。</p><p>通常可以考虑尝试些学习率：$\alpha=…,0.01，0.03，0.1，0.3，1，3，10,…$</p><h4 id="4-5-Features-and-Polynomial-Regression"><a href="#4-5-Features-and-Polynomial-Regression" class="headerlink" title="4.5 Features and Polynomial Regression"></a>4.5 Features and Polynomial Regression</h4><p>线性回归并不适用于所有数据，有时我们需要曲线来适应我们的数据，比如一个二次方模型：</p><script type="math/tex; mode=display">h_{\theta}( x )=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}^2</script><h4 id="4-6-Normal-Equation"><a href="#4-6-Normal-Equation" class="headerlink" title="4.6 Normal Equation"></a>4.6 Normal Equation</h4><p>到目前为止，我们都在使用梯度下降算法，但是对于某些线性回归问题，<strong>Normal Equation</strong> 作为更好的解决方案可以一次性解出最优的值。</p><script type="math/tex; mode=display">\theta =\left( {X^T}X \right)^{-1}X^{T}y</script><p>在使用这个方法的时候，Feature Scaling 可以不用做</p><p>梯度下降与正规方程的比较：</p><div class="table-container"><table><thead><tr><th style="text-align:center">梯度下降</th><th style="text-align:center">正规方程</th></tr></thead><tbody><tr><td style="text-align:center">需要选择学习率$\alpha$</td><td style="text-align:center">不需要选择学习率$\alpha$</td></tr><tr><td style="text-align:center">需要多次迭代</td><td style="text-align:center">一次运算得出</td></tr><tr><td style="text-align:center">当特征数量$n$大时也能较好适用</td><td style="text-align:center">需要计算$\left( X^TX \right)^{-1}$ 如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为$O\left( n^3 \right)$，通常来说当$n$小于10000 时还是可以接受的</td></tr><tr><td style="text-align:center">适用于各种类型的模型</td><td style="text-align:center">只适用于线性模型，不适合逻辑回归模型等其他模型</td></tr></tbody></table></div><h5 id="【推导过程】"><a href="#【推导过程】" class="headerlink" title="【推导过程】"></a>【推导过程】</h5><script type="math/tex; mode=display">J\left( \theta  \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}\left( h_{\theta}\left( x^{(i)} \right)-y^{(i)} \right)^{2}</script><script type="math/tex; mode=display">h_{\theta}( x )=\theta^{T}X=\theta_{0}x_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}+\cdots+\theta_{n}x_{n}</script><p>将向量表达形式转为矩阵表达形式，则有</p><script type="math/tex; mode=display">\begin{aligned}J(\theta )&=\frac{1}{2}\left( X\theta -y\right)^{T}\left( X\theta -y \right)\\&=\frac{1}{2}\left( \theta ^{T}X^T-y^{T} \right)\left(X\theta -y \right)\\&=\frac{1}{2}\left( \theta ^{T}X^TX\theta -\theta^{T}X^Ty-y^{T}X\theta -y^{T}y \right)\end{aligned}</script><p>接下来对$J(\theta )$偏导，需要用到以下几个矩阵的求导法则:</p><ul><li><p>$\frac{dAB}{dB}=A^{T}$ </p></li><li><p>$\frac{dX^{T}AX}{dX}=2AX$                            </p></li></ul><p>所以有</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial J\left( \theta  \right)}{\partial \theta }&=\frac{1}{2}\left(2X^TX\theta -X^Ty -(y^{T}X )^{T}-0 \right)\\&=\frac{1}{2}\left(2X^TX\theta -X^Ty -X^Ty -0 \right)\\&=X^TX\theta -X^Ty\end{aligned}</script><p>当等式取 0 时，则有$\theta =\left( X^{T}X \right)^{-1}X^{T}y$</p><h5 id="【python-代码】"><a href="#【python-代码】" class="headerlink" title="【python 代码】"></a>【python 代码】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalEqn</span>(<span class="hljs-params">X, y</span>):<br>    <br>   theta = np.linalg.inv(X.T@X)@X.T@y <br><br><span class="hljs-comment">#X.T@X等价于X.T.dot(X)</span><br>    <br>   <span class="hljs-keyword">return</span> theta<br></code></pre></td></tr></table></figure><h2 id="Week-3-Logistic-Regression"><a href="#Week-3-Logistic-Regression" class="headerlink" title="Week 3: Logistic Regression"></a>Week 3: Logistic Regression</h2><h3 id="5-Classification-and-Representation"><a href="#5-Classification-and-Representation" class="headerlink" title="5. Classification and Representation"></a>5. Classification and Representation</h3><h4 id="5-1-Classification"><a href="#5-1-Classification" class="headerlink" title="5.1 Classification"></a>5.1 Classification</h4><p>我们从二元的分类问题开始讨论，将因变量（<strong>dependent variable</strong>）可能属于的两个类分别称为负向类（<strong>negative class</strong>）和正向类（<strong>positive class</strong>），则因变量$y\in { 0,1 \\}$ ，其中 0 表示负向类，1 表示正向类。</p><p>如果我们要用线性回归算法来解决一个分类问题，那么假设函数的输出值可能远大于 1，或者远小于0，即使所有训练样本的标签  $y$ 都等于 0 或 1。所以我们在接下来的要研究的算法就叫做<strong>逻辑回归算法</strong>，这个算法的性质是：它的输出值永远在0到 1 之间。</p><h4 id="5-2-Hypothesis-Representation"><a href="#5-2-Hypothesis-Representation" class="headerlink" title="5.2 Hypothesis Representation"></a>5.2 Hypothesis Representation</h4><p>根据线性回归模型我们只能预测连续的值，然而对于分类问题，我们需要输出0或1，我们可以预测：</p><ul><li><p>当$h_\theta( x )&gt;=0.5$时，预测 $y=1$</p></li><li><p>当$h_\theta( x )&lt;0.5$时，预测 $y=0$ </p></li></ul><p>逻辑回归模型的假设函数是</p><script type="math/tex; mode=display">h_\theta ( x )=g\left(\theta^{T}X \right),\qquad g\left( z \right)=\frac{1}{1+e^{-z}}</script><p>其中 $g$ 代表逻辑函数（<strong>logistic function</strong>）是一个常用的逻辑函数为<strong>S</strong>形函数（<strong>Sigmoid function</strong>）</p><p><img src="/2022/08/03/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B_1/pic6-2.jpg" alt></p><p>$h_\theta ( x )$的作用是，对于给定的输入变量，根据选择的参数计算输出变量为 1 的可能性（<strong>estimated probablity</strong>）即 $h_\theta ( x )=P\left( y=1|x;\theta \right)$</p><h5 id="【python-代码】-1"><a href="#【python-代码】-1" class="headerlink" title="【python 代码】"></a>【python 代码】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">z</span>):<br>    <br>   <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-z))<br></code></pre></td></tr></table></figure><h4 id="5-3-Decision-Boundary"><a href="#5-3-Decision-Boundary" class="headerlink" title="5.3 Decision Boundary"></a>5.3 Decision Boundary</h4><p>根据上面绘制出的 <strong>S</strong> 形函数图像，我们知道当</p><ul><li><p>$z\geq0$ 时 $g(z)\geq0.5$，即 $\theta^{T}x&gt;=0$  时，预测 $y=1$</p></li><li><p>$z&lt;0$ 时 $g(z)&lt;0.5$，即 $\theta^{T}x&lt;0$  时，预测 $y=0$</p></li></ul><p>逻辑回归实际上是以 $\theta^{T}=0$ 构成的函数为分界线，将预测为1的区域和预测为 0的区域分隔开。上为正，下为负。这条分界线就被成为<strong>决策边界</strong>（Decision Boundary）</p><h5 id="【python-代码】-2"><a href="#【python-代码】-2" class="headerlink" title="【python 代码】"></a>【python 代码】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">theta, X</span>):<br>    <br>    probability = sigmoid(X @ theta.T)<br>    <span class="hljs-keyword">return</span> [<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> x &gt;= <span class="hljs-number">0.5</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> probability]<br></code></pre></td></tr></table></figure><h3 id="6-Logistic-Regression-Model"><a href="#6-Logistic-Regression-Model" class="headerlink" title="6. Logistic Regression Model"></a>6. Logistic Regression Model</h3><h4 id="6-1-Cost-Function"><a href="#6-1-Cost-Function" class="headerlink" title="6.1 Cost Function"></a>6.1 Cost Function</h4><p>对于线性回归模型，我们定义的代价函数是所有模型误差的平方和。理论上来说，我们也可以对逻辑回归模型沿用这个定义，但是问题在于，当我们将 $h_\theta( x )=\frac{1}{1+e^{-\theta^{T}x}}$ 带入到这样定义了的代价函数中时，我们得到的代价函数将是一个<strong>非凸函数</strong>（<strong>non-convexfunction</strong>）。这意味着我们的代价函数有许多局部最小值，这将影响梯度下降算法寻找全局最小值。</p><p>我们重新定义逻辑回归的代价函数为</p><script type="math/tex; mode=display">J\left( \theta  \right)=\frac{1}{m}\sum\limits_{i=1}^{m}\text{Cost}\left( h_\theta\left( x^{(i)} \right),y^{(i)} \right)</script><script type="math/tex; mode=display">\text{Cost}\left(h_{\theta}(x), y\right)=\left\{\begin{aligned}-\log \left(h_{\theta}(x)\right) & \text{ if } y=1 \\-\log \left(1-h_{\theta}(x)\right) & \text{ if } y=0 \end{aligned}\right.</script><ul><li>当实际的  $y=1$ 且 $h_\theta( x )$ 也为 1 时误差为 0</li><li>当 $y=1$ 但 $h_\theta( x )$ 不为1时误差随着 $h_\theta( x )$ 变小而变大</li><li>当实际的 $y=0$ 且 $h_\theta( x )$ 也为 0 时代价为 0</li><li>当 $y=0$ 但 $h_\theta( x )$ 不为 0 时误差随着 $h_\theta( x )$ 的变大而变大</li></ul><p>简化如下：</p><script type="math/tex; mode=display">Cost\left( h_\theta( x ),y \right)=-y\times log\left( h_\theta( x ) \right)-(1-y)\times log\left( 1-h_\theta( x ) \right)</script><h5 id="【Python-代码】-4"><a href="#【Python-代码】-4" class="headerlink" title="【Python 代码】"></a>【Python 代码】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cost</span>(<span class="hljs-params">theta, X, Y</span>):<br>    <br>    first = Y * np.log(sigmoid(X@theta.T))<br>    second = (<span class="hljs-number">1</span> - Y) * np.log(<span class="hljs-number">1</span> - sigmoid(X@theta.T))<br>    <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span> * np.mean(first + second)<br></code></pre></td></tr></table></figure><h4 id="6-2-Simplified-Cost-Function-and-Gradient-Descent"><a href="#6-2-Simplified-Cost-Function-and-Gradient-Descent" class="headerlink" title="6.2 Simplified Cost Function and Gradient Descent"></a>6.2 Simplified Cost Function and Gradient Descent</h4><h5 id="【Cost-Function-推导】"><a href="#【Cost-Function-推导】" class="headerlink" title="【Cost Function 推导】"></a>【Cost Function 推导】</h5><script type="math/tex; mode=display">J\left( \theta  \right)=-\frac{1}{m}\sum\limits_{i=1}^{m}[y^{(i)}\log \left( h_\theta\left( x^{(i)} \right) \right)+\left( 1-y^{(i)} \right)\log \left( 1-h_\theta\left( x^{(i)} \right) \right)]</script><p>代入函数</p><script type="math/tex; mode=display">h_\theta\left( x^{(i)} \right)=\frac{1}{1+e^{-\theta^Tx^{(i)}}}</script><p>得到</p><script type="math/tex; mode=display">\begin{aligned}&y^{(i)}\log \left( h_\theta\left( x^{(i)} \right) \right)+\left( 1-y^{(i)} \right)\log \left( 1-h_\theta\left( x^{(i)} \right) \right)\\=&y^{(i)}\log \left( \frac{1}{1+e^{-\theta^Tx^{(i)}}} \right)+\left( 1-y^{(i)} \right)\log \left( 1-\frac{1}{1+e^{-\theta^Tx^{(i)}}} \right)\\=&-y^{(i)}\log \left( 1+e^{-\theta^Tx^{(i)}} \right)-\left( 1-y^{(i)} \right)\log \left( 1+e^{\theta^Tx^{(i)}} \right)\end{aligned}</script><p>对函数进行求导</p><script type="math/tex; mode=display">\begin{aligned}&\frac{\partial }{\partial \theta_{j}}J\left( \theta  \right)=\frac{\partial }{\partial \theta_{j}}[-\frac{1}{m}\sum\limits_{i=1}^{m}[-y^{(i)}\log \left( 1+e^{-\theta^{T}x^{(i)}} \right)-\left( 1-y^{(i)} \right)\log \left( 1+e^{\theta^{T}x^{(i)}} \right)]]\\=&-\frac{1}{m}\sum\limits_{i=1}^{m}[-y^{(i)}\frac{-x_{j}^{(i)}e^{-\theta^{T}x^{(i)}}}{1+e^{-\theta^{T}x^{(i)}}}-\left( 1-y^{(i)} \right)\frac{x_j^{(i)}e^{\theta^Tx^{(i)}}}{1+e^{\theta^Tx^{(i)}}}]\\=&-\frac{1}{m}\sum\limits_{i=1}^{m}[y^{(i)}\frac{x_j^{(i)}}{1+e^{\theta^Tx^{(i)}}}-\left( 1-y^{(i)} \right)\frac{x_j^{(i)}e^{\theta^Tx^{(i)}}}{1+e^{\theta^Tx^{(i)}}}]\\=&-\frac{1}{m}\sum\limits_{i=1}^{m}\frac{y^{(i)}x_j^{(i)}-x_j^{(i)}e^{\theta^Tx^{(i)}}+y^{(i)}x_j^{(i)}e^{\theta^Tx^{(i)}}}{1+e^{\theta^Tx^{(i)}}}\\=&-\frac{1}{m}\sum\limits_{i=1}^{m}\frac{y^{(i)}\left( 1\text{+}e^{\theta^Tx^{(i)}} \right)-e^{\theta^Tx^{(i)}}}{1+e^{\theta^Tx^{(i)}}}x_j^{(i)}\\=&-\frac{1}{m}\sum\limits_{i=1}^{m}(y^{(i)}-\frac{e^{\theta^Tx^{(i)}}}{1+e^{\theta^Tx^{(i)}}})x_j^{(i)}\\=&-\frac{1}{m}\sum\limits_{i=1}^{m}(y^{(i)}-\frac{1}{1+e^{-\theta^Tx^{(i)}}})x_j^{(i)}\\=&-\frac{1}{m}\sum\limits_{i=1}^{m}[y^{(i)}-h_\theta\left( x^{(i)} \right)]x_j^{(i)}\\=&\frac{1}{m}\sum\limits_{i=1}^{m}[h_\theta\left( x^{(i)} \right)-y^{(i)}]x_j^{(i)}\end{aligned}</script><p>因此，我们得到同样的</p><script type="math/tex; mode=display">\theta_j := \theta_j - \alpha \frac{1}{m}\sum\limits_{i=1}^{m}{\left( h_\theta\left( x^{(i)} \right)-y^{(i)} \right)}x_{j}^{(i)}</script><h5 id="【Python-代码】-5"><a href="#【Python-代码】-5" class="headerlink" title="【Python 代码】"></a>【Python 代码】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient</span>(<span class="hljs-params">theta, X, Y</span>):<br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>/<span class="hljs-built_in">len</span>(X) *  (sigmoid(X @ theta.T) - Y) @ X<br><br><span class="hljs-keyword">import</span> scipy.optimize <span class="hljs-keyword">as</span> opt<br><br>theta = opt.fmin_tnc(func=cost, x0=theta, fprime=gradient, args=(X, Y))<br><span class="hljs-comment"># model = opt.minimize(fun=cost, x0=theta, args=(X, Y), method=&#x27;Newton-CG&#x27;, jac=gradient)</span><br><br><span class="hljs-comment"># or</span><br><br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><br>model = LogisticRegression()<br>model.fit(X, Y)<br></code></pre></td></tr></table></figure><h4 id="6-4-Advanced-Optimization"><a href="#6-4-Advanced-Optimization" class="headerlink" title="6.4 Advanced Optimization"></a>6.4 Advanced Optimization</h4><p>除了梯度下降算法以外，还有另外一些常被用来令代价函数最小的算法，这些算法更加复杂和优越，而且通常不需要人工选择学习率，比梯度下降算法要更加快速。这些算法有：<strong>共轭梯度</strong>（<strong>Conjugate Gradient</strong>），<strong>局部优化法</strong>(<strong>Broyden fletcher goldfarb shann,BFGS</strong>) ，<strong>有限内存局部优化法</strong>(<strong>LBFGS</strong>) ，<strong>变尺度法</strong>(<strong>Variable Metric Algorithm</strong>) 。</p><p><a href="https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E6%9C%80%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/L-BFGS/lbfgs.md">更多信息参考</a></p><h4 id="6-5-Multiclass-Classification-One-vs-all"><a href="#6-5-Multiclass-Classification-One-vs-all" class="headerlink" title="6.5 Multiclass Classification_ One-vs-all"></a>6.5 Multiclass Classification_ One-vs-all</h4><p>我们现在已经知道二元分类可以使用逻辑回归将数据集一分为二为正类和负类。而此分类思想也可以用在多类分类问题上。比如假设有三个类别，我们可以将其分成三个二元分类问题。最后，在我们需要做预测时，我们将所有的分类机都运行一遍，然后对每一个输入变量，都选择最高可能性的输出变量。</p><h4 id="6-6-特征映射"><a href="#6-6-特征映射" class="headerlink" title="6.6 特征映射"></a>6.6 特征映射</h4><script type="math/tex; mode=display">\operatorname{mapFeature}(x)=\left[\begin{array}{c}x_{1}^{0} x_{2}^{0} \\ x_{1}^{1} x_{2}^{0} \\ x_{1}^{0} x_{2}^{1} \\ x_{1}^{2} x_{2}^{0} \\ x_{1}^{1} x_{2}^{1} \\ x_{1}^{0} x_{2}^{2} \\ \vdots \\ x_{1}^{1} x_{2}^{5} \\ x_{1}^{0} x_{2}^{6}\end{array}\right]=\left[\begin{array}{c}1 \\ x_{1} \\ x_{2} \\ x_{1}^{2} \\ x_{1}^{1} x_{2}^{1} \\ x_{2}^{2} \\ \vdots \\ x_{1}^{1} x_{2}^{5} \\ x_{2}^{6}\end{array}\right]</script><h5 id="【Python-代码】-6"><a href="#【Python-代码】-6" class="headerlink" title="【Python 代码】"></a>【Python 代码】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">feature_mapping</span>(<span class="hljs-params">x, y, power, as_ndarray=<span class="hljs-literal">False</span></span>):<br>    <br>    data = &#123;<span class="hljs-string">&#x27;f&#123;0&#125;&#123;1&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i-p, p): np.power(x, i-p) * np.power(y, p)<br>                <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, power+<span class="hljs-number">1</span>)<br>                <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, i+<span class="hljs-number">1</span>)<br>           &#125;<br>    <span class="hljs-keyword">if</span> as_ndarray:<br>        <span class="hljs-keyword">return</span> pd.DataFrame(data).values<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> pd.DataFrame(data)<br>    <br><span class="hljs-comment"># 决策边界，thetaX = 0, thetaX &lt;= threshhold</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">find_decision_boundary</span>(<span class="hljs-params">density, power, theta, threshhold</span>):<br>    t1 = np.linspace(-<span class="hljs-number">1</span>, <span class="hljs-number">1.2</span>, density)<br>    t2 = np.linspace(-<span class="hljs-number">1</span>, <span class="hljs-number">1.2</span>, density)<br>    cordinates = [(x, y) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> t1 <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> t2]<br>    x_cord, y_cord = <span class="hljs-built_in">zip</span>(*cordinates)<br>    mapped_cord = feature_mapping(x_cord, y_cord, power)<br>    <br>    pred = mapped_cord.values @ theta.T<br>    decision = mapped_cord[np.<span class="hljs-built_in">abs</span>(pred) &lt;= threshhold]<br>    <br>    <span class="hljs-keyword">return</span> decision.f10, decision.f01<br></code></pre></td></tr></table></figure><h3 id="7-Regularization"><a href="#7-Regularization" class="headerlink" title="7. Regularization"></a>7. Regularization</h3><h4 id="7-1-The-Problem-of-Overfitting"><a href="#7-1-The-Problem-of-Overfitting" class="headerlink" title="7.1 The Problem of Overfitting"></a>7.1 The Problem of Overfitting</h4><p>到现在为止，我们已经学习了几种不同的学习算法，包括线性回归和逻辑回归，它们能够有效地解决许多问题，但是当将它们应用到某些特定的机器学习应用时，会遇到过拟合 (<strong>over-fitting</strong>) 的问题，导致它们效果很差。</p><p>就以多项式理解，$x$ 的次数越高，拟合的越好，但我们并没有足够的数据去约束这么多变量，导致相应的预测的能力就可能变差。</p><p>如果我们发现了过拟合问题，应该如何处理？</p><ol><li>丢弃一些不能帮助我们正确预测的特征<ul><li>可以是手工选择保留哪些特征</li><li>或者使用一些模型选择的算法来帮忙（例如<strong>PCA</strong>）</li></ul></li><li>正则化<ul><li>保留所有的特征，但是减少参数的大小（<strong>magnitude</strong>）</li></ul></li></ol><h4 id="7-2-Cost-Function"><a href="#7-2-Cost-Function" class="headerlink" title="7.2 Cost Function"></a>7.2 Cost Function</h4><p>使用正则化的方法，我们可以手动对特定的系数添加惩罚项，即在代价函数中加入系数的平方。这个操作能减少变量过多的影响，但又不需要去除变量。</p><p>假如我们有非常多的特征，我们并不知道其中哪些特征我们要惩罚，我们将对所有的特征进行惩罚，并且让代价函数最优化的软件来选择这些惩罚的程度。这样的结果是得到了一个较为简单的能防止过拟合问题的假设：</p><script type="math/tex; mode=display">J\left( \theta  \right)=\frac{1}{2m}[\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^{2}+\lambda \sum\limits_{j=1}^{n}\theta_{j}^{2}]</script><p>$\lambda $又称为正则化参数（<strong>Regularization Parameter</strong>）, 如果选择的正则化参数$\lambda$ 过大，则会把所有的参数都最小化了，导致模型变成 $h_\theta( x )=\theta_{0}$，也就造成欠拟合。</p><h4 id="7-3-Regularized-Linear-Regression"><a href="#7-3-Regularized-Linear-Regression" class="headerlink" title="7.3 Regularized Linear Regression"></a>7.3 Regularized Linear Regression</h4><p>正则化线性回归的代价函数为</p><script type="math/tex; mode=display">J\left( \theta  \right)=\frac{1}{2m}\sum\limits_{i=1}^{m}[((h_\theta(x^{(i)})-y^{(i)})^{2}+\lambda \sum\limits_{j=1}^{n}\theta _{j}^{2})]</script><p>如果我们要使用梯度下降法令这个代价函数最小化，因为我们未对$\theta_0$进行正则化，所以梯度下降算法将分两种情形：</p><script type="math/tex; mode=display">\theta_0:=\theta_0-a\frac{1}{m}\sum\limits_{i=1}^{m}((h_\theta(x^{(i)})-y^{(i)})x_{0}^{(i)})</script><script type="math/tex; mode=display">\theta_j:=\theta_j-a[\frac{1}{m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x_{j}^{\left( i \right)}+\frac{\lambda }{m}\theta_j]\text{ , for }j=1,2,...n</script><p>我们同样也可以利用正规方程来求解正则化线性回归模型，方法如下所示：</p><script type="math/tex; mode=display">\theta=(X^TX+\lambda[\ 0\ I_0\ ])^{-1}X^Ty</script><p>其中的 $[ 0 I_n]$ 为矩阵尺寸为 $(n+1)*(n+1)$，除了首行斜对角都为 1 的矩阵</p><p>If $\lambda&gt;0$， 对于严格对角占优矩阵 $X^TX+\lambda[ 0 I_0 ]$ 一定可逆</p><h4 id="7-4-Regularized-Logistic-Regression"><a href="#7-4-Regularized-Logistic-Regression" class="headerlink" title="7.4 Regularized Logistic Regression"></a>7.4 Regularized Logistic Regression</h4><p>逻辑回归的代价函数增加一个正则化，得到</p><script type="math/tex; mode=display">J\left( \theta  \right)=\frac{1}{m}\sum\limits_{i=1}^{m}[-y^{(i)}\log \left( h_\theta\left( x^{(i)} \right) \right)-\left( 1-y^{(i)} \right)\log \left( 1-h_\theta\left( x^{(i)} \right) \right)]+\frac{\lambda }{2m}\sum\limits_{j=1}^{n}\theta _{j}^{2}</script><p>要最小化该代价函数，通过求导，得出梯度下降算法为</p><script type="math/tex; mode=display">\theta_0:=\theta_0-a\frac{1}{m}\sum\limits_{i=1}^{m}((h_\theta(x^{(i)})-y^{(i)})x_{0}^{(i)})</script><script type="math/tex; mode=display">\theta_j:=\theta_j-a[\frac{1}{m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x_{j}^{\left( i \right)}+\frac{\lambda }{m}\theta_j]\text{ , for }j=1,2,...n</script><h5 id="【Python-代码】-7"><a href="#【Python-代码】-7" class="headerlink" title="【Python 代码】"></a>【Python 代码】</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">costReg</span>(<span class="hljs-params">theta, X, y, learningRate</span>):<br>    <br>    theta = np.matrix(theta)<br>    X = np.matrix(X)<br>    y = np.matrix(y)<br>    first = np.multiply(-y, np.log(sigmoid(X*theta.T)))<br>    second = np.multiply((<span class="hljs-number">1</span> - y), np.log(<span class="hljs-number">1</span> - sigmoid(X*theta.T)))<br>    reg = (learningRate /<span class="hljs-number">2</span>* np.mean(np.power(theta[:,<span class="hljs-number">1</span>:theta.shape[<span class="hljs-number">1</span>]],<span class="hljs-number">2</span>))<br>    <span class="hljs-keyword">return</span> np.mean(first - second) + reg<br>           <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">regularized_gradient</span>(<span class="hljs-params">theta, X, Y, learningRate=<span class="hljs-number">1</span></span>):<br>           <br>    regularized_theta = learningRate / <span class="hljs-built_in">len</span>(X) * theta[<span class="hljs-number">1</span>:]<br>    regularized_term = np.concatenate([np.array([<span class="hljs-number">0</span>]), regularized_theta])<br>    <br>    <span class="hljs-keyword">return</span>  gradient(theta, X, Y) + regularized_term<br>           <br><span class="hljs-comment"># or</span><br>           <br><span class="hljs-keyword">import</span> scipy.optimize <span class="hljs-keyword">as</span> opt<br>           <br>res = opt.minimize(fun=regularized_cost, x0=theta, args=(X, Y), method=<span class="hljs-string">&#x27;Newton-CG&#x27;</span>, jac=regularized_gradient)<br></code></pre></td></tr></table></figure><blockquote><p>seaborn  是基于 matplotlib 的<strong>数据集分布可视化库</strong>。它在 matplotlib 的基础上，进行了更高级的封装，从而使得绘图更加容易，不需要经过大量的调整，就能使图像变得精致。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Supervised Learning</tag>
      
      <tag>linear regression</tag>
      
      <tag>Logistic Regression</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】高等数学复习笔记-随机过程</title>
    <link href="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/"/>
    <url>/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于 ChiuFai WONG 教授的随机过程课件的笔记；</p><p>结合应坚刚教授的随机分析讲义；</p><p>程士宏教授测度论与概率论基础进行整理；</p><p>对于部分基础多有忽略，主要用于知识点查找；</p></blockquote><span id="more"></span><h2 id="1-概率论预备知识"><a href="#1-概率论预备知识" class="headerlink" title="1. 概率论预备知识"></a>1. 概率论预备知识</h2><h4 id="1-1-集合的运算"><a href="#1-1-集合的运算" class="headerlink" title="1.1 集合的运算"></a>1.1 集合的运算</h4><script type="math/tex; mode=display">\begin{array}{l}A \cup B \stackrel{\text { def }}{=}\{x: x \in A \text { 或 } x \in B\}, \\ A \cap B \stackrel{\text { def }}{=}\{x: x \in A \text { 且 } x \in B\}, \\ A \backslash B \stackrel{\text { def }}{=}\{x: x \in A \text { 且 } x \notin B\}, \\ A \Delta B \stackrel{\text { def }}{=}(A \backslash B) \bigcup(B \backslash A)\end{array}</script><p>分别称为集合 A 和 B 的<strong>并, 交, 差</strong>和<strong>对称差</strong>. 如 $B \subset A$ , 则 $A \backslash B$ 也称为 A 和 B 的<strong>真差</strong>. </p><h4 id="1-2-单调序列"><a href="#1-2-单调序列" class="headerlink" title="1.2 单调序列"></a>1.2 单调序列</h4><p>设 $\left\{A_{n}, n=1,2, \cdots\right\}$ 是一个集合序列. 如果对每个 $n=1,2, \cdots$ , 有</p><script type="math/tex; mode=display">A_{n} \subset A_{n+1}</script><p>则称 $A_{n}$  为<strong>非降的</strong>, 记为 $A_{n} \uparrow$  , 并把集合 $\lim_{n \rightarrow \infty} A_{n} \stackrel{ def }{=} \bigcup_{n=1}^{\infty} A_{n} $ 叫做它的极限; </p><p>如果对每个 $n=1,2, \cdots$  , 有</p><script type="math/tex; mode=display">A_{n} \supset A_{n+1}</script><p>则称 $A_{n}$ 为<strong>非增的</strong>, 记为 $A_{n} \downarrow$  , 并称 $\lim_{n \rightarrow \infty} A_{n} \stackrel{ def }{=} \bigcap_{n=1}^{\infty} A_{n}$  为它的极限. 非降或非增的集合序列统称为<strong>单调序列</strong>. 因此, <strong>单调集合序列总有极限</strong>. </p><p>对于任意给定的一个集合序列 $\left\{A_{n}, n=1,2, \cdots\right\} $ , 集合序列非降和非增分别有极限</p><script type="math/tex; mode=display">\liminf _{n \rightarrow \infty} A_{n}=\bigcup_{n=1}^{\infty} \bigcap_{k=n}^{\infty} A_{k} \qquad\text{和}\qquad\limsup _{n \rightarrow \infty} A_{n}=\bigcap_{n=1}^{\infty} \bigcup_{k=n}^{\infty} A_{k}</script><blockquote><p>注意第二个运算符的范围是从 n 到 $\infty$ ，因此左边是非减右侧是非增</p></blockquote><p>我们将把 $\liminf _{n \rightarrow \infty} A_{n}$  和 $\lim _{n \rightarrow \infty} \sup A_{n}$ 分别叫做 $\left\{A_{n}, n=1,2, \cdots\right\}$  的<strong>下极限</strong>和<strong>上极限</strong>. </p><h4 id="1-3-集合系"><a href="#1-3-集合系" class="headerlink" title="1.3 集合系"></a>1.3 集合系</h4><p>以空间 X 中的一些集合为元素组成的集合成为 X 上的<strong>集合系</strong>，一般用花体字母来表示。</p><ul><li><p>$\pi$ 系：如果 X 上的非空集合系 $\mathscr{P}$ 对<strong>交</strong>是运算是<strong>封闭的</strong>，即</p><script type="math/tex; mode=display">A,B\in\mathscr{P}\Rightarrow A\bigcap B\in \mathscr{P}</script><p>则称 $\mathscr{P}$ 为 $\pi$ 系</p></li><li><p>半环：满足 $\pi$ 系要求的基础上，对任意的 $A,B\in\mathscr{Q}$ 且 $A\supset B$，存在有限个两两不相交的 $\{C_k\in\mathscr{Q},k=1,…,n\}$ 使得</p><script type="math/tex; mode=display">A\backslash B=\bigcup_{k=1}^nC_k</script></li></ul><ul><li><p>环：如果 X 上的非空集合系 $\mathscr{R}$ 对<strong>并和差</strong>是运算是<strong>封闭的</strong>，则称 $\mathscr{R}$ 为 <strong>环</strong></p></li><li><p>域：满足 $\pi$ 系要求的基础上</p><script type="math/tex; mode=display">X\in\mathscr{A};\quad A\in\mathscr{A}\Rightarrow A^c\in\mathscr{A}</script></li><li><p>$\lambda$ 系：集合系 $\mathscr{L}$  称为 $\lambda$ 系，如果它满足下列条件</p><script type="math/tex; mode=display">\begin{array}{l}X \in \mathscr{L} ; \\ A, B \in \mathscr{L} \text { 且 } A \supset B \Longrightarrow A \backslash B \in \mathscr{L}\\ A_{n} \in \mathscr{L} \text { 且 } A_{n} \uparrow \Longrightarrow \bigcup_{n=1}^{\infty} A_{n} \in \mathscr{L}\end{array}</script></li><li><p>$\sigma$ 域：集合系 $\mathscr{F}$  称为 $\sigma$ 域，如果它满足下列条件</p><script type="math/tex; mode=display">\begin{array}{l}X \in \mathscr{F} ; \\ A \in \mathscr{F} \Longrightarrow A^{c} \in \mathscr{F} \\ A_{n} \in \mathscr{F}, n=1,2, \cdots \Longrightarrow \bigcup_{n=1}^{\infty} A_{n} \in \mathscr{T}\end{array}</script></li><li><p>Borel 集合系：$\mathscr{O}_R$ 为 $R$ 中开集组成的集合系</p><script type="math/tex; mode=display">\mathscr{B}\stackrel{ def }{=}\sigma(\mathscr{O})</script></li></ul><h4 id="1-4-事件域与信息"><a href="#1-4-事件域与信息" class="headerlink" title="1.4 事件域与信息"></a>1.4 事件域与信息</h4><p>一个随机现象可能出现的所有结果称为<strong>样本空间</strong> $\Omega$，$\mathscr{F}$ 是 $\Omega$ 的子集组成的集合，如果满足</p><ol><li>$\emptyset, \Omega \in \mathscr{F}$ </li><li>如果 $A \in \mathscr{F}$, 则 $A^{c} \in \mathscr{F}$</li><li>如果 $A_{n} \in \mathscr{F}, n \geq 1$ , 则 $\bigcup_{n} A_{n} \in \mathscr{F}$</li></ol><p>则可称 $\mathscr{F}$ 为一个<strong>事件域</strong>，属于由 $\Omega$ 生成的 $\sigma$ 域 $\sigma(\Omega)$，而 $(\Omega,\mathscr{F},\mathbb{P})$ 是一个概率空间</p><h2 id="2-条件期望"><a href="#2-条件期望" class="headerlink" title="2. 条件期望"></a>2. 条件期望</h2><h4 id="2-1-期望和数字特征"><a href="#2-1-期望和数字特征" class="headerlink" title="2.1 期望和数字特征"></a>2.1 期望和数字特征</h4><p><strong>连续性或者单调收敛定理</strong>：如果 $\xi_n$ 是非负递增的随机序列，那么</p><script type="math/tex; mode=display">\mathbb{E}[\lim_n\xi_n]=\lim_n\mathbb{E}[\xi_n]</script><p>期望是随机变量的一个数字特征, 或者说是分布的数字特征, 表示平均. 这是最有用的, 它是使得函数 $f(x)=\mathbb{E}\left[(\xi-x)^{2}\right]$ 达到最小值的地方, 通常两个随机变量 $\xi, \eta$ 的均方距离定义为</p><script type="math/tex; mode=display">\sqrt{\mathbb{E}[(\xi-\eta)^2]}</script><p>那么期望是实数空间中离 $\xi$ 的均方距离最近的数字. 实数空间是关于最少信息 $\{\empty,\Omega\}$ 可测的随机变量全体. </p><h4 id="2-2-条件期望的直观"><a href="#2-2-条件期望的直观" class="headerlink" title="2.2 条件期望的直观"></a>2.2 条件期望的直观</h4><p>让我们用 Hilbert 空间的眼光看条件期望的问题, 我们已经有一个 Hilbert 空间 $ L^{2}(\Omega, \mathscr{F}, \mathbb{P}) $ , 关于部分信息 $ \mathscr{G} $ 可测的平方可积随机变量全体 $ L^{2}(\Omega, \mathscr{G}, \mathbb{P})$ 是 $ L^{2}(\Omega, \mathscr{F}, \mathbb{P}) $ 的闭子空间. </p><p>空间 $ L^{2}(\Omega, \mathscr{G}, \mathbb{P})$ 中距离 $\xi$ 最近的那个随机变量记为 $\mathbb{E}[\xi|\mathscr{G}]=\eta$ ，等价于说 $\eta$ 是 $\xi$ 在子空间上的正交投影，即 $\xi-\eta$ 与子空间垂直或者说正交，对于任何 $\zeta\in L^{2}(\Omega, \mathscr{G}, \mathbb{P})$ 有</p><script type="math/tex; mode=display">\mathbb{E}[(\xi-\eta) \zeta]=0</script><h4 id="2-3-条件期望的性质"><a href="#2-3-条件期望的性质" class="headerlink" title="2.3 条件期望的性质"></a>2.3 条件期望的性质</h4><ol><li><p>条件期望是线性算子</p></li><li><p>$\mathbb{E}[\xi \mid\{\emptyset, \Omega\}]=\mathbb{E}[\xi]$ </p></li><li><p>如果 $\xi$ 是 $\mathscr{G}$ 可测的, 那么 $\mathbb{E}[\xi \mid \mathscr{G}]=\xi$ . 这是因为投影算子在闭子空间自身上是恒等算子.</p></li><li><p>条件期望有保正性: 如果 $\xi \geq 0$ a.s., 那么 $\mathbb{E}[\xi \mid \mathscr{G}] \geq 0$ a.s. 事实上, 由定义的第二条推出, 对任何 $A \in \mathscr{G}$ 有 $\mathbb{E}[\mathbb{E}[\xi \mid \mathscr{G}] ; A] \geq 0$, 因此 $\mathbb{E}[\xi \mid \mathscr{G}] \geq 0$.</p></li><li><p>塔性 (相容性): 如果 $\mathscr{G}_{1} \subset \mathscr{G}_{2}$ 是两个子事件域, 那么 </p><script type="math/tex; mode=display">\mathbb{E}\left[\mathbb{E}\left[\xi \mid \mathscr{G}_{2}\right] \mid \mathscr{G}_{1}\right]=\mathbb{E}\left[\xi \mid \mathscr{G}_{1}\right]=\mathbb{E}\left[\mathbb{E}\left[\xi \mid \mathscr{G}_{1}\right] \mid \mathscr{G}_{2}\right]</script><p>如果 $\xi$ 在大的子空间上投影然后再投影到小的子空间上，等于它自己投影到小的子空间上</p></li><li><p>如果 $\eta$  是 $ \mathscr{G}$ 可测的随机变量, 那么</p><script type="math/tex; mode=display">\mathbb{E}[\xi \eta \mid \mathscr{G}]=\eta \mathbb{E}[\xi \mid \mathscr{G}]</script></li><li><p>如果 $ \xi $ 与 $ \mathscr{G}$ 独立, 那么 $ \mathbb{E}[\xi \mid \mathscr{G}]=\mathbb{E} \xi$. 也就是说, $ \mathscr{G} $ 代表的信息对于预测 $ \xi $ 没有任何作用.</p></li></ol><h2 id="3-Discrete-Markov-Chain"><a href="#3-Discrete-Markov-Chain" class="headerlink" title="3. Discrete Markov Chain"></a>3. Discrete Markov Chain</h2><ul><li><strong>P</strong> denote the one-step transition matrix of probabilities </li><li>A state $i$ is said to be <strong>absorbing</strong> if once entered they are never left</li><li>the n-step transition probabilities ,$P_{i,j}^n$ to be the probability that a process in state i will be in state j after n additional transitions.</li><li>Two states that <strong>communicate</strong> are said to be in the same <strong>class</strong>. </li><li>$f_{i,j}^n$ to be the probability that, starting in i, the <strong>first transition</strong> into j occurs at time n.</li><li>State i is said to be <strong>recurrent</strong> if $f_{i,i}=1$ and <strong>transient</strong> if $f_{i,i}&lt;1$</li><li>State i is said to be <strong>recurrent</strong> if $\sum_{n=0}^{\infty} P_{i, i}^{n}=\infty$ and <strong>transient</strong> if $\sum_{n=0}^{\infty} P_{i, i}^{n}&lt;\infty$</li><li>$P_{i, j}^{n}=f_{i, j}^{n}+f_{i, j}^{n-1} P_{j, j}^{1}+\cdots+f_{i, j}^{1} P_{i, i}^{n-1} \quad n \geq 1$</li></ul><h4 id="Theorem-1"><a href="#Theorem-1" class="headerlink" title="Theorem 1"></a>Theorem 1</h4><p>Let $P_{i, j}(z)=\sum_{n=0}^{\infty} P_{i, j}^{n} z^{n}$ be the probability generating function of number of transition entering state $j$ starting from state $i$ and let $\delta_{i, j}=\left\{\begin{array}{cc}1 &amp; \text { if } i=j \ 0 &amp; \text { otherwise. }\end{array}\right.$ Then $P_{i, j}(z)=\delta_{i, j}+f_{i, j}(z) P_{j, j}(z)$. In particular, </p><script type="math/tex; mode=display">P_{i, i}(z)=\frac{1}{1-f_{i, i}(z)}</script><h4 id="Theorem-2"><a href="#Theorem-2" class="headerlink" title="Theorem 2"></a>Theorem 2</h4><p>Let $T$ denote the set of all transient states. If $j$ is recurrent, then the set of probabilities $\left\{f_{i, j}, i \in T\right\}$ satisfies</p><script type="math/tex; mode=display">f_{i, j}=\sum_{k \in T} P_{i, k} f_{k, j}+\sum_{k \in R_{j}} P_{i, k}, \quad i \in T,</script><p>where $R_{j}$ denotes the set of recurrence states communicating with $j$.</p><h4 id="Theorem-3"><a href="#Theorem-3" class="headerlink" title="Theorem 3"></a>Theorem 3</h4><p>Assuming that successive plays of the game are independent, what is the probability that, starting with $i$ units, the gambler’s fortune will reach $N$ before reaching 0?</p><p><img src="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/pic5-1.jpg" alt></p><script type="math/tex; mode=display">P_{i}=\left\{\begin{array}{cc}\frac{1-(q / p)^{i}}{1-(q / p)^{N}}, & \text { if } p \neq \frac{1}{2} \\\frac{i}{N}, & \text { if } p=\frac{1}{2}\end{array}\right.</script><p>The expected number of bets that the gambler starting at $k, 0 &lt; k &lt; N$, will reach $0$ or $N$ is</p><script type="math/tex; mode=display">m_{k}=\left\{\begin{array}{cl}\frac{1}{2 p-1}\left[N \frac{1-(q / p)^{k}}{1-(q / p)^{N}}-k\right] & \text { if } p \neq \frac{1}{2} \\N k-k^{2} & \text { if } p=\frac{1}{2}\end{array}\right.</script><ul><li><p>let $m_{i,j}$ denote the expected number of visits in state $j$, given that </p><p>it starts in state $i$.</p></li><li><p>$m_{i, j}=\delta_{i, j}+\sum_{k} P_{i, k} m_{k, j}$, $M=I_{t}+P_{T} M\to M=\left(I_{t}-P_{T}\right)^{-1}$</p></li><li><p>$f_{i, j}=\frac{m_{i, j}-\delta_{i, j}}{m_{j, j}}$</p></li><li><p>A state with period 1 is said to be <strong>aperiodic</strong></p></li><li><p>$\mu_{i,j}$ denote the expected number of transition need to return state $i$. That is, $\mu_{i,i}=\sum_{n=1}^\infty nf_{i,i}^n$</p></li><li><p>If the expected recurrence time is finite then this is called <strong>positive-recurrent</strong>; if the expected recurrence time is infinite then this is called <strong>null recurrent</strong>. Positive recurrent, aperiodic states are called <strong>ergodic</strong>.</p></li></ul><h4 id="Stirling’s-approximation"><a href="#Stirling’s-approximation" class="headerlink" title="Stirling’s approximation"></a>Stirling’s approximation</h4><p>for $n$ large</p><script type="math/tex; mode=display">n!\approx\sqrt{2\pi n}(\frac n e)^n</script><h3 id="1-dimensional-Simple-Random-Walk"><a href="#1-dimensional-Simple-Random-Walk" class="headerlink" title="1-dimensional Simple Random Walk"></a>1-dimensional Simple Random Walk</h3><p><img src="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/pic5-2.jpg" alt></p><ul><li>The chain is recurrent when $p=\frac12$ and transient if $p\ne\frac12$</li></ul><p>Because  $f_{0,1}(z)=pz+(qz)f_{0,1}(z)f_{-1,0}(z)=pz+(qz)f_{0,1}(z)^2$</p><p>we obtain</p><script type="math/tex; mode=display">f_{0,1}(z)=\frac{1-\sqrt{1-4pqz^2}}{2qz}=p z+\cdots+\frac{(2 n-2) !}{n !(n-1) !} p^{n} q^{n-1} z^{2 n-1}+\cdots</script><p>So $p_{2n-1}=\frac{(2 n-2) !}{n !(n-1) !} p^{n} q^{n-1}$. As the same $q_{2n-1}=\frac{(2 n-2) !}{n !(n-1) !} p^{n-1} q^{n}$.</p><p>Then</p><script type="math/tex; mode=display">f_{0,0}(z)=(p z) f_{1,0}(z)+(q z) f_{-1,0}(z)=(p z) f_{0,-1}(z)+(q z) f_{0,1}(z)=1-\sqrt{1-4 p q z^{2}}</script><p>And</p><script type="math/tex; mode=display">f_{0,0}=f_{0,0}(1)=1-\sqrt{1-4 p q}=1-\sqrt{(p+q)^{2}-4 p q}=1-\sqrt{(p-q)^{2}}=1-|p-q|</script><p>if $p=q$</p><script type="math/tex; mode=display">\mu_{i,i}=f'_{0,0}(1)=\frac z{\sqrt{1-z^2}}\bigg|_{z=1}=\infty</script><ul><li>$\pi_j=\sum_i\pi_jP_{i,j}$ is called <strong>stationary</strong> probability. </li><li>$\pi_j=\lim_{n\to\infty}P_{i,j}^n$ and $\pi P=\pi\to\pi(P-I)=0$</li></ul><p>For an irreducible Markov chain, suppose state $i$ has period $d$</p><script type="math/tex; mode=display">\lim_{n\to\infty}P_{i,i}^{nd}=\frac d{\mu_{i,i}}=d\pi_i</script><h2 id="4-Poisson-Process"><a href="#4-Poisson-Process" class="headerlink" title="4. Poisson Process"></a>4. Poisson Process</h2><script type="math/tex; mode=display">P(N(t+s)-N(s)=n)=e^{-\lambda t} \frac{(\lambda t)^{n}}{n !}, \quad n=0,1, \cdots</script><ul><li><p>$\lambda$ is called the rate of the process</p></li><li><p>$\{T_n,n=1,2,…\}$ is called the <strong>sequence of interarrival times</strong>. </p><script type="math/tex; mode=display">\begin{aligned}P\left(T_{2}>t \mid T_{1}=s\right) &=P\left(0 \text { events in }(s, s+t] \mid T_{1}=s\right) \\&=P(0 \text { events in }(s, s+t]) \\&=e^{-\lambda t}\end{aligned}</script><p>$T_1$ has an exponential distribution with mean $1/\lambda$. </p></li><li><p>$S_n=\sum_{i=1}^nT_i,n\ge 1$ called the <strong>waiting time</strong> until the nth event</p><script type="math/tex; mode=display">M_{S_{n}}(t)=E\left[e^{t\left(T_{1}+\cdots+T_{n}\right)}\right]=E\left[e^{t T_{1}}\right] \cdots E\left[e^{t T_{n}}\right]=\left(\frac{\lambda}{\lambda-t}\right)^{n} \quad \text { for } t<\lambda</script><p>$S_n$ has a gamma distribution with parameters n and $\lambda$, and $P\left(S_{n} \leq t\right)=P(N(t) \geq n)$</p></li></ul><h2 id="5-Brownian-Motion"><a href="#5-Brownian-Motion" class="headerlink" title="5. Brownian Motion"></a>5. Brownian Motion</h2><p>Define</p><script type="math/tex; mode=display">\Delta x=\sigma \sqrt{\Delta t}, \quad \text { and } \quad p=\frac{1}{2}\left(1+\frac{\mu}{\sigma} \sqrt{\Delta t}\right)</script><p>the position at time t, is</p><script type="math/tex; mode=display">W_{n}(t)=\sigma \sqrt{\Delta t}\left(X_{1}+\cdots+X_{n}\right)</script><p>Now</p><script type="math/tex; mode=display">E\left[X_{i}\right]=1(p)-1(1-p)=2 p-1=\frac{\mu}{\sigma} \sqrt{\Delta t} \quad \text { and } \quad \operatorname{Var}\left[X_{i}\right]=E\left[X_{i}^{2}\right]-E\left[X_{i}\right]^{2}=1-(2 p-1)^{2}</script><p>Then</p><script type="math/tex; mode=display">E[W_n(t)]=\mu t\qquad Var(W_n(t))=\sigma^2t(1-(2p-1)^2)</script><h4 id="Theorem-1-1"><a href="#Theorem-1-1" class="headerlink" title="Theorem 1"></a>Theorem 1</h4><p>Set $W\left(t_{1}\right)=x_{1}, W\left(t_{2}\right)=x_{2}, \cdots, W\left(t_{m}\right)=x_{m}$</p><script type="math/tex; mode=display">f(x_1,x_2,\cdots,x_m)=\frac{1}{(2 \pi)^{m / 2} \sigma^{m} \sqrt{t_{1}\left(t_{2}-t_{1}\right) \cdots\left(t_{m}-t_{m-1}\right)}} e^{-\frac{1}{2 \sigma^{2}}\left[\frac{\left.\left(x_{1}-\mu_{1}\right)^{2}\right|}{t_{1}}+\frac{\left(\left(x_{2}-x_{1}\right)-\mu\left(t_{2}-t_{1}\right)\right)^{2}}{t_{2}-t_{1}}+\cdots+\frac{\left(\left(x_{m}-x_{m-1}\right)-\mu\left(t_{m}-t_{m-1}\right)\right)^{2}}{t_{m}-t_{m-1}}\right]}</script><h4 id="Theorem-2-1"><a href="#Theorem-2-1" class="headerlink" title="Theorem 2"></a>Theorem 2</h4><p>The probability of $W(t)+x$ starting at x will hit A before B where $B\le x\le A$ is</p><script type="math/tex; mode=display">P(\text{up to A beforce down to B | starting at x})=\left\{\begin{array}{cl}\frac{1-e^{-2 \mu(x-B) / \sigma^{2}}}{1-e^{-2 \mu(A-B) / \sigma^{2}},} & \text { if } \mu \neq 0 \\\frac{x-B}{A-B}, & \text { if } \mu=0\end{array}\right.</script><p>If $\mu&gt;0$, by letting $A\to\infty$,</p><script type="math/tex; mode=display">P(\text{never goes down to B | starting at x})=\lim _{A \rightarrow \infty} \frac{1-e^{-2 \mu(x-B) / \sigma^{2}}}{1-e^{-2 \mu(A-B) / \sigma^{2}}}=1-e^{-\frac{2 \mu(x-B)}{\sigma^{2}}}</script><h4 id="Theorem-3-1"><a href="#Theorem-3-1" class="headerlink" title="Theorem 3"></a>Theorem 3</h4><p>Define the stopping time T by $T=min\{t:W(t)=A\quad or\quad W(t)=B\}$</p><script type="math/tex; mode=display">E[T]=\left\{\begin{array}{cl}\frac{(A-x)(x-B)}{\sigma^{2}} & \text { if } \mu=0 \\\frac{(A-x)\left(e^{2 \mu(x-B) / \sigma^{2}}-1\right)+(x-B)\left(e^{-2 \mu(A-x) / \sigma^{2}}-1\right)}{\mu\left(e^{2 \mu(x-B) / \sigma^{2}}-e^{-2 \mu(A-x) / \sigma^{2}}\right)} & \text { if } \mu \neq 0\end{array}\right.</script><p>Let $T_A$ denote the first time W(t) is equal to A, by setting $B\to\infty$</p><script type="math/tex; mode=display">E[T_A]=\frac{A-x}{\mu}+\lim _{x - B \rightarrow \infty} \frac{e^{-2 \mu(A-x) / \sigma^{2}}-1}{\mu e^{2 \mu(x-B) / \sigma^{2}}\left(2 \mu / \sigma^{2}\right)}=\frac{A-x}{\mu}</script><h4 id="Theorem-4"><a href="#Theorem-4" class="headerlink" title="Theorem 4"></a>Theorem 4</h4><script type="math/tex; mode=display">\begin{aligned}&P\left(T_{A} \leq t\right)=P\left(\max _{0 \leq s \leq t} W(s) \geq A\right)=e^{\frac{2 \mu(A-x)}{\sigma^{2}}}\left(1-N\left(\frac{A-x+\mu t}{\sigma \sqrt{t}}\right)\right)+\left(1-N\left(\frac{A-x-\mu t}{\sigma \sqrt{t}}\right)\right) \\&P\left(T_{B} \leq t\right)=P\left(\min _{0 \leq s \leq t} W(s) \leq B\right)=e^{-\frac{2 \mu(x-B)}{\sigma^{2}}}\left(1-N\left(\frac{x-B-\mu t}{\sigma \sqrt{t}}\right)\right)+\left(1-N\left(\frac{x-B+\mu t}{\sigma \sqrt{t}}\right)\right)\end{aligned}</script><h2 id="6-Geometric-Brownian-Motion"><a href="#6-Geometric-Brownian-Motion" class="headerlink" title="6. Geometric Brownian Motion"></a>6. Geometric Brownian Motion</h2><script type="math/tex; mode=display">S(t)=S(0)e^{W(t)}=S(0)e^{\sigma Z(t)+\mu t}</script><p>$ln(S(t)/S(0))$ is normally distributed with parameters $(\mu t,\sigma^2t)$.Then $S(t)/S(0)$ has a lognormal distribution with parameters $(\mu t,\sigma^2 t)$E</p><script type="math/tex; mode=display">E[S(t)]=S(0)e^{(\mu+\sigma^2/2)t}</script><h4 id="Theorem-1-2"><a href="#Theorem-1-2" class="headerlink" title="Theorem 1"></a>Theorem 1</h4><p>The covariance of $S(t_1)$ and $S(t_2)$, for $t_1&lt;t_2$</p><p>Let $Q_{1}=S\left(t_{1}\right) / S(0)=e^{\mu t_{1}+\sigma Z\left(t_{1}\right)}$ and $Q_{2}=S\left(t_{2}\right) / S\left(t_{1}\right)=e^{\mu\left(t_{2}-t_{1}\right)+\sigma Z\left(t_{2}-t_{1}\right)}$</p><script type="math/tex; mode=display">\begin{aligned}E\left[S\left(t_{1}\right) S\left(t_{2}\right)\right] &=S(0)^{2} E\left[Q_{1}^{2} Q_{2}\right] \\&=S(0)^{2} E\left[Q_{1}^{2}\right] E\left[Q_{2}\right] \\&=S(0)^{2} e^{2 \mu t_{1}+2 \sigma^{2} t_{1}} e^{\mu\left(t_{2}-t_{1}\right)+0.5 \sigma^{2}\left(t_{2}-t_{1}\right)} \\&=S(0)^{2} e^{\mu\left(t_{2}+t_{1}\right)+\sigma^{2}\left(1.5 t_{1}+0.5 t_{2}\right)}\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}Cov\left(S\left(t_{1}\right), S\left(t_{2}\right)\right)&=E\left[S\left(t_{1}\right) S\left(t_{2}\right)\right]-E\left[S\left(t_{1}\right) \right]E\left[S\left(t_{2}\right) \right]\\&=S(0)^{2}\left(e^{\mu\left(t_{1}+t_{2}\right)+\sigma^{2}\left(1.5 t_{1}+0.5 t_{2}\right)}-e^{\mu\left(t_{1}+t_{2}\right)+0.5 \sigma^{2}\left(t_{1}+t_{2}\right)}\right)\\&=S(0)^{2} e^{\left(\mu+0.5 \sigma^{2}\right)\left(t_{1}+t_{2}\right)}\left(e^{\sigma^{2} t_{1}}-1\right)\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}\rho_{S\left(t_{1}\right), S\left(t_{2}\right)}&=\frac{\operatorname{Cov}\left(S\left(t_{1}\right), S\left(t_{2}\right)\right)}{\sigma_{S\left(t_{1}\right)} \sigma_{S\left(h_{2}\right)}}\\&=\frac{S(0)^{2} e^{\left(\mu+0.5 \sigma^{2}\right)\left(\left(_{1}+t_{2}\right)\right.}\left(e^{\sigma^{2} t_{1}}-1\right)}{\sqrt{S(0)^{2} e^{2\left(\mu+0.5 \sigma^{2}\right) x_{1}}\left(e^{\sigma^{2} t_{1}}-1\right) S(0)^{2} e^{2\left(\mu+0.5 \sigma^{2}\right) r_{2}}\left(e^{\sigma^{2} t_{2}}-1\right)}}\\&=\sqrt{\frac{e^{\sigma^{2} t_{1}}-1}{e^{\sigma^{2} t_{2}}-1}}\end{aligned}</script><p>Suppose $S_1\left(t\right)=S_1(0)e^{\mu_1 t+\sigma_1 Z_2\left(t\right)}$ and $S_2\left(t\right)=S_2(0)e^{\mu_2 t+\sigma_2 Z_2\left(t\right)}$</p><script type="math/tex; mode=display">Cov\left(S_{1}(t), S_{2}(t)\right)=S_{1}(0) S_{2}(0) e^{\left(\mu_{1}+\mu_{2}\right) t+\frac{1}{2}\left(\sigma_{1}^{2}+\sigma_{2}^{2}\right) t}\left(e^{\rho \sigma_{1} \sigma_{2} t}-1\right)</script><script type="math/tex; mode=display">\rho_{S_{1}(t), S_{2}(t)}=\frac{e^{\rho \sigma_{1} \sigma_{2} t}-1}{\sqrt{\left(e^{\rho \sigma_{1}^{2} t}-1\right)\left(e^{\rho \sigma_{2}^{2} t}-1\right)}}</script><h2 id="7-Price-jump"><a href="#7-Price-jump" class="headerlink" title="7. Price jump"></a>7. Price jump</h2><p>$S_J(t)$ denote the stock price (with jump) at time t</p><script type="math/tex; mode=display">S_J(t)=S(t)\prod_{i=1}^{N(t)} J_{i},\quad t\ge 0</script><script type="math/tex; mode=display">\begin{aligned}E\left[\prod_{i=1}^{N(t)} J_{i}\right] &=\sum_{n=0}^{\infty} E\left[\prod_{i=1}^{N(t)} J_{i} \mid N(t)=n\right] P(N(t)=n) \\&=\sum_{n=0}^{\infty}(E[J])^{n} \frac{e^{-\lambda t}(\lambda t)^{n}}{n !} \\&=e^{-\lambda t} \sum_{n=0}^{\infty} \frac{(\lambda E[J] t)^{n}}{n !} \\&=e^{-\lambda t(1-E[J])}\end{aligned}</script><script type="math/tex; mode=display">E\left[S_{J}(t)\right]=E\left[S(t) \prod_{i=1}^{N(t)} J_{i}\right] \stackrel{\text { independence }}{=} E[S(t)] E\left[\prod_{i=1}^{N(t)} J_{i}\right]=S(0) e^{\left(\mu+\sigma^{2} / 2-\lambda(1-E[J]) r\right.}</script><p>Set $\mu=r-\sigma^2/2+\lambda(1-E[J])$</p><p>If the jumps $J_i$ have a lognormal distribution $X_i=ln(J_i),i\ge 1$ with mean $\mu_0$ and variance $\sigma_0^2$.The no-arbitrage cost of a European call option having strike price K and expiration time T is</p><script type="math/tex; mode=display">e^{-r T} E\left[\left(S_{J}(T)-K\right)^{+}\right]=e^{-r T} E\left[\left(S(0) e^{W(T)} \prod_{i=1}^{N(T)} J_{i}-K\right)^{+}\right]=e^{-r T} E\left[\left(S(0) e^{W(T)+\sum_{i=1}^{N(T)} X_{i}}-K\right)^{+}\right]</script><p>eq to</p><script type="math/tex; mode=display">\sum_{n=0}^\infty e^{-\lambda E[J]T}\frac{(\lambda E[J]T)^n}{n!}C(S(0),T,K,\sigma(n),r(n))</script><p>where</p><script type="math/tex; mode=display">\sigma(n)=\sqrt{\sigma^{2}+\frac{n \sigma_{0}^{2}}{T}}, \quad E[J]=e^{\mu_{0}+\frac{\sigma_{0}^{2}}{2}} \quad \text { and } \quad r(n)=\mu+\sigma^{2} / 2+\lambda(1-E[J])+\frac{n \ln E[J]}{T}</script><p>A jump is called <strong>pure</strong> if the jump happens at a specific time</p><script type="math/tex; mode=display">S_J(t)=S(t)U^{N_1(t)}D^{N_2(t)},\quad t\ge 0</script><p>where</p><script type="math/tex; mode=display">N_1(t)\sim Poisson(\lambda p),N_2(t)\sim Poisson(\lambda (1-p))</script><script type="math/tex; mode=display">E\left[S_{J}(t)\right]=E\left[S(t) U^{N_{1}(t)} D^{N_{2}(t)}\right]=E[S(t)] E\left[U^{N_{1}(t)}\right] E\left[D^{N_{2}(t)}\right]=S(0) e^{\left(\mu+\sigma^{2} / 2+\lambda p(U-1)+\lambda(1-p)(D-1)\right) t}</script><p>Under the above assumption, the no-arbitrage cost of a European call option having strike price K and expiration time T is given by</p><script type="math/tex; mode=display">\sum_{m=0}^{\infty} \sum_{n=0}^{\infty} e^{-\lambda p T} \frac{(\lambda p T)^{m}}{m !} e^{-\lambda(1-p) T} \frac{(\lambda(1-p) T)^{n}}{n !} C\left(S(0) U^{m} D^{n}, T, K, \sigma, r\right)</script>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Stochastic Process</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】高等数学复习笔记-高等概率</title>
    <link href="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87/"/>
    <url>/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于 ChiuFai WONG 教授的课件进行高等概率零碎知识的整理；</p></blockquote><span id="more"></span><h2 id="随机事件和概率"><a href="#随机事件和概率" class="headerlink" title="随机事件和概率"></a>随机事件和概率</h2><h3 id="运算律"><a href="#运算律" class="headerlink" title="运算律"></a>运算律</h3><ol><li>交换律：$A\bigcup B=B\bigcup A,A\bigcap B=B\bigcap A$</li><li>结合律：$(A\bigcup B)\bigcup C=A\bigcup (B\bigcup C)$</li><li>分配律：$(A\bigcap B)\bigcap C=A\bigcap (B\bigcap C)$</li></ol><h3 id="德-centerdot-摩根律"><a href="#德-centerdot-摩根律" class="headerlink" title="德$\centerdot $摩根律"></a>德$\centerdot $摩根律</h3><ol><li>$\overline{A\bigcup B}=\bar{A}\bigcap \bar{B}$</li><li>$\overline{A\bigcap B}=\bar{A}\bigcup \bar{B}$</li></ol><blockquote><p>并的补等于补的交，交的补等于补的并</p></blockquote><h3 id="概率的基本公式"><a href="#概率的基本公式" class="headerlink" title="概率的基本公式"></a>概率的基本公式</h3><h4 id="全概率公式-Total-Probability-Theorem"><a href="#全概率公式-Total-Probability-Theorem" class="headerlink" title="全概率公式 Total Probability Theorem"></a>全概率公式 Total Probability Theorem</h4><p>If</p><script type="math/tex; mode=display">E_1\cup E_2\cup ...\cup E_n=\Omega\quad and\quad E_i\cap E_j=\varnothing\quad for\quad i\ne j</script><p>by using the fact that the events $A\cap E_i,i=1,2,…,n$ are  mutually exclusive, we obtain</p><script type="math/tex; mode=display">P(A)=\sum_i P(A|E_i)P(E_i)</script><h4 id="Bayes-Theorem"><a href="#Bayes-Theorem" class="headerlink" title="Bayes Theorem"></a>Bayes Theorem</h4><p>Let $\{E_i\}_{i\in I}$ be a finite or countable disjoint union of $\Omega$, and suppose $P(A) &gt; 0$. Then</p><script type="math/tex; mode=display">P(E_n|A)=\frac{P(A\cap E_n)}{P(A)}=\frac{P(A|E_n)P(E_n)}{\sum_i P(A|E_i)P(E_i)}</script><h2 id="随机变量及其概率分布"><a href="#随机变量及其概率分布" class="headerlink" title="随机变量及其概率分布"></a>随机变量及其概率分布</h2><h3 id="Expected-Value"><a href="#Expected-Value" class="headerlink" title="Expected Value"></a>Expected Value</h3><p>In general,  if $g’’(x)&gt;0(or g’’(x)&lt;0)$ for all $x$, then $g(E[x])\le E<a href="\text{or}\ g(E[x]">g(x)</a>\ge E[g(x)])$</p><h3 id="Variance"><a href="#Variance" class="headerlink" title="Variance"></a>Variance</h3><script type="math/tex; mode=display">Var(x)=E[(x-\mu)^2]=E[x^2]-E[x]^2</script><h3 id="Probability-Generating-Function"><a href="#Probability-Generating-Function" class="headerlink" title="Probability Generating Function"></a>Probability Generating Function</h3><script type="math/tex; mode=display">P_X(z)=E(z^X)=p(0)+p(1)z+p(2)z^2+...</script><p>Clearly, $p(n)=\frac1{n!}\frac{d^n}{dz^n}P_X(z)\bigg|_{z=0}$ and $P_X(1)=p(0)+p(1)+p(2)+…=1$</p><p>Also $P’_X(1)=E[X],P’’_X(1)=E[X^2]-E[X],Var[x]=P’’_X(1)+P’_X(1)-P’_X(1)^2$</p><h3 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h3><script type="math/tex; mode=display">f_{Y_1,Y_2}(y_1,y_2)=f_{x_1,x_2}(g_1^{-1}(y_1,y_2),g_2^{-1}(y_1,y_2))|J|</script><p>where $J$ is the Jacobian of $g^{-1}$</p><script type="math/tex; mode=display">f_Z(Z)=\int_{-\infty}^{\infty}f_X(w)f_Y(Z-w)dw</script><h3 id="Law-of-Total-Expectation"><a href="#Law-of-Total-Expectation" class="headerlink" title="Law of Total Expectation"></a>Law of Total Expectation</h3><script type="math/tex; mode=display">E[X]=\sum_yE[X|Y=y]P(Y=y)</script><script type="math/tex; mode=display">Var(X|Y)=E[X^2|Y]-E[X|Y]^2</script><script type="math/tex; mode=display">Var[X]=E[X^2]-E[X]^2=E[Var(X|Y)]+Var(E[X|Y])</script><h3 id="Bivariate-normal-distribution"><a href="#Bivariate-normal-distribution" class="headerlink" title="Bivariate normal distribution"></a>Bivariate normal distribution</h3><script type="math/tex; mode=display">f_{X, Y}(x, y)=\frac{1}{2 \pi \sigma_{X} \sigma_{Y} \sqrt{1-\rho^{2}}} e^{-\frac{1}{2\left(1-\rho^{2}\right)}\left[\left(\frac{x-\mu_{X}}{\sigma_{X}}\right)^{2}-2 \rho\left(\frac{x-\mu_{X}}{\sigma_{X}}\right)\left(\frac{y-\mu_{Y}}{\sigma_{Y}}\right)+\left(\frac{y-\mu_{Y}}{\sigma_{Y}}\right)^{2}\right]}</script><p>$f_{X|Y}(x|y)$ is normally distributed with mean $E[X|Y=y]=\mu_x+\rho \sigma_x\frac{y-\mu_Y}{\sigma_Y}$ </p><p>and variance $Var[X|Y=y]=(1-\rho^2)\sigma_x^2$.</p><h3 id="Moment-generating-function"><a href="#Moment-generating-function" class="headerlink" title="Moment generating function"></a>Moment generating function</h3><script type="math/tex; mode=display">M_{X}(t)=E\left[e^{t x}\right]=\left\{\begin{array}{cl}\sum_{x} e^{t x} p(x) & \text { if } X \text { is discrete with probability mass function } p(x) \\\int_{-\infty}^{\infty} e^{t x} f(x) d x & \text { if } X \text { is continuous with probability density function } f_{X}(x)\end{array}\right.</script><p>Hence</p><script type="math/tex; mode=display">E[X^k]=\frac{d^k}{dt^k}M_X(t)\bigg|_{t=0}</script><p>Furthermore,</p><script type="math/tex; mode=display">\begin{array}{c}\left.\frac{d}{d t} \ln M_{X}(t)\right|_{t=0}=\left.\frac{M_{X}^{\prime}(t)}{M_{X}(t)}\right|_{t=0}=E[X] \text { and } \\\left.\frac{d^{2}}{d t^{2}} \ln M_{X}(t)\right|_{t=0}=\left.\frac{d}{d t}\left(\frac{M_{X}^{\prime}(t)}{M_{X}(t)}\right)\right|_{t=0}=\left.\frac{M_{X}(t) M_{X}^{\prime \prime}(t)-M_{X}^{\prime}(t)^{2}}{M_{X}^{2}(t)}\right|_{t=0}=\operatorname{Var}[X]\end{array}</script><p>the joint moment generating function,</p><script type="math/tex; mode=display">M\left(t_{1}, \cdots, t_{n}\right)=E\left[e^{t_{1} X_{1}+\cdots+t_{n} X_{n}}\right]</script><p>如果 $ \mathbb{E}\left[|\xi|^{n}\right]&lt;\infty$ ,我们就说 $\xi$ 是 $n$ 次可积的, 或者说有 $n$  阶矩. 高阶矩的存在蕴含着低阶矩的存在. 存在蕴含一阶矩存在. 距的存在性实际上依赖于 $\xi$ 的分布函数的尾部大小, $\mathbb{P}(|\xi|&gt;x)$ 作为 $x$ 的函数称为是尾部, 尾部总是一个无穷小量, 可积性非常依赖于尾部的阶. 例如 $\mathbb{E}\left[\left.|\xi\right|^{n}\right]&lt;\infty $ 蕴含着</p><script type="math/tex; mode=display">\lim _{x \rightarrow \infty}|x|^{n} \mathbb{P}(|\xi|>x)=0</script><h3 id="Convergence-of-Random-Variables"><a href="#Convergence-of-Random-Variables" class="headerlink" title="Convergence of Random Variables"></a>Convergence of Random Variables</h3><p><img src="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87/pic4-3.jpg" alt></p><p>In this figure, the stronger types of convergence are on top and, as we move to the bottom, the convergence becomes weaker.</p><h4 id="Convergence-in-Distribution"><a href="#Convergence-in-Distribution" class="headerlink" title="Convergence in Distribution"></a><strong>Convergence in Distribution</strong></h4><script type="math/tex; mode=display">\lim _{n \rightarrow \infty} F_{X_{n}}(x)=F_{X}(x)</script><p>Also</p><script type="math/tex; mode=display">\lim _{n \rightarrow \infty} p_{X_{n}}(x)=p_{X}(x)</script><p><strong>Central Limit Theorem</strong></p><p>Let $Z_{1}, Z_{2}, \cdots$ be a sequence of random variables having distribution functions $F_{Z_{n}}$ and moment generating functions $M_{Z_{n}}, n \geq 1$ , and let $Z$ be a random variable having distribution function $F_{Z}$ and moment generating function $M_{Z}$. If  $M_{Z_{n}}(t) \rightarrow M_{Z}(t) $ for all $t$, then $F_{Z_{n}}(t) \rightarrow F_{Z}(t)$ for all $t$ at which $F_{Z}(t) $ is continuous.</p><script type="math/tex; mode=display">P\left(\frac{X_{1}+\cdots+X_{n}-n \mu}{\sigma \sqrt{n}} \leq a\right)=P\left(\frac{\bar{X}-\mu}{\sigma / \sqrt{n}} \leq a\right) \rightarrow \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{a} e^{-\frac{x^{2}}{2}} d x \text { as } n \rightarrow \infty</script><h4 id="Convergence-in-Probability"><a href="#Convergence-in-Probability" class="headerlink" title="Convergence in Probability"></a><strong>Convergence in Probability</strong></h4><script type="math/tex; mode=display">\lim _{n \rightarrow \infty} P\left(\left|X_{n}-X\right| \geq \varepsilon\right)=0 \text {, for all } \varepsilon>0</script><p><strong>Markov’s inequality</strong></p><script type="math/tex; mode=display">P(X \geq a) \leq \frac{E[X]}{a}</script><p>Proof</p><p>For $a&gt;0$ , define an event $A=\{X \geq a\}$ and $I_{A}$ an indicator for $A$ , that is</p><script type="math/tex; mode=display">I_{A}=\left\{\begin{array}{ll}1 & \text { if } A \text { occurs }(X \geq a) \\ 0 & \text { if } A^{c} \text { occurs }(X<a)\end{array}\right.</script><p>Note that, since $X \geq 0, I_{A} \leq \frac{X}{a}$ and taking expectations of the preceding  inequality yields</p><script type="math/tex; mode=display">P(X \geq a)=P(A)=E\left[I_{A}\right] \leq \frac{E[X]}{a}</script><p><strong>Chebyshev’s inequality</strong></p><script type="math/tex; mode=display">P(|X-\mu| \geq k) \leq \frac{\sigma^{2}}{k^{2}}</script><p><strong>Weak Law of Large Numbers</strong></p><script type="math/tex; mode=display">\lim _{n \rightarrow \infty} P(|\bar{X}-\mu| \geq \varepsilon)\leq \frac{\sigma^{2}}{n\varepsilon^{2}}=0</script><h4 id="Convergence-in-the-r-th-Mean"><a href="#Convergence-in-the-r-th-Mean" class="headerlink" title="Convergence in the r-th Mean"></a><strong>Convergence in the r-th Mean</strong></h4><script type="math/tex; mode=display">\lim _{n \rightarrow \infty} E\left(\left|X_{n}-X\right|^{r}\right)=0</script><h4 id="Almost-Sure-Convergence"><a href="#Almost-Sure-Convergence" class="headerlink" title="Almost Sure Convergence"></a><strong>Almost Sure Convergence</strong></h4><script type="math/tex; mode=display">P\left(\omega \in \Omega: \lim _{n \rightarrow \infty} X_{n}(\omega)=X(\omega)\right)=1</script><p>Also</p><script type="math/tex; mode=display">\mathbb{P}\left(\lim \sup \left\{\left|X_{n}-X\right|>\varepsilon\right\}\right)=0</script><p>由 Borel-Cantelli 推出</p><script type="math/tex; mode=display">\sum_{n=1}^{\infty} P\left(\left|X_{n}-X\right| \geq \varepsilon\right)<\infty</script><h2 id="Special-distributions"><a href="#Special-distributions" class="headerlink" title="Special distributions"></a>Special distributions</h2><h3 id="Discrete-random-variables"><a href="#Discrete-random-variables" class="headerlink" title="Discrete random variables"></a><strong>Discrete random variables</strong></h3><ol><li><h4 id="Bernoulli-p"><a href="#Bernoulli-p" class="headerlink" title="Bernoulli $(p)$"></a>Bernoulli $(p)$</h4><p>Description: $X$ indicates whether a trial that results in a success with probability $p$ is a success or not.</p><p>Probability mass function: $p_{X}(k)=P(X=k)=\left\{\begin{array}{cc}p &amp; \text { for } k=1 \ 1-p &amp; \text { for } k=0 \ 0 &amp; \text { otherwise }\end{array}\right.$</p><p>Mean: $E[X]=p$</p><p>Variance: $\operatorname{Var}[X]=p(1-p)$</p><p>Moment generating function: $M_{X}(t)=1-p+p e^{t}$</p></li><li><h4 id="Binomial-n-p"><a href="#Binomial-n-p" class="headerlink" title="Binomial$(n, p)$"></a>Binomial$(n, p)$</h4><p>Description: $X$ represents the number of successes in $n$ independent trials when each trial is a success with probability $p$.</p><p>Probability mass function: $p_{X}(k)=P(X=k)=\left\{\begin{array}{cc}\left(\begin{array}{l}n \ k\end{array}\right) p^{k}(1-p)^{n-k} &amp; \text { for } k=0,1, \cdots, n \ 0 &amp; \text { otherwise }\end{array}\right.$</p><p>Mean: $E[X]=n p$</p><p>Variance: $\operatorname{Var}[X]=n p(1-p)$</p><p>Moment generating function: $M_{X}(t)=\left(1-p+p e^{t}\right)^{n}$</p><p>Properties:</p><ul><li><p>Binomial$(1, p)$=Binomial$(p)$</p></li><li><p>Sum of $n$ independent Binomial$(p)$ random variables is Binomial$(n, p)$</p></li><li><p>For Binomial tree model : $E[S_n]=S_0(pu+(1-p)d)^n$，$E[S_n^2]=S_0^2(pu^2+(1-p)d^2)^n$</p><p><img src="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87/pic4-1.jpg" alt></p></li></ul></li></ol><ol><li><h4 id="Geometric-p"><a href="#Geometric-p" class="headerlink" title="Geometric $(p)$"></a>Geometric $(p)$</h4><p>Description: $X$ is the number of trials needed to obtain a success when each trial is independently a success with probability $p$.</p><p>Probability mass function: $p_{X}(k)=P(X=k)=\left\{\begin{array}{cc}p(1-p)^{k-1} &amp; \text { for } k=1,2, \cdots \ 0 &amp; \text { otherwise }\end{array}\right.$</p><p>Cumulative distribution function: $P(X&gt;n)=(1-p)^n$</p><p>Mean: $E[X]=\frac{1}{p}$</p><p>Variance: $\operatorname{Var}[X]=\frac{1-p}{p^{2}}$</p><p>Moment generating function: $M_{X}(t)=\frac{p e^{t}}{1-(1-p) e^{t}}$</p><p>Properties:</p><ul><li>Geometric distribution is memoryless. That means that if you intend to repeat an experiment until the first success, then, given that the first success has not yet occurred, the conditional probability distribution of the number of additional trials does not depend on how many failures have been observed.</li><li>Discrete analogue of Exponential random variable.</li></ul></li><li><h4 id="Negative-Binomial-r-p"><a href="#Negative-Binomial-r-p" class="headerlink" title="Negative Binomial $(r, p)$"></a>Negative Binomial $(r, p)$</h4><p>Description: $X$ is the number of trials needed to obtain a total of $r$ successes when each trial is independently a success with probability $p$.</p><p>Probability mass function: $p_{X}(k)=P(X=k)=\left\{\begin{array}{cc}\left(\begin{array}{c}k-1 \ r-1\end{array}\right) p^{r}(1-p)^{k-r} &amp; \text { for } k=r, r+1, \cdots \ 0 &amp; \text { otherwise }\end{array}\right.$</p><p>Mean: $E[X]=\frac{r}{p}$</p><p>Variance: $\operatorname{Var}[X]=r \frac{1-p}{p^{2}}$</p><p>Moment generating function: $M_{X}(t)=\left(\frac{p e^{t}}{1-(1-p) e^{t}}\right)^{r}$</p><p>Properties:</p><ul><li>Negative Binomial$(1, p)$=Geometric$(p)$</li><li>Sum of $r$ independent Geometric $(p)$ random variables is Negative Binomial$(r, p)$</li><li>Discrete analogue of Gamma random variable</li><li>$P(X&gt;n)=P(Y&lt;r)$ for $Y$ a binomial random variable with parameters $n$ and $p$.</li></ul></li><li><h4 id="Poisson-lambda"><a href="#Poisson-lambda" class="headerlink" title="Poisson$(\lambda)$"></a>Poisson$(\lambda)$</h4><p>Description: $X$ is used to model the number of events that occur in many trials that has a small probability of occurrence.</p><p>Probability mass function: $p_{X}(k)=P(X=k)=\left\{\begin{array}{cc}e^{-\lambda} \frac{\lambda^{k}}{k !} &amp; \text { for } k=0,1, \cdots \ 0 &amp; \text { otherwise }\end{array}\right.$</p><p>Mean: $E[X]=\lambda$</p><p>Variance: $\operatorname{Var}[X]=\lambda$</p><p>Moment generating function: $M_{X}(t)=e^{\lambda\left(e^{t}-1\right)}$</p><p>Properties:</p><ul><li>A Poisson random variable $X$ with parameter $\lambda=n p$ provides a good approximation to a Poisson$(n, p)$ random variable when $n$ is large and $p$ is small.</li><li>If events are occurring one at a time in a random manner for which (a) the number of events that occur in disjoint time intervals is independent and (b) the probability of an event occurring in any small time interval is approximately $\lambda$ times the length of the interval, then the number of events in an interval of length $t$ will be a Poisson $(\lambda t)$ random variable.</li></ul></li><li><h4 id="Hypergeometric-n-N-m"><a href="#Hypergeometric-n-N-m" class="headerlink" title="Hypergeometric $(n, N, m)$"></a>Hypergeometric $(n, N, m)$</h4><p>Description: $X$ is the number of white balls in a random sample of $n$ balls chosen without replacement from an urn of $N$ balls of which $m$ are white.</p><p>Probability mass function: $p_{X}(k)=P(X=k)=\left\{\begin{array}{cc}\frac{\left(\begin{array}{c}m \ k\end{array}\right)\left(\begin{array}{c}N-m \ n-k\end{array}\right)}{\left(\begin{array}{c}N \ n\end{array}\right)} &amp; \text { for } k=0,1, \cdots \ 0 &amp; \text { otherwise }\end{array}\right.$</p><p>The preceding uses the convention that $\left(\begin{array}{l}r \ j\end{array}\right)=0$ if either $j<0$ or $j>r$.</0$></p><p>Mean: $E[X]=n \frac{m}{N}$</p><p>Variance: $\operatorname{Var}[X]=n \frac{m}{N}\left(1-\frac{m}{N}\right)\left(\frac{N-n}{N-1}\right)$</p><p>Property:</p><ul><li>If each ball were replaced before the next selection, then $X$ would be a Binomial$(n, p)$ random variable.</li></ul></li></ol><h3 id="Continuous-random-variables"><a href="#Continuous-random-variables" class="headerlink" title="Continuous random variables"></a><strong>Continuous random variables</strong></h3><ol><li><h4 id="Uniform-a-b"><a href="#Uniform-a-b" class="headerlink" title="Uniform $(a, b)$"></a>Uniform $(a, b)$</h4><p>Description: $X$ is equally likely to be near each value in the interval $(a, b)$.</p><p>Probability density function: $f_{X}(x)=\left\{\begin{array}{cl}\frac{1}{b-a} &amp; a&lt;x&lt;b \ 0 &amp; \text { otherwise }\end{array}\right.$</p><p>Mean: $E[X]=\frac{a+b}{2}$</p><p>Variance: $\operatorname{Var}[X]=\frac{(b-a)^{2}}{12}$</p><p>Moment generating function: $M_{X}(t)=\left\{\begin{array}{cc}\frac{e^{b t}-e^{a t}}{t(b-a)} &amp; t \neq 0 \ 1 &amp; t=0\end{array}\right.$</p></li><li><h4 id="Exponential-lambda"><a href="#Exponential-lambda" class="headerlink" title="Exponential $(\lambda)$"></a>Exponential $(\lambda)$</h4><p>Description: $X$ is the waiting time until an event occurs when events are always occurring at a rate $\lambda&gt;0$.</p><p>Probability density function: $f_{X}(x)=\left\{\begin{array}{cc}\lambda e^{-\lambda x} &amp; x\ge0 \ 0 &amp; \text { otherwise }\end{array}\right.$</p><p>Cumulative density function: $F_X(x)=\left\{\begin{array}{cc}1-e^{-\lambda x} &amp; x\ge0 \ 0 &amp; \text { otherwise }\end{array}\right.$</p><p>Mean: $E[X]=\frac{1}{\lambda}$</p><p>Variance: $\operatorname{Var}[X]=\frac{1}{\lambda^{2}}$</p><p>Moment generating function: $M_{X}(t)=\frac{\lambda}{\lambda-t}$ for $\lambda&gt;t$</p><p>Properties:</p><ul><li>$X$ is memoryless, in that the remaining life of an item whose life distribution is Exponential $(\lambda)$ is also Exponential $(\lambda)$, no matter what the current age of the item is.</li><li>Continuous analogue of Geometric random variable.</li></ul></li><li><h4 id="Gamma-alpha-lambda"><a href="#Gamma-alpha-lambda" class="headerlink" title="Gamma$(\alpha, \lambda)$"></a>Gamma$(\alpha, \lambda)$</h4><p>Description: When $\alpha=n, X$ is the waiting time until $n$ events occur when events are always occurring at a rate $\lambda&gt;0$.</p><p>Probability density function: $f_{X}(x)=\left\{\begin{array}{cc}\frac{\lambda e^{-\lambda x}(\lambda x)^{\alpha-1}}{\Gamma(\alpha)} &amp; x&gt;0 \ 0 &amp; \text { otherwise }\end{array}\right.$ where $\Gamma(\alpha)=\int_{0}^{\infty} e^{-x} x^{\alpha-1} d x$ is called the Gamma function.</p><p>Using integration by parts, $\Gamma(\alpha)=(\alpha-1)\Gamma(\alpha-1), \Gamma(n)=(n-1)!$</p><p>Mean: $E[X]=\frac{\alpha}{\lambda}$</p><p>Variance: $\operatorname{Var}[X]=\frac{\alpha}{\lambda^{2}}$</p><p>Moment generating function: $M_{X}(t)=\left(\frac{\lambda}{\lambda-t}\right)^{\alpha}$ for $\lambda&gt;t$</p><p>Properties:</p><ul><li>Gamma$(1, \lambda)$=Gamma$(\lambda)$</li><li>If the random variables are independent, then the sum of a Gamma$\left(\alpha_{1}, \lambda\right)$ and a Gamma $\left(\alpha_{2}, \lambda\right)$ is a Gamma$\left(\alpha_{1}+\alpha_{2}, \lambda\right)$</li><li>The sum of $n$ independent and identically distributed exponentials with parameter $\lambda$ is a Gamma$(n, \lambda)$</li><li>$P\left(S_{n} \leq t\right)=P(N(t) \geq n)$, where $S_{n}$ has Gamma distribution with parameter $(n, \lambda)$ and $N(t)$ is Po isson with mean $\lambda t$.</li></ul><p><img src="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87/pic4-2.jpg" alt></p></li><li><h4 id="Normal-left-mu-sigma-2-right"><a href="#Normal-left-mu-sigma-2-right" class="headerlink" title="Normal$\left(\mu, \sigma^{2}\right)$"></a>Normal$\left(\mu, \sigma^{2}\right)$</h4><p>Description: In many real applications, a certain random variable of interest is a sum of a large number of independent random variables. We are often able to use the Central Limit Theorem to justify using the normal distribution.</p><p>Probability density function: $f_{X}(x)=\frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}$</p><p>Mean: $E[X]=\mu$</p><p>Variance: $\operatorname{Var}[X]=\sigma^{2}$</p><p>Moment generating function: $M_{X}(t)=e^{\mu+\frac{1}{2} \sigma^{2} r^{2}}$</p><p>Properties:</p><ul><li>When $\mu=0, \sigma=1, X$ is called a standard nomal. If $X$ is Normal$\left(\mu, \sigma^{2}\right), Z=\frac{X-\mu}{\sigma}$ is standard normal.</li><li>Sum of independent normal random variables is also normal.</li><li>An important result is the Central Limit Theorem, which states that the distribution of the sum of $n$ independent and identically distributed random variables becomes normal as $n$ goes to infinity, for any distribution of these random variables that has a finite mean and variance.</li><li>Zero covariance of 2 nomal random variables implies these 2 variables are independent.</li></ul></li><li><h4 id="Lognormal-left-mu-sigma-2-right"><a href="#Lognormal-left-mu-sigma-2-right" class="headerlink" title="Lognormal$\left(\mu, \sigma^{2}\right)$"></a>Lognormal$\left(\mu, \sigma^{2}\right)$</h4><p>Description: Lognormal random variable is often used as the distribution of the ratio of the price of security at the end of one day to its price at the end of the prior day.</p><p>Probability density function: $f_{X}(x)=\left\{\begin{array}{cl}\frac{1}{x \sigma \sqrt{2 \pi}} e^{-\frac{(\ln x-\mu)^{2}}{2 \sigma^{2}}} &amp; \text { if } x&gt;0 \ 0 &amp; \text { otherwise }\end{array}\right.$</p><p>Mean: $E[X]=e^{\mu+\frac{1}{2} \sigma^{2}}$</p><p>Variance: $\operatorname{Var}[X]=e^{2 \mu+\sigma^{2}}\left(e^{\sigma^{2}}-1\right)$</p><p>Median: $x_{0.5}=e^{\mu}$</p><p>Properties: $X$ is a lognormal random variable with parameters $\left(\mu, \sigma^{2}\right)$ if $Y=\ln X$ is a normal random variable with parameters $\left(\mu, \sigma^{2}\right)$, that is, lognormal $\rightarrow X=e^{Y \leftarrow \text { mamal }}$</p></li><li><h4 id="Beta-a-b"><a href="#Beta-a-b" class="headerlink" title="Beta$(a, b)$"></a>Beta$(a, b)$</h4><p>Description: The $i$-th smallest of $n$ independent uniform $(0,1)$ random variables is a Beta$(i, n-i+1)$ random variable.</p><p>Probability density function: $f_{X}(x)=\left\{\begin{array}{cl}\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} x^{a-1}(1-x)^{b-1} &amp; 0&lt;x&lt;1 \ 0 &amp; \text { otherwise }\end{array}\right.$ where $\Gamma$ is Gamma function.</p><p>Mean: $E[X]=\frac{a}{a+b}$</p><p>Variance: $\operatorname{Var}[Y]=\frac{a b}{(a+b)^{2}(a+b+1)}$</p><p>Properties: Beta$(1,1)$ and Uniform $(0,1)$ are identical.</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Advanced Probability</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】高等数学复习笔记-微分方程</title>
    <link href="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/"/>
    <url>/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于 William E, Boyce, Richard C 所著的《Elementary Differential Equations and Boundary Value Problems》以及课堂笔记；</p><p>加上网上资料结合进行整理；</p><p>对于部分基础多有忽略，主要用于知识点查找；</p></blockquote><span id="more"></span><h2 id="First-Order-Differential-Equations"><a href="#First-Order-Differential-Equations" class="headerlink" title="First Order Differential Equations"></a>First Order Differential Equations</h2><p>The general first order linear equation is</p><script type="math/tex; mode=display">\frac{dy}{dt}+p(t)y=g(t)\qquad y(t_0)=y_0</script><p>If we multiply the equation above by $\mu(t)$</p><script type="math/tex; mode=display">\mu(t)\frac{dy}{dt}+p(t)\mu(t)y=\mu(t)g(t)</script><p>In order to construct the equation</p><script type="math/tex; mode=display">(uv)'=uv'+u'v</script><p>we set</p><script type="math/tex; mode=display">\frac{d\mu(t)}{dt}=p(t)\mu(t)</script><p>then we have</p><script type="math/tex; mode=display">\frac{d\mu(t)/dt}{\mu(t)}=p(t)</script><p>and consequently</p><script type="math/tex; mode=display">\ln\mu(t)=\int_{t_0}^t p(s)ds+k</script><p>By choosing the arbitrary constant $k$ to be zero</p><script type="math/tex; mode=display">\mu(t)=\exp\int_{t_0}^t p(s)ds</script><p>Returning to the first equation, we have</p><script type="math/tex; mode=display">\frac d{dt}[\mu(t)y]=\mu(t)g(t)</script><p>To satisfy the initial condition (2) we must choose $c = y_0$, Hence</p><script type="math/tex; mode=display">y=\frac{\int_{t_0}^t \mu(s)g(s)ds+y_0}{\mu(t)}</script><h3 id="Separable-Equations"><a href="#Separable-Equations" class="headerlink" title="Separable Equations"></a>Separable Equations</h3><p>The general first order equation is</p><script type="math/tex; mode=display">\frac{dy}{dx}=f(x,y)</script><p> rewrite it in the form</p><script type="math/tex; mode=display">M(x,y)+N(x,y)\frac{dy}{dx}=0</script><p>If $M $ is a function of $x$ only and $N$ is a function of $y$ only (<strong>separable</strong>) , set</p><script type="math/tex; mode=display">H_1'(x)=M(x),\qquad H_2'(y)=N(y)</script><p>the equation becomes</p><script type="math/tex; mode=display">H_1'(x)+H_2'(y)\frac{dy}{dx}=0</script><p>Consequently,</p><script type="math/tex; mode=display">\frac{d}{dx}[H_1(x)+H_2(y)]=0</script><p>we obtain</p><script type="math/tex; mode=display">H_1(x)+H_2(y)=c</script><h3 id="Exact-Equations-and-Integrating-Factors"><a href="#Exact-Equations-and-Integrating-Factors" class="headerlink" title="Exact Equations and Integrating Factors"></a>Exact Equations and Integrating Factors</h3><p> let the differential equation</p><script type="math/tex; mode=display">M(x,y)+N(x,y)y'=0</script><p>If</p><script type="math/tex; mode=display">M_y(x,y)=N_x(x,y)</script><p>there exists a function $\psi$</p><script type="math/tex; mode=display">\psi_x=M(x,y),\qquad \psi_y=N(x,y)</script><p> We define $y = \phi(x)$, Then</p><script type="math/tex; mode=display">\frac{\partial \psi}{\partial x}+\frac{\partial \psi}{\partial y}\frac{dy}{dx}=\frac d{dx}\psi[x,\phi(x)]=0</script><p> Solutions are given implicitly by</p><script type="math/tex; mode=display">\psi(x,y)=c</script><p>where $c$ is an arbitrary constant.</p><p>If</p><script type="math/tex; mode=display">M_y(x,y)\ne N_x(x,y)</script><p>we need an integrating factor $\mu(x,y)$, and satisfies</p><script type="math/tex; mode=display">\begin{aligned}(\mu M)_y&=(\mu N)_x\\M\mu_y+M_y\mu&=N\mu_x+N_x\mu\end{aligned}</script><p>Unfortunately, this function is ordinarily at least as difficult to solve as the original equation. The most important situations in which simple integrating factors can be found occur when $\mu$ is a function of only one of the variables $x$ or $y$, instead of both.</p><script type="math/tex; mode=display">(\mu M)_y=\mu M_y,\qquad(\mu N)_x=\mu N_x+N\frac{d\mu}{dx}</script><p>Thus</p><script type="math/tex; mode=display">\frac{d\mu}{dx}=\frac{M_y-N_x}{N}\mu</script><h2 id="Homogeneous-Equations-with-Constant-Coefficients"><a href="#Homogeneous-Equations-with-Constant-Coefficients" class="headerlink" title="Homogeneous Equations with Constant Coefficients"></a>Homogeneous Equations with Constant Coefficients</h2><script type="math/tex; mode=display">ay''+by'+cy=0</script><p>we set</p><script type="math/tex; mode=display">y_1(t)=e^{r_1t},\qquad y_2(t)=e^{r_2t}</script><p>The <strong>characteristic equation</strong> for the differential equation is</p><script type="math/tex; mode=display">ar^2+br+c=0</script><p>if $r_1\ne r_2$</p><script type="math/tex; mode=display">y=c_1y_1(t)+c_2y_2(t)</script><p>if $r_1,r_2=\lambda\pm i\mu$</p><script type="math/tex; mode=display">y=c_1e^{\lambda t}\cos\mu t+c_2e^{\lambda t}\sin\mu t</script><p>if $r_1 = r_2$</p><script type="math/tex; mode=display">y=c_1y(t)+c_2ty(t)</script><h3 id="Fundamental-Solutions-of-Linear-Homogeneous-Equations"><a href="#Fundamental-Solutions-of-Linear-Homogeneous-Equations" class="headerlink" title="Fundamental Solutions of Linear Homogeneous Equations"></a>Fundamental Solutions of Linear Homogeneous Equations</h3><script type="math/tex; mode=display">y''+p(t)y'+q(t)y=0</script><p><strong>Wronskian determinant</strong></p><script type="math/tex; mode=display">W(y_1,y_2)=\begin{vmatrix}y_1&y_2\\y_1'&y_2'\end{vmatrix}=y_1y_2'-y_1'y_2</script><script type="math/tex; mode=display">W'(y_1,y_2)=y_1'y_2'+y_1y_2''-y_1'y_2'-y_1''y_2=y_1y_2''-y_1''y_2=\begin{vmatrix}y_1&y_2\\y_1''&y_2''\end{vmatrix}</script><p><a href="https://zhuanlan.zhihu.com/p/142082838">扩展</a></p><script type="math/tex; mode=display">\begin{aligned}y_1''+p(t)y_1'+q(t)y_1=0\\y_2''+p(t)y_2'+q(t)y_2=0\end{aligned}</script><p>If we multiply the first equation by $−y_2$, the second by $y_1$, and add the resulting<br>equations, we obtain</p><script type="math/tex; mode=display">(y_1y_2''-y_1''y_2)+p(t)(y_1y_2'-y_1'y_2) = 0</script><p>Then we can write in the form</p><script type="math/tex; mode=display">W'+p(t)W=0</script><p> It is a first order linear equation</p><script type="math/tex; mode=display">W(t)=c\exp[-\int p(t)dt]</script><h3 id="Euler-Equations"><a href="#Euler-Equations" class="headerlink" title="Euler Equations"></a>Euler Equations</h3><script type="math/tex; mode=display">L[y]=x^2y''+\alpha xy'+\beta y=0</script><p>we assume that</p><script type="math/tex; mode=display">y=x^r</script><p>The roots of equation are</p><script type="math/tex; mode=display">r_1,r_2=\frac{-(\alpha-1)\pm\sqrt{(\alpha-1)^2-4\beta}}2</script><p>If the roots are real and different, then</p><script type="math/tex; mode=display">y=c_{1}|x|^{r_{1}}+c_{2}|x|^{r_{2}}</script><p>If the roots are real and equal, then</p><script type="math/tex; mode=display">y=\left(c_{1}+c_{2} \ln |x|\right)|x|^{r_{1}}</script><p>If the roots are complex, then</p><script type="math/tex; mode=display">y=|x|^{\lambda}\left[c_{1} \cos (\mu \ln |x|)+c_{2} \sin (\mu \ln |x|)\right]</script><p>where  $r_{1}, r_{2}=\lambda \pm i \mu$ </p><h2 id="Nonhomogeneous-Equations"><a href="#Nonhomogeneous-Equations" class="headerlink" title="Nonhomogeneous Equations"></a>Nonhomogeneous Equations</h2><script type="math/tex; mode=display">ay''+by'+cy=g(t)</script><script type="math/tex; mode=display">\begin{array}{l|l}\hline g(t) & Y(t) \\ \hline P_{n}(t)=a_{0} t^{n}+a_{1} t^{n-1}+\cdots+a_{n} & t^{s}\left(A_{0} t^{n}+A_{1} t^{n-1}+\cdots+A_{n}\right) \\P_{n}(t) e^{\alpha t} & t^{s}\left(A_{0} t^{n}+A_{1} t^{n-1}+\cdots+A_{n}\right) e^{\alpha t} \\P_{n}(t) e^{\alpha t}\left\{\begin{array}{l}\sin \beta t \\\cos \beta t\end{array}\right. & \begin{array}{l}t^{s}[\left(A_{0} t^{n}+A_{1} t^{n-1}+\cdots+A_{n}\right) e^{\alpha t} \cos \beta t\\+\left(B_{0} t^{n}+B_{1} t^{n-1}+\cdots+B_{n}\right) e^{\alpha t} \sin \beta t]\end{array}\end{array}</script><script type="math/tex; mode=display">y''+p(t)y'+q(t)y=g(x)</script><p>then a particular solution is</p><script type="math/tex; mode=display">Y(t)=-y_{1}(t) \int \frac{y_{2}(t) g(t)}{W\left(y_{1}, y_{2}\right)(t)} d t+y_{2}(t) \int \frac{y_{1}(t) g(t)}{W\left(y_{1}, y_{2}\right)(t)} d t</script><p>and the general solution is</p><script type="math/tex; mode=display">y=c_{1} y_{1}(t)+c_{2} y_{2}(t)+Y(t)</script><h2 id="Series-Solutions-near-an-Ordinary-Point"><a href="#Series-Solutions-near-an-Ordinary-Point" class="headerlink" title="Series Solutions near an Ordinary Point"></a>Series Solutions near an Ordinary Point</h2><p>Find a series solution of the equation</p><script type="math/tex; mode=display">y''+y=0</script><p>We look for a solution in the form of a power series about $x_0 = 0$</p><script type="math/tex; mode=display">y=\sum_{n=0}^\infty a_nx^n</script><p>Differentiating term by term yields</p><script type="math/tex; mode=display">y''=\sum_{n=2}^\infty n(n-1)a_nx^{n-2}</script><p>Substituting the series and y’’ gives</p><script type="math/tex; mode=display">\sum_{n=2}^\infty n(n-1)a_nx^{n-2}+\sum_{n=0}^\infty a_nx^n=0</script><p>We obtain</p><script type="math/tex; mode=display">\sum_{n=0}^\infty[(n+2)(n+1)a_{n+2}+a_n]x^n=0</script><p>hence</p><script type="math/tex; mode=display">(n+2)(n+1)a_{n+2}+a_n=0</script><p>by this recurrence relation we get</p><script type="math/tex; mode=display">a_n=a_{2k}=\frac{(-1)^k}{(2k)!}a_0,\qquad k=1,2,3...</script><p>and</p><script type="math/tex; mode=display">a_n=a_{2k}=\frac{(-1)^k}{(2k+1)!}a_1,\qquad k=1,2,3...</script><p>Substituting these coefficients into equation</p><script type="math/tex; mode=display">y=a_0+a_1x-\frac{a_0}{2!}x^2-\frac{a_1}{3!}x^3+\frac{a_0}{4!}x^4+\frac{a_1}{5!}x^5+...=a_0\sum_{n=0}^\infty\frac{(-1)^n}{(2n)!}x^{2n}+a_1\sum_{n=0}^\infty\frac{(-1)^n}{(2n+1)!}x^{2n+1}</script><h2 id="Series-Solutions-near-a-Regular-Singular-Point"><a href="#Series-Solutions-near-a-Regular-Singular-Point" class="headerlink" title="Series Solutions near a Regular Singular Point"></a>Series Solutions near a Regular Singular Point</h2><p> if $x = 0$ is a regular singular point of the equation</p><script type="math/tex; mode=display">P(x)y''+Q(x)y'+R(x)y=0</script><script type="math/tex; mode=display">p_0=\lim_{x\to0}x\frac{Q(x)}{P(x)},\qquad q_0=\lim_{x\to0}x^2\frac{R(x)}{P(x)}</script><p><strong>Indicial equation</strong></p><script type="math/tex; mode=display">F(r)=r(r-1)+p_0r+q_0</script><script type="math/tex; mode=display">y_1(x)=|x|^{r_1}[1+\sum_{n=1}^\infty a_n(r_1)x^n]</script><p>If $r_1\ge r_2$ </p><script type="math/tex; mode=display">y_2(x)=ay_1(x)\ln|x|+|x|^{r_2}[1+\sum_{n=1}^\infty c_n(r_2)x^n]</script><p>If $r_1=r_2$</p><script type="math/tex; mode=display">y_2(x)=y_1(x)\ln|x|+|x|^{r_1}\sum_{n=1}^\infty b_n(r_1)x^n</script><h2 id="Homogeneous-Linear-Systems-with-Constant-Coefficients"><a href="#Homogeneous-Linear-Systems-with-Constant-Coefficients" class="headerlink" title="Homogeneous Linear Systems with Constant Coefficients"></a>Homogeneous Linear Systems with Constant Coefficients</h2><script type="math/tex; mode=display">x'=Ax</script><p>Set</p><script type="math/tex; mode=display">x=\xi e^{rt}</script><p>Substituting for $x$ in equation</p><script type="math/tex; mode=display">r\xi e^{rt}=A\xi e^{rt}</script><p>we obtain </p><script type="math/tex; mode=display">(A-rI)\xi=0</script><h2 id="Nonhomogeneous-Linear-Systems"><a href="#Nonhomogeneous-Linear-Systems" class="headerlink" title="Nonhomogeneous Linear Systems"></a>Nonhomogeneous Linear Systems</h2><script type="math/tex; mode=display">x'=P(t)x+g(t)</script><p>Let $T$ be the matrix whose columns are the eigenvectors $\xi^{(1)},…,\xi^{(n)}$ of $A$, and<br>define a new dependent variable $y$ by</p><script type="math/tex; mode=display">x=Ty</script><p>Then substituting for $x$ in equation</p><script type="math/tex; mode=display">Ty'=ATy+g(t)</script><p>By multiplying by $T^{-1}$</p><script type="math/tex; mode=display">y'=(T^{-1}AT)y+T^{-1}g(t)=Dy+h(t)</script><p> the equations can be solved separately</p><script type="math/tex; mode=display">y_j(t)=e^{r_jt}\int_{t_0}^te^{-r_js}h_j(s)ds+c_je^{r_jt},\qquad j=1,...,n,</script>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Elementary Differential Equations</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】高等数学复习笔记-微积分</title>
    <link href="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E7%A7%AF%E5%88%86/"/>
    <url>/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E7%A7%AF%E5%88%86/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于 ChiuFai WONG 教授的线性代数课件的笔记；</p><p>与网上资料结合进行整理；</p><p>对于部分基础多有忽略，主要用于知识点查找；</p></blockquote><span id="more"></span><h3 id="函数的可导性与连续性之间的关系"><a href="#函数的可导性与连续性之间的关系" class="headerlink" title="函数的可导性与连续性之间的关系"></a>函数的可导性与连续性之间的关系</h3><p><strong>Th1:</strong> 函数$f(x)$在$x_0$处可微$\Leftrightarrow f(x)$在$x_0$处可导</p><p><strong>Th2:</strong> 若函数在点$x_0$处可导，则$y=f(x)$在点$x_0$处连续，反之则不成立。即函数连续不一定可导。</p><p><strong>Th3:</strong> $f’(x_{0})$存在$\Leftrightarrow f’_{-}(x_{0})=f’_{+}(x_{0})$</p><h3 id="平面曲线的切线和法线"><a href="#平面曲线的切线和法线" class="headerlink" title="平面曲线的切线和法线"></a>平面曲线的切线和法线</h3><p>切线方程 : $y-y_{0}=f’(x_{0})(x-x_{0})$</p><p>法线方程：$y-y_{0}=-\frac{1}{f’(x_{0})}(x-x_{0}),f’(x_{0})\ne 0$</p><h3 id="渐近线的求法"><a href="#渐近线的求法" class="headerlink" title="渐近线的求法"></a>渐近线的求法</h3><ol><li><p>水平渐近线 若$\underset{x\to +\infty }{\mathop{\lim }}\,f(x)=b$，或$\underset{x\to -\infty }{\mathop{\lim }}\,f(x)=b$，则</p><p>$y=b$称为函数$y=f(x)$的水平渐近线。</p></li><li><p>铅直渐近线 若$\underset{x\to x_{0}^{-}}{\mathop{\lim }}\,f(x)=\infty $，或$\underset{x\to x_{0}^{+}}{\mathop{\lim }}\,f(x)=\infty $，则</p><p>$x=x_{0}$称为$y=f(x)$的铅直渐近线。</p></li><li><p>斜渐近线 若$a=\underset{x\to \infty }{\mathop{\lim }}\,\frac{f(x)}{x},\quad b=\underset{x\to \infty }{\mathop{\lim }}\,[f(x)-ax]$，则$</p><p>y=ax+b$称为$y=f(x)$的斜渐近线。</p></li></ol><h3 id="函数凹凸性的判断"><a href="#函数凹凸性的判断" class="headerlink" title="函数凹凸性的判断"></a>函数凹凸性的判断</h3><p><strong>Th1:</strong> (凹凸性的判别定理）若在 I 上$f’’(x)<0$（或$f''(x)>0$），则$f(x)$在 I 上是凸的（或凹的）。</0$（或$f''(x)></p><p><strong>Th2:</strong> (拐点的判别定理 1）若在$x_{0}$处$f’’(x)=0$，（或$f’’(x)$不存在），当$x$变动经过$x_{0}$时，$f’’(x)$变号，则$(x_{0},f(x_{0}))$为拐点。</p><p><strong>Th3:</strong> (拐点的判别定理 2）设$f(x)$在$x_{0}$点的某邻域内有三阶导数，且$f’’(x)=0$，$f’’’(x)\ne 0$，则<script type="math/tex">(x_{0},f(x_{0}))</script>为拐点。</p><h3 id="四则运算法则"><a href="#四则运算法则" class="headerlink" title="四则运算法则"></a>四则运算法则</h3><p>设函数$u=u(x)，v=v(x)$在点$x$可导则</p><ol><li>$(u\pm v{)}’={u}’\pm {v}’$ $d(u\pm v)=du\pm dv$</li><li>$(uv{)}’=u{v}’+v{u}’$ $d(uv)=udv+vdu$</li><li>$(\frac{u}{v}{)}’=\frac{v{u}’-u{v}’}{v^{2}}(v\ne 0)$ $d(\frac{u}{v})=\frac{vdu-udv}{v^{2}}$</li></ol><h3 id="微分中值定理"><a href="#微分中值定理" class="headerlink" title="微分中值定理"></a>微分中值定理</h3><h4 id="费马定理"><a href="#费马定理" class="headerlink" title="费马定理"></a>费马定理</h4><p>函数$f(x)$在$x_{0}$的某邻域内有定义，并且在此邻域内恒有 $f(x)\le f(x_{0})$或 $f(x)\ge f(x_{0})$，且 $f(x)$在$x_{0}$处可导,则有 ${f}’(x_{0})=0$</p><h4 id="罗尔定理-Rolle’s-Theorem"><a href="#罗尔定理-Rolle’s-Theorem" class="headerlink" title="罗尔定理 Rolle’s Theorem"></a>罗尔定理 Rolle’s Theorem</h4><p>Let $f$ be continuous on a closed interval $[a, b]$ and differentiable on $(a, b)$ with $f (a) = f (b)$ . There is at least one point $c$ in $(a, b)$ such that $f’(x)=0$</p><h4 id="拉格朗日中值定理-Lagrange-Mean-Value-Theorem"><a href="#拉格朗日中值定理-Lagrange-Mean-Value-Theorem" class="headerlink" title="拉格朗日中值定理 Lagrange Mean Value Theorem"></a>拉格朗日中值定理 Lagrange Mean Value Theorem</h4><p>Let $f$ be continuous on a closed interval $[a, b]$ and differentiable on $(a, b)$ , then there is at least one point $x$ in $(a, b)$ such that</p><script type="math/tex; mode=display">\frac{f(b)-f(a)}{b-a}=f'(x)</script><h4 id="柯西中值定理-Cauchy-mean-value-theorem"><a href="#柯西中值定理-Cauchy-mean-value-theorem" class="headerlink" title="柯西中值定理 Cauchy mean value theorem"></a>柯西中值定理 Cauchy mean value theorem</h4><p>Let $f，g$ be continuous on a closed interval $[a, b]$ and differentiable on $(a, b)$ with ${g}’(x)\ne 0$，then there is at least one point $x$ in $(a, b)$ such that</p><script type="math/tex; mode=display">\frac{f(b)-f(a)}{g(b)-g(a)}=\frac{f'(x)}{g'(x)}</script><h3 id="洛必达法则-L’Hopital’s-Rule"><a href="#洛必达法则-L’Hopital’s-Rule" class="headerlink" title="洛必达法则 L’Hôpital’s Rule"></a>洛必达法则 L’Hôpital’s Rule</h3><h4 id="0-0-型"><a href="#0-0-型" class="headerlink" title="$0/0$ 型"></a>$0/0$ 型</h4><p>Suppose $f$ and $g$ are differentiable on an open interval $I$ containing $a$ with $g(x)\ne 0$ on $I$ . when $x\ne a$ .</p><p>If $\lim_{x\to a}f(x)=\lim_{x\to a}g(x)=0$, then</p><script type="math/tex; mode=display">\lim_{x\to a}\frac{f(x)}{g(x)}=\lim_{x\to a}\frac{f'(x)}{g'(x)}</script><p><strong>Proof:</strong></p><script type="math/tex; mode=display">f(x)\approx f'(a)(x-a)\qquad g(x)\approx g'(a)(x-a)</script><script type="math/tex; mode=display">\frac{f(x)}{g(x)}\approx\frac{f'(x)(x-a)}{g'(x)(x-a)}=\frac{f'(x)}{g'(x)}</script><h4 id="infty-infty-型"><a href="#infty-infty-型" class="headerlink" title="$\infty/\infty$ 型"></a>$\infty/\infty$ 型</h4><p>If $\lim_{x\to a}f(x)=\pm\infty$ and $\lim_{x\to a}g(x)=\pm\infty$, then</p><script type="math/tex; mode=display">\lim_{x\to a}\frac{f(x)}{g(x)}=\lim_{x\to a}\frac{f'(x)}{g'(x)}</script><p><strong>Proof:</strong></p><p>Let $F(x)=f(x)^{-1}$ and $G(x)=g(x)^{-1}$. Then $\lim_{x\to a}F(x)=\lim_{x\to a}G(x)=0$</p><script type="math/tex; mode=display">\lim_{x\to a}\frac{f(x)}{g(x)}=\lim_{x\to a}\frac{G(x)}{F(x)}=\lim_{x\to a}\frac{G'(x)}{F'(x)}=\lim_{x\to a}\frac{-g'(x)^{-2}g'(x)}{-f'(x)^{-2}f'(x)}=\lim_{x\to a}\frac{f'(x)^{2}g'(x)}{g'(x)^{2}f'(x)}=\lim_{x\to a}\frac{f'(x)}{g'(x)}</script><h4 id="特殊情况中转换成-0-0-型的方法"><a href="#特殊情况中转换成-0-0-型的方法" class="headerlink" title="特殊情况中转换成 $0/0$ 型的方法"></a>特殊情况中转换成 $0/0$ 型的方法</h4><ol><li>$0\cdot\infty: \lim_{x\to a}\underbrace{f(x)}_{\to0}\underbrace{g(x)}_{\to\infty}=\lim_{x\to a}\frac{\overbrace{f(x)}^{\to0}}{\underbrace{g(x)^{-1}}_{\to0}}$</li><li>$\infty-\infty: \lim_{x\to a}(\underbrace{f(x)}_{\to\infty}-\underbrace{g(x)}_{\to\infty})=\lim_{x\to a}(\underbrace{\frac1{f(x)^{-1}}}_{\to0}-\underbrace{\frac1{g(x)^{-1}}}_{\to0})=\lim_{x\to a}\frac{\overbrace{g(x)^{-1}-f(x)^{-1}}^{\to0}}{\underbrace{f(x)^{-1}g(x)^{-1}}_{\to0}}$</li><li>$0^{0}: \lim _{x \to a} \underbrace{f(x)^{\overbrace{g(x)}^{\to 0}}}_{\to 0}=\lim _{x \to a} e^{\overbrace{g(x)}^{\to0} \overbrace{\ln f(x)}^{\to -\infty}}=e^{\lim_{x\to a}\overbrace{g(x)}^{\to0} \overbrace{\ln f(x)}^{\to -\infty}}$ reduced to case (1); </li><li>$1^{\infty}: \lim _{x \to a} \underbrace{f(x)^{\overbrace{g(x)}^{\to \infty}}}_{\to 1}=\lim _{x \to a} e^{\overbrace{g(x)}^{\to\infty} \overbrace{\ln f(x)}^{\to0}}=e^{\lim_{x\to a}\overbrace{g(x)}^{\to\infty} \overbrace{\ln f(x)}^{\to 0}}$ reduced to case (1); </li><li>$\infty ^{0}: \lim _{x \to a} \underbrace{f(x)^{\overbrace{g(x)}^{\to 0}}}_{\to 0}=\lim _{x \to a} e^{\overbrace{g(x)}^{\to0} \overbrace{\ln f(x)}^{\to \infty}}=e^{\lim_{x\to a}\overbrace{g(x)}^{\to0} \overbrace{\ln f(x)}^{\to \infty}}$ reduced to case (1); </li></ol><h3 id="泰勒公式"><a href="#泰勒公式" class="headerlink" title="泰勒公式"></a>泰勒公式</h3><p>设函数$f(x)$在点$x_{0}$处的某邻域内具有$n+1$阶导数，则对该邻域内异于$x_{0}$的任意点$x$：</p><script type="math/tex; mode=display">f(x)=f(x_{0})+f'(x_{0})(x-x_{0})+\frac{1}{2!}f''(x_{0})(x-x_{0})^{2}+\cdots+\frac{f^{(n)}(x_{0})}{n!}(x-x_{0})^{n}+R_{n}(x)</script><p>当 $x_0=0$ 时，为<strong>麦克劳林公式</strong></p><h3 id="Growth-Rates-of-Functions-as-x-to-infty"><a href="#Growth-Rates-of-Functions-as-x-to-infty" class="headerlink" title="Growth Rates of Functions (as $x\to\infty$)"></a>Growth Rates of Functions (as $x\to\infty$)</h3><p>Let $f\ll g$ mean that $g$ grows faster than $f$ as $x\to\infty$ . With positive real number $p, q, r, s$, and $a &gt;1$,</p><script type="math/tex; mode=display">(\ln x)^q\ll x^p\ll x^p(\ln x)^r\ll x^{p+s}\ll a^x\ll x^x</script><h3 id="Growth-Rates-of-Sequences"><a href="#Growth-Rates-of-Sequences" class="headerlink" title="Growth Rates of Sequences"></a>Growth Rates of Sequences</h3><p>The following sequences are ordered according to increasing growth rates as $n\to\infty$; that is,  if $\{a_n\}\ll\{b_n\}$ in the list, then $\lim_{n\to\infty}\frac{a_n}{b_n}=0$:</p><script type="math/tex; mode=display">\{(\ln n)^q\}\ll\{n^p\}\ll\{n^p(\ln n)^r\}\ll\{n^{p+s}\}\ll\{a^n\}\ll\{n!\}\ll\{n^n\}</script><h3 id="Integration-by-parts"><a href="#Integration-by-parts" class="headerlink" title="Integration by parts"></a>Integration by parts</h3><p>the Product Rule states that</p><script type="math/tex; mode=display">(uv)'=uv'+u'v</script><p>By integrating both sides, we have</p><script type="math/tex; mode=display">uv=\int(uv)'dx=\int uv'dx+\int u'vdx=\int udv+\int vdu</script><p>Rearranging this expression, integration by parts for indefinite integral is </p><script type="math/tex; mode=display">\int udv=uv-\int vdu</script><p>Similarly, integration by parts for definite integral is</p><script type="math/tex; mode=display">\int_a^b uv'dx=uv\bigg |_a^b-\int_a^b vu'dx</script><h3 id="Beta-function"><a href="#Beta-function" class="headerlink" title="Beta function"></a>Beta function</h3><p>Let $m, n$ be two non-negative integers. Define</p><script type="math/tex; mode=display">I_{m,n}=\int_0^1x^m(1-x)^ndx</script><script type="math/tex; mode=display">I_{m,n}=\frac n{m+n+1}I_{m,n-1}\qquad I_{m,n}=\frac{m!n!}{(m+n+1)!}</script><h3 id="Strategies-for-solving-int-sin-mx-cos-nx-dx"><a href="#Strategies-for-solving-int-sin-mx-cos-nx-dx" class="headerlink" title="Strategies for solving $\int\sin^mx \cos^nx dx$"></a>Strategies for solving $\int\sin^mx \cos^nx dx$</h3><p>(i) $\quad m=2 k+1$ odd, $n$ real</p><script type="math/tex; mode=display">\begin{aligned}\int \sin ^{2 k+1} x \cos ^{n} x d x &=\int \sin ^{2 k} x \cos ^{n} x \sin x d x \\&=\int\left(1-\cos ^{2} x\right)^{k} \cos ^{n} x \sin x d x \\&=-\int\left(1-\cos ^{2} x\right)^{k} \cos ^{n} x d \cos x\end{aligned}</script><p>(ii) $m$ real, $n=2 l+1$ odd</p><script type="math/tex; mode=display">\begin{aligned}\int \sin ^{m} x \cos ^{2 l+1} x d x &=\int \sin ^{m} x \cos ^{2 l} x \cos x d x \\&=\int \sin ^{m} x\left(1-\sin ^{2} x\right)^{l} \cos x d x \\&=\int \sin ^{m} x\left(1-\sin ^{2} x\right)^{l} d \sin x\end{aligned}</script><p>(iii) both $m=2 k$ and $n=2 l$ nonnegative even integers</p><p>Method 1: </p><p>Use $\sin ^{2} x=\frac{1-\cos 2 x}{2}$ and $\cos ^{2} x=\frac{1+\cos 2 x}{2}$ to transform $\sin ^{2 k} x \cos ^{2 l} x$ into a polynomial in $\cos 2 x$;</p><script type="math/tex; mode=display">\int \sin ^{2 k} x \cos ^{2 l} x d x=\frac{1}{2^{k+l}} \int(1-\cos 2 x)^{k}(1+\cos 2 x)^{l} d x</script><p>and apply the preceding strategies once again to powers of $\cos 2 x$ greater than 1.</p><p>Method 2:  </p><script type="math/tex; mode=display">\quad \int \sin ^{2 k} x \cos ^{2 l} x d x=\int\left(1-\cos ^{2} x\right)^{k} \cos ^{2 l} x d x</script><p>and apply reduction formula (b) in <strong>Reduction Formulas for Power of Trigonometric Functions</strong> to each term on the right after expansion.</p><h2 id="特殊例题"><a href="#特殊例题" class="headerlink" title="特殊例题"></a>特殊例题</h2><h3 id="Exponential-constant"><a href="#Exponential-constant" class="headerlink" title="Exponential constant"></a>Exponential constant</h3><script type="math/tex; mode=display">\lim_{n\to\infty}(1+\frac1n)^n=e</script><p><strong>Method 1:</strong></p><script type="math/tex; mode=display">\begin{aligned}\left(1+\frac{1}{n}\right)^{n}&=\left(\begin{array}{l}n \\0\end{array}\right)+\left(\begin{array}{c}n \\1\end{array}\right) \frac{1}{n}+\left(\begin{array}{c}n \\2\end{array}\right) \frac{1}{n^{2}}+\cdots+\left(\begin{array}{l}n\\k\end{array}\right) \frac{1}{n^{k}}+\cdots+\left(\begin{array}{l}n\\n\end{array}\right) \frac{1}{n^{n}} \\&=1+\frac{1}{1 !} \cdot \frac{n}{n}+\frac{1}{2 !} \cdot \frac{n(n-1)}{n^{2}}+\cdots+\frac{1}{k !} \cdot \frac{n(n-1) \cdots(n-k+1)}{n^{k}}+\cdots+\frac{1}{n !} \cdot \frac{n !}{n^{n}} \\&=1+\frac{1}{1 !}+\frac{1}{2 !}\left(1-\frac{1}{n}\right)+\cdots+\frac{1}{k !}\left(1-\frac{1}{n}\right) \cdots\left(1-\frac{k-1}{n}\right)+\cdots+\frac{1}{n !} \cdot\left(1-\frac{1}{n}\right) \cdots\left(1-\frac{n-1}{n}\right) \\\end{aligned}</script><script type="math/tex; mode=display">\lim_{n\to\infty}(1+\frac1n)^n=1+\frac{1}{1 !}+\frac{1}{2 !} \cdots+\frac{1}{k !}+\cdots+\frac{1}{n !}=e</script><p><strong>Method 2:</strong></p><script type="math/tex; mode=display">\ln (1+\frac1n)^n=n\cdot\ln(1+\frac1n)</script><p>By L’Hôpital’s rule</p><script type="math/tex; mode=display">\lim_{n\to\infty}n\cdot\ln(1+\frac1n)=\lim_{n\to\infty}\frac{\ln(1+\frac1n)}{\frac1n}=\lim_{n\to\infty}\frac{-1}{(1+\frac1n)\cdot n^2}/\frac{-1}{n^2}=1</script><script type="math/tex; mode=display">\lim_{n\to\infty}(1+\frac1n)^n=e</script><p><strong>扩展:</strong></p><script type="math/tex; mode=display">1-\frac{1}{x}=\frac{x-1}{x}=\frac{1}{\left(\frac{x}{x-1}\right)}=\frac{1}{1+\frac{1}{x-1}}=(1+\frac{1}{x-1})^{-1}</script><p> Then</p><script type="math/tex; mode=display">\lim _{x \rightarrow \infty}\left(1-\frac{1}{x}\right)^{-x}=\lim _{x \rightarrow \infty}\left(1+\frac{1}{x-1}\right)^{x}=\lim _{x \rightarrow \infty}\left(1+\frac{1}{x-1}\right)^{x-1} \cdot\left(1+\frac{1}{x-1}\right)=e</script><p>Furthermore</p><script type="math/tex; mode=display">\lim _{y \rightarrow-\infty}\left(1+\frac{1}{y}\right)^{y}=\lim _{x \rightarrow \infty}\left(1-\frac{1}{x}\right)^{-x}=e</script><h3 id="Squeeze-Theorem-例题"><a href="#Squeeze-Theorem-例题" class="headerlink" title="Squeeze Theorem 例题"></a>Squeeze Theorem 例题</h3><script type="math/tex; mode=display">\lim _{x \rightarrow 0} \frac{\sin x}{x}=1</script><p><strong>Proof:</strong></p><p><img src="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E7%A7%AF%E5%88%86/pic2-1.jpg" alt></p><p>Area of  $\Delta O A D=\frac{1}{2}(O D)(A D)=\frac{1}{2} \cos x \sin x $</p><p> $角度(x)=弧长/半径$ ，Area of sector  $O A C=\frac{1}{2} \cdot 1^{2} \cdot x=\frac{x}{2} $</p><p>Area of $ \triangle O B C=\frac{1}{2}(O C)(B C)=\frac{1}{2} \tan x$ </p><p>Since area of  $\triangle O A D&lt; $ area of $ O A C&lt;$  area of  $\triangle O B C$ , we have</p><script type="math/tex; mode=display">\frac{1}{2} \cos x \sin x<\frac{x}{2}<\frac{1}{2} \tan x</script><p>Hence</p><script type="math/tex; mode=display">\cos x<\frac{\sin x}{x}<\frac{1}{\cos x}</script><p>we find that</p><script type="math/tex; mode=display">1=\lim _{x \rightarrow 0^{+}} \cos x<\lim _{x \rightarrow 0^{+}} \frac{\sin x}{x}<\lim _{x \rightarrow 0^{+}} \frac{1}{\cos x}=1</script><p>By Squeeze Theorem</p><script type="math/tex; mode=display">\lim _{x \rightarrow 0^{+}} \frac{\sin x}{x}=1</script><p>Similarly</p><script type="math/tex; mode=display"> \lim _{x \rightarrow 0^{-}} \frac{\sin x}{x}=1</script><p>Therefore</p><script type="math/tex; mode=display">\lim _{x \rightarrow 0} \frac{\sin x}{x}=1</script><h3 id="ln-求导的辅助作用"><a href="#ln-求导的辅助作用" class="headerlink" title="$\ln$ 求导的辅助作用"></a>$\ln$ 求导的辅助作用</h3><script type="math/tex; mode=display">d\ln f(x)=\frac{f'(x)}{f(x)}</script><p>可转换成以下方程求导</p><script type="math/tex; mode=display">f'(x)=f(x)\times d\ln f(x)</script><h2 id="公式查找表"><a href="#公式查找表" class="headerlink" title="公式查找表"></a>公式查找表</h2><h3 id="常用泰勒公式"><a href="#常用泰勒公式" class="headerlink" title="常用泰勒公式"></a>常用泰勒公式</h3><script type="math/tex; mode=display">\begin{aligned}e^{x}&=1+x+\frac{1}{2 !} x^{2}+\cdots+\frac{1}{n !} x^{n}+o\left(x^{n}\right) \\ \sin x&=x-\frac{1}{3 !} x^{3}+\cdots+(-1)^{n-1} \frac{x^{2 n-1}}{(2 n-1) !}+o\left(x^{2 n}\right) \\ \cos x&=1-\frac{1}{2 !} x^{2}+\cdots+(-1)^{n-1} \frac{x^{2 n}}{(2 n) !}+o\left(x^{2 n-1}\right) \\ \ln (1+x)&=x-\frac{1}{2} x^{2}+\frac{1}{3} x^{3}-\cdots+(-1)^{n-1} \frac{x^{n}}{n}+o\left(x^{n}\right) \\ (1+x)^{m}&=1+m x+\frac{m(m-1)}{2 !} x^{2}+\cdots+\frac{m(m-1) \cdots(m-n+1)}{n !} x^{n}+o\left(x^{n}\right) \\ \frac{1}{1-x}&=1+x+x^{2}+\cdots+x^{n}+o\left(x^{n}\right)\end{aligned}</script><h3 id="基本导数与微分表"><a href="#基本导数与微分表" class="headerlink" title="基本导数与微分表"></a>基本导数与微分表</h3><script type="math/tex; mode=display">\begin{array}{c|c}\text { 导数公式 } & \text { 微分公式 } \\\hline(C)^{\prime} = 0 & d C = 0 \\\left(x^{\mu}\right)^{\prime} = \mu x^{\mu-1} & d\left(x^{\mu}\right) = \mu x^{\mu-1} d x \\\left(a^{x}\right)^{\prime} = a^{x} \cdot \ln a & d\left(a^{x}\right) = a^{x} \cdot \ln x d x \\\left(e^{x}\right)^{\prime} = e^{x} & d\left(e^{x}\right) = e^{x} d x \\\left(\log _{a} x\right)^{\prime} = \frac{1}{x \ln a} & d\left(\log _{a} x\right) = \frac{1}{x \ln a} d x \\(\ln x)^{\prime} = \frac{1}{x} & d(\ln x) = \frac{1}{x} d x \\(\sin x)^{\prime} = \cos x & d(\sin x) = \cos x d x \\(\cos x)^{\prime} = -\sin x & d(\cos x) = -\sin x d x \\(\tan x)^{\prime} = \sec ^{2} x & d(\tan x) = \sec { }^{2} x d x\\(\cot x)^{\prime}=-\csc ^{2} x & d(\cot x)=-\csc ^{2} x d x \\(\sec x)^{\prime}=\sec x \cdot \tan x & d(\sec x)=\sec x \cdot \tan x d x \\(\csc x)^{\prime}=-\csc x \cdot \cot x & d(\csc x)=-\csc x \cdot \cot x d x \\(\arcsin x)^{\prime}=\frac{1}{\sqrt{1-x^{2}}} & d(\arcsin x)=\frac{1}{\sqrt{1-x^{2}}} d x \\(\arccos x)^{\prime}=-\frac{1}{\sqrt{1-x^{2}}} & d(\arccos x)=-\frac{1}{\sqrt{1-x^{2}}} d x \\(\arctan x)^{\prime}=\frac{1}{1+x^{2}} & d(\arctan x)=\frac{1}{1+x^{2}} d x \\(\operatorname{arccot} x)^{\prime}=-\frac{1}{1+x^{2}} & d(\operatorname{arccot} x)=-\frac{1}{1+x^{2}} d x\end{array}</script><h3 id="三角函数公式表"><a href="#三角函数公式表" class="headerlink" title="三角函数公式表"></a>三角函数公式表</h3><script type="math/tex; mode=display">\begin{array}{c|c|c|c}倒数关系 & 商的关系 & 平方关系 & 万能公式 \\\hline \tan A \cot A  =1 & \frac{\sin A}{\cos A} =\tan A=\frac{\sec A}{\csc A} & \sin^2 A +\cos^2 A =1&\sin A=\frac{2\tan(A/2)}{1+\tan2(A/2)}\\\sin A \csc A  =1 & \frac{\cos A}{\sin A} =\cot A=\frac{\csc A}{\sec A} & 1+\tan^2 A  =\sec^2 A&\cos A=\frac{1-\tan2(A/2)}{1+\tan2(A/2)}\\\cos A \sec A  = 1 && 1+\cot^2 A =\csc^2 A&\tan A=\frac{2\tan(A/2)}{1-\tan2(A/2)}\\\end{array}</script><script type="math/tex; mode=display">\begin{array}{c|c|c}两角和公式 & 半角公式 & 倍角公式 \\\hline \sin (A+B) = \sin A \cos B+\cos A \sin B & \sin \left(\frac{A}{2}\right) = \sqrt{\frac{1-\cos A}{2}}&\tan 2 A = \frac{2 \tan A}{1-\tan ^{2} A} \\\sin (A-B) = \sin A \cos B-\cos A \sin B & \cos \left(\frac{A}{2}\right) = \sqrt{\frac{1+\cos A}{2}}&\sin 2 A = 2 \sin A \cdot \cos A \\\cos (A+B) = \cos A \cos B-\sin A \sin B & \cot \left(\frac{A}{2}\right) = \sqrt{\frac{1+\cos A}{1-\cos A}}&\cos 2 A = \cos ^{2} A-\sin ^{2} A  \\\cos (A-B) = \cos A \cos B+\sin A \sin B & \tan \left(\frac{A}{2}\right) = \sqrt{\frac{1-\cos A}{1+\cos A}}&\quad\quad= 2 \cos ^{2} A-1 \\\tan (A+B) = \frac{\tan A+\tan B}{1-\tan A \tan B} & \quad\qquad= \frac{1-\cos A}{\sin A}&\quad\quad= 1-2 \sin ^{2} A\\\tan (A-B) = \frac{\tan A-\tan B}{1+\tan A \tan B} & \quad\qquad= \frac{\sin A}{1+\cos A}&\sin 3 A = 3 \sin A-4(\sin A)^{3} \\\cot (A+B) = \frac{\cot A \cot B-1}{\cot B+\cot A}&&\cos 3 A = 4(\cos A)^{3}-3 \cos A \\\cot (A-B) = \frac{\cot A \cot B+1}{\cot B-\cot A}&&\tan 3 A = \tan A \cdot \tan (\frac{\pi}{3}+A) \cdot \tan (\frac{\pi}{3}-A)\end{array}</script><script type="math/tex; mode=display">\begin{array}{c|c}和差化积 & 积化和差 \\\hline \sin A+\sin B = 2 \sin \frac{A+B}{2} \cos \frac{A-B}{2} &\sin A \cos B = \frac{1}{2}[\sin (A+B)+\sin (A-B)] \\\sin A-\sin B = 2 \cos \frac{A+B}{2} \sin \frac{A-B}{2} &\sin A \sin B = \frac{1}{2}[\cos (A-B)-\cos (A+B)] \\\cos A+\cos B = 2 \cos \frac{A+B}{2} \cos \frac{A-B}{2} &\cos A \cos B = \frac{1}{2}[\cos (A-B)+\cos (A+B)] \\\cos A-\cos B = -2 \sin \frac{A+B}{2} \sin \frac{A-B}{2} &\cos A \sin B = \frac{1}{2}[\sin (A+B)-\sin (A-B)]\\\tan A+\tan B = \frac{\sin (A+B)}{\cos A \cos B}\end{array}</script><h3 id="常用高阶导数公式"><a href="#常用高阶导数公式" class="headerlink" title="常用高阶导数公式"></a>常用高阶导数公式</h3><ol><li><p>$\left(a^{x}\right)^{(n)}=a^{x} \ln ^{n} a \quad(a&gt;0) \quad ; \quad\left(e^{x}\right)^{(n)}=e^{x}$</p></li><li><p>$(\sin k x)^{(n)}=k^{n} \sin \left(k x+n \cdot \frac{\pi}{2}\right)$</p></li><li><p>$(\cos k x)^{(n)}=k^{n} \cos \left(k x+n \cdot \frac{\pi}{2}\right)$</p></li><li><p>$\left(x^{m}\right)^{(n)}=m(m-1) \cdots(m-n+1) x^{m-n}$</p></li><li><p>$(\ln x)^{(n)}=(-1)^{(n-1)} \frac{(n-1) !}{x^{n}}$</p></li><li><p>莱布尼兹公式 (Leibniz’s) ：若$u(x)\,,v(x)$均$n$阶可导，则</p><script type="math/tex; mode=display">(uv)^{(n)}=\sum\limits_{i={0}}^{n}c_{n}^{i}u^{(i)}v^{(n-i)}</script><p>其中$u^{(0)}=u$，$v^{(0)}=v$</p></li></ol><h3 id="Reduction-Formulas-for-Power-of-Trigonometric-Functions"><a href="#Reduction-Formulas-for-Power-of-Trigonometric-Functions" class="headerlink" title="Reduction Formulas for Power of Trigonometric Functions"></a>Reduction Formulas for Power of Trigonometric Functions</h3><script type="math/tex; mode=display">\begin{align}&\int \sin ^{n} x d x=-\frac{\sin ^{n-1} x \cos x}{n}+\frac{n-1}{n} \int \sin ^{n-2} x d x\\&\int \cos ^{n} x d x=\frac{\cos ^{n-1} x \sin x}{n}+\frac{n-1}{n} \int \cos ^{n-2} x d x\\&\int \tan ^{n} x d x=\frac{\tan ^{n-1} x}{n-1}-\int \tan ^{n-2} x d x, n \neq 1\\&\int \sec ^{n} x d x=\frac{\sec ^{n-2} x \tan x}{n-1}+\frac{n-2}{n-1} \int \sec ^{n-2} x d x, n \neq 1\end{align}</script><h3 id="三角函数替换"><a href="#三角函数替换" class="headerlink" title="三角函数替换"></a>三角函数替换</h3><p><img src="/2022/07/29/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%BE%AE%E7%A7%AF%E5%88%86/pic2-2.jpg" alt></p>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Calculus</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】高等数学复习笔记-线性代数</title>
    <link href="/2022/07/28/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    <url>/2022/07/28/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于 ChiuFai WONG 教授的线性代数课件的笔记；</p><p>斯坦福大学CS 229机器学习课程的 <a href="http://cs229.stanford.edu/summer2019/cs229-linalg.pdf">基础材料</a>；</p><p>与 Coursera 中的 Mathematics for Machine Learning: Linear Algebra <a href="https://www.coursera.org/learn/linear-algebra-machine-learning?specialization=mathematics-machine-learning#syllabus">课程</a> ；</p><p>三方教程结合进行整理；</p><p>对于部分基础多有忽略，主要用于知识点查找；</p></blockquote><span id="more"></span><h2 id="1-基础概念和符号"><a href="#1-基础概念和符号" class="headerlink" title="1. 基础概念和符号"></a>1. 基础概念和符号</h2><p>我们使用以下符号：</p><ul><li><p>$A \in \mathbb{R}^{m \times n}$，表示 $A$ 为由实数组成具有$m$行和$n$列的矩阵。</p></li><li><p>$x \in \mathbb{R}^{ n}$，表示具有$n$个元素的向量。 通常，向量$x$将表示列向量。</p><script type="math/tex; mode=display">x=\left[\begin{array}{c}{x_{1}} \\ {x_{2}} \\ {\vdots} \\ {x_{n}}\end{array}\right]</script></li></ul><h2 id="2-矩阵的运算"><a href="#2-矩阵的运算" class="headerlink" title="2. 矩阵的运算"></a>2. 矩阵的运算</h2><h4 id="2-1-矩阵乘法"><a href="#2-1-矩阵乘法" class="headerlink" title="2.1 矩阵乘法"></a>2.1 矩阵乘法</h4><ul><li>矩阵乘法结合律: $(AB)C = A(BC)$</li><li>矩阵乘法分配律: $A(B + C) = AB + AC$</li><li>矩阵乘法通常不是可交换的; 也就是说，通常$AB \ne BA$。</li></ul><h4 id="2-2-Dot-Products-and-Cross-Products"><a href="#2-2-Dot-Products-and-Cross-Products" class="headerlink" title="2.2 Dot Products and Cross Products"></a>2.2 Dot Products and Cross Products</h4><p><a href="https://achlier.github.io/2021/02/15/Inner_product_and_Cross_Product/">详细见连接</a></p><h2 id="3-矩阵的属性"><a href="#3-矩阵的属性" class="headerlink" title="3. 矩阵的属性"></a>3. 矩阵的属性</h2><h4 id="3-1-单位矩阵和对角矩阵"><a href="#3-1-单位矩阵和对角矩阵" class="headerlink" title="3.1 单位矩阵和对角矩阵"></a>3.1 单位矩阵和对角矩阵</h4><p><strong>单位矩阵</strong>,$I \in \mathbb{R}^{n \times n} $</p><script type="math/tex; mode=display">I_{i j}=\left\{\begin{array}{ll}{1} & {i=j} \\ {0} & {i \neq j}\end{array}\right.</script><p><strong>对角矩阵</strong>,$D= diag(d_1, d_2, . . . , d_n)$</p><script type="math/tex; mode=display">D_{i j}=\left\{\begin{array}{ll}{d_{i}} & {i=j} \\ {0} & {i \neq j}\end{array}\right.</script><blockquote><p>$ I = diag(1, 1, . . . , 1)$</p></blockquote><h4 id="3-2-转置"><a href="#3-2-转置" class="headerlink" title="3.2 转置"></a>3.2 转置</h4><script type="math/tex; mode=display">(A^T)_{ij} = A_{ji}</script><h4 id="3-3-对称矩阵"><a href="#3-3-对称矩阵" class="headerlink" title="3.3 对称矩阵"></a>3.3 对称矩阵</h4><p>如果$A =  A^T$，则矩阵$A \in \mathbb{R}^ {n \times n}$是<strong>对称矩阵</strong>。 如果$ A =  -  A^T$，它是<strong>反对称</strong>的。</p><p>对于任何矩阵$A \in \mathbb{R}^ {n \times n}$，矩阵$A  +  A^ T$是对称的，矩阵$A -A^T$是反对称的。 由此得出，任何方矩阵$A \in \mathbb{R}^ {n \times n}$可以表示为对称矩阵和反对称矩阵的和，所以：</p><script type="math/tex; mode=display">A=\frac{1}{2}(A+A^T)+\frac{1}{2}(A-A^T)</script><h4 id="3-4-矩阵的迹"><a href="#3-4-矩阵的迹" class="headerlink" title="3.4 矩阵的迹"></a>3.4 矩阵的迹</h4><script type="math/tex; mode=display">\operatorname{tr} A=\sum_{i=1}^{n} A_{i i}</script><p>对于矩阵 $A$, $B$, $C$, $ABC$为方阵, 则：</p><ul><li><p>$\operatorname{tr}A =\operatorname{tr}A^T$</p></li><li><p>$\operatorname{tr}(A + B) = \operatorname{tr}A + \operatorname{tr}B$ with $A,B \in \mathbb{R}^ {n \times n}$</p></li><li><p>$\operatorname{tr}(tA) = t\operatorname{tr}A$ with $ t \in \mathbb{R}$</p></li><li><p>$\operatorname{tr}AB = \operatorname{tr}BA$</p></li><li><p>$\operatorname{tr}ABC = \operatorname{tr}BCA=\operatorname{tr}CAB$</p></li></ul><h4 id="3-5-范数"><a href="#3-5-范数" class="headerlink" title="3.5 范数"></a>3.5 范数</h4><p>欧几里德（$\ell_{2}$）范数，</p><script type="math/tex; mode=display">\|x\|_{2}=\sqrt{x^{T} x}=\sqrt{\sum_{i=1}^{n} x_{i}^{2}}</script><p>$\ell_1$范数:</p><script type="math/tex; mode=display">\|x\|_{1}=\sum_{i=1}^{n}\left|x_{i}\right|</script><p>$\ell_{\infty }$范数：</p><script type="math/tex; mode=display">\|x\|_{\infty}=\max _{i}\left|x_{i}\right|</script><p>以上所提出的三个范数都是$\ell_p$范数族的例子，它们由实数$p \geq 1$参数化，并定义为：</p><script type="math/tex; mode=display">\|x\|_{p}=\left(\sum_{i=1}^{n}\left|x_{i}\right|^{p}\right)^{1 / p}</script><p>Frobenius范数:</p><script type="math/tex; mode=display">\|A\|_{F}=\sqrt{\sum_{i=1}^{m} \sum_{j=1}^{n} A_{i j}^{2}}=\sqrt{\operatorname{tr}\left(A^{T} A\right)}</script><p>范数满足的4个属性（$f : \mathbb{R}^{n} \rightarrow \mathbb{R}$）：</p><ol><li>对于所有的 $x \in \mathbb{R}^ {n}$, $f(x) \geq 0 $ (非负).</li><li>当且仅当$x = 0$ 时，$f(x) = 0$ (明确性).</li><li>对于所有$x \in \mathbb{R}^ {n}$,$t\in \mathbb{R}$，则 $f(tx) = \left| t \right|f(x)$ (正齐次性).</li><li>对于所有 $x,y \in \mathbb{R}^ {n}$, $f(x + y) \leq f(x) + f(y)$ (三角不等式)</li></ol><h4 id="3-6-线性相关性和秩"><a href="#3-6-线性相关性和秩" class="headerlink" title="3.6 线性相关性和秩"></a>3.6 线性相关性和秩</h4><p>矩阵$A  \in \mathbb{R}^{m \times n}$的<strong>列秩</strong>是构成线性无关集合的$A$的最大列子集的大小。<strong>行秩</strong>是构成线性无关集合的$A$的最大行数。 对于任何矩阵$A  \in \mathbb{R}^{m \times n}$，事实证明$A$的列秩等于$A$的行秩，因此两个量统称为$A$的<strong>秩</strong>，用 $\text{rank}(A)$表示。</p><ul><li>对于  $A  \in \mathbb{R}^{m \times n}$，$\text{rank}(A) \leq min(m, n)$，如果$ \text{rank}(A) = \text{min} (m, n)$，则： $A$ 被称作<strong>满秩</strong>。</li><li>对于  $A  \in \mathbb{R}^{m \times n}$， $\text{rank}(A) = \text{rank}(A^T)$</li><li>对于  $A  \in \mathbb{R}^{m \times n}$， $B  \in \mathbb{R}^{n \times p}$ ， $\text{rank}(AB) \leq \text{min} ( \text{rank}(A), \text{rank}(B))$</li><li>对于  $A,B \in \mathbb{R}^{m \times n}$， $\text{rank}(A + B) \leq \text{rank}(A) + \text{rank}(B)$</li></ul><h4 id="3-7-方阵的逆"><a href="#3-7-方阵的逆" class="headerlink" title="3.7 方阵的逆"></a>3.7 方阵的逆</h4><p>方阵$A  \in \mathbb{R}^{n \times n}$的倒数表示为$A^{-1}$。但并非所有矩阵都具有逆。如果矩阵的逆存在，则称它为<strong>正则/可逆/非奇异</strong>，否则称为<strong>奇异/不可逆</strong>。当矩阵逆存在时，这个逆是唯一的。</p><p>If  $A_{i j}$  denotes the cofactor of  $a_{i j}$, then</p><script type="math/tex; mode=display">\begin{aligned}A(\text{adj}(A))&=\left(\begin{array}{cccc}a_{11} & a_{12} & \cdots & a_{1 n} \\a_{21} & a_{22} & \cdots & a_{2 n} \\\vdots & \vdots & \ddots & \vdots \\a_{n 1} & a_{n 2} & \cdots & a_{n n}\end{array}\right)\left(\begin{array}{cccc}A_{11} & A_{21} & \cdots & A_{n 1} \\A_{12} & A_{22} & \cdots & A_{n 2} \\\vdots & \vdots & \ddots & \vdots \\A_{1 n} & A_{2 n} & \cdots & A_{n n}\end{array}\right)\\&=\left(\begin{array}{cccc}A_{11} & A_{21} & \cdots & A_{n 1} \\A_{12} & A_{22} & \cdots & A_{n 2} \\\vdots & \vdots & \ddots & \vdots \\A_{1 n} & A_{2 n} & \cdots & A_{n n}\end{array}\right)\left(\begin{array}{cccc}a_{11} & a_{12} & \cdots & a_{1 n} \\a_{21} & a_{22} & \cdots & a_{2 n} \\\vdots & \vdots & \ddots & \vdots \\a_{n 1} & a_{n 2} & \cdots & a_{n n}\end{array}\right) \\&=\left(\begin{array}{cccc}\text{det}(A) & 0 & \cdots & 0 \\0 & \text{det}(A) & \ddots & \vdots \\\vdots & \ddots & \ddots & 0 \\0 & \cdots & 0 & \text{det}(A)\end{array}\right)=\text{det}(A) I_{n}\end{aligned}</script><p>So  $A^{-1}=\frac1{\text{det}(A) }\text{adj}(A)$.</p><h4 id="3-8-正交阵"><a href="#3-8-正交阵" class="headerlink" title="3.8 正交阵"></a>3.8 正交阵</h4><p>如果一个方阵$U\in \mathbb{R}^{n \times n}$的所有列彼此正交并被归一化，则方阵$U$是<strong>正交阵</strong>。</p><ul><li><p>$x^Ty=0$，则两个向量$x,y\in \mathbb{R}^{n}$ 是<strong>正交</strong></p></li><li><p>$|x|_2=1$，则向量$x\in \mathbb{R}^{n}$ 被归一化</p></li><li><p>可以从正交性和正态性的定义中得出，正交矩阵的逆是其转置。</p><script type="math/tex; mode=display">U^ TU = I = U U^T</script></li><li><p>在具有正交矩阵的向量上操作不会改变其欧几里德范数，即:</p><script type="math/tex; mode=display">\|U x\|_{2}=\|x\|_{2}</script></li></ul><blockquote><p> 注意，如果$U$不是方阵 :即，$U\in \mathbb{R}^{m \times n}$，$n &lt;m$  ，但其列仍然是正交的，则$U^TU = I$，但是$UU^T \neq I$。</p></blockquote><h4 id="3-9-矩阵的值域和零空间"><a href="#3-9-矩阵的值域和零空间" class="headerlink" title="3.9 矩阵的值域和零空间"></a>3.9 矩阵的值域和零空间</h4><p>矩阵$A\in \mathbb{R}^{m \times n}$的值域，表示为$\mathcal{R}(A)$</p><script type="math/tex; mode=display">\mathcal{R}(A)=\left\{v \in \mathbb{R}^{m} : v=A x, x \in \mathbb{R}^{n}\right\}</script><p>矩阵$A\in \mathbb{R}^{m \times n}$的零空间 $\mathcal{N}(A)$ 是所有乘以$A$时等于0向量的集合，即：</p><script type="math/tex; mode=display">\mathcal{N}(A)=\left\{x \in \mathbb{R}^{n} : A x=0\right\}</script><p>我们将投影表示为$\operatorname{Proj}\left(y ;\left\{x_{1}, \ldots x_{n}\right\}\right)$，并且可以将其正式定义为:</p><script type="math/tex; mode=display">\operatorname{Proj}\left(y ;\left\{x_{1}, \ldots x_{n}\right\}\right)=\operatorname{argmin}_{v \in \operatorname{span}\left(\left\{x_{1}, \ldots, x_{n}\right\}\right)}\|y-v\|_{2}</script><p>其中$\{x_{1}, \ldots x_{n}\}$的线性组合的所有向量的集合为：</p><script type="math/tex; mode=display">\operatorname{span}\left(\left\{x_{1}, \ldots x_{n}\right\}\right)=\left\{v : v=\sum_{i=1}^{n} \alpha_{i} x_{i}, \quad \alpha_{i} \in \mathbb{R}\right\}</script><p>如果$A$是满秩且$n &lt;m$，向量$y \in \mathbb{R}^{m}$到$A$的范围的投影由下式给出:</p><script type="math/tex; mode=display">\operatorname{Proj}(y ; A)=\operatorname{argmin}_{v \in \mathcal{R}(A)}\|v-y\|_{2}=A\left(A^{T} A\right)^{-1} A^{T} y</script><h5 id="Proof："><a href="#Proof：" class="headerlink" title="Proof："></a>Proof：</h5><script type="math/tex; mode=display">\begin{aligned}\|A x-y\|_{2}^{2} &=(A x-y)^{T}(A x-y) \\ &=x^{T} A^{T} A x-2 y^{T} A x+y^{T} y \end{aligned}</script><script type="math/tex; mode=display">\begin{aligned} \nabla_{x}\left(x^{T} A^{T} A x-2 y^{T} A x+y^{T} y\right) &=\nabla_{x} x^{T} A^{T} A x-\nabla_{x} 2 y^{T} A x+\nabla_{x} y^{T} y \\ &=2 A^{T} A x-2 A^{T} y \end{aligned}</script><p>将最后一个表达式设置为零，然后解出$x$，得到了正规方程：</p><script type="math/tex; mode=display">x = (A^TA)^{-1}A^Ty ,\qquad v = A(A^TA)^{-1}A^Ty</script><p>$\mathcal{R}(A^T)$和 $\mathcal{N}(A)$ 是不相交的子集，它们一起跨越$\mathbb{R}^{n}$的整个空间。 这种类型的集合称为<strong>正交补</strong>，我们用$\mathcal{R}(A^T)= \mathcal{N}(A)^{\perp}$表示。</p><script type="math/tex; mode=display">\left\{w : w=u+v, u \in \mathcal{R}\left(A^{T}\right), v \in \mathcal{N}(A)\right\}=\mathbb{R}^{n} \text { and } \mathcal{R}\left(A^{T}\right) \cap \mathcal{N}(A)=\{\mathbf{0}\}</script><h5 id="Schmidt-正交化"><a href="#Schmidt-正交化" class="headerlink" title="Schmidt 正交化"></a>Schmidt 正交化</h5><p>若$\alpha_{1},\alpha_{2},\cdots,\alpha_{s}$线性无关，则可构造$\beta_{1},\beta_{2},\cdots,\beta_{s}$使其两两正交，且$\beta_{i}$仅是$\alpha_{1},\alpha_{2},\cdots,\alpha_{i}$的线性组合$(i= 1,2,\cdots,n)$，再把$\beta_{i}$单位化，记$\gamma_{i} =\frac{\beta_{i}}{|\beta_{i}|}$，则$\gamma_{1},\gamma_{2},\cdots,\gamma_{i}$是规范正交向量组。其中:</p><script type="math/tex; mode=display">\begin{aligned}&\beta_{1} = \alpha_{1},\quad\beta_{2} = \alpha_{2} -\frac{\alpha_{2}·\beta_{1}}{\|\beta_{1}\|^2}\beta_{1},\quad\beta_{3} =\alpha_{3} - \frac{\alpha_{3}·\beta_{1}}{\|\beta_{1}\|^2}\beta_{1} -\frac{\alpha_{3}·\beta_{2}}{\|\beta_{2}\|^2}\beta_{2},\\&\cdots\\&\beta_{s} = \alpha_{s} - \frac{\alpha_{s}·\beta_{1}}{\|\beta_{1}\|^2}\beta_{1} - \frac{\alpha_{s}·\beta_{2}}{\|\beta_{2}\|^2}\beta_{2} - \cdots - \frac{\alpha_{s}·\beta_{s - 1}}{\|\beta_{s-1}\|^2}\beta_{s - 1}\end{aligned}</script><h4 id="3-10-行列式"><a href="#3-10-行列式" class="headerlink" title="3.10 行列式"></a>3.10 行列式</h4><p>一个方阵$A  \in \mathbb{R}^{n \times n}$的行列式是函数$\text {det}$：$\mathbb{R}^{n \times n} \rightarrow \mathbb{R}^{n} $，并且表示为$\left| A \right|$， 或者$\text{det} A$。$A$的行列式的绝对值是对集合$S$的“体积”的度量。</p><p>行列式满足以下属性</p><script type="math/tex; mode=display">\left|\left[\begin{array}{ccc}{-} & {t a_{1}^{T}} & {-} \\ {-} & {a_{2}^{T}} & {-} \\ {} & {\vdots} & {} \\ {} & {a_{m}^{T}} & {-}\end{array}\right]\right|=t|A|,\qquad\left|\left[\begin{array}{ccc}{-} & {a_{2}^{T}} & {-} \\ {-} & {a_{1}^{T}} & {-} \\ {} & {\vdots} & {} \\ {-} & {a_{m}^{T}} & {-}\end{array}\right]\right|=-|A|</script><script type="math/tex; mode=display">\left|\left[\begin{array}{ccc}{-} & {a_{1}^{T}+b_{1}^{T}} & {-} \\ {-} & {a_{2}^{T}} & {-} \\ {} & {\vdots} & {} \\ {} & {a_{m}^{T}} & {-}\end{array}\right]\right|=|A|+\left|\left[\begin{array}{ccc}{-} & {b_{1}^{T}} & {-} \\ {-} & {a_{2}^{T}} & {-} \\ {} & {\vdots} & {} \\ {} & {a_{m}^{T}} & {-}\end{array}\right]\right|</script><p>对于 $A,B \in \mathbb{R}^{n \times n}$:</p><ul><li>$\left| A \right| = \left| A^T \right|$</li><li>$\left| {AB} \right| = \left| A \right|\left| B \right| = \left| B \right|\left| A \right| = \left| {BA} \right|$，但$\left| A \pm B \right| = \left| A \right| \pm \left| B \right|$不一定成立。</li><li>有且只有当$A$是奇异时，$\left| A \right|= 0$</li><li>$A$为非奇异时，$\left| A ^{−1}\right| = 1/\left| A \right|$</li><li>$\left| {kA} \right| = k^{n}\left| A \right|$</li><li>$\left| \begin{matrix}  &amp; {A\quad O} \  &amp; {O\quad B} \ \end{matrix} \right| = \left| \begin{matrix}  &amp; {A\quad C} \  &amp; {O\quad B} \ \end{matrix} \right| = \left| \begin{matrix}  &amp; {A\quad O} \  &amp; {C\quad B} \ \end{matrix} \right| =| A||B|$<br>，$A,B$为方阵，$\left| \begin{matrix} {O} &amp; A_{m \times m} \  B_{n \times n} &amp; { O} \ \end{matrix} \right| = ({- 1)}^|A||B|$ </li><li>$\lambda_{i}(i = 1,2\cdots,n)$是$A$的$n$个特征值，则$|A| = \prod_{i = 1}^{n}\lambda_{i}$</li><li><p>Let  $\left(\begin{array}{cc}A_{k \times k} &amp; B_{k \times k} \ C_{k \times k} &amp; D_{k \times k}\end{array}\right)$  be a  $2 k \times 2 k$  block matrix. Suppose  $C_{k \times k} D_{k \times k}=D_{k \times k} C_{k \times k}$  and $\text{det} D_{k \times k} \neq 0$ . Then</p><script type="math/tex; mode=display">\text{det}\left(\begin{array}{cc}A_{k \times k} & B_{k \times k} \\ C_{k \times k} & D_{k \times k}\end{array}\right)=\text{det}\left(A_{k \times k} D_{k \times k}-B_{k \times k} C_{k \times k}\right)</script></li></ul><h5 id="范德蒙行列式"><a href="#范德蒙行列式" class="headerlink" title="范德蒙行列式"></a>范德蒙行列式</h5><script type="math/tex; mode=display">D_{n} = \begin{vmatrix} 1 & 1 & \ldots & 1 \\ x_{1} & x_{2} & \ldots & x_{n} \\ \ldots & \ldots & \ldots & \ldots \\ x_{1}^{n - 1} & x_{2}^{n 1} & \ldots & x_{n}^{n - 1} \\ \end{vmatrix} =  \prod_{1 \leq j < i \leq n}^{}\,(x_{i} - x_{j})</script><h5 id="克莱姆法则-Cramer’s-Rule"><a href="#克莱姆法则-Cramer’s-Rule" class="headerlink" title="克莱姆法则 Cramer’s Rule"></a>克莱姆法则 Cramer’s Rule</h5><p>Let  A  be an  $n \times n$  nonsingular matrix, and let  $\boldsymbol{b} \in \mathbb{R}^{n}$ . Let  $A_{i}$  be the matrix obtained by replacing the</p><p> i-th column of  A  by  $\boldsymbol{b}$ . If $ \boldsymbol{x}$  is the unique solution of  A $\boldsymbol{x}=\boldsymbol{b}$, then</p><script type="math/tex; mode=display">x_{i}=\frac{\text{det}\left(A_{i}\right)}{\text{det}(A)} \quad \text { for } i=1, \cdots, n</script><h5 id="【有趣的例题】"><a href="#【有趣的例题】" class="headerlink" title="【有趣的例题】"></a>【有趣的例题】</h5><p>1.</p><script type="math/tex; mode=display">\begin{aligned}\left|\begin{array}{ccc}1 & 1 & 1 \\ a & b & c \\ a^{2} & b^{2} & c^{2}\end{array}\right|&=\left|\begin{array}{ccc}1 & 0 & 0 \\ a & b-a & c-a \\ a^{2} & b^{2}-a^{2} & c^{2}-a^{2}\end{array}\right| \quad\left[C_{2}-C_{1} \rightarrow C_{2}, C_{3}-C_{1} \rightarrow C_{3}\right]\\&=\left|\begin{array}{cc}b-a & c-a \\ b^{2}-a^{2} & c^{2}-a^{2}\end{array}\right|\\&=(b-a)(c-a)\left|\begin{array}{cc}1 & 1 \\ b+a & c+a\end{array}\right|\\&=(b-a)(c-a)(c-b)\end{aligned}</script><p>2.</p><script type="math/tex; mode=display">\begin{aligned}\left|\begin{array}{ccc}a+b & b+c & c+a \\ a^{2}+b^{2} & b^{2}+c^{2} & c^{2}+a^{2} \\ a^{3}+b^{3} & b^{3}+c^{3} & c^{3}+a^{3}\end{array}\right|&=\left|\begin{array}{ccc}a & b & c \\ a^{2} & b^{2} & c^{2} \\ a^{3} & b^{3} & c^{3}\end{array}\right|\left|\begin{array}{ccc}1 & 0 & 1 \\ 1 & 1 & 0 \\ 0 & 1 & 1\end{array}\right|\\&=2abc\left|\begin{array}{ccc}1 & 1 & 1 \\a & b & c \\a^{2} & b^{2} & c^{2} \end{array}\right| \\&=2 a b c(b-a)(c-a)(c-b)\end{aligned}</script><h4 id="3-11-二次型和半正定矩阵"><a href="#3-11-二次型和半正定矩阵" class="headerlink" title="3.11 二次型和半正定矩阵"></a>3.11 二次型和半正定矩阵</h4><p>给定方矩阵$A  \in \mathbb{R}^{n \times n}$和向量$x \in \mathbb{R}^{n}$，标量值$x^T Ax$被称为二次型。</p><script type="math/tex; mode=display">x^{T} A x=\sum_{i=1}^{n} x_{i}(A x)_{i}=\sum_{i=1}^{n} x_{i}\left(\sum_{j=1}^{n} A_{i j} x_{j}\right)=\sum_{i=1}^{n} \sum_{j=1}^{n} A_{i j} x_{i} x_{j}</script><blockquote><script type="math/tex; mode=display">x^{T} A x=\left(x^{T} A x\right)^{T}=x^{T} A^{T} x=x^{T}\left(\frac{1}{2} A+\frac{1}{2} A^{T}\right) x</script><p>我们经常隐含地假设以二次型出现的矩阵是对称阵。</p></blockquote><ul><li><p>对于所有非零向量$x \in \mathbb{R}^n$，$x^TAx&gt;0$，对称阵$A \in \mathbb{S}^n$为<strong>正定</strong>（<strong>positive definite,PD</strong>）。这通常表示为$A\succ0$（或$A&gt;0$），并且通常将所有正定矩阵的集合表示为$\mathbb{S}_{++}^n$。</p></li><li><p>对于所有向量$x^TAx\geq 0$，对称矩阵$A \in \mathbb{S}^n$是<strong>半正定</strong>(<strong>positive semidefinite ,PSD</strong>)。 这写为（或$A \succeq 0$仅$A≥0$），并且所有半正定矩阵的集合通常表示为$\mathbb{S}_+^n$。</p></li><li><p>同样，对称矩阵$A \in \mathbb{S}^n$是<strong>负定</strong>（<strong>negative definite,ND</strong>），如果对于所有非零$x \in \mathbb{R}^n$，则$x^TAx &lt;0$表示为$A\prec0$（或$A &lt;0$）。</p></li><li><p>类似地，对称矩阵$A \in \mathbb{S}^n$是<strong>半负定</strong>(<strong>negative semidefinite,NSD</strong>），如果对于所有$x \in \mathbb{R}^n$，则$x^TAx \leq 0$表示为$A\preceq 0$（或$A≤0$）。</p></li><li><p>最后，对称矩阵$A \in \mathbb{S}^n$是<strong>不定</strong>的，如果它既不是正半定也不是负半定，即，如果存在$x_1,x_2 \in \mathbb{R}^n$，那么$x_1^TAx_1&gt;0$且$x_2^TAx_2&lt;0$。</p></li></ul><p>给定矩阵$A  \in \mathbb{R}^{m \times n}$，矩阵$G = A^T A$（有时称为<strong>Gram矩阵</strong>）总是半正定的。 此外，如果$m\geq n$（同时为了方便起见，我们假设$A$是满秩），则$G = A^T A$是正定的。</p><h4 id="3-12-特征值和特征向量"><a href="#3-12-特征值和特征向量" class="headerlink" title="3.12 特征值和特征向量"></a>3.12 特征值和特征向量</h4><p>给定一个方阵$A \in\mathbb{R}^{n\times n}$，我们认为在以下条件下，$\lambda \in\mathbb{C}$是$A$的<strong>特征值</strong>，$x\in\mathbb{C}^n$是相应的<strong>特征向量</strong>：</p><script type="math/tex; mode=display">Ax=\lambda x,x \ne 0</script><ul><li><p>设$\lambda$是$A$的一个特征值，则 ${kA},{aA} + {bE},A^{2},A^{m},f(A),A^{T},A^{- 1}$有一个特征值分别为<br>${kλ},{aλ} + b,\lambda^{2},\lambda^{m},f(\lambda),\lambda,\lambda^{- 1},$ 且对应特征向量相同（$A^{T}$ 例外）</p></li><li><p>若$\lambda_{1},\lambda_{2},\cdots,\lambda_{n}$为$A$的$n$个特征值，则$\sum_{i= 1}^{n}\lambda_{i} = \sum_{i = 1}^{n}a_,\prod_{i = 1}^{n}\lambda_{i}= |A|$ ,从而$|A| \neq 0 \Leftrightarrow A$没有特征值</p></li></ul><h5 id="Jordan-block"><a href="#Jordan-block" class="headerlink" title="Jordan block"></a>Jordan block</h5><p>Let $A \in M_{n \times n}(C)$ and $v \in C^{n}$ be a generalized eigenvector of $A$ corresponding to the eigenvalue $\lambda$.</p><p>Suppose that $p$ is the smallest positive integer such that $\left(A-\lambda I_{n}\right)^{p}(\boldsymbol{v})=\boldsymbol{0}$. Let $\gamma=\left\{\left(A-\lambda I_{n}\right)^{p-1}(\boldsymbol{v}), \cdots,\left(A-\lambda I_{n}\right)(\boldsymbol{v}), \boldsymbol{v}\right\}$. Then </p><script type="math/tex; mode=display">[A]_{\gamma}=\left(\begin{array}{ccccc}\lambda & 1 & 0 & \cdots & 0 \\ 0 & \lambda & 1 & \ddots & \vdots \\ \vdots & \ddots & \ddots & \ddots & 0 \\ \vdots & & \ddots & \lambda & 1 \\ 0 & \cdots & 0 & 0 & \lambda\end{array}\right)</script><h5 id="【Example】"><a href="#【Example】" class="headerlink" title="【Example】"></a>【Example】</h5><p>Consider $A=\left(\begin{array}{ccc}3 &amp; 1 &amp; 0 \ -1 &amp; 1 &amp; 0 \ 3 &amp; 2 &amp; 2\end{array}\right)$. Its characteristic polynomial is $\operatorname{det}\left(\lambda I_{3}-A\right)=(\lambda-2)^{3}$.</p><p>There is 1 eigenvalue $\lambda=2$ (multiplicity $=3$ ).</p><p>Consider </p><script type="math/tex; mode=display">E_{2}=N\left(A-2 I_{3}\right)=N\left(\begin{array}{ccc}1 & 1 & 0 \\ -1 & -1 & 0 \\ 3 & 2 & 0\end{array}\right)=\operatorname{span}\left\{\left(\begin{array}{l}0 \\ 0 \\ 1\end{array}\right)\right\}</script><p>Since $\operatorname{dim} E_{2}=1 \neq 3$ (multiplicity of $\left.\lambda=2\right), A$ is not diagonalizable.</p><p>Extend $E_{2}$ to</p><script type="math/tex; mode=display">K_{2}=N\left(\left(A-2 I_{5}\right)^{2}\right)=N\left(\begin{array}{lll}0 & 0 & 0 \\ 0 & 0 & 0 \\ 1 & 1 & 0\end{array}\right)=\operatorname{span}\left\{\left(\begin{array}{l}0 \\ 0 \\ 1\end{array}\right),\left(\begin{array}{c}1 \\ -1 \\ 0\end{array}\right)\right\}, \operatorname{dim} K_{2}=2 \neq 3</script><p> The generalized eigenspace $K_2$ is not large enough to provide 3 eigenvectors. Let us consider</p><script type="math/tex; mode=display">N\left(\left(A-2 I_{3}\right)^{3}\right)=N\left(\begin{array}{lll}0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0\end{array}\right)=C^3</script><p>which has dimension 3. Choose a vector, say </p><script type="math/tex; mode=display">\left(\begin{array}{l}1 \\ 0 \\ 0\end{array}\right) \in N\left(\left(A-2 I_{3}\right)^{3}\right) \backslash N\left(\left(A-2 I_{3}\right)^{2}\right)</script><p>$AP=PJ\Rightarrow(AP_1,AP_2AP_3)=(2P_1,P_1+2P_2,P_2+2P_3)$</p><script type="math/tex; mode=display">\left\{\begin{array}{lcl}AP_1&=&2P_1\\AP_2&=&P_1+2P_2\\AP_3&=&P_2+2P_3\end{array}\right.\Rightarrow\left\{\begin{array}{lcl}(A-2I_3)P_1&=&0\\(A-2I_3)P_2&=&P_1\\(A-2I_3)P_3&=&P_2\end{array}\right.</script><p>Then $P=\left\{(A-2I_3)^2\left(\begin{array}{l}1 \ 0 \ 0\end{array}\right)=\left(\begin{array}{l}0 \ 0 \     1\end{array}\right),(A-2I_3)\left(\begin{array}{l}1 \ 0 \ 0\end{array}\right)=\left(\begin{array}{l}1 \ -1 \     3\end{array}\right),\left(\begin{array}{l}1 \ 0 \ 0\end{array}\right) \right\}$ will form a basis of $C^3$. We have</p><script type="math/tex; mode=display">\begin{aligned}\left(\begin{array}{ccc}3 & 1 & 0 \\-1 & 1 & 0 \\3 & 2 & 2\end{array}\right) &=\left(\begin{array}{ccc}0 & 1 & 1 \\0 & -1 & 0 \\1 & 3 & 0\end{array}\right)\left(\begin{array}{lll}2 & 1 & 0 \\0 & 2 & 1 \\0 & 0 & 2\end{array}\right)\left(\begin{array}{ccc}0 & 1 & 1 \\0 & -1 & 0 \\1 & 3 & 0\end{array}\right)^{-1} \\&=\left(\begin{array}{ccc}0 & 1 & 1 \\0 & -1 & 0 \\1 & 3 & 0\end{array}\right)\left(\begin{array}{ccc}2 & 1 & 0 \\0 & 2 & 1 \\0 & 0 & 2\end{array}\right)\left(\begin{array}{ccc}0 & 3 & 1 \\0 & -1 & 0 \\1 & 1 & 0\end{array}\right)\end{aligned}</script><h5 id="【特殊的例题】"><a href="#【特殊的例题】" class="headerlink" title="【特殊的例题】"></a>【特殊的例题】</h5><p>Let $M_{2 n \times 2 n}=\left(\begin{array}{ll}A_{n \times n} &amp; B_{n \times n} \ C_{n \times n} &amp; D_{n \times n}\end{array}\right)$ be a $2 n \times 2 n$ matrix such that $A_{n \times n}+B_{n \times n}=C_{n \times n}+D_{n \times n}$. Then the characteristic polynomial of $M_{2 n \times 2 n}$ is</p><script type="math/tex; mode=display">\operatorname{det}\left(\lambda I_{2 n}-M_{2 n \times 2 n}\right)=\operatorname{det}\left(\lambda I_{n}-\left(A_{n \times n}-C_{n \times n}\right)\right) \operatorname{det}\left(\lambda I_{n}-\left(C_{n \times n}+D_{n \times n}\right)\right)</script><h2 id="4-矩阵微积分"><a href="#4-矩阵微积分" class="headerlink" title="4.矩阵微积分"></a>4.矩阵微积分</h2><h4 id="4-1-梯度"><a href="#4-1-梯度" class="headerlink" title="4.1 梯度"></a>4.1 梯度</h4><p>假设$f: \mathbb{R}^{m \times n} \rightarrow \mathbb{R}$是将维度为$m \times n$的矩阵$A\in \mathbb{R}^{m \times n}$作为输入并返回实数值的函数。 然后$f$的梯度是偏导数矩阵，定义如下：</p><script type="math/tex; mode=display">\nabla_{A} f(A) \in \mathbb{R}^{m \times n}=\left[\begin{array}{cccc}{\frac{\partial f(A)}{\partial A_{11}}} & {\frac{\partial f(A)}{\partial A_{12}}} & {\cdots} & {\frac{\partial f(A)}{\partial A_{1n}}} \\ {\frac{\partial f(A)}{\partial A_{21}}} & {\frac{\partial f(A)}{\partial A_{22}}} & {\cdots} & {\frac{\partial f(A)}{\partial A_{2 n}}} \\ {\vdots} & {\vdots} & {\ddots} & {\vdots} \\ {\frac{\partial f(A)}{\partial A_{m 1}}} & {\frac{\partial f(A)}{\partial A_{m 2}}} & {\cdots} & {\frac{\partial f(A)}{\partial A_{m n}}}\end{array}\right]</script><p>如果$A$只是向量$A\in \mathbb{R}^{n}$，则</p><script type="math/tex; mode=display">\nabla_{x} f(x)=\left[\begin{array}{c}{\frac{\partial f(x)}{\partial x_{1}}} \\ {\frac{\partial f(x)}{\partial x_{2}}} \\ {\vdots} \\ {\frac{\partial f(x)}{\partial x_{n}}}\end{array}\right]</script><p>从偏导数的等价性质得出：</p><ul><li><p>$\nabla_{x}(f(x)+g(x))=\nabla_{x} f(x)+\nabla_{x} g(x)$</p></li><li><p>对于$t \in \mathbb{R}$ ，$\nabla_{x}(t f(x))=t \nabla_{x} f(x)$</p></li></ul><h4 id="4-2-黑塞矩阵"><a href="#4-2-黑塞矩阵" class="headerlink" title="4.2 黑塞矩阵"></a>4.2 黑塞矩阵</h4><p>假设$f: \mathbb{R}^{n} \rightarrow \mathbb{R}$是一个函数，它接受$\mathbb{R}^{n}$中的向量并返回实数。那么关于$x$的<strong>黑塞矩阵</strong>（也有翻译作海森矩阵），写做：$\nabla_x ^2 f(A x)$，或者简单地说，$H$是$n \times n$矩阵的偏导数：</p><script type="math/tex; mode=display">\nabla_{x}^{2} f(x) \in \mathbb{R}^{n \times n}=\left[\begin{array}{cccc}{\frac{\partial^{2} f(x)}{\partial x_{1}^{2}}} & {\frac{\partial^{2} f(x)}{\partial x_{1} \partial x_{2}}} & {\cdots} & {\frac{\partial^{2} f(x)}{\partial x_{1} \partial x_{n}}} \\ {\frac{\partial^{2} f(x)}{\partial x_{2} \partial x_{1}}} & {\frac{\partial^{2} f(x)}{\partial x_{2}^{2}}} & {\cdots} & {\frac{\partial^{2} f(x)}{\partial x_{2} \partial x_{n}}} \\ {\vdots} & {\vdots} & {\ddots} & {\vdots} \\ {\frac{\partial^{2} f(x)}{\partial x_{n} \partial x_{1}}} & {\frac{\partial^{2} f(x)}{\partial x_{n} \partial x_{2}}} & {\cdots} & {\frac{\partial^{2} f(x)}{\partial x_{n}^{2}}}\end{array}\right]</script><h4 id="4-3-朗斯基行列式-Wronskian"><a href="#4-3-朗斯基行列式-Wronskian" class="headerlink" title="4.3 朗斯基行列式 Wronskian"></a>4.3 朗斯基行列式 Wronskian</h4><script type="math/tex; mode=display">W\left(f_{1}, \cdots, f_{n}\right)(x)=\left|\begin{array}{cccc}f_{1}(x) & f_{2}(x) & \cdots & f_{n}(x) \\f_{1}^{\prime}(x) & f_{2}^{\prime}(x) & \cdots & f_{n}^{\prime}(x) \\\vdots & \vdots & \ddots & \vdots \\f_{1}^{(n-1)}(x) & f_{2}^{(n-1)}(x) & \cdots & f_{n}^{(n-1)}(x)\end{array}\right|</script><p>$W\left(f_{1}, \cdots, f_{n}\right)(x) \neq 0$  if and only if  $f_{1}, \cdots, f_{n}$  are linearly independent.</p><h2 id="5-Linear-Transformations"><a href="#5-Linear-Transformations" class="headerlink" title="5. Linear Transformations"></a>5. Linear Transformations</h2><h4 id="5-1-Transformations"><a href="#5-1-Transformations" class="headerlink" title="5.1 Transformations"></a>5.1 Transformations</h4><p>做矩阵乘法可以看作是对一个矩阵做基的转换。给定一个方阵$A \in\mathbb{R}^{2\times 2}$，以 $AI_2$ 为例</p><ol><li><p>$\boldsymbol{A}_{1}=\left[\begin{array}{ll}\frac{1}{2} &amp; 0 \ 0 &amp; 2\end{array}\right]$ 两个特征向量的方向与 $\mathbb{R}^{2}$ 中的标准基向量相同，即在两个主轴上。纵轴延长2倍（特征值$ \lambda_{1}=2$）。 横轴压缩 $\frac{1}{2}$ 倍（特征值 $ \lambda_{2}=\frac{1}{2}$）。该映射不会改变原图形面积$\operatorname{det}\left(\boldsymbol{A}_{1}\right)=1=2 \cdot \frac{1}{2}$</p><p><img src="/2022/07/28/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/pic1-3.png" alt></p></li><li><p>$\boldsymbol{A}_{2}=\left[\begin{array}{ll}1 &amp; \frac{1}{2} \ 0 &amp; 1\end{array}\right]$ 对应于剪切映射( shearing mapping)，即如果点位于垂直轴的正半轴，则沿水平轴向右剪切点，反之亦然。这个映射不改变原图形的面积 ( $\operatorname{det}\left(\boldsymbol{A}_{2}\right)=1$)。特征值重复 $\lambda_{1}=1=\lambda_{2}$ ，且特征向量共线 (此处的绘制强调的是两个相反方向)。这表示映射仅沿一个方向 (水平轴) 起作用。</p><p><img src="/2022/07/28/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/pic1-4.png" alt></p></li><li><p>$\boldsymbol{A}_{3}=\left[\begin{array}{cc}\cos \left(\frac{\pi}{6}\right) &amp; -\sin \left(\frac{\pi}{6}\right) \ \sin \left(\frac{\pi}{6}\right) &amp; \cos \left(\frac{\pi}{6}\right)\end{array}\right]=\frac{1}{2}\left[\begin{array}{cc}\sqrt{3} &amp; -1 \ 1 &amp; \sqrt{3}\end{array}\right]$ 矩阵 $\boldsymbol{A}_{3} $ 将原图形的点逆时针旋转 $ \frac{\pi}{6} \mathrm{rad}=30^{\circ}$ ，并且只有复数的特征值，这反映出映射是旋转 (因此，没有绘制特征向量)。旋转必须保持体积不变，所以行列式是1。</p><p><img src="/2022/07/28/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/pic1-5.png" alt></p></li><li><p>$\boldsymbol{A}_{4}=\left[\begin{array}{cc}1 &amp; -1 \ -1 &amp; 1\end{array}\right]$ 表示将二维域折叠到一维的标准基映射。由于有一个特征值为 0 ，与 $\lambda_{1}=0$ 对应的 (蓝色) 特征向量方向上的空间收缩为 0 ，而与蓝色正交的 (红色) 特征向量将空间拉伸 $\lambda_{2}=2$ 倍。因此，图像的面积为 0  。</p><p><img src="/2022/07/28/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/pic1-6.png" alt></p></li><li><p>$\boldsymbol{A}_{5}=\left[\begin{array}{cc}1 &amp; \frac{1}{2} \ \frac{1}{2} &amp; 1\end{array}\right]$ 是一种剪切和拉伸映射，它将空间缩放 75% ，因为 $\left|\operatorname{det}\left(\mathrm{A}_{5}\right)\right|=\frac{3}{4}$。它将空间沿 $\lambda_{2}$ 的 (红色) 特征向量方向拉伸1.5倍，并沿与红色正交的 (蓝色) 特征向量方向压缩0.5倍。</p><p><img src="/2022/07/28/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/pic1-7.png" alt></p></li></ol><h4 id="5-3-Projection"><a href="#5-3-Projection" class="headerlink" title="5.3 Projection"></a>5.3 Projection</h4><p>Let  $T: \boldsymbol{R}^{2} \rightarrow \boldsymbol{R}^{2}$  be linear transformation defined by  $T\left(\begin{array}{c}1 \ m\end{array}\right)=\left(\begin{array}{c}1 \ m\end{array}\right)$ and  $ T\left(\begin{array}{c}-m \ 1\end{array}\right)=\left(\begin{array}{l}0 \ 0\end{array}\right) $</p><p><img src="/2022/07/28/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/pic1-1.jpg" alt></p><h5 id="Method-1"><a href="#Method-1" class="headerlink" title="Method 1 :"></a>Method 1 :</h5><p>Since  $\text{det}\left(\begin{array}{cc}1 &amp; -m \ m &amp; 1\end{array}\right)=1+m^{2} \neq 0$,$\left\{\left(\begin{array}{c}1 \\m\end{array}\right),\left(\begin{array}{c}-m \ 1\end{array}\right)\right\}$  is linearly independent. Hence  $\left\{\left(\begin{array}{c}1 \ m\end{array}\right),\left(\begin{array}{c}-m \ 1\end{array}\right)\right\}$  is a basis of  $\boldsymbol{R}^{2}$ . Consider</p><script type="math/tex; mode=display">\left(\begin{array}{l}1 \\0\end{array}\right)=a\left(\begin{array}{c}1 \\m\end{array}\right)+b\left(\begin{array}{c}-m \\1\end{array}\right) \text { and }\left(\begin{array}{l}0 \\1\end{array}\right)=c\left(\begin{array}{c}1 \\m\end{array}\right)+d\left(\begin{array}{c}-m \\1\end{array}\right)</script><p>That is</p><script type="math/tex; mode=display">\left(\begin{array}{l}1 \\0\end{array}\right)=\left(\begin{array}{cc}1 & -m \\m & 1\end{array}\right)\left(\begin{array}{l}a \\b\end{array}\right) \text { and }\left(\begin{array}{l}0\\1\end{array}\right)=\left(\begin{array}{cc}1 & -m \\m & 1\end{array}\right)\left(\begin{array}{l}c \\d\end{array}\right)</script><p>By Cramer’s rule,</p><script type="math/tex; mode=display">\begin{aligned}a=\frac{\left|\begin{array}{cc}1 & -m \\0 & 1\end{array}\right|}{\left|\begin{array}{cc}1 & -m \\m & 1\end{array}\right|}=\frac{1}{1+m^{2}} \quad b=\frac{\left|\begin{array}{cc}1 & 1 \\m & 0\end{array}\right|}{\left|\begin{array}{cc}1 & -m \\m & 1\end{array}\right|}=\frac{-m}{1+m^{2}}\\ \\c=\frac{\left|\begin{array}{cc}0 & -m \\1 & 1\end{array}\right|}{\left|\begin{array}{cc}1 & -m \\m & 1\end{array}\right|}=\frac{m}{1+m^{2}} \quad d=\frac{\left|\begin{array}{cc}1 & 0 \\m & 1\end{array}\right|}{\left|\begin{array}{cc}1 & -m \\m & 1\end{array}\right|}=\frac{1}{1+m^{2}}\end{aligned}</script><p>Then</p><script type="math/tex; mode=display">\begin{aligned}\left(\begin{array}{l}1 \\0\end{array}\right) = \frac{1}{1+m^{2}}\left(\begin{array}{c}1 \\m\end{array}\right)-\frac{m}{1+m^{2}}\left(\begin{array}{c}-m \\1\end{array}\right)\\\left(\begin{array}{l}0 \\1\end{array}\right) = \frac{m}{1+m^{2}}\left(\begin{array}{c}1 \\m\end{array}\right)+\frac{1}{1+m^{2}}\left(\begin{array}{c}-m \\1\end{array}\right)\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}T\left(\begin{array}{l}1 \\0\end{array}\right) & = T\left(\frac{1}{1+m^{2}}\left(\begin{array}{c}1 \\m\end{array}\right)-\frac{m}{1+m^{2}}\left(\begin{array}{c}-m\\1\end{array}\right)\right)\\& = \frac{1}{1+m^{2}} T\left(\begin{array}{c}1 \\m\end{array}\right)-\frac{m}{1+m^{2}} T\left(\begin{array}{c}-m \\1\end{array}\right)\\& = \frac{1}{1+m^{2}}\left(\begin{array}{c}1 \\m\end{array}\right)\\ & = \left(\begin{array}{c}\frac{1}{1+m^{2}} \\\frac{m}{1+m^{2}}\end{array}\right)\\& = \frac{1}{1+m^{2}}\left(\begin{array}{l}1 \\0\end{array}\right)+\frac{m}{1+m^{2}}\left(\begin{array}{l}0 \\1\end{array}\right)\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}T\left(\begin{array}{l}0\\1\end{array}\right) & = T\left(\frac{m}{1+m^{2}}\left(\begin{array}{c}1 \\m\end{array}\right)+\frac{1}{1+m^{2}}\left(\begin{array}{c}-m \\1\end{array}\right)\right)\\& = \frac{m}{1+m^{2}} T\left(\begin{array}{c}1 \\m\end{array}\right)+\frac{1}{1+m^{2}} T\left(\begin{array}{c}-m \\1\end{array}\right)\\& = \frac{m}{1+m^{2}}\left(\begin{array}{c}1 \\m\end{array}\right)\\ & = \left(\begin{array}{c}\frac{m}{1+m^{2}} \\ \frac{m^{2}}{1+m^{2}}\end{array}\right)\\& = \frac{m}{1+m^{2}}\left(\begin{array}{l}1 \\0\end{array}\right)+\frac{m^{2}}{1+m^{2}}\left(\begin{array}{l}0 \\1\end{array}\right)\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}{\left[T^{2}\right]_{\beta} } &=\left([T]_{\beta}\right)^{2} \\&=\left(\begin{array}{ll}\frac{1}{1+m^{2}} & \frac{m}{1+m^{2}} \\\frac{m}{1+m^{2}} & \frac{m^{2}}{1+m^{2}}\end{array}\right)\left(\begin{array}{cc}\frac{1}{1+m^{2}} & \frac{m}{1+m^{2}} \\\frac{m}{1+m^{2}} & \frac{m^{2}}{1+m^{2}}\end{array}\right) \\&=\left(\begin{array}{ll}\frac{1+m^{2}}{\left(1+m^{2}\right)^{2}} & \frac{m+m^{3}}{\left(1+m^{2}\right)^{2}} \\\frac{m+m^{3}}{\left(1+m^{2}\right)^{2}} & \frac{m^{2}+m^{4}}{\left(1+m^{2}\right)^{2}}\end{array}\right) \\&=\left(\begin{array}{ll}\frac{1}{1+m^{2}} & \frac{m}{1+m^{2}} \\\frac{m}{1+m^{2}} & \frac{m^{2}}{1+m^{2}}\end{array}\right)=[T]_{\beta}\end{aligned}</script><h5 id="Method-2"><a href="#Method-2" class="headerlink" title="Method 2 :"></a>Method 2 :</h5><script type="math/tex; mode=display">\boldsymbol{p}=\frac{(x, y)\left(\begin{array}{c}1 \\m\end{array}\right)}{(1, m)\left(\begin{array}{c}1 \\m\end{array}\right)}\left(\begin{array}{c}1 \\m\end{array}\right)=\frac{x+m y}{1+m^{2}}\left(\begin{array}{c}1 \\m\end{array}\right)=\left(\begin{array}{cc}\frac{1}{1+m^{2}} & \frac{m}{1+m^{2}} \\ \frac{m}{1+m^{2}} & \frac{m^{2}}{1+m^{2}}\end{array}\right)\left(\begin{array}{l}x \\y\end{array}\right)</script><script type="math/tex; mode=display">\begin{aligned}\boldsymbol{x}-\boldsymbol{p}&=\left(\begin{array}{l}x \\y\end{array}\right)-\frac{x+m y}{1+m^{2}}\left(\begin{array}{c}1 \\m\end{array}\right)\\&=\left(\begin{array}{c}x-\frac{x+m y}{1+m^{2}} \\y-m \frac{x+m y}{1+m^{2}}\end{array}\right)\\&=\left(\begin{array}{c}\frac{x\left(1+m^{2}\right)-(x+m y)}{1+m^{2}} \\\frac{y\left(1+m^{2}\right)-\left(m x+m^{2} y\right)}{1+m^{2}}\end{array}\right)\\&=\left(\begin{array}{c}\frac{x m^{2}-m y}{1+m^{2}} \\\frac{y-m x}{1+m^{2}}\end{array}\right)\\&=\frac{y-m x}{1+m^{2}}\left(\begin{array}{c}-m \\1\end{array}\right)\\&=\frac{(x, y)\left(\begin{array}{c}-m \\1\end{array}\right)}{(-m, 1)\left(\begin{array}{c}-m \\1\end{array}\right)}\left(\begin{array}{c}-m \\1\end{array}\right) \in W^{\perp}\end{aligned}</script><p>So, $\boldsymbol{x}-\boldsymbol{p}=\text{proj}_{W^{\perp}}\left(\begin{array}{l}x \\y\end{array}\right)$ and $\boldsymbol{x}=\text{proj}_{W}\left(\begin{array}{l}x \\y\end{array}\right)+\text{proj}_{W^{\perp}}\left(\begin{array}{l}x \\y\end{array}\right)$</p><h4 id="5-3-Reflection"><a href="#5-3-Reflection" class="headerlink" title="5.3 Reflection"></a>5.3 Reflection</h4><p>Let  $T: \boldsymbol{R}^{2} \rightarrow \boldsymbol{R}^{2}$  be linear transformation defined by  $T\left(\begin{array}{c}1 \ m\end{array}\right)=\left(\begin{array}{c}1 \ m\end{array}\right)$ and  $ T\left(\begin{array}{c}-m \ 1\end{array}\right)=\left(\begin{array}{l}m \ -1\end{array}\right) $</p><p><img src="/2022/07/28/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/pic1-2.jpg" alt></p><script type="math/tex; mode=display">\begin{aligned}T\left(\begin{array}{l}1 \\0\end{array}\right) & = T\left(\frac{1}{1+m^{2}}\left(\begin{array}{c}1 \\m\end{array}\right)-\frac{m}{1+m^{2}}\left(\begin{array}{c}-m\\1\end{array}\right)\right)\\& = \frac{1}{1+m^{2}} T\left(\begin{array}{c}1 \\m\end{array}\right)-\frac{m}{1+m^{2}} T\left(\begin{array}{c}-m \\1\end{array}\right)\\& = \frac{1}{1+m^{2}}\left(\begin{array}{c}1 \\m\end{array}\right)-\frac{m}{1+m^{2}}\left(\begin{array}{c}m \\-1\end{array}\right)\\ & = \left(\begin{array}{c}\frac{1-m^{2}}{1+m^{2}} \\\frac{2 m}{1+m^{2}}\end{array}\right)\\& = \frac{1-m^{2}}{1+m^{2}}\left(\begin{array}{l}1 \\0\end{array}\right)+\frac{2 m}{1+m^{2}}\left(\begin{array}{l}0 \\1\end{array}\right)\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}T\left(\begin{array}{l}0\\1\end{array}\right) & = T\left(\frac{m}{1+m^{2}}\left(\begin{array}{c}1 \\m\end{array}\right)+\frac{1}{1+m^{2}}\left(\begin{array}{c}-m \\1\end{array}\right)\right)\\& = \frac{m}{1+m^{2}} T\left(\begin{array}{c}1 \\m\end{array}\right)+\frac{1}{1+m^{2}} T\left(\begin{array}{c}-m \\1\end{array}\right)\\& = \frac{m}{1+m^{2}}\left(\begin{array}{c}1 \\m\end{array}\right)+\frac{1}{1+m^{2}}\left(\begin{array}{c}m \\-1\end{array}\right)\\ & = \left(\begin{array}{c}\frac{2 m}{1+m^{2}} \\-\frac{1-m^{2}}{1+m^{2}}\end{array}\right)\\& = \frac{2 m}{1+m^{2}}\left(\begin{array}{l}1 \\0\end{array}\right)-\frac{1-m^{2}}{1+m^{2}}\left(\begin{array}{l}0 \\1\end{array}\right)\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}{\left[T^{2}\right]_{\beta} } &=\left([T]_{\beta}\right)^{2} \\&=\left(\begin{array}{cc}\frac{1-m^{2}}{1+m^{2}} & \frac{2 m}{1+m^{2}} \\\frac{2 m}{1+m^{2}} & -\frac{1-m^{2}}{1+m^{2}}\end{array}\right)\left(\begin{array}{cc}\frac{1-m^{2}}{1+m^{2}} & \frac{2 m}{1+m^{2}} \\\frac{2 m}{1+m^{2}} & -\frac{1-m^{2}}{1+m^{2}}\end{array}\right) \\&=\left(\begin{array}{cc}\frac{\left(1-m^{2}\right)^{2}+(2 m)^{2}}{\left(1+m^{2}\right)^{2}} & \frac{2 m\left(1-m^{2}\right)-\left(1-m^{2}\right) 2 m}{\left(1+m^{2}\right)^{2}} \\\frac{2 m\left(1-m^{2}\right)-\left(1-m^{2}\right) 2 m}{\left(1+m^{2}\right)^{2}} & \frac{\left(1-m^{2}\right)^{2}+(2 m)^{2}}{\left(1+m^{2}\right)^{2}}\end{array}\right) \\&=\left(\begin{array}{ll}1 & 0 \\0 & 1\end{array}\right)\end{aligned}</script>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linear Algebra</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【推导】BS PDE To BS Model</title>
    <link href="/2022/07/09/BS-PDE_To_BS-Model/"/>
    <url>/2022/07/09/BS-PDE_To_BS-Model/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于 ChiuFai WONG 教授的FM2课件中从 BS-PDE 到 BS-MODEL 的推导过程；</p><p>带有个人理解；</p></blockquote><span id="more"></span><h2 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h2><p><strong>Black-Scholes partial differential equation</strong></p><script type="math/tex; mode=display">\frac{\partial V}{\partial t}+\frac{1}{2} \sigma^{2} S^{2} \frac{\partial^{2} V}{\partial S^{2}}+r S \frac{\partial V}{\partial S}-r V=0</script><p>with boundary conditions</p><script type="math/tex; mode=display">C(S, T)=\max (S(T)-K, 0), \quad C(0, t)=0</script><p><strong>$S(t)$ with Brownian motion $Z(t)$ has the following features</strong></p><script type="math/tex; mode=display">dS(t)=\alpha S(t)dt+\sigma S(t)dZ(t)</script><script type="math/tex; mode=display">S(t)=S(0)e^{\sigma Z(t)+(\alpha -\frac12 \sigma^2)t}</script><h2 id="Step-1-换元化简"><a href="#Step-1-换元化简" class="headerlink" title="Step 1 换元化简"></a>Step 1 换元化简</h2><p>In order to get rid of $S \frac{\partial C}{\partial S}$ and $S^{2} \frac{\partial^{2} C}{\partial S^{2}}$ in Black-Scholes equation, we set</p><script type="math/tex; mode=display">S(t)=K e^{x}, \quad t=T-\frac{2 \tau}{\sigma^{2}}, \quad C(S, t)=K v(x, \tau)=K v\left(\ln \frac{S(t)}{K}, \frac{\sigma^{2}}{2}(T-t)\right)</script><blockquote><p>这步主要排除偏导前 S 的影响, 同时为了配合 S 把 K 消除</p></blockquote><p>So we have</p><script type="math/tex; mode=display">\frac{\partial C}{\partial t}=-\frac{\sigma^{2} K}{2} \frac{\partial v}{\partial \tau}, \quad \frac{\partial C}{\partial S}=\frac{K}{S} \frac{\partial v}{\partial x}, \quad \frac{\partial^{2} C}{\partial S^{2}}=-\frac{K}{S^{2}} \frac{\partial v}{\partial x}+\frac{K}{S^{2}} \frac{\partial^{2} v}{\partial x^{2}}</script><p>Placing these expressions into the Black-Scholes partial differential equation and simplifying, we have</p><script type="math/tex; mode=display">\frac{\partial^{2} v}{\partial x^{2}}+(k-1)\frac{\partial v}{\partial x}-kv=\frac{\partial v}{\partial \tau}, \quad -\infty<x<\infty, \quad 0\leq\tau\leq\frac{\sigma^2}2T</script><p>where $k=2\frac r{\sigma^{2}}$. The initial condition becomes</p><script type="math/tex; mode=display">v(x, 0)=\frac{1}{K} C(S, T)=\max \left(e^{x}-1,0\right)</script><p>In order to eliminate $v$ and $\frac{\partial v}{\partial x}$, we set</p><script type="math/tex; mode=display">v(x, \tau)=e^{a x+b \tau} u(x, \tau)</script><p> Computing the partials of $v$ in terms of $x$ and $\tau$ , we have</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial v}{\partial \tau}&=b e^{a x+b \tau} u(x, \tau)+e^{a x+b \tau} \frac{\partial u}{\partial \tau} \\\frac{\partial v}{\partial x}&=a e^{a x+b \tau} u(x, \tau)+e^{a x+b \tau} \frac{\partial u}{\partial x} \\\frac{\partial^{2} v}{\partial x^{2}}&=a^{2} e^{a x+b \tau} u(x, \tau)+2 a e^{a x+b \tau} \frac{\partial u}{\partial x}+e^{a x+b \tau} \frac{\partial^{2} u}{\partial x^{2}}\end{aligned}</script><p>Placing these expressions into the partial differential equation</p><script type="math/tex; mode=display">\begin{aligned}a^{2}u+2 a\frac{\partial u}{\partial x}+\frac{\partial^{2} u}{\partial x^{2}}+(k-1)(au+\frac{\partial u}{\partial x})-ku&=bu+\frac{\partial u}{\partial \tau} \\\frac{\partial^{2} u}{\partial x^{2}}+(2a+k-1)\frac{\partial u}{\partial x}+(a^{2}+a(k-1)-b-k)u&=\frac{\partial u}{\partial \tau}\end{aligned}</script><p>So we can obtain an equation by choosing</p><script type="math/tex; mode=display">\begin{aligned}&b=a^2+(k-1)a-k,\quad 2a=1-k\\\Rightarrow\quad &a=-\frac12(k-1)=\frac{\sigma^2-2r}{2\sigma^2},\quad b=-\frac14(k+1)^2=-(\frac{\sigma^2+2r}{2\sigma^2})^2\\\Rightarrow\quad & v(x, \tau)=e^{-\frac{1}{2}(k-1) x-\frac{1}{4}(k+1)^{2} \tau} u(x, \tau)\end{aligned}</script><p>We then have the heat equation</p><script type="math/tex; mode=display">\frac{\partial u}{\partial \tau}=\frac{\partial^{2} u}{\partial x^{2}}, \quad-\infty<x<\infty, \quad 0 \leq \tau \leq \frac{\sigma^{2}}{2} T</script><p>with initial condition</p><script type="math/tex; mode=display">u(x, 0)=e^{-\alpha x} v(x, 0)=\max \left(e^{\frac{1}{2}(k+1) x}-e^{\frac{1}{2}(k-1) x}, 0\right)</script><h2 id="Step-2-使用Laplace变换的方法求热传导公式"><a href="#Step-2-使用Laplace变换的方法求热传导公式" class="headerlink" title="Step 2 使用Laplace变换的方法求热传导公式"></a>Step 2 使用Laplace变换的方法求热传导公式</h2><h4 id="知识点回顾-Fourier-Transform"><a href="#知识点回顾-Fourier-Transform" class="headerlink" title="知识点回顾 Fourier Transform"></a>知识点回顾 <a href="https://achlier.github.io/2021/05/30/Fourier_Transform">Fourier Transform</a></h4><p>Define </p><script type="math/tex; mode=display">U(x, s)=\mathfrak{L}_{s}(u(x, \tau)):=\int_{0}^{\infty} e^{-s \tau} u(x, \tau) d \tau</script><p>where $\mathfrak{L}_{s}$​ is the Laplace operator with parameter $s$. Then, we have</p><script type="math/tex; mode=display">sU(x, s)-u(x, 0)=U_{x x}(x, s)</script><p>Its characteristic equation is $r^2-s=0$. The roots are $r_1=\sqrt{s},r_2=-\sqrt{s}$</p><p>The homogeneous solution is </p><script type="math/tex; mode=display">U_{h}(x, s)=c_{1} e^{x \sqrt{s}}+c_{2} e^{-x \sqrt{s}}</script><hr><h4 id="Before-calculating-particular-solution-we-need-Definition-4-12-and-Theorem-4-13"><a href="#Before-calculating-particular-solution-we-need-Definition-4-12-and-Theorem-4-13" class="headerlink" title="Before calculating particular solution, we need Definition 4.12 and Theorem 4.13"></a>Before calculating particular solution, we need Definition 4.12 and Theorem 4.13</h4><h5 id="Definition-4-12"><a href="#Definition-4-12" class="headerlink" title="Definition 4.12"></a>Definition 4.12</h5><p>Define error function $\operatorname{erf}(x)=\frac{1}{\sqrt{\pi}} \int_{-x}^{x} e^{-t^{2}} d t=\frac{2}{\sqrt{\pi}} \int_{0}^{x} e^{-t^{2}} d t$ and complementary error function $\operatorname{erfc}(x)=1-\operatorname{erf}(x)=\frac{2}{\sqrt{\pi}} \int_{x}^{\infty} e^{-t^{2}} d t$</p><h5 id="Theorem-4-13"><a href="#Theorem-4-13" class="headerlink" title="Theorem 4.13"></a>Theorem 4.13</h5><p>Suppose $\frac{\partial u}{\partial \tau}=\frac{\partial^{2} u}{\partial x^{2}}$ with $u(x, 0)=u(\infty, \tau)=0, u(0, \tau)=1$ . Then we have</p><ol><li>$u(x, \tau)=\frac{2}{\sqrt{\pi}} \int_{\frac{x}{2 \sqrt{\tau}}}^{\infty} e^{-t^{2}} d t$ . </li><li>$\mathfrak{L}_{s}\left(\frac{1}{2 \sqrt{\pi \tau}} e^{-\frac{x^{2}}{4 \tau}}\right)=\frac{e^{-x \sqrt{s}}}{2 \sqrt{s}} \text { for } x&gt;0$ .</li></ol><h5 id="proof-1"><a href="#proof-1" class="headerlink" title="proof 1"></a>proof 1</h5><p>Let $\xi=\frac{x}{\sqrt{\tau}}$ such that $u(x, \tau)=U(\xi)$</p><blockquote><p>此处的 $U$ 与之前的不相同，这里表示的是以 $\xi$ 为变量的 $u$ 的另外一个形式</p></blockquote><script type="math/tex; mode=display">\begin{aligned}&\frac{\partial u}{\partial \tau}=U^{\prime}(\xi) \frac{d \xi}{d \tau}=U^{\prime}(\xi)\left(-\frac{1}{2} x \tau^{-\frac{3}{2}}\right)=-\frac{1}{2 \tau} \xi U^{\prime}(\xi) \\&\frac{\partial u}{\partial x}=U^{\prime}(\xi) \frac{d \xi}{d x}=U^{\prime}(\xi) \frac{1}{\sqrt{\tau}} \\&\frac{\partial^{2} u}{\partial x^{2}}=U^{\prime \prime}(\xi) \frac{d \xi}{d x} \frac{1}{\sqrt{\tau}}=U^{\prime \prime}(\xi) \frac{1}{\tau}\end{aligned}</script><script type="math/tex; mode=display">\frac{\partial^{2} u}{\partial x^{2}}=\frac{\partial u}{\partial \tau} \Rightarrow U^{\prime \prime}(\xi) \frac{1}{\tau}=-\frac{1}{2 \tau} \xi U^{\prime}(\xi) \Rightarrow \frac{U^{\prime \prime}(\xi)}{U^{\prime}(\xi)}=-\frac{1}{2} \xi \Rightarrow \int \frac{U^{\prime \prime}(\xi)}{U^{\prime}(\xi)} d \xi=\int-\frac{1}{2} \xi d \xi</script><script type="math/tex; mode=display">\begin{aligned}&U^{\prime}(\xi)=C e^{-\frac{\xi^{2}}{4}} \\&U(\xi)=C \int_{0}^{\xi} e^{-\frac{s^{2}}{4}} d s+D \\&u(x, 0)=u(\infty, \tau)=0, u(0, \tau)=1 \Rightarrow U(0)=1, U(\infty)=0\\\end{aligned}</script><p>Recall $\int_{0}^{\infty} e^{-\frac{s^{2}}{4}} d s=\sqrt{\pi}$  . We have $D=1, \quad C=-\frac{1}{\sqrt{\pi}}$</p><script type="math/tex; mode=display">U(\xi)=\frac{1}{\sqrt{\pi}} \int_{\xi}^{\infty} e^{-\frac{s^{2}}{4}} d s</script><script type="math/tex; mode=display">u(x, \tau)=\frac{1}{\sqrt{\pi}} \int_{\frac{x}{\sqrt{\tau}}}^{\infty} e^{-\frac{s^{2}}{4}} d s \quad \stackrel{t=\frac{s}{2}}{=} \frac{2}{\sqrt{\pi}} \int_{\frac{x}{2 \sqrt{\tau}}}^{\infty} e^{-t^{2}} d t=\operatorname{erfc}\left(\frac{x}{2 \sqrt{\tau}}\right)</script><h5 id="proof-2"><a href="#proof-2" class="headerlink" title="proof 2"></a>proof 2</h5><p>We have found that</p><script type="math/tex; mode=display">U(x, s)=c_{1} e^{x \sqrt{s}}+c_{2} e^{-x \sqrt{s}}</script><script type="math/tex; mode=display">\begin{aligned}&U(\infty, s)=\mathfrak{L}_{s}(u(\infty, \tau))=0 \Rightarrow c_{1}=0 \\&U(0, s)=\mathfrak{L}_{s}(u(0, \tau))=\int_{0}^{\infty} e^{-s \tau} d \tau=\frac{1}{s} \Rightarrow c_{2}=\frac{1}{s}\end{aligned}</script><p>So we have both $u(x,\tau)$ and $U(x,s)$</p><script type="math/tex; mode=display">\frac{e^{-x \sqrt{s}}}{s}=U(x, s)=\mathfrak{L}_{s}\left(\operatorname{erfc}\left(\frac{x}{2 \sqrt{\tau}}\right)\right)</script><p>Since $\mathfrak{L}_{s}\left(f^{\prime}(\tau)\right)=s \mathfrak{L}_{s}(f(\tau))-\lim _{\tau \rightarrow 0^{+}} f(\tau)$,</p><script type="math/tex; mode=display">\begin{aligned}\mathfrak{L}_{s}\left(\frac{d}{d \tau} \operatorname{erf} c\left(\frac{x}{2 \sqrt{\tau}}\right)\right)&=s \mathfrak{L}_{s}\left(\operatorname{erfc}\left(\frac{x}{2 \sqrt{\tau}}\right)\right)-\operatorname{erfc}(\infty) \quad \text { if } x>0 \\\mathfrak{L}_{s}\left(\left(\frac{x}{2}\right)\left(-\frac{1}{2}\right)\left(\frac{1}{\sqrt{\tau^{3}}}\right) \frac{-2}{\sqrt{\pi}} e^{-\frac{x^{2}}{4 \tau}}\right)&=e^{-x \sqrt{s}}+0 \\\mathfrak{L}_{s}\left(\frac{-x \tau}{2 \sqrt{\pi \tau^{3}}} e^{-\frac{x^{2}}{4 \tau}}\right)=\frac{d}{d s} \mathfrak{L}_{s}\left(\frac{x}{2 \sqrt{\pi \tau^{3}}} e^{-\frac{x^{2}}{4 \tau}}\right)&=\frac{d}{d s} e^{-x \sqrt{s}}=\frac{-x e^{-x \sqrt{s}}}{2 \sqrt{s}}\end{aligned}</script><blockquote><p>第三行则是考虑到了此类变换的求导性质</p><ul><li>$f^{(n)}(\tau)\leftrightarrow(s)^ng(s)$</li><li>$(-i\tau)^nf(\tau)\leftrightarrow g^{(n)}(s)$</li></ul></blockquote><p>We have</p><script type="math/tex; mode=display">\mathfrak{L}_{s}\left(\frac{1}{2 \sqrt{\pi \tau}} e^{-\frac{x^{2}}{4 \tau}}\right)=\frac{e^{-x \sqrt{s}}}{2 \sqrt{s}}</script><blockquote><p>同时除 $x$ 并且消掉 $\tau$ 后得到</p></blockquote><hr><p>Let us come back to particular solution.</p><script type="math/tex; mode=display">y_{1}(x)=e^{x \sqrt{s}} \text { and } y_{2}(x)=e^{-x \sqrt{s}}</script><p>The Wronskian of $y_1(x)$ and $y_2(x)$ is</p><script type="math/tex; mode=display">W\left(y_{1}, y_{2}\right)=y_{1} y_{2}^{\prime}-y_{1}^{\prime} y_{2}=-\sqrt{s} e^{x \sqrt{s}} e^{-x \sqrt{s}}-\sqrt{s} e^{x \sqrt{s}} e^{-x \sqrt{s}}=-2 \sqrt{s}</script><p>Recall that</p><script type="math/tex; mode=display">U_{x x}(x, s)-sU(x, s)=-u(x, 0)</script><p>Then, the particular solution is</p><script type="math/tex; mode=display">U_{p}(x, s)=u_{1}(x) y_{1}(x)+u_{2}(x) y_{2}(x)=u_{1}(x) e^{x \sqrt{s}}+u_{2}(x) e^{-x \sqrt{s}}</script><p>with <a href="https://achlier.github.io/2022/03/28/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/#Nonhomogeneous-Equations">the computating of Nonhomogeneous Equations</a></p><script type="math/tex; mode=display">u_{1}^{\prime}(x)=\frac{y_{2}(x) u(x, 0)}{W\left(y_{1}, y_{2}\right)(x)}=-\frac{e^{-x \sqrt{s}} u(x, 0)}{2 \sqrt{s}} \text { and } u_{2}^{\prime}(x)=-\frac{y_{1}(x) u(x, 0)}{W\left(y_{1}, y_{2}\right)(x)}=\frac{e^{x \sqrt{s}} u(x, 0)}{2 \sqrt{s}} \text {. }</script><p>So</p><script type="math/tex; mode=display">\begin{aligned}&u_{1}(x)=-\int \frac{e^{-x \sqrt{s}} u(x, 0)}{2 \sqrt{s}} d x=-\int_{\infty}^{x} \frac{e^{-\xi \sqrt{s}} u(\xi, 0)}{2 \sqrt{s}} d \xi=\int_{x}^{\infty} \frac{e^{-\xi \sqrt{s}} u(\xi, 0)}{2 \sqrt{s}} d \xi\\&u_{2}(x)=\int \frac{e^{x \sqrt{s}} u(x, 0)}{2 \sqrt{s}} d x=\int_{-\infty}^{x} \frac{e^{\xi \sqrt{s}} u(\xi, 0)}{2 \sqrt{s}} d \xi\end{aligned}</script><blockquote><p>11th ODE教材中写到，对于求积的下限 $t_0$ “ t0 is any conveniently chosen point in interval I ” </p></blockquote><script type="math/tex; mode=display">\begin{aligned}U_{p}(x, s) &=u_{1}(x) e^{x \sqrt{s}}+u_{2}(x) e^{-x \sqrt{s}} \\&=e^{x \sqrt{s}} \int_{x}^{\infty} \frac{e^{-\xi \sqrt{s}} u(\xi, 0)}{2 \sqrt{s}} d \xi+e^{-x \sqrt{s}} \int_{-\infty}^{x} \frac{e^{\xi \sqrt{s}} u(\xi, 0)}{2 \sqrt{s}} d \xi \\&=\int_{x}^{\infty} \frac{e^{-(\xi-x) \sqrt{s}} u(\xi, 0)}{2 \sqrt{s}} d \xi+\int_{-\infty}^{x} \frac{e^{-(x-\xi) \sqrt{s}} u(\xi, 0)}{2 \sqrt{s}} d \xi \\&=\int_{-\infty}^{\infty} \frac{e^{-|\xi-x| \sqrt{s}} u(\xi, 0)}{2 \sqrt{s}} d \xi \end{aligned}</script><p>Thus, to get $u(x,\tau)$ it has to be done inverse Laplace operation</p><script type="math/tex; mode=display">\begin{aligned}u(x, \tau)&=\mathfrak{L}_{s}^{-1}(U(x, s)) \\ &=\mathfrak{L}_{s}^{-1}\left(\int_{-\infty}^{\infty} \frac{e^{-|\xi-x| \sqrt{s}} u(\xi, 0)}{2 \sqrt{s}} d \xi\right) \\&=\int_{-\infty}^{\infty} \mathfrak{L}_{s}^{-1}\left(\frac{e^{-|\xi-x| \sqrt{s}}}{2 \sqrt{s}}\right) u(\xi, 0) d \xi \\ &=\frac{1}{2 \sqrt{\pi \tau}} \int_{-\infty}^{\infty} e^{-\frac{(\xi-x)^{2}}{4 \tau}} u(\xi, 0) d \xi\end{aligned}</script><h2 id="Step-3-将系数代回"><a href="#Step-3-将系数代回" class="headerlink" title="Step 3 将系数代回"></a>Step 3 将系数代回</h2><p>It is convenient to make the change of variable $x_{1}=\frac{\xi-x}{\sqrt{2 \tau}}$， so that</p><script type="math/tex; mode=display">\begin{aligned}u(x, \tau) &=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} u\left(x_{1} \sqrt{2 \tau}+x, 0\right) e^{-\frac{x_{1}^{2}}{2}} d x_{1} \\&=\underbrace{\frac{1}{\sqrt{2 \pi}} \int_{-\frac{x}{\sqrt{2 \tau}}}^{\infty} e^{\frac{1}{2}(k+1)\left(x+x_{1} \sqrt{2 \tau}\right)} e^{-\frac{x_{1}^{2}}{2}} d x_{1}}_{I_{1}}-\underbrace{\frac{1}{\sqrt{2 \pi}} \int_{-\frac{x}{\sqrt{2 \tau}}}^{\infty} e^{\frac{1}{2}(k-1)\left(x+x_{1} \sqrt{2 \tau}\right)} e^{-\frac{x_{1}^{2}}{2}} d x_{1}}_{I_{2}} \end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}I_{1} &=\frac{1}{\sqrt{2 \pi}} \int_{-\frac{x}{\sqrt{2 \tau}}}^{\infty} e^{\frac{1}{2}(k+1)\left(x+x_{1} \sqrt{2 \tau}\right)} e^{-\frac{x_1^{2}}{2}} d x_{1} \\&=\frac{e^{\frac{1}{2}(k+1) x}}{\sqrt{2 \pi}} \int_{-\frac{x}{\sqrt{2 \tau}}}^{\infty} e^{\frac{1}{4}(k+1)^{2} \tau} e^{-\frac{1}{2}\left(x_{1}-\frac{1}{2}(k+1) \sqrt{2 \tau}\right)^{2}} d x_{1} \\&=\frac{e^{\frac{1}{2}(k+1) x+\frac{1}{4}(k+1)^{2} \tau}}{\sqrt{2 \pi}} \int_{-\frac{x}{\sqrt{2 \tau}}-\frac{1}{2}(k+1) \sqrt{2 \tau}}^{\infty} e^{-\frac{1}{2} \rho^{2}} d \rho \quad\left[\rho=x_{1}-\frac{1}{2}(k+1) \sqrt{2 \tau}\right] \\&=e^{\frac{1}{2}(k+1) x+\frac{1}{4}(k+1)^{2} \tau} N\left(d_{1}\right)\end{aligned}</script><p>Similarly, $I_{2}=e^{\frac{1}{2}(k-1) x+\frac{1}{4}(k-1)^{2} \tau} N\left(d_{2}\right)$</p><script type="math/tex; mode=display">\begin{aligned}v(x, \tau) &=e^{\alpha x+\beta t} u(x, \tau) \\&=e^{-\frac{1}{2}(k-1) x-\frac{1}{4}(k+1)^{2} \tau}\left(e^{\frac{1}{2}(k+1) x+\frac{1}{4}(k+1)^{2} \tau} N\left(d_{1}\right)-e^{\frac{1}{2}(k-1) x+\frac{1}{4}(k-1)^{2} \tau} N\left(d_{2}\right)\right) \\&=e^{x} N\left(d_{1}\right)-e^{-k \tau} N\left(d_{2}\right) \\&=\frac{S(t)}{K} N\left(d_{1}\right)-e^{-\frac{2 r}{\sigma^{2}} \frac{\sigma^{2}}{2}(T-t)} N\left(d_{2}\right) \\&=\frac{S(t)}{K} N\left(d_{1}\right)-e^{-r(T-t)} N\left(d_{2}\right) \end{aligned}</script><p>额外资料-<a href="http://www.doc88.com/p-5744422808605.html">求解 Black-Scholes 偏微分方程</a></p>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Black Scholes Model</tag>
      
      <tag>Black Scholes PDE</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【BUG】Blog搭建常见问题</title>
    <link href="/2022/05/21/Blog%E6%90%AD%E5%BB%BA%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <url>/2022/05/21/Blog%E6%90%AD%E5%BB%BA%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<blockquote><p>报错备忘录，以免下次再找半天资料</p></blockquote><span id="more"></span><h1 id="本人目前遇到比较头疼的"><a href="#本人目前遇到比较头疼的" class="headerlink" title="本人目前遇到比较头疼的"></a>本人目前遇到比较头疼的</h1><ol><li><p><a href="https://www.cnblogs.com/zhyantao/p/10424874.html">在 Hexo 主题中添加数学公式支持</a></p></li><li><p><a href="https://www.jianshu.com/p/d43535c17ce2?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">Hexo mathjax 远端博客无法渲染</a></p></li><li><p><a href="https://cloud.tencent.com/developer/article/1588598">Hexo 的图片和视频显示</a></p></li><li><p>当使用 hexo s 时，显示 4000 端口被占用</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">netstat -ano | findstr <span class="hljs-number">4000</span><br>taskkill -PID pid -F<br></code></pre></td></tr></table></figure></li><li><p>Node.js 版本过高导致的页面布局混乱</p><p>找到合适的 Node 版本 ( 最好版本低点 如 12.14 ) <a href="https://nodejs.org/zh-cn/download/releases/">并下载</a></p></li><li><p>完整流程参考- <a href="https://zhuanlan.zhihu.com/p/35668237">超详细Hexo+Github博客搭建小白教程</a></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>【Others】</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Blog</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】Financial_Mathematics</title>
    <link href="/2022/05/11/Financial_Mathematics/"/>
    <url>/2022/05/11/Financial_Mathematics/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于 ChiuFai WONG 教授的FM课件进行的零碎知识的整理；</p></blockquote><span id="more"></span><h1 id="Chapter-1-Annuities"><a href="#Chapter-1-Annuities" class="headerlink" title="Chapter 1 Annuities"></a>Chapter 1 Annuities</h1><ul><li><p>$i_t=\frac{a(t)-a(t-1)}{a(t-1)}$ , $d_t=\frac{a(t)-a(t-1)}{a(t)}$</p></li><li><p>$a(t)=(1+i)^t$ <strong>compound interest accumulation function</strong></p></li><li><p>$a(t)=(1-d)^{-t}$ <strong>compound discount accumulation function</strong></p></li><li><p>$1-d=v=\frac1{1+i}$</p></li><li><p>$i^{(m)}$ <strong>nominal rate of interest compounded m times a year</strong></p></li><li><p>$(1+\frac{i^{(m)}}m)^m=1+i$ , $i^{(m)}=m((1+i)^{1/m}-1)$</p></li><li><p>$d^{(m)}$ <strong>nominal rate of discount compounded m times a year</strong></p></li><li><p>$(1-\frac{d^{(m)}}m)^m=1-d$ , $d^{(m)}=m(1-(1-d)^{1/m})$</p></li><li><p>$a_{_n\bigg\urcorner_i}=\frac{1-v^{n}}{i}$ <strong>annuity-immediate</strong></p><p><img src="/2022/05/11/Financial_Mathematics/pic1-1.jpg" alt></p></li><li><p>$S_{_n\bigg\urcorner_i}=(1+i)^na_{_n\bigg\urcorner_i}=\frac{(1+i)^n-1}{i}$</p></li><li><p>$\ddot a_{_n\bigg\urcorner_i}=\frac{1-v^{n}}{d}$ <strong>annuity-due</strong> , $\ddot a_{_n\bigg\urcorner_i}=(1+i)a_{_n\bigg\urcorner_i}=1+a_{_{n-1}\bigg\urcorner_i}$</p><p><img src="/2022/05/11/Financial_Mathematics/pic1-2.jpg" alt></p></li><li><p>$\ddot S_{_n\bigg\urcorner_i}=\frac{(1+i)^n-1}{d}$ , $S_{_n\bigg\urcorner_i}=(1+i)^{-1}\ddot S_{_n\bigg\urcorner_i}=1+\ddot S_{_{n-1}\bigg\urcorner_i}$</p></li><li><p>$a_{_\infty\bigg\urcorner_i}=\frac{1}{i}$ <strong>perpetuity-due</strong></p></li><li><p>$\frac{a_{_n\bigg\urcorner_i}}{S_{_k\bigg\urcorner_i}}$ pays 1 at the end of each k interest periods for a total of n interest periods</p><p><img src="/2022/05/11/Financial_Mathematics/pic1-3.jpg" alt></p></li><li><p><script type="math/tex">\frac{a_{_n\bigg\urcorner_i}}{a_{_k\bigg\urcorner_i}}</script> pays 1 at the beginning of each k interest periods for a total of n interest periods</p><p><img src="/2022/05/11/Financial_Mathematics/pic1-4.jpg" alt></p></li><li><p>$a_{_n\bigg\urcorner_i}^{(m)}=\frac{1-v^n}{i^{(m)}}$ pays 1/m at the end of each m-th of an interest period for a total of n interest periods</p><p><img src="/2022/05/11/Financial_Mathematics/pic1-5.jpg" alt></p></li><li><p>$S_{_n\bigg\urcorner_i}^{(m)}=\frac{(1+i)^n-1}{i^{(m)}}$</p></li><li><p>$\ddot a_{_n\bigg\urcorner_i}^{(m)}=\frac{1-v^n}{d^{(m)}}$ pays 1 m at the end of each m-th of an interest period for a total of n interest periods</p><p><img src="/2022/05/11/Financial_Mathematics/pic1-6.jpg" alt></p></li><li><p>$S_{_n\bigg\urcorner_i}^{(m)}=\frac{(1+i)^n-1}{d^{(m)}}$</p></li></ul><h1 id="Chapter-2-Forwards-and-Futures"><a href="#Chapter-2-Forwards-and-Futures" class="headerlink" title="Chapter 2 Forwards and Futures"></a>Chapter 2 Forwards and Futures</h1><script type="math/tex; mode=display">\begin{array}{|c|c|c|}\hline \text { Underlying asset } & \text { Forward price } F_{t, T} & \text { Prepaid forward price } F_{t, T}^{P} \\\hline \text { Non-dividend pay stock } & S(t) e^{r(T-t)} & S(t) \\\hline \text { Discrete dividend paying stock } & S(t) e^{r(T-t)}-\text { CumValue(Divs) } & S(t)-\mathrm{PV}_{t, T}(\text { Divs }) \\\hline \text { Continuous dividend paying stock } & S(t) e^{(r-\delta)(T-t)} & S(t) e^{-\delta(T-t)} \\\hline \begin{array}{c}\text { Currency, denominated in currency } \\d \text { for delivery of currency } f\end{array} & x(t) e^{\left(r_{d}-r_{f}\right)(T-t)} & x(t) e^{-r_{f}(T-t)} \\\hline\end{array}</script><h1 id="Chapter-3-Options"><a href="#Chapter-3-Options" class="headerlink" title="Chapter 3 Options"></a>Chapter 3 Options</h1><ul><li>$\Delta=\frac{f_{u}-f_{d}}{S(0) u-S(0) d}$</li><li>$p=\frac{e^{(r-\delta) T}-d}{u-d}$ (on the futures $p=\frac{1-d}{u-d}$)</li><li>$f=e^{-r T}\left(p f_{u}+(1-p) f_{d}\right)$  expected future payoff in a risk-neutral world discounted at the risk-free rate</li></ul><h3 id="Cox-Ross-Rubinstein-Formula"><a href="#Cox-Ross-Rubinstein-Formula" class="headerlink" title="Cox-Ross-Rubinstein Formula"></a>Cox-Ross-Rubinstein Formula</h3><script type="math/tex; mode=display">C_{E u r}(S(0), K, N \Delta t)=S(0)\left[1-\Phi\left(m-1, N, p u e^{-r \Delta t}\right)\right]-e^{-r N \Delta t} K[1-\Phi(m-1, N, p)]</script><script type="math/tex; mode=display">P_{E u r}(S(0), K, N \Delta t)=e^{-r N \Delta t} K \Phi(m-1, N, p)-S(0) \Phi\left(m-1, N, p u e^{-r \Delta t}\right)</script><p>In order to match the stock price volatility with the tree’s parameters, we must therefore have</p><script type="math/tex; mode=display">\begin{aligned}\sigma^{2} \Delta t &=p u^{2}+(1-p) d^{2}-(p u+(1-p) d)^{2} \\&=p(1-p) u^{2}+p(1-p) d^{2}-2 p(1-p) u d \\&=p(1-p)(u-d)^{2} \\&=\left(u-e^{r \Delta t}\right)\left(e^{r \Delta t}-d\right) \\&=e^{r \Delta t}(u+d)-u d-e^{2 r \Delta t}\end{aligned}</script><p>where</p><script type="math/tex; mode=display">u=e^{\sigma \sqrt{\Delta t}} \quad \text { and } \quad d=e^{-\sigma \sqrt{\Delta t}}</script><h3 id="Black-Scholes-Formula"><a href="#Black-Scholes-Formula" class="headerlink" title="Black-Scholes Formula"></a>Black-Scholes Formula</h3><script type="math/tex; mode=display">C=S(0) N\left(d_{1}\right)-K e^{-r T} N\left(d_{2}\right) \quad \text { and } \quad P=K e^{-r T} N\left(-d_{2}\right)-S(0) N\left(-d_{1}\right)</script><p>where</p><script type="math/tex; mode=display">d_1=\frac{\ln(S_0/K)+(r + \frac{\sigma^2}{2})T}{\sigma\sqrt T}</script><script type="math/tex; mode=display">d_2=\frac{\ln(S_0/K)+(r - \frac{\sigma^2}{2})T}{\sigma\sqrt T}=d_1-\sigma\sqrt{T}</script><h3 id="Put-Call-parity"><a href="#Put-Call-parity" class="headerlink" title="Put-Call parity"></a>Put-Call parity</h3><script type="math/tex; mode=display">C(K,T)-P(K,T)=S(0)-Ke^{-rT}-PV_{0,T}(Divs)</script><p><strong>For put futures option</strong></p><script type="math/tex; mode=display">C(K,T)-P(K,T)=F(0)e^{-rT}-Ke^{-rT}</script><p><strong>The put-call parity result for currency options (in domestic HK dollars) is</strong></p><script type="math/tex; mode=display">C_d(x(0),K,T)-P_d(x(0),K,T)=x(0)e^{-r_fT}-Ke^{-r_dT}</script><p>$C_d(x(0),K,T)$ purchase 1 foreign currency(US dollars) for K domestic currency</p><script type="math/tex; mode=display">\underbrace{C_{d}(x(0), K, T)}_{\text {domestic curency }}=\underbrace{Kx(0) P_{f}\left(\frac{1}{x(0)}, \frac{1}{K}, T\right)}_{\text {foreign curency }}</script><p><strong>Exchange option</strong></p><script type="math/tex; mode=display">C(S_1(t),S_2(t),T-t)-P(S_1(t),S_2(t),T-t)=F_{t,T}^P(S_1)-F_{t,T}^P(S_2)</script><p>or</p><script type="math/tex; mode=display">C(S_1(t),S_2(t),T-t)-C(S_2(t),S_1(t),T-t)=F_{t,T}^P(S_1)-F_{t,T}^P(S_2)</script><script type="math/tex; mode=display">P(S_2(t),S_1(t),T-t)-P(S_1(t),S_2(t),T-t)=F_{t,T}^P(S_1)-F_{t,T}^P(S_2)</script><h3 id="Early-exercise-of-American-call-option"><a href="#Early-exercise-of-American-call-option" class="headerlink" title="Early exercise of American call option"></a>Early exercise of American call option</h3><script type="math/tex; mode=display">\begin{aligned}C_{A m e r}(S(t), K, T-t) & \geq C_{E u r}(S(t), K, T-t) \\&=P_{E u r}(S(t), K, T-t)+F_{t, T}^{P}(S)-K e^{-r(T-t)} \\&=P_{E u r}(S(t), K, T-t)+S(t)-\mathrm{PV}_{t, T}(\mathrm{Div})-K e^{-r(T-t)} \\&=P_{E u r}(S(t), K, T-t)+\underbrace{(S(t)-K)}_{\text {call exercise value at } t}+\underbrace{K\left(1-e^{-r(T-t)}\right)}_{\text {PV of interest of } K \text { in } T-t}-\mathrm{PV}_{t, T}(\text { Div) }\end{aligned}</script><p>The put option must be worth at least 0. Early exercise will not be rational if $PV_{t,T}(Div)&lt;K(1-e^{-r(T-t)})$ , because $C_{Amer}\ge(S(t)-K)$</p><h3 id="The-bounds-for-European-and-American-put-option-on-a-non-dividend-paying-stock"><a href="#The-bounds-for-European-and-American-put-option-on-a-non-dividend-paying-stock" class="headerlink" title="The bounds for European and American put option on a non-dividend-paying stock"></a><strong>The bounds for European and American put option on a non-dividend-paying stock</strong></h3><p><img src="/2022/05/11/Financial_Mathematics/pic1-7.jpg" alt></p><h1 id="Chapter-4-Black-Scholes-Equations"><a href="#Chapter-4-Black-Scholes-Equations" class="headerlink" title="Chapter 4 Black-Scholes Equations"></a>Chapter 4 Black-Scholes Equations</h1><p>Let $X_i$, either $\sqrt{t/n}$ or $-\sqrt{t/n}$, $Z_n=\sum_{i=1}^nX_i$</p><p>The <strong>quadratic variation</strong> of the random walk is defined by</p><script type="math/tex; mode=display">\sum_{i=1}^n(Z_i-Z_{i-1})^2=\sum_{i=1}^nX_i^2=t</script><p>If the time steps go to zero , $Z(t)$ is called <strong>Brownian motion</strong></p><script type="math/tex; mode=display">(dZ(t))^2=dt,\quad dZ(t)\sim N(0,dt)</script><p>Let $S(t)$ be stock price at time t</p><script type="math/tex; mode=display">dS(t)=\alpha S(t)dt+\sigma S(t)dZ(t)</script><script type="math/tex; mode=display">S(t)=S(0)e^{\sigma Z(t)+(\alpha -\frac12 \sigma^2)t}</script><p><strong>Let us analyze a portfolio $W$</strong></p><script type="math/tex; mode=display">W(t)=\varphi S(t)+(1-\varphi)B(t)</script><p>Hence</p><script type="math/tex; mode=display">\frac{d W(t)}{W(t)}=(\varphi \alpha+(1-\varphi) r) d t+\varphi \sigma d Z(t)</script><script type="math/tex; mode=display">\frac{W(t)}{W(0)}=e^{(\varphi \alpha+(1-\varphi) r-0.5\varphi^2\sigma^2)t+\varphi \sigma d Z(t)}=\left(\frac{S(t)}{S(0)}\right)^{\varphi}e^{(1-\varphi)(r+0.5\varphi\sigma^2)t}</script><p>with $\delta_s$ and $\delta_w$ be the continuous dividend rates of the stock and the portfolio</p><script type="math/tex; mode=display">\frac{W(t)}{W(0)}=\left(\frac{S(t)}{S(0)}\right)^{\varphi}e^{(\varphi\delta_s-\delta_w+(1-\varphi)r-0.5\varphi^2\sigma^2+0.5\phi\sigma^2)t}</script><p><strong>Sharpe ratio</strong></p><p>If $c_1S_1(t)+c_2S_2(t)$ is a risk free portfolio with risk-free interest rate $r$</p><script type="math/tex; mode=display">c_{1}\left(\alpha_{1}-\delta_{1}\right) S_{1}(t)+c_{2}\left(\alpha_{2}-\delta_{2}\right) S_{2}(t)=r\left(c_{1} S_{1}(t)+c_{2} S_{2}(t)\right)</script><p>with $c_1\sigma_1S_1(t)\pm c_2\sigma_2S_2(t)=0$</p><script type="math/tex; mode=display">\frac{\alpha_{1}-\delta_{1}-r}{\sigma_{1}}=\pm \frac{\alpha_{2}-\delta_{2}-r}{\sigma_{2}}</script><p><strong>Black-Scholes for currency</strong></p><script type="math/tex; mode=display">C=x(t)e^{-r_f T}N\left(d_{1}\right)-K e^{-r T} N\left(d_{2}\right) \quad \text { and } \quad P=K e^{-r T} N\left(-d_{2}\right)-x(t)e^{-r_f T}N\left(-d_{1}\right)</script><p><strong>Black-Scholes for options on Future</strong></p><script type="math/tex; mode=display">C=Fe^{-r T}N\left(d_{1}\right)-K e^{-r T} N\left(d_{2}\right) \quad \text { and } \quad P=K e^{-r T} N\left(-d_{2}\right)-Fe^{-r T}N\left(-d_{1}\right)</script><p><strong>Black-Scholes PDE for options on Future</strong></p><script type="math/tex; mode=display">\frac{\partial V}{\partial t}+\frac{1}{2} \sigma^{2} F^{2} \frac{\partial^{2} V}{\partial F^{2}}-r V=0</script><h1 id="Chapter-5-Greek-Symbol-and-Hedging"><a href="#Chapter-5-Greek-Symbol-and-Hedging" class="headerlink" title="Chapter 5 Greek Symbol and Hedging"></a>Chapter 5 Greek Symbol and Hedging</h1><h3 id="Black-Scholes-partial-differential-equation"><a href="#Black-Scholes-partial-differential-equation" class="headerlink" title="Black-Scholes partial differential equation"></a>Black-Scholes partial differential equation</h3><script type="math/tex; mode=display">\frac{\partial V}{\partial t}+\frac{1}{2} \sigma^{2} S^{2} \frac{\partial^{2} V}{\partial S^{2}}+(r-\delta) S \frac{\partial V}{\partial S}-r V=0</script><p>gives us the relation between Greek symbols</p><script type="math/tex; mode=display">\theta+(r-\delta) \Delta S+0.5 S^{2} \sigma^{2} \Gamma=r V</script><h3 id="A-better-approximation-of-the-change-on-option-value"><a href="#A-better-approximation-of-the-change-on-option-value" class="headerlink" title="A better approximation of the change on option value"></a>A better approximation of the change on option value</h3><script type="math/tex; mode=display">f(x)=f(x_0)+f'(x_0)(x-x_0)+\frac12f''(x_0)(x-x_0)^2+error</script><p>set $\varepsilon=S(t+h)-S(t)$ , $x_0=S(t)$ , $x=S(t+h)$ , $f(x_0)=V(S(t))$ , $f’(x_0)=\Delta$ , $f’’(x_0)=\Gamma$ , error term $=\theta h$</p><script type="math/tex; mode=display">V(S(t+h))=V(S(t))+\Delta \varepsilon+\frac{1}{2} \Gamma \varepsilon^{2}+\theta h</script><p>Consider a delta-neutral portfolio</p><script type="math/tex; mode=display">V(S(t+h))-V(S(t))=\frac{1}{2} \Gamma \varepsilon^{2}+\theta h</script><p><strong>The market-maker makes</strong></p><p>Assume a delta hedged portfolio consists of selling (or buying) an option $V(0)$, buying $\Delta$ shares of stock $S(0)$, and borrowing the money needed for the other two transactions $\Delta S(0)-V(0)$.</p><script type="math/tex; mode=display">Profit = -\overbrace{(V(h)-V(0))}^{\text{change in the value of the option}}+\Delta\overbrace{(S(h)-S(0))}^{\text{change in the price of the stock}}-\overbrace{(e^{rh}-1)(\Delta S(0)-V(0))}^{\text{Interest on the borrowed money}}+\overbrace{\delta h\Delta S(0)}^{\text{dividend}}</script><p>If we approximate $e^{rh}-1$ as $rh$</p><script type="math/tex; mode=display">\begin{aligned}\text { Profit }&=-(V(h)-V(0))+\Delta(S(h)-S(0))-\left(e^{r h}-1\right)(\Delta S(0)-V(0))+\delta h\Delta S(0)\\&\approx-\left(\overbrace{\frac{1}{2} \Gamma \varepsilon^{2}}^{\text{change of stock price effect}}+\overbrace{\theta h}^{\text{time decayof option}}+\overbrace{rh(\Delta S(0)-V(0))}^{\text{interest effect}}-\delta h\Delta S(0)\right)  \quad\text{[by delta-gamma-theta approximation]}\\&=-\left(\frac{1}{2} \Gamma \varepsilon^{2}-\frac{1}{2} \Gamma \sigma^{2} S(0)^{2} h\right) \quad \text { [by Black-Scholes Equation] }\end{aligned}</script>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Financial Mathematics</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【代码】Numerical_Analysis</title>
    <link href="/2022/03/13/Numerical_Analysis/"/>
    <url>/2022/03/13/Numerical_Analysis/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于 UIC 金融数学的课程 Numerical Analysis 中代码的复习笔记；</p></blockquote><span id="more"></span><h2 id="The-Bisection-Method"><a href="#The-Bisection-Method" class="headerlink" title="The Bisection Method"></a>The Bisection Method</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">sol</span> = <span class="hljs-title">Bisection</span><span class="hljs-params">(a,b,tol,n0)</span></span><br><span class="hljs-comment">%input:</span><br><span class="hljs-comment">%    interval [a,b]</span><br><span class="hljs-comment">%    function fx</span><br><span class="hljs-comment">%    tolerance tol</span><br><span class="hljs-comment">%    maximum number of iterations n0</span><br><span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>;<br>fa = fx(a);<br><span class="hljs-keyword">if</span> fx(a)*fx(b) &gt; <span class="hljs-number">0</span><br>    fprintf(<span class="hljs-string">&quot;Please change the interval [a,b].\n&quot;</span>)<br><span class="hljs-keyword">else</span><br>    <span class="hljs-keyword">while</span> <span class="hljs-built_in">i</span> &lt;= n0<br>        p = a+(b-a)/<span class="hljs-number">2</span>;<br>        fp = fx(p);<br>        <span class="hljs-keyword">if</span> fp == <span class="hljs-number">0</span> || (b-a)/<span class="hljs-number">2</span> &lt; tol<br>            sol = p;<br>            <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">else</span><br>            <span class="hljs-built_in">i</span> = <span class="hljs-built_in">i</span>+<span class="hljs-number">1</span>;<br>            fprintf(<span class="hljs-string">&quot;a:&quot;</span>+a+<span class="hljs-string">&quot; b:&quot;</span>+b+<span class="hljs-string">&quot; p:&quot;</span>+p+<span class="hljs-string">&quot;\n&quot;</span>)<br>            <span class="hljs-keyword">if</span> fa*fp &gt; <span class="hljs-number">0</span><br>                a=p;<br>                fa=fp;<br>            <span class="hljs-keyword">else</span><br>                b=p;<br>            <span class="hljs-keyword">end</span><br>        <span class="hljs-keyword">end</span><br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><h2 id="Fixed-point-Iteration"><a href="#Fixed-point-Iteration" class="headerlink" title="Fixed-point Iteration"></a>Fixed-point Iteration</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">sol</span> =  <span class="hljs-title">FixedPoint</span><span class="hljs-params">(p0,tol,n0)</span></span><br><span class="hljs-comment">%input:</span><br><span class="hljs-comment">%    initial approximation p0</span><br><span class="hljs-comment">%    function fx</span><br><span class="hljs-comment">%    tolerance tol</span><br><span class="hljs-comment">%    maximum number of iterations n0</span><br><span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>;<br><span class="hljs-keyword">while</span> <span class="hljs-built_in">i</span> &lt;= n0<br>    fprintf(<span class="hljs-string">&quot;p&quot;</span>+(<span class="hljs-built_in">i</span><span class="hljs-number">-1</span>)+<span class="hljs-string">&quot;:&quot;</span>+p0+<span class="hljs-string">&quot;\n&quot;</span>)<br>    p = fx(p0);<br>    fprintf(<span class="hljs-string">&quot;|p-p0|:&quot;</span>+<span class="hljs-built_in">abs</span>(p-p0)+<span class="hljs-string">&quot;\n&quot;</span>)<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(p-p0) &lt; tol<br>        sol = p;<br>        <span class="hljs-keyword">break</span><br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-built_in">i</span> = <span class="hljs-built_in">i</span>+<span class="hljs-number">1</span>;<br>        p0 = p;<br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><h2 id="Newton’s-Method"><a href="#Newton’s-Method" class="headerlink" title="Newton’s Method"></a>Newton’s Method</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">sol</span> =  <span class="hljs-title">Newton</span><span class="hljs-params">(p0,tol,n0)</span></span><br><span class="hljs-comment">%input:</span><br><span class="hljs-comment">%    initial approximation p0</span><br><span class="hljs-comment">%    function fx</span><br><span class="hljs-comment">%    tolerance tol</span><br><span class="hljs-comment">%    maximum number of iterations n0</span><br>fx = @(x) x<span class="hljs-number">-0.8</span><span class="hljs-number">-0.2</span>*<span class="hljs-built_in">sin</span>(x);<br>dfx = @(x) <span class="hljs-number">1</span><span class="hljs-number">-0.2</span>*<span class="hljs-built_in">cos</span>(x);<br><span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>;<br><span class="hljs-keyword">while</span> <span class="hljs-built_in">i</span> &lt;= n0<br>    fprintf(<span class="hljs-string">&quot;p&quot;</span>+(<span class="hljs-built_in">i</span><span class="hljs-number">-1</span>)+<span class="hljs-string">&quot;:&quot;</span>+p0+<span class="hljs-string">&quot;\n&quot;</span>)<br>    p = p0-fx(p0)/dfx(p0);<br>    fprintf(<span class="hljs-string">&quot;|p-p0|:&quot;</span>+<span class="hljs-built_in">abs</span>(p-p0)+<span class="hljs-string">&quot;\n&quot;</span>)<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(p-p0) &lt; tol<br>        sol = p;<br>        <span class="hljs-keyword">break</span><br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-built_in">i</span> = <span class="hljs-built_in">i</span>+<span class="hljs-number">1</span>;<br>        p0 = p;<br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><h2 id="nth-Lagrange-Interpolation-Polynomials"><a href="#nth-Lagrange-Interpolation-Polynomials" class="headerlink" title="nth Lagrange Interpolation Polynomials"></a>nth Lagrange Interpolation Polynomials</h2><p>如果我们已知 n+1 个点的值 </p><script type="math/tex; mode=display">(x_0,f(x_0)),(x_1,f(x_1)),(x_2,f(x_2))...(x_n,f(x_n))</script><p>存在一个多项式</p><script type="math/tex; mode=display">P(x)=f(x_{0}) L_{n, 0}(x)+\cdots+f(x_{n}) L_{n, n}(x)=\sum_{k=0}^{n} f(x_{k}) L_{n, k}(x)</script><p>通过所有点</p><script type="math/tex; mode=display">L_{n, k}(x_{j})=\left\{\begin{array}{ll}1, & \text { if } j=k \\0, & \text { if } j \neq k\end{array}\right.</script><script type="math/tex; mode=display">L_{n, k}(x)=\frac{(x-x_{0})(x-x_{1}) \cdots(x-x_{k-1})(x-x_{k+1}) \cdots(x-x_{n})}{(x_{k}-x_{0})(x_{k}-x_{1}) \cdots(x_{k}-x_{k-1})(x_{k}-x_{k+1}) \cdots(x_{k}-x_{n})}=\prod_{\substack{i=0 \\ i \neq k}}^{n} \frac{(x-x_{i})}{(x_{k}-x_{i})}</script><h4 id="Code-of-Degree-one"><a href="#Code-of-Degree-one" class="headerlink" title="Code of Degree one"></a>Code of Degree one</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">sol</span> = <span class="hljs-title">Degree1_Interpolation</span><span class="hljs-params">(x0,x1,X)</span></span><br><span class="hljs-comment">%input:</span><br><span class="hljs-comment">%    distinct nodes x0,x1</span><br><span class="hljs-comment">%    function fx</span><br>L0 = @(x) (x-x1)/(x0-x1);<br>L1 = @(x) (x-x0)/(x1-x0);<br>sol = L0(X)*fx(x0)+L1(X)*fx(x1);<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><h4 id="Code-of-Degree-two"><a href="#Code-of-Degree-two" class="headerlink" title="Code of Degree two"></a>Code of Degree two</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">sol</span> = <span class="hljs-title">Degree2_Interpolation</span><span class="hljs-params">(x0,x1,x2,X)</span></span><br><span class="hljs-comment">%input:</span><br><span class="hljs-comment">%    distinct nodes x0,x1,x2</span><br><span class="hljs-comment">%    function fx</span><br>L0 = @(x) (x-x1)*(x-x2)/((x0-x1)*(x0-x2));<br>L1 = @(x) (x-x0)*(x-x2)/((x1-x0)*(x1-x2));<br>L2 = @(x) (x-x0)*(x-x1)/((x2-x0)*(x2-x1));<br>sol = L0(X)*fx(x0)+L1(X)*fx(x1)+L2(X)*fx(x2);<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><p>注意：预测的点应该在已知点的范围之间</p><h2 id="Neville’s-Iterated-Interpolation"><a href="#Neville’s-Iterated-Interpolation" class="headerlink" title="Neville’s Iterated Interpolation"></a>Neville’s Iterated Interpolation</h2><p>如果一个多项式建立在 k 个确定的点上 $x_{m_1},x_{m_2},…,x_{m_k}$。那么，此多项式可以表示为 $P_{m_1,m_2,…,m_k}$，$Q_{i,j}=P_{i-j,i-j+1,…,i-1,i}$</p><script type="math/tex; mode=display">P(x)=\frac{(x-x_{j}) P_{0,1, \cdots, j-1, j+1, \cdots, k}(x)-(x-x_{i}) P_{0,1, \cdots, i-1, i+1, \cdots, k}(x)}{x_{i}-x_{j}}</script><script type="math/tex; mode=display">Q_{i, j}=\frac{(x-x_{i-j}) Q_{i, j-1}-(x-x_{i}) Q_{i-1, j-1}}{x_{i}-x_{i-j}}</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">sol</span> = <span class="hljs-title">Qfunction</span><span class="hljs-params">(x0,x1,y0,y1,X)</span></span><br><span class="hljs-comment">%input:</span><br><span class="hljs-comment">%    distinct nodes (x0,y0),(x1,y1)</span><br><span class="hljs-comment">%    function fx</span><br>L0 = @(x) (x-x1)/(x0-x1);<br>L1 = @(x) (x-x0)/(x1-x0);<br>sol = L0(X)*y0+L1(X)*y1;<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">sol</span> = <span class="hljs-title">NevilleIterated</span><span class="hljs-params">(x,x_box,y_box)</span></span><br>Q = <span class="hljs-built_in">zeros</span>(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>);<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:<span class="hljs-number">3</span><br>    Q(<span class="hljs-built_in">i</span>,<span class="hljs-number">1</span>) = Qfunction(x_box(<span class="hljs-built_in">i</span>),x_box(<span class="hljs-built_in">i</span>+<span class="hljs-number">1</span>),y_box(<span class="hljs-built_in">i</span>),y_box(<span class="hljs-built_in">i</span>+<span class="hljs-number">1</span>),x);<br><span class="hljs-keyword">end</span><br><span class="hljs-comment">%[ p12 , p123 , p1234</span><br><span class="hljs-comment">%         </span><br><span class="hljs-comment">%  p23 , p234</span><br><span class="hljs-comment">%</span><br><span class="hljs-comment">%  p34 ,</span><br><span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span> = <span class="hljs-number">2</span>:<span class="hljs-number">3</span><br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:<span class="hljs-number">4</span>-<span class="hljs-built_in">j</span><br>        Q(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span>) = ((x-x_box(<span class="hljs-built_in">i</span>))*Q(<span class="hljs-built_in">i</span>+<span class="hljs-number">1</span>,<span class="hljs-built_in">j</span><span class="hljs-number">-1</span>)-(x-x_box(<span class="hljs-built_in">i</span>+<span class="hljs-built_in">j</span>))*Q(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span><span class="hljs-number">-1</span>))/(x_box(<span class="hljs-built_in">i</span>+<span class="hljs-built_in">j</span>)-x_box(<span class="hljs-built_in">i</span>));<br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br>sol = Q(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>);<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><h2 id="Numerical-Differentiation"><a href="#Numerical-Differentiation" class="headerlink" title="Numerical Differentiation"></a>Numerical Differentiation</h2><ul><li><strong>The  (n+1) -point formula</strong> to approximate  $f^{\prime}\left(x_{j}\right)$</li></ul><script type="math/tex; mode=display">f^{\prime}\left(x_{j}\right)=\sum_{k=0}^{n} f\left(x_{k}\right) L_{k}^{\prime}\left(x_{j}\right)+\frac{f^{(n+1)}\left[\xi\left(x_{j}\right)\right]}{(n+1) !} \prod_{\substack{k=0 \\ k \neq j}}^{n}\left(x_{j}-x_{k}\right)</script><ul><li><strong>Forward-Difference and Backward-Difference Formula</strong></li></ul><script type="math/tex; mode=display">f^{\prime}\left(x_{0}\right)=\frac{f\left(x_{0}+h\right)-f\left(x_{0}\right)}{h}-\frac{h}{2} f^{\prime \prime}[\xi(x)]</script><p>where $ \xi(x)$  lies between  $x_{0}$  and  $x_{0}+h$ . When  $h&gt;0$ , it is the forward-difference formula; The backward-difference formula if  $h&lt;0$ .</p><ul><li><strong>Three-Point Endpoint Formula</strong></li></ul><script type="math/tex; mode=display">f^{\prime}\left(x_{0}\right)=\frac{-3 f\left(x_{0}\right)+4 f\left(x_{0}+h\right)-f\left(x_{0}+2 h\right)}{2 h}+\frac{h^{2}}{3} f^{(3)}\left(\xi_{0}\right)</script><p>where  $\xi_{0}$  lies between  $x_{0}$  and  $x_{0}+2 h$ .</p><ul><li><strong>Three-Point Midpoint Formula</strong></li></ul><script type="math/tex; mode=display">f^{\prime}\left(x_{0}\right)=\frac{f\left(x_{0}+h\right)-f\left(x_{0}-h\right)}{2 h}-\frac{h^{2}}{6} f^{(3)}\left(\xi_{1}\right)</script><p>where  $\xi_{1}$  lies between  $x_{0}-h$  and  $x_{0}+h$ .</p><ul><li><strong>Five-Point Endpoint Formula</strong></li></ul><script type="math/tex; mode=display">f^{\prime}\left(x_{0}\right)=\frac{1}{12 h}\left[-25 f\left(x_{0}\right)+48 f\left(x_{0}+h\right)-36 f\left(x_{0}+2 h\right)+16 f\left(x_{0}+3 h\right)-3 f\left(x_{0}+4 h\right)\right]+\frac{h^{4}}{5} f^{(5)}\left(\xi_{0}\right)</script><p>where  $\xi_{0}$  lies between  $x_{0}$  and  $x_{0}+4 h$ .</p><ul><li><strong>Five-Point Midpoint Formula</strong></li></ul><script type="math/tex; mode=display">f^{\prime}\left(x_{0}\right)=\frac{1}{12 h}\left[f\left(x_{0}-2 h\right)-8 f\left(x_{0}-h\right)+8 f\left(x_{0}+h\right)-f\left(x_{0}+2 h\right)\right]+\frac{h^{4}}{30} f^{(5)}\left(\xi_{1}\right)</script><p>where  $\xi_{1}$  lies between  $x_{0}-2 h$  and  $x_{0}+2 h$ .</p><ul><li><strong>Second Derivative Midpoint Formula</strong> (To approximate  $f^{\prime \prime}\left(x_{0}\right)$)</li></ul><script type="math/tex; mode=display">f^{\prime \prime}\left(x_{0}\right)=\frac{1}{h^{2}}\left[f\left(x_{0}-h\right)-2 f\left(x_{0}\right)+f\left(x_{0}+h\right)\right]-\frac{h^{2}}{12} f^{(4)}(\xi)</script><p>where  $\xi$  lies between  $x_{0}-h$  and  $x_{0}+h$ .</p><h2 id="Numerical-Integration"><a href="#Numerical-Integration" class="headerlink" title="Numerical Integration"></a>Numerical Integration</h2><h4 id="The-n-1-point-Closed-Newton-Cotes-Formulas"><a href="#The-n-1-point-Closed-Newton-Cotes-Formulas" class="headerlink" title="The  $(n+1)$ -point Closed Newton-Cotes Formulas:"></a>The  $(n+1)$ -point Closed Newton-Cotes Formulas:</h4><p>Use  $x_{i}=x_{0}+i h$ , for  $i=   0,1, \cdots, n$ , where  $x_{0}=a, x_{n}=b$  and  $h=(b-a) / n$ . The endpoints of the closed interval  [a, b]  are included as nodes.</p><script type="math/tex; mode=display">\int_{a}^{b} f(x) \mathrm{d} x \approx \sum_{i=0}^{n} a_{i} f\left(x_{i}\right)</script><p>where  $a_{i}=\int_{a}^{b} L_{i}(x) \mathrm{d} x$ .</p><ul><li><strong>Trapezoidal Rule</strong>  (n=1) </li></ul><script type="math/tex; mode=display">\int_{x_{0}}^{x_{1}} f(x) \mathrm{d} x=\frac{h}{2}\left[f\left(x_{0}\right)+f\left(x_{1}\right)\right]-\frac{h^{3}}{12} f^{\prime \prime}(\xi), \quad \xi \in\left(x_{0}, x_{1}\right)</script><ul><li><strong>Simpson’s Rule</strong>  (n=2) </li></ul><script type="math/tex; mode=display">\int_{x_{0}}^{x_{2}} f(x) \mathrm{d} x=\frac{h}{3}\left[f\left(x_{0}\right)+4 f\left(x_{1}\right)+f\left(x_{2}\right)\right]-\frac{h^{5}}{90} f^{(4)}(\xi), \quad \xi \in\left(x_{0}, x_{2}\right)</script><ul><li><strong>Simpson’s Three-Eights Rule</strong>  (n=3) </li></ul><script type="math/tex; mode=display">\int_{x_{0}}^{x_{3}} f(x) \mathrm{d} x=\frac{3 h}{8}\left[f\left(x_{0}\right)+3 f\left(x_{1}\right)+3 f\left(x_{2}\right)+f\left(x_{3}\right)\right]-\frac{3 h^{5}}{80} f^{(4)}(\xi), \quad \xi \in\left(x_{0}, x_{3}\right)</script><h4 id="The-n-1-point-Open-Newton-Cotes-Formulas"><a href="#The-n-1-point-Open-Newton-Cotes-Formulas" class="headerlink" title="The $(n+1)$-point Open Newton-Cotes Formulas:"></a>The $(n+1)$-point Open Newton-Cotes Formulas:</h4><p>Use $x_{i}=x_{0}+i h$, for $i=$ $0,1, \cdots, n$, where $h=(b-a) /(n+2), x_{0}=a+h$ and $x_{n}=b-h$. Label the endpoints as $x_{-1}=a$ and $x_{n+1}=b$. Open formulas contain all the nodes within the open interval $(a, b)$.</p><script type="math/tex; mode=display">\int_{a}^{b} f(x) \mathrm{d} x=\int_{x-1}^{x_{n+1}} f(x) \mathrm{d} x \approx \sum_{i=0}^{n} a_{i} f\left(x_{i}\right)</script><p>where $a_{i}=\int_{a}^{b} L_{i}(x) \mathrm{d} x$.</p><ul><li>Midpoint Rule $(n=0)$</li></ul><script type="math/tex; mode=display">\int_{x-1}^{x_{1}} f(x) \mathrm{d} x=2 h f\left(x_{0}\right)+\frac{h^{3}}{3} f^{\prime \prime}(\xi), \quad \xi \in\left(x_{-1}, x_{1}\right) .</script><h4 id="Composite-Numerical-Integration"><a href="#Composite-Numerical-Integration" class="headerlink" title="Composite Numerical Integration"></a>Composite Numerical Integration</h4><ul><li><strong>Composite Simpsons rule:</strong> Let $f \in C^{4}[a, b], n$ be even, $h=(b-a) / n$, and $x_{j}=a+j h$, for each $j=0,1, \cdots, n$. There exists a $\mu \in(a, b)$ for which the Composite Simpsons rule for $n$ subintervals can be written with its error term as<script type="math/tex; mode=display">\int_{a}^{b} f(x) \mathrm{d} x=\frac{h}{3}\left[f(a)+2 \sum_{j=1}^{(n / 2)-1} f\left(x_{2 j}\right)+4 \sum_{j=1}^{n / 2} f\left(x_{2 j-1}\right)+f(b)\right]-\frac{b-a}{180} h^{4} f^{(4)}(\mu)</script></li><li><strong>Composite Trapezoidal rule:</strong> Let $f \in C^{2}[a, b], h=(b-a) / n$, and $x_{j}=a+j h$, for each $j=0,1, \cdots, n$. There exists a $\mu \in(a, b)$ for which the Composite Trapezoidal rule for $n$ subintervals can be written with its error term as<script type="math/tex; mode=display">\int_{a}^{b} f(x) \mathrm{d} x=\frac{h}{2}\left[f(a)+2 \sum_{j=1}^{n-1} f\left(x_{j}\right)+f(b)\right]-\frac{b-a}{12} h^{2} f^{\prime \prime}(\mu)</script></li><li><strong>Composite Midpoint rule:</strong> Let $f \in C^{2}[a, b], n$ be even, $h=(b-a) /(n+2)$, and $x_{j}=a+(j+1) h$, for each $j=-1,0, \cdots, n+1$. There exists a $\mu \in(a, b)$ for which the Composite Midpoint rule for $n+2$ subintervals can be written with its error term as</li></ul><script type="math/tex; mode=display">\int_{a}^{b} f(x) \mathrm{d} x=2 h \sum_{j=1}^{n / 2} f\left(x_{2 j}\right)+\frac{b-a}{6} h^{2} f^{\prime \prime}(\mu)</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">sol</span> = <span class="hljs-title">ComTrapezoidal</span><span class="hljs-params">(a,b,n)</span></span><br>h = (b-a)/n;<br>sum = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:(n<span class="hljs-number">-1</span>)<br>    sum = sum+fx(a+<span class="hljs-built_in">i</span>*h);<br><span class="hljs-keyword">end</span><br>sol = h/<span class="hljs-number">2</span>*(fx(a)+fx(b)+<span class="hljs-number">2</span>*sum);<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">sol</span> = <span class="hljs-title">ComSimpsons</span><span class="hljs-params">(a,b,n)</span></span><br>h = (b-a)/n;<br>sum1 = <span class="hljs-number">0</span>;<br>sum2 = dfx(a+(n<span class="hljs-number">-1</span>)*h);<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:(n/<span class="hljs-number">2</span><span class="hljs-number">-1</span>)<br>    sum1 = sum1+dfx(a+<span class="hljs-number">2</span>*<span class="hljs-built_in">i</span>*h);<br>    sum2 = sum2+dfx(a+(<span class="hljs-number">2</span>*<span class="hljs-built_in">i</span><span class="hljs-number">-1</span>)*h);<br><span class="hljs-keyword">end</span><br>sol = h/<span class="hljs-number">3</span>*(dfx(a)+dfx(b)+<span class="hljs-number">2</span>*sum1+<span class="hljs-number">4</span>*sum2);<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><h2 id="Initial-Value-Problems-for-ODEs"><a href="#Initial-Value-Problems-for-ODEs" class="headerlink" title="Initial Value Problems for ODEs"></a>Initial Value Problems for ODEs</h2><p>Approximate the solution $y(t)$ to an initial-value problem</p><script type="math/tex; mode=display">y'(t)=f(t,y),\quad a\le t\le b,\quad y(a)=\alpha</script><h4 id="Euler’s-Method"><a href="#Euler’s-Method" class="headerlink" title="Euler’s Method"></a>Euler’s Method</h4><ul><li><strong>Forward Euler’s Method</strong>:</li></ul><script type="math/tex; mode=display">\begin{array}{rcl}w_0&=&a\\w_{i+1}&=&w_i+hf(t_i,w_i)\qquad \text{for each }i =0,1,...,N-1\end{array}</script><ul><li><strong>Backward Euler’s Method</strong>: </li></ul><script type="math/tex; mode=display">\begin{array}{rcl}w_0&=&a\\w_{i+1}&=&w_i+hf(t_{i+1},w_{i+1})\qquad \text{for each }i =0,1,...,N-1\end{array}</script><h4 id="Higher-Order-Taylor-Methods"><a href="#Higher-Order-Taylor-Methods" class="headerlink" title="Higher-Order Taylor Methods"></a>Higher-Order Taylor Methods</h4><ul><li>Taylor method of order $n$ :<script type="math/tex; mode=display">\begin{aligned}w_{0} &=\alpha \\w_{i+1} &=w_{i}+h T^{(n)}\left(t_{i}, w_{i}\right), \quad \text { for each } i=0,1, \cdots, N-1\end{aligned}</script>where<script type="math/tex; mode=display">T^{(n)}\left(t_{i}, w_{i}\right)=f\left(t_{i}, w_{i}\right)+\frac{h}{2} f^{\prime}\left(t_{i}, w_{i}\right)+\cdots+\frac{h^{n-1}}{n !} f^{(n-1)}\left(t_{i}, w_{i}\right)</script></li><li>Forward Euler’s Method is Taylor’s method of order one.</li></ul><h4 id="Runge-Kutta-Method"><a href="#Runge-Kutta-Method" class="headerlink" title="Runge-Kutta Method"></a>Runge-Kutta Method</h4><ul><li><p>Runge-Kutta methods of order two (RK2):</p><ul><li><p>Midpoint method: with local truncation error $O\left(h^{2}\right)$</p><script type="math/tex; mode=display">\begin{aligned}w_{0} &=\alpha \\w_{i+1} &=w_{i}+h f\left(t_{i}+\frac{h}{2}, w_{i}+\frac{h}{2} f\left(t_{i}, w_{i}\right)\right)\end{aligned}</script><p>for each $i=0,1, \cdots, N-1$.</p></li><li><p>Modified Euler method: with local truncation error $O\left(h^{2}\right)$</p><script type="math/tex; mode=display">\begin{aligned}w_{0} &=\alpha \\w_{i+1} &=w_{i}+\frac{h}{2}\left[f\left(t_{i}, w_{i}\right)+f\left(t_{i+1}, w_{i}+h f\left(t_{i}, w_{i}\right)\right)\right]\end{aligned}</script><p>for each $i=0,1, \cdots, N-1$.</p></li></ul></li><li><p>Runge-Kutta methods of order four (RK4):</p><script type="math/tex; mode=display">\begin{aligned}w_{0} &=\alpha \\k_{1} &=h f\left(t_{i}, w_{i}\right) \\k_{2} &=h f\left(t_{i}+\frac{h}{2}, w_{i}+\frac{1}{2} k_{1}\right) \\k_{3} &=h f\left(t_{i}+\frac{h}{2}, w_{i}+\frac{1}{2} k_{2}\right) \\k_{4} &=f\left(t_{i+1}, w_{i}+k_{3}\right), \\w_{i+1} &=w_{i}+\frac{h}{6}\left(k_{1}+2 k_{2}+2 k_{3}+k_{4}\right),\end{aligned}</script><p>for each $i=0,1, \cdots, N-1$.</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Matlab</tag>
      
      <tag>Numerical Analysis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【代码】Lab of Applied Computational Finance</title>
    <link href="/2022/03/11/Lab_of_Applied_Computational_Finance/"/>
    <url>/2022/03/11/Lab_of_Applied_Computational_Finance/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于格拉斯哥ECON5065中Lab的代码的笔记；</p></blockquote><span id="more"></span><p>如果需要代码与数据可以在 <a href="https://github.com/Achlier/CodeAndData/tree/main/Applied%20Computational%20Finance%20Lab">本人Github页面</a> 上找到</p><h2 id="Week-2-Newton’s-method-to-compute-implied-volatility"><a href="#Week-2-Newton’s-method-to-compute-implied-volatility" class="headerlink" title="Week 2: Newton’s method to compute implied volatility"></a>Week 2: Newton’s method to compute implied volatility</h2><p>此部分对应于笔记中的 <a href="https://achlier.github.io/2021/05/12/Applied_Computational_Finance/#Unit-1-5：Implied-Volatility">Unit 1.5</a> 。首先，我们用牛顿法对 implied volatility 进行估计，然后将结果画成 implied volatility surface，并与 Matlab 自带的求解 implied volatility 的公式 blsimpv 比较。期权数据来自于 Yahoo Finance。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">vol</span>=<span class="hljs-title">newtoniv</span><span class="hljs-params">(S,K,r,T,price,callput)</span></span><br><span class="hljs-comment">% S is stock price, </span><br><span class="hljs-comment">% K is strike price,  </span><br><span class="hljs-comment">% r is free interest rate, </span><br><span class="hljs-comment">% T is time to maturity, </span><br><span class="hljs-comment">% price is market option price,</span><br><span class="hljs-comment">% callput is 1 if call 0 if put</span><br><br>vol     = <span class="hljs-number">1.0</span>; <span class="hljs-comment">% initial value of implied volatility</span><br>sigma   = vol+<span class="hljs-number">0.1</span>; <span class="hljs-comment">% sigma is volatility in BS model</span><br>maxiter = <span class="hljs-number">20</span>;<br>tol     = <span class="hljs-number">1e-4</span>;<br>iter    = <span class="hljs-number">0</span>;<br><br><span class="hljs-comment">% newton-raphson method</span><br><span class="hljs-keyword">while</span> <span class="hljs-built_in">abs</span>(sigma-vol)&gt;tol || iter &lt; maxiter <span class="hljs-comment">% precision of result</span><br>    sigma = vol;<br>    d1    = (<span class="hljs-built_in">log</span>(S/K)+(r+sigma^<span class="hljs-number">2</span>/<span class="hljs-number">2</span>)*T)/(sigma*<span class="hljs-built_in">sqrt</span>(T));<br>    d2    = d1-sigma*<span class="hljs-built_in">sqrt</span>(T);<br>    <span class="hljs-keyword">if</span> callput == <span class="hljs-number">1</span><br>        cp = S*normcdf(d1)-K*<span class="hljs-built_in">exp</span>(-r*T)*normcdf(d2);   <span class="hljs-comment">%European call option price under BS model</span><br>    <span class="hljs-keyword">else</span><br>        cp = K*<span class="hljs-built_in">exp</span>(-r*T)*normcdf(-d2) - S*normcdf(-d1);   <span class="hljs-comment">%European put option price under BS model</span><br>    <span class="hljs-keyword">end</span><br>    vega   = S*<span class="hljs-built_in">sqrt</span>(T)*normpdf(d1);<span class="hljs-comment">% call/put vega</span><br>    fsigma = cp-price;<br>    vol    = sigma-fsigma/vega;<span class="hljs-comment">% 期权对 sigma 的偏导即 vega</span><br>    iter   = iter + <span class="hljs-number">1</span>;<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><script type="math/tex; mode=display">\sigma_{k+1} = \sigma_k - \frac{C(t,T, \sigma_k,K)-C^{obs}(t)}{\frac{\partial}{\partial \sigma}C(t,T, \sigma_k,K)}</script><p>在验证的过程中，使用 Matlab 公式 blsimpv - Black-Scholes implied volatility</p><blockquote><p>This MATLAB function using a Black-Scholes model computes the implied volatilityof an underlying asset from the market value of European call and put options.</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">&gt;Volatility = blsimpv(Price,Strike,Rate,Time,Value)<br></code></pre></td></tr></table></figure></blockquote><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs matlab">S=<span class="hljs-number">260.05</span>;<span class="hljs-comment">% stock price</span><br>r=<span class="hljs-number">0.02</span>; <span class="hljs-comment">% interest rate</span><br>T=[<span class="hljs-number">4</span>/<span class="hljs-number">365</span>,<span class="hljs-number">11</span>/<span class="hljs-number">365</span>,<span class="hljs-number">18</span>/<span class="hljs-number">365</span>,<span class="hljs-number">25</span>/<span class="hljs-number">365</span>,<span class="hljs-number">32</span>/<span class="hljs-number">365</span>]; <span class="hljs-comment">% time maturity</span><br>K=[<span class="hljs-number">250</span>,<span class="hljs-number">252.5</span>,<span class="hljs-number">255</span>,<span class="hljs-number">257.5</span>,<span class="hljs-number">260</span>,<span class="hljs-number">262.5</span>,<span class="hljs-number">265</span>,<span class="hljs-number">267.5</span>,<span class="hljs-number">270</span>];<span class="hljs-comment">%strike price</span><br>C=[ <span class="hljs-number">10.4</span> <span class="hljs-number">7.73</span> <span class="hljs-number">5.8</span> <span class="hljs-number">3.8</span> <span class="hljs-number">2.3</span> <span class="hljs-number">1.19</span> <span class="hljs-number">0.55</span> <span class="hljs-number">0.25</span> <span class="hljs-number">0.12</span>;<br>    <span class="hljs-number">10.24</span> <span class="hljs-number">8.69</span> <span class="hljs-number">6.6</span> <span class="hljs-number">4.85</span> <span class="hljs-number">3.3</span> <span class="hljs-number">2.2</span> <span class="hljs-number">1.29</span> <span class="hljs-number">0.81</span> <span class="hljs-number">0.46</span>;<br>    <span class="hljs-number">10.9</span> <span class="hljs-number">8.23</span> <span class="hljs-number">6.4</span> <span class="hljs-number">4.65</span> <span class="hljs-number">3.42</span> <span class="hljs-number">2.45</span> <span class="hljs-number">1.72</span> <span class="hljs-number">1.11</span> <span class="hljs-number">0.75</span>;<br>    <span class="hljs-number">12</span> <span class="hljs-number">9.89</span> <span class="hljs-number">7.95</span> <span class="hljs-number">6.4</span> <span class="hljs-number">4.9</span> <span class="hljs-number">3.84</span> <span class="hljs-number">2.52</span> <span class="hljs-number">1.8</span> <span class="hljs-number">1.4</span>;<br>    <span class="hljs-number">11.57</span> <span class="hljs-number">10.83</span><span class="hljs-number">8.02</span> <span class="hljs-number">7.26</span> <span class="hljs-number">5.7</span> <span class="hljs-number">4.1</span> <span class="hljs-number">3.55</span> <span class="hljs-number">2.54</span> <span class="hljs-number">1.97</span>;];<span class="hljs-comment">%prices for different maturities in rows</span><br>volatility=<span class="hljs-built_in">zeros</span>(<span class="hljs-number">5</span>,<span class="hljs-number">9</span>);<br><span class="hljs-comment">% plot implied volatility surface</span><br>[x,y]=<span class="hljs-built_in">meshgrid</span>(K,T);<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>:<span class="hljs-number">5</span>  <br>   <span class="hljs-keyword">for</span>  <span class="hljs-built_in">j</span>=<span class="hljs-number">1</span>:<span class="hljs-number">9</span><br>     volatility(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span>)=blsimpv(S,K(<span class="hljs-built_in">j</span>),r,T(<span class="hljs-built_in">i</span>),C(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span>));<br>   <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br>surf(x,y,volatility)<br></code></pre></td></tr></table></figure><p><img src="/2022/03/11/Lab_of_Applied_Computational_Finance/pic2-1.jpg" alt></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>:<span class="hljs-number">5</span>  <br>   <span class="hljs-keyword">for</span>  <span class="hljs-built_in">j</span>=<span class="hljs-number">1</span>:<span class="hljs-number">9</span><br>     volatility(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span>)=newtoniv(S,K(<span class="hljs-built_in">j</span>),r,T(<span class="hljs-built_in">i</span>),C(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span>),<span class="hljs-number">1</span>);<br>   <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br>surf(x,y,volatility)<br></code></pre></td></tr></table></figure><p><img src="/2022/03/11/Lab_of_Applied_Computational_Finance/pic2-2.jpg" alt></p><p>我们可以发现结果是很相似的</p><h2 id="Week-3-Delta-hedging-in-the-Black-Scholes-model"><a href="#Week-3-Delta-hedging-in-the-Black-Scholes-model" class="headerlink" title="Week 3: Delta-hedging in the Black-Scholes model"></a>Week 3: Delta-hedging in the Black-Scholes model</h2><p>此部分主要计算采用 Delta 对冲后的策略价值。首先我们引入股票价格的增长公式</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">ST</span>=<span class="hljs-title">BSpath</span><span class="hljs-params">(S0,mu,sigma,T,n,N)</span></span><br><span class="hljs-comment">% S0 is the initial stock price, </span><br><span class="hljs-comment">% K is strike price,  </span><br><span class="hljs-comment">% r is free interest rate, </span><br><span class="hljs-comment">% T is time to maturity, </span><br><span class="hljs-comment">% n is the number of time discretisation steps,</span><br><span class="hljs-comment">% N is the sample size</span><br><span class="hljs-comment">% mu is the asset&#x27;s rate of return </span><br><span class="hljs-comment">% sigma is the asset&#x27;s volatility</span><br><br>nstep = power(<span class="hljs-number">2</span>,n); <span class="hljs-comment">% 步数</span><br>delt = T/nstep; <span class="hljs-comment">% 每步时间间隔</span><br>const = <span class="hljs-built_in">ones</span>(N,nstep+<span class="hljs-number">1</span>)*(mu - <span class="hljs-number">0.5</span>*sigma*sigma)*delt; <span class="hljs-comment">% 计算 s（t+1）时固定增长量</span><br>BMval = normrnd(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,[N,nstep+<span class="hljs-number">1</span>]); <span class="hljs-comment">% Brownian Motion Value/Matrix</span><br>BMval(<span class="hljs-number">1</span>:N,<span class="hljs-number">1</span>) = <span class="hljs-number">0</span>;<br>const(<span class="hljs-number">1</span>:N,<span class="hljs-number">1</span>) = <span class="hljs-number">0</span>;<br>incr = const + sigma*<span class="hljs-built_in">sqrt</span>(delt)*BMval;<br>ST = S0*cumprod(<span class="hljs-built_in">exp</span>(incr));<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><p>其中 cumprod 输出的是累计乘积的值</p><blockquote><p>cumprod([1 2 3])</p><p>ans =</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-number">1</span>     <span class="hljs-number">2</span>     <span class="hljs-number">6</span><br></code></pre></td></tr></table></figure></blockquote><p>因此 BSpath 输出的是股票波动的路径。我们在此基础上建立对冲资产组合的路径。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-params">[X,PNL]</span>=<span class="hljs-title">deltahedge</span><span class="hljs-params">(S0,K,r,mu,sigma,T,n,N)</span></span><br><span class="hljs-comment">% S0 is the initial stock price, </span><br><span class="hljs-comment">% K is strike price,  </span><br><span class="hljs-comment">% r is free interest rate, </span><br><span class="hljs-comment">% T is time to maturity, </span><br><span class="hljs-comment">% n is the number of time discretisation steps,</span><br><span class="hljs-comment">% N is the sample size</span><br><span class="hljs-comment">% mu is the asset&#x27;s rate of return </span><br><span class="hljs-comment">% sigma is the asset&#x27;s volatility</span><br><br>strike = K;<br>nstep = power(<span class="hljs-number">2</span>,n); <span class="hljs-comment">% number of time steps</span><br>delt = T/nstep;<span class="hljs-comment">% time step size</span><br>tstep = <span class="hljs-built_in">linspace</span>(<span class="hljs-number">0</span>,T,nstep+<span class="hljs-number">1</span>);<br>const = <span class="hljs-built_in">ones</span>(N,nstep+<span class="hljs-number">1</span>)*(mu - <span class="hljs-number">0.5</span>*sigma*sigma)*delt;<br>BMval = normrnd(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,[N,nstep+<span class="hljs-number">1</span>]); <span class="hljs-comment">% Brownian motion increments</span><br>BMval(<span class="hljs-number">1</span>:N,<span class="hljs-number">1</span>) = <span class="hljs-number">0</span>;<br>const(<span class="hljs-number">1</span>:N,<span class="hljs-number">1</span>) = <span class="hljs-number">0</span>;<br>incr = const + sigma*<span class="hljs-built_in">sqrt</span>(delt)*BMval;<br>ST = S0*cumprod(<span class="hljs-built_in">exp</span>(incr),<span class="hljs-number">2</span>);<br><span class="hljs-comment">% Compute delta at each readjustment time</span><br>tt = T-tstep(<span class="hljs-number">1</span>:nstep); <span class="hljs-comment">% 剩余时间</span><br>X = <span class="hljs-built_in">zeros</span>(N,<span class="hljs-built_in">length</span>(K)); <span class="hljs-comment">% final value of the self-financing portfolio</span><br>PNL = <span class="hljs-built_in">zeros</span>(N,<span class="hljs-built_in">length</span>(K)); <span class="hljs-comment">% Profit and loss over Monte Carlo sample paths</span><br><br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>:N<br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span>=<span class="hljs-number">1</span>:<span class="hljs-built_in">length</span>(K)<br>        price = blsprice(S0,strike(<span class="hljs-built_in">j</span>),r,T,sigma); <span class="hljs-comment">% Black-Scholes call price</span><br>        d1 = (<span class="hljs-built_in">log</span>(ST(<span class="hljs-built_in">i</span>,<span class="hljs-number">1</span>:nstep)./(strike(<span class="hljs-built_in">j</span>)*<span class="hljs-built_in">exp</span>(-r*tt))) + <span class="hljs-number">0.5</span>*sigma*sigma*tt)./(sigma*<span class="hljs-built_in">sqrt</span>(tt));<br>        delta = normcdf(d1); <span class="hljs-comment">% 每时期对冲需要的股票数</span><br>        temp = ST(<span class="hljs-built_in">i</span>,<span class="hljs-number">2</span>:nstep+<span class="hljs-number">1</span>).*<span class="hljs-built_in">exp</span>(-r*tstep(<span class="hljs-number">2</span>:nstep+<span class="hljs-number">1</span>)) - ST(<span class="hljs-built_in">i</span>,<span class="hljs-number">1</span>:nstep).*<span class="hljs-built_in">exp</span>(-r*tstep(<span class="hljs-number">1</span>:nstep)); <span class="hljs-comment">% 每时期持有一单位股票收益</span><br>        chng = delta.*temp;<br>        X(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span>) = <span class="hljs-built_in">exp</span>(r*T)*(price +sum(chng));<br>        PNL(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span>) = <span class="hljs-built_in">exp</span>(-r*T)*(X(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span>) - <span class="hljs-built_in">max</span>(ST(<span class="hljs-built_in">i</span>,nstep+<span class="hljs-number">1</span>)-strike(<span class="hljs-built_in">j</span>),<span class="hljs-number">0</span>));<br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs matlab">S0 = <span class="hljs-number">100</span>; <span class="hljs-comment">%Starting price</span><br>r = <span class="hljs-number">0.05</span>; <span class="hljs-comment">%interest rate</span><br>T = <span class="hljs-number">1</span>; <span class="hljs-comment">%call option maturity</span><br>n = <span class="hljs-number">5</span>; <span class="hljs-comment">%exponent in the number of time steps</span><br>N = <span class="hljs-number">1000</span>; <span class="hljs-comment">%number of Monte Carlo sample paths</span><br>mu = <span class="hljs-number">0.02</span>; <span class="hljs-comment">%asset return</span><br>sigma = <span class="hljs-number">0.2</span>; <span class="hljs-comment">%volatility parameter</span><br>K = <span class="hljs-number">80</span>; <span class="hljs-comment">%option strike</span><br><br>[X,PNL]=deltahedge(S0,K,r,mu,sigma,T,n,N);<br><span class="hljs-built_in">mean</span>(PNL)<br>var(PNL)<br></code></pre></td></tr></table></figure><p>如果将 n 从 5 增长到 8/10。Mean 和 Var 将由下表所示</p><div class="table-container"><table><thead><tr><th>n =</th><th>5</th><th>8</th><th>10</th></tr></thead><tbody><tr><td>Mean</td><td>0.01219</td><td>0.00385</td><td>0.00122</td></tr><tr><td>Var</td><td>0.31075</td><td>0.04385</td><td>0.01038</td></tr></tbody></table></div><p>从中我们可以发现，收益的均值随着对冲的频率增加而减少，但是波动也随之减少。另外，虽然我们的结果显示收益大多为正数，但是在我们的代码中并没考虑到交易成本这一问题，在现实的交易中，频繁的交易可能会带来大量的手续费。因此，在动态对冲中，过于频繁地调整组合也不一定是一件好事。</p><h2 id="Week-4-Pricing-European-options-in-Heston‘s-model-using-inverse-Fourier-transform"><a href="#Week-4-Pricing-European-options-in-Heston‘s-model-using-inverse-Fourier-transform" class="headerlink" title="Week 4: Pricing European options in Heston‘s model using inverse Fourier transform"></a>Week 4: Pricing European options in Heston‘s model using inverse Fourier transform</h2><p>此部分对应于笔记中的 <a href="https://achlier.github.io/2021/05/12/Applied_Computational_Finance/#Unit-2-9：The-Heston-Model">Unit 2.9</a> 。普通定价模型中将风险定义为一个常量，而Heston’s Stochastic Volatility Model 则将其定义为一个随时间变换的值。并且 sigma 的值是 mean-reversion 的。如果它偏离了 mean 会有一种力量把它纠正回原点的方向。</p><script type="math/tex; mode=display">\frac{dS_t}{S_t}=rdt+\sigma_tdW_t</script><script type="math/tex; mode=display">\begin{align}&d\sigma_t^2=k(\theta-\sigma_t^2)dt+\delta\sigma_tdW'_t,\ d\langle W,W'\rangle_t=\rho dt\\or,\ &dv_t=k(\theta-v_t)dt+\delta\sqrt{v_t}dW'_t,\ with\ v_t=\sigma_t^2\end{align}</script><p>解出定价公式需要用到 <a href="https://achlier.github.io/2021/05/30/Fourier_Transform/">Fourier transform</a> 的知识，但这在我们的课程中并不做要求。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">call</span> = <span class="hljs-title">HestonCallQuad</span><span class="hljs-params">(kappa,theta,sigma,rho,v0,r,T,s0,K)</span></span><br>warning off;<br>call = s0*HestonP(kappa,theta,sigma,rho,v0,r,T,s0,K,<span class="hljs-number">1</span>) - ...<br>K*<span class="hljs-built_in">exp</span>(-r*T)*HestonP(kappa,theta,sigma,rho,v0,r,T,s0,K,<span class="hljs-number">2</span>);<br><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">ret</span> = <span class="hljs-title">HestonP</span><span class="hljs-params">(kappa,theta,sigma,rho,v0,r,T,s0,K,type)</span></span><br>ret = <span class="hljs-number">0.5</span> + <span class="hljs-number">1</span>/<span class="hljs-built_in">pi</span>*quadl(@HestonPIntegrand,<span class="hljs-number">0</span>,<span class="hljs-number">100</span>,[],[],kappa, ...<br>theta,sigma,rho,v0,r,T,s0,K,<span class="hljs-built_in">type</span>);<br><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">ret</span> = <span class="hljs-title">HestonPIntegrand</span><span class="hljs-params">(phi,kappa,theta,sigma,rho, ...</span></span><br><span class="hljs-params"><span class="hljs-function">v0,r,T,s0,K,type)</span></span><br>ret = <span class="hljs-built_in">real</span>(<span class="hljs-built_in">exp</span>(<span class="hljs-number">-1</span><span class="hljs-built_in">i</span>*phi*<span class="hljs-built_in">log</span>(K)).*Hestf(phi,kappa,theta,sigma, ...<br>rho,v0,r,T,s0,<span class="hljs-built_in">type</span>)./(<span class="hljs-number">1</span><span class="hljs-built_in">i</span>*phi));<br><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">f</span> = <span class="hljs-title">Hestf</span><span class="hljs-params">(phi,kappa,theta,sigma,rho,v0,r,T,s0,type)</span></span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span> == <span class="hljs-number">1</span><br>u = <span class="hljs-number">0.5</span>;<br>b = kappa - rho*sigma;<br><span class="hljs-keyword">else</span><br>u = <span class="hljs-number">-0.5</span>;<br>b = kappa;<br><span class="hljs-keyword">end</span><br>a = kappa*theta; x = <span class="hljs-built_in">log</span>(s0);<br>d = <span class="hljs-built_in">sqrt</span>((rho*sigma*phi.*<span class="hljs-number">1</span><span class="hljs-built_in">i</span>-b).^<span class="hljs-number">2</span>-sigma^<span class="hljs-number">2</span>*(<span class="hljs-number">2</span>*u*phi.*<span class="hljs-number">1</span><span class="hljs-built_in">i</span>-phi.^<span class="hljs-number">2</span>));<br>g = (b-rho*sigma*phi*<span class="hljs-number">1</span><span class="hljs-built_in">i</span> + d)./(b-rho*sigma*phi*<span class="hljs-number">1</span><span class="hljs-built_in">i</span> - d);<br>C = r*phi.*<span class="hljs-number">1</span><span class="hljs-built_in">i</span>*T + a/sigma^<span class="hljs-number">2.</span>*((b- rho*sigma*phi*<span class="hljs-number">1</span><span class="hljs-built_in">i</span> + d)*T - ...<br><span class="hljs-number">2</span>*<span class="hljs-built_in">log</span>((<span class="hljs-number">1</span>-g.*<span class="hljs-built_in">exp</span>(d*T))./(<span class="hljs-number">1</span>-g)));<br>D = (b-rho*sigma*phi*<span class="hljs-number">1</span><span class="hljs-built_in">i</span> + d)./sigma^<span class="hljs-number">2.</span>*((<span class="hljs-number">1</span>-<span class="hljs-built_in">exp</span>(d*T))./ ...<br>(<span class="hljs-number">1</span>-g.*<span class="hljs-built_in">exp</span>(d*T)));<br>f = <span class="hljs-built_in">exp</span>(C + D*v0 + <span class="hljs-number">1</span><span class="hljs-built_in">i</span>*phi*x);<br></code></pre></td></tr></table></figure><p>Matlab 强大的数学运算功能提供了我们一个非常方便的工具来运算解，使用 quadl 来进行数值积分大大减少了我们的负担。但值得注意的是，quadl 进行的运算是以矩阵的形式，因此进行积分的公式需要兼容矩阵运算的格式。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-comment">% initialization of parameters for Heston model</span><br>s0=<span class="hljs-number">100</span>;<span class="hljs-comment">% stock price</span><br>r=<span class="hljs-number">0.02</span>; <span class="hljs-comment">% interest rate</span><br>kappa=<span class="hljs-number">5</span>; <span class="hljs-comment">% speed of mean reversion</span><br>theta=<span class="hljs-number">0.04</span>;<span class="hljs-comment">% long term mean</span><br>sigma=<span class="hljs-number">0.5</span>; <span class="hljs-comment">% volatility of volatility</span><br>rho=<span class="hljs-number">-0.7</span>;<br>v0=<span class="hljs-number">0.5</span>;<span class="hljs-comment">% initial variance</span><br>T=[<span class="hljs-number">0.2</span>,<span class="hljs-number">0.4</span>,<span class="hljs-number">0.6</span>,<span class="hljs-number">0.8</span>,<span class="hljs-number">1</span>]; <span class="hljs-comment">% time maturity</span><br>K=[<span class="hljs-number">80</span>,<span class="hljs-number">90</span>,<span class="hljs-number">100</span>,<span class="hljs-number">110</span>,<span class="hljs-number">120</span>]; <span class="hljs-comment">% strike price</span><br><br>C=<span class="hljs-built_in">zeros</span>(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>);<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>:<span class="hljs-number">5</span><br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span>=<span class="hljs-number">1</span>:<span class="hljs-number">5</span><br>        C(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span>)=HestonCallQuad(kappa,theta,sigma,rho,v0,r,T(<span class="hljs-built_in">i</span>),s0,K(<span class="hljs-built_in">j</span>)); <span class="hljs-comment">% European call option price under Heston model</span><br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br><br>volatility=<span class="hljs-built_in">zeros</span>(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>);<br><span class="hljs-comment">% plot implied volatility surface</span><br>[x,y]=<span class="hljs-built_in">meshgrid</span>(T,K);<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>:<span class="hljs-number">5</span><br>   <span class="hljs-keyword">for</span>  <span class="hljs-built_in">j</span>=<span class="hljs-number">1</span>:<span class="hljs-number">5</span><br>     volatility(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span>)=blsimpv(s0,K(<span class="hljs-built_in">j</span>),r,T(<span class="hljs-built_in">i</span>),C(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span>));<br>   <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br>surf(x,y,volatility)<br></code></pre></td></tr></table></figure><p><img src="/2022/03/11/Lab_of_Applied_Computational_Finance/pic4-1.jpg" alt></p><p>如果将 sigma=0.5 代入 Heston’s Model 求出的值重新用 blsimpv 求 volatility。我们可以从图中发现，结果确实是围绕在 0.5 附近的。</p><h2 id="Week-5-Calibration-of-Heston’s-model-to-market-data"><a href="#Week-5-Calibration-of-Heston’s-model-to-market-data" class="headerlink" title="Week 5: Calibration of Heston’s model to market data"></a>Week 5: Calibration of Heston’s model to market data</h2><p>但实际上 Heston’s model 的准确度非常依赖它的系数与波动率初始值 （$\kappa,\theta,\sigma,\rho,v_0$）。因此，在运用模型之前还需要运用 lsqnonlin 对模型的系数进行训练。如果令 $\Theta = (\kappa,\theta,\sigma,\rho,v_0)$，优化函数则是</p><script type="math/tex; mode=display">\min_{\Theta}\sum_{i,j}w_{i,j}(P^{model(\Theta)}(T_i,K_j)-P^{market}(T_i,k_j))^2</script><script type="math/tex; mode=display">w_{ij}=\frac1{|P^{market,bid}(T_i,K_j)-P^{market,ask}(T_i,K_j)|}</script><script type="math/tex; mode=display">P^{market}(T_i,k_j)=\frac{P^{market,bid}(T_i,K_j)+P^{market,ask}(T_i,K_j)}2</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">ret</span> = <span class="hljs-title">HestonDifferences</span><span class="hljs-params">(input)</span></span><br><span class="hljs-keyword">global</span> NoOfOptions;<br><span class="hljs-keyword">global</span> OptionData;<br><span class="hljs-keyword">global</span> NoOfIterations;<br><span class="hljs-keyword">global</span> PriceDifference;<br>NoOfIterations = NoOfIterations + <span class="hljs-number">1</span>;<br><span class="hljs-comment">%counts the no of iterations run to calibrate model</span><br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:NoOfOptions<br>PriceDifference(<span class="hljs-built_in">i</span>) = (OptionData(<span class="hljs-built_in">i</span>,<span class="hljs-number">5</span>)-HestonCallQuad( ...<br>(input(<span class="hljs-number">1</span>)+input(<span class="hljs-number">3</span>)^<span class="hljs-number">2</span>)/(<span class="hljs-number">2</span>*input(<span class="hljs-number">2</span>)),input(<span class="hljs-number">2</span>),input(<span class="hljs-number">3</span>),input(<span class="hljs-number">4</span>),input(<span class="hljs-number">5</span>), ...<br>OptionData(<span class="hljs-built_in">i</span>,<span class="hljs-number">1</span>),OptionData(<span class="hljs-built_in">i</span>,<span class="hljs-number">2</span>),OptionData(<span class="hljs-built_in">i</span>,<span class="hljs-number">3</span>),OptionData(<span class="hljs-built_in">i</span>,<span class="hljs-number">4</span>)))...<br>/<span class="hljs-built_in">sqrt</span>((<span class="hljs-built_in">abs</span>(OptionData(<span class="hljs-built_in">i</span>,<span class="hljs-number">6</span>)- OptionData(<span class="hljs-built_in">i</span>,<span class="hljs-number">7</span>))));<br><span class="hljs-comment">%Option Value-Estimated Value(4个系数，4个已知)</span><br><span class="hljs-comment">%kappa=(?+sigma^2)/2theta,theta,sigma,rho,v0,r,T,s0,K</span><br><span class="hljs-comment">%sqrt((abs(OptionData(i,6)-OptionData(i,7))))-&gt; w_ij (weight)</span><br><span class="hljs-keyword">end</span><br>ret = PriceDifference&#x27;;<br></code></pre></td></tr></table></figure><p>因为要求 $\kappa &gt; \sigma^2/2\theta$ ，input(1) 需要大于0</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs matlab">clear;<br><span class="hljs-keyword">global</span> OptionData;<br><span class="hljs-keyword">global</span> NoOfOptions;<br><span class="hljs-keyword">global</span> NoOfIterations;<br><span class="hljs-keyword">global</span> PriceDifference;<br>NoOfIterations = <span class="hljs-number">0</span>;<br>load OptionData.m ;<br><span class="hljs-comment">%OptionData = [r,T,S0,K,Option Value,bid,offer]</span><br>Size = <span class="hljs-built_in">size</span>(OptionData);<br>NoOfOptions = Size(<span class="hljs-number">1</span>);<br><span class="hljs-comment">%input sequence in initial vectors [2*kappa*theta - sigma^2,theta,sigma,rho,v0]</span><br><span class="hljs-comment">%x0 = [0.05 0.05 0.5 -0.5 0.15];</span><br>x0 = [<span class="hljs-number">0.5</span> <span class="hljs-number">0.1</span> <span class="hljs-number">1.3</span> <span class="hljs-number">-0.75</span> <span class="hljs-number">0.2</span>]; <span class="hljs-comment">% 系数训练初始值</span><br>lb = [<span class="hljs-number">0</span> <span class="hljs-number">0</span> <span class="hljs-number">0</span> <span class="hljs-number">-1</span> <span class="hljs-number">0</span>]; <span class="hljs-comment">% 系数训练最小值</span><br>ub = [<span class="hljs-number">20</span> <span class="hljs-number">1</span> <span class="hljs-number">5</span> <span class="hljs-number">0</span> <span class="hljs-number">1</span>]; <span class="hljs-comment">% 系数训练最大值</span><br>options = optimset(<span class="hljs-string">&#x27;MaxFunEvals&#x27;</span>,<span class="hljs-number">20000</span>);<br><span class="hljs-comment">%sets the max no. of iteration to 20000 so that termination doesn&#x27;t take place early.</span><br>tic;<br>Calibration = lsqnonlin(@HestonDifferences,x0,lb,ub);<br>toc;<br>Solution = [(Calibration(<span class="hljs-number">1</span>)+Calibration(<span class="hljs-number">3</span>)^<span class="hljs-number">2</span>)/(<span class="hljs-number">2</span>*Calibration(<span class="hljs-number">2</span>)), Calibration(<span class="hljs-number">2</span>:<span class="hljs-number">5</span>)];<br><span class="hljs-comment">%output sequence in Solution = [kappa,theta,sigma,rho,v0]</span><br></code></pre></td></tr></table></figure><h2 id="Week-6-Pricing-of-European-option-in-Heston’s-model-using-the-Monte-Carlo-method"><a href="#Week-6-Pricing-of-European-option-in-Heston’s-model-using-the-Monte-Carlo-method" class="headerlink" title="Week 6: Pricing of European option in Heston’s model using the Monte Carlo method"></a>Week 6: Pricing of European option in Heston’s model using the Monte Carlo method</h2><p>此部分对应于笔记中的 <a href="https://achlier.github.io/2021/05/12/Applied_Computational_Finance/#Unit-3-1：Monte-Carlo-methods">Unit 3.1</a> 。蒙特卡洛部分要使用 Euler-Maruyama 和 Milstein schemes 两种方法来运算，并且对比。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-comment">% European call option under Heston model with Euler-Maruyama-Method and Milstein method</span><br>clear all;<br>M = <span class="hljs-number">50000</span>; <span class="hljs-comment">% number of paths</span><br>N = <span class="hljs-number">100</span>;<span class="hljs-comment">% number of time steps</span><br>T = <span class="hljs-number">1</span>;<span class="hljs-comment">% maturity</span><br>h = T/N;<span class="hljs-comment">%delta t</span><br>S0 = <span class="hljs-number">100</span>; <br>sigma20 = <span class="hljs-number">0.0625</span>; <span class="hljs-comment">%variance at t=0</span><br>K=<span class="hljs-number">100</span>; <span class="hljs-comment">% strike</span><br>kappa = <span class="hljs-number">2</span>;<br>theta = <span class="hljs-number">0.4</span>;<br>nu = <span class="hljs-number">0.2</span>;<br>rho = <span class="hljs-number">-0.7</span>;<br>r=<span class="hljs-number">0.02</span>;<br><br><span class="hljs-comment">% two dimensional Brownian motion</span><br>dW1 = <span class="hljs-built_in">randn</span>(M,N+<span class="hljs-number">1</span>)*<span class="hljs-built_in">sqrt</span>(h);<br>dW2 = rho*dW1 + <span class="hljs-built_in">sqrt</span>(<span class="hljs-number">1</span>-rho^<span class="hljs-number">2</span>)*<span class="hljs-built_in">randn</span>(M,N+<span class="hljs-number">1</span>)*<span class="hljs-built_in">sqrt</span>(h);<br></code></pre></td></tr></table></figure><p>Euler Maruyama method 的主要公式是</p><script type="math/tex; mode=display">dX(t)=b(t,X(t))dt+\sigma(t,X(t))dW_t</script><script type="math/tex; mode=display">X_n^h:=X(t_n^h)=X_{n-1}^h+b(t_{n-1}^h,X_{n-1}^h)h+\sigma(t_{n-1}^h,X_{n-1}^h)\Delta W_n^h</script><p>其中 </p><script type="math/tex; mode=display">b(t,X(t))\Rightarrow k(\theta-\sigma_t^2)dt\quad \sigma(t,X(t))\Rightarrow\delta\sigma_tdW'_t</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-comment">% Initialisation of stock price and volatility for Euler Maruyama method</span><br>S = S0*<span class="hljs-built_in">ones</span>(M,N+<span class="hljs-number">1</span>);<br>sigma2 = sigma20*<span class="hljs-built_in">ones</span>(M,N+<span class="hljs-number">1</span>);<br><br><span class="hljs-comment">% Solution of the SDE-System with Euler-Maruyama-Method</span><br><span class="hljs-comment">% <span class="hljs-doctag">NOTE:</span> we don&#x27;t need to store the entire simulation path to compute the </span><br><span class="hljs-comment">%European option payoff!</span><br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:N<br>    sigma2(:,<span class="hljs-built_in">i</span>+<span class="hljs-number">1</span>) = sigma2(:,<span class="hljs-built_in">i</span>) + kappa*(theta-sigma2(:,<span class="hljs-built_in">i</span>))*h ...<br>        + nu*<span class="hljs-built_in">sqrt</span>(<span class="hljs-built_in">abs</span>(sigma2(:,<span class="hljs-built_in">i</span>))).*dW2(:,<span class="hljs-built_in">i</span>);<br>    S(:,<span class="hljs-built_in">i</span>+<span class="hljs-number">1</span>) = S(:,<span class="hljs-built_in">i</span>).*(<span class="hljs-number">1</span> + r*h + <span class="hljs-built_in">sqrt</span>(<span class="hljs-built_in">abs</span>(sigma2(:,<span class="hljs-built_in">i</span>))).*dW1(:,<span class="hljs-built_in">i</span>));<br><span class="hljs-keyword">end</span><br><br>payoff = <span class="hljs-built_in">exp</span>(-r*T)*<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>,S(:,<span class="hljs-keyword">end</span>)-K);<br>stdpayoff = std(payoff);<br>V = <span class="hljs-built_in">mean</span>(payoff)<br>Vleft = V - <span class="hljs-number">1.96</span>*stdpayoff/<span class="hljs-built_in">sqrt</span>(M)<br>Vright = V + <span class="hljs-number">1.96</span>*stdpayoff/<span class="hljs-built_in">sqrt</span>(M)<br></code></pre></td></tr></table></figure><p>Milstein Scheme 的主要公式是</p><script type="math/tex; mode=display">X_n^h=X(t_n^h)=X_{n-1}^h+bh+\sigma\Delta W_n^h+\frac12\partial_x\sigma\sigma_t((\Delta W_n^h)^2-h)</script><p>其中</p><script type="math/tex; mode=display">\partial_x\sigma\Rightarrow \partial_{\sigma^2}\delta\sigma_t=\frac\delta{2\sigma_t}</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-comment">% Initialisation of stock price and volatility for Milstein method</span><br>S1 = S0*<span class="hljs-built_in">ones</span>(M,N+<span class="hljs-number">1</span>);<br>sigma3 = sigma20*<span class="hljs-built_in">ones</span>(M,N+<span class="hljs-number">1</span>);<br><span class="hljs-comment">% Solution of the Milstein method</span><br><br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:N<br>    sigma3(:,<span class="hljs-built_in">i</span>+<span class="hljs-number">1</span>) = sigma3(:,<span class="hljs-built_in">i</span>) + kappa*(theta-sigma3(:,<span class="hljs-built_in">i</span>))*h ...<br>        + nu*<span class="hljs-built_in">sqrt</span>(<span class="hljs-built_in">abs</span>(sigma3(:,<span class="hljs-built_in">i</span>))).*dW2(:,<span class="hljs-built_in">i</span>)+<span class="hljs-number">1</span>/<span class="hljs-number">4</span>*nu.*(dW2(:,<span class="hljs-built_in">i</span>).^<span class="hljs-number">2</span>-h);<br>    S1(:,<span class="hljs-built_in">i</span>+<span class="hljs-number">1</span>) = S1(:,<span class="hljs-built_in">i</span>).*(<span class="hljs-number">1</span> + r*h + <span class="hljs-built_in">sqrt</span>(<span class="hljs-built_in">abs</span>(sigma3(:,<span class="hljs-built_in">i</span>))).*dW1(:,<span class="hljs-built_in">i</span>))+<span class="hljs-number">1</span>/<span class="hljs-number">2</span>*sigma3(:,<span class="hljs-built_in">i</span>).*S1(:,<span class="hljs-built_in">i</span>).*(dW1(:,<span class="hljs-built_in">i</span>).^<span class="hljs-number">2</span>-h);<br><span class="hljs-keyword">end</span><br><br>payoff1 = <span class="hljs-built_in">exp</span>(-r*T)*<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>,S1(:,<span class="hljs-keyword">end</span>)-K);<br>stdpayoff1 = std(payoff1);<br>V1 = <span class="hljs-built_in">mean</span>(payoff1)<br>V1left = V1 - <span class="hljs-number">1.96</span>*stdpayoff1/<span class="hljs-built_in">sqrt</span>(M)<br>V1right = V1 + <span class="hljs-number">1.96</span>*stdpayoff1/<span class="hljs-built_in">sqrt</span>(M)<br></code></pre></td></tr></table></figure><p>运算的结果，可以与前面的 HestonCallQuad 进行确认</p><h2 id="Week-7-Variance-reduction-method-in-the-Black-Scholes-model-for-Asian-option-pricing"><a href="#Week-7-Variance-reduction-method-in-the-Black-Scholes-model-for-Asian-option-pricing" class="headerlink" title="Week 7: Variance reduction method in the Black-Scholes model for Asian option pricing"></a>Week 7: Variance reduction method in the Black-Scholes model for Asian option pricing</h2><p>此部分对应笔记中的 <a href="https://achlier.github.io/2021/05/12/Applied_Computational_Finance/#Control-Variates">Unit 3.2.1</a>。我们想要预测 Arithmetic average Asian call option 的价格，同时将 Geometric average Asian option 作为 control variate 来降低预测值的 VAR。在代码中使用的 Geometric Asian option 的定价方程参考于 Nielsen 的论文《Pricing Asian Options》^[1]^。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-params">[Pasian_cv,CIasian_cv,Pasian,CIasian,Pgm,CIgm,Pgeo]</span> = <span class="hljs-title">asiancall_cv</span><span class="hljs-params">(S0,K,r,sigma,T,n,N,b)</span></span><br>dt= T/n;<br>R = <span class="hljs-built_in">exp</span>(-r*T);<br>m = (r - sigma^<span class="hljs-number">2</span>/<span class="hljs-number">2</span>)*dt;<br>s = sigma*<span class="hljs-built_in">sqrt</span>(dt);<br>Vcall = <span class="hljs-built_in">zeros</span>(<span class="hljs-number">1</span>,N);<br>Vgmcall = <span class="hljs-built_in">zeros</span>(<span class="hljs-number">1</span>,N);<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span> = <span class="hljs-number">1</span>:N<br>    Z= m+s*<span class="hljs-built_in">randn</span>(<span class="hljs-number">1</span>,n);<br>    S = cumsum([<span class="hljs-built_in">log</span>(S0), Z],<span class="hljs-number">2</span>);<br>    Vcall(<span class="hljs-built_in">j</span>) = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">mean</span>(<span class="hljs-built_in">exp</span>(S))-K,<span class="hljs-number">0</span>); <span class="hljs-comment">% Arithmetic average</span><br>    Vgmcall(<span class="hljs-built_in">j</span>) = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">exp</span>(<span class="hljs-built_in">mean</span>(S))-K,<span class="hljs-number">0</span>); <span class="hljs-comment">% Geometric average</span><br><span class="hljs-keyword">end</span><br>Pasian = <span class="hljs-built_in">mean</span>(R*Vcall); <br>CIasian = std(R*Vcall)/<span class="hljs-built_in">sqrt</span>(N);<br>Pgm = <span class="hljs-built_in">mean</span>(R*Vgmcall);<br>CIgm = std(R*Vgmcall)/<span class="hljs-built_in">sqrt</span>(N);<br><br>sigmaG = sigma*<span class="hljs-built_in">sqrt</span>(dt*(<span class="hljs-number">2</span>*n+<span class="hljs-number">1</span>)*(n+<span class="hljs-number">1</span>)/(<span class="hljs-number">6</span>*n));<br>muG = <span class="hljs-built_in">log</span>(S0) + <span class="hljs-number">1</span>/<span class="hljs-number">2</span>*(r-sigma^<span class="hljs-number">2</span>/<span class="hljs-number">2</span>)*(T+dt);<br>d1 = (muG -<span class="hljs-built_in">log</span>(K) + sigmaG^<span class="hljs-number">2</span>)/sigmaG;<br>d2 = d1 - sigmaG;<br>Pgeo = R*(<span class="hljs-built_in">exp</span>(muG+<span class="hljs-number">0.5</span>*sigmaG^<span class="hljs-number">2</span>)*normcdf(d1) - K*normcdf(d2)); <span class="hljs-comment">% the price of Geometric Asian option</span><br><br>Pasian_cv = R*Vcall - b*(R*Vgmcall-Pgeo);<br>CIasian_cv = std(Pasian_cv)/<span class="hljs-built_in">sqrt</span>(N);<br>Pasian_cv = <span class="hljs-built_in">mean</span>(Pasian_cv);<br><br></code></pre></td></tr></table></figure><p>Variance reduction 主要的部分是</p><script type="math/tex; mode=display">Y_i(\hat b_N):=Y_i-\hat b_N(X_i-\alpha_0)</script><ul><li><p>$\alpha_0$ ：Pgeo</p></li><li><p>变量 $\hat b_N$ 的值是一个固定的数，需要预先拟合出来。</p></li></ul><script type="math/tex; mode=display">b^*=\frac{Cov(X,Y)}{Var(X)}</script><blockquote><p>[1] Nielsen, L. Pricing Asian Options. Master of Science Dissertation, University of Aarhus</p></blockquote><h2 id="Week-8-Finite-difference-method-to-solve-the-Black-Scholes-PDE"><a href="#Week-8-Finite-difference-method-to-solve-the-Black-Scholes-PDE" class="headerlink" title="Week 8: Finite difference method to solve the Black-Scholes PDE"></a>Week 8: Finite difference method to solve the Black-Scholes PDE</h2><p>此部分对应笔记中的 <a href="https://achlier.github.io/2021/05/12/Applied_Computational_Finance/#Unit-4-1：Finite-difference-methods">Unit 4.1</a> 。代码只包括 Explicit Scheme 的部分，对于 Implicit Scheme 的部分需要用到 c 语言编写的程序 thomas，暂时没有进行详细的阅读，就不放在笔记中了。更多相关知识也可以搜索数值分析课程进行学习。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs matlab">clear all<br>close all<br><br>J=<span class="hljs-number">1000</span>;<br>S0=<span class="hljs-number">17</span>;<br><span class="hljs-comment">% time steps to ensure numerical convergence</span><br>N = J^<span class="hljs-number">2</span>;<br>K = <span class="hljs-number">15</span>;<br>logstrk = <span class="hljs-built_in">log</span>(K);<br>T=<span class="hljs-number">0.3041</span>;<br>r=<span class="hljs-number">0.03</span>;<br>sigma = <span class="hljs-number">0.25</span>;<br>mu = r - <span class="hljs-number">0.5</span>*sigma^<span class="hljs-number">2</span>;<br>xmin = <span class="hljs-built_in">log</span>(<span class="hljs-number">10e-6</span>);<br>xmax = <span class="hljs-built_in">log</span>(<span class="hljs-number">2</span>*K);<br>dx=(xmax-xmin)/J; <br>x=[xmin:dx:xmax]&#x27;; <span class="hljs-comment">%length = J+1</span><br>dt=T/N;<br><br>V=<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>,<span class="hljs-built_in">exp</span>(x)-K);<br>Vold=V;<br>const1 = <span class="hljs-number">1</span> - sigma^<span class="hljs-number">2</span>*dt/dx^<span class="hljs-number">2</span>;<br>const2 = <span class="hljs-number">0.5</span>*sigma^<span class="hljs-number">2</span>*dt/dx^<span class="hljs-number">2</span>;<br>const3 = <span class="hljs-number">0.5</span>*mu*dt/dx;<br><br><span class="hljs-keyword">for</span> n=<span class="hljs-number">1</span>:N <br>    <span class="hljs-comment">%boundary condition at x = xmin  </span><br>    V(<span class="hljs-number">1</span>)=<span class="hljs-number">0</span>;  <br>        <br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span>=<span class="hljs-number">2</span>:J <span class="hljs-comment">%in the interior</span><br>        V(<span class="hljs-built_in">j</span>)= Vold(<span class="hljs-built_in">j</span>)*const1 + Vold(<span class="hljs-built_in">j</span>+<span class="hljs-number">1</span>)*(const2+const3) + Vold(<span class="hljs-built_in">j</span><span class="hljs-number">-1</span>)*(const2-const3) - r*dt*Vold(<span class="hljs-built_in">j</span>);<br>    <span class="hljs-keyword">end</span><br>    <br>    <span class="hljs-comment">%boundary condition at x = xmax</span><br>    V(J+<span class="hljs-number">1</span>)= <span class="hljs-built_in">exp</span>(xmax)-K;<br>    <br>    Vold=V;<br><span class="hljs-keyword">end</span><br><br>V_Final = interp1(x, V, <span class="hljs-built_in">log</span>(S0));<br><br><span class="hljs-built_in">figure</span>(<span class="hljs-number">1</span>)<br>clf<br><span class="hljs-built_in">plot</span>(<span class="hljs-built_in">exp</span>(x),V)<br>xlabel(<span class="hljs-string">&#x27;asset price&#x27;</span>)<br>ylabel(<span class="hljs-string">&#x27;call price&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="Week-9-Finite-difference-method-to-solve-the-Heston-model-PDE"><a href="#Week-9-Finite-difference-method-to-solve-the-Heston-model-PDE" class="headerlink" title="Week 9: Finite difference method to solve the Heston model PDE"></a>Week 9: Finite difference method to solve the Heston model PDE</h2><p>本章代码是根据 Sensen Lin 的论文 《Finite Difference Schemes for Heston Model》^[2]^。其中定义 Heston model</p><script type="math/tex; mode=display">d S=\mu S d t+\sqrt{v(t)} S d z_{1}(t)</script><script type="math/tex; mode=display">d v(t)=\kappa[\theta-v(t)] d t+\delta\sqrt{v(t)} d z_{2}(t)</script><p>那么期权合约 C 服从 partial differential equation</p><script type="math/tex; mode=display">\begin{align}\frac{1}{2} v S^{2} \frac{\partial^{2} C}{\partial S^{2}}+\rho \delta v S \frac{\partial^{2} C}{\partial S \partial v}+\frac{1}{2} \delta^{2} v \frac{\partial^{2} C}{\partial v^{2}}+r S \frac{\partial C}{\partial S} \\+\kappa(\theta-v(t))\frac{\partial C}{\partial v}-r C+\frac{\partial C}{\partial t} & = 0\end{align}</script><p> 其边界条件为</p><script type="math/tex; mode=display">\begin{align}&C(s, v, T) = \max (0, s-K) \\&C(0, v, T) = 0 \\&C(s, \infty, t) = s\\&\frac{\partial C}{\partial s}(\infty, v, t) = 1 \\&r s \frac{\partial C}{\partial s}(s, 0, t)+\kappa \theta\frac{\partial C}{\partial v}(s, 0, t)-r C(s, 0, t)+\frac{\partial C}{\partial t}(s, 0, t) = 0\end{align}</script><p>公式中的偏导部分可以变换为</p><script type="math/tex; mode=display">\begin{align}&\frac{\partial C}{\partial S}(i\Delta s,j\Delta v) \approx \frac{C_{i+1, j}-C_{i-1, j}}{2 \Delta s} \\&\frac{\partial C}{\partial v}(i\Delta s,j\Delta v) \approx \frac{C_{i, j+1}-C_{i, j-1}}{2 \Delta v} \\&\frac{\partial^{2} C}{\partial S^{2}}(i\Delta s,j\Delta v) \approx \frac{C_{i+1, j}-2 C_{i, j}+C_{i-1, j}}{(\Delta s)^{2}} \\&\frac{\partial^{2} C}{\partial v^{2}}(i\Delta s,j\Delta v) \approx \frac{C_{i, j+1}-2 C_{i, j}+C_{i, j-1}}{(\Delta v)^{2}} \\&\frac{\partial^{2} C}{\partial S \partial v}(i\Delta s,j\Delta v) \approx \frac{C_{i+1, j+1}+C_{i-1, j-1}-C_{i-1, j+1}-C_{i+1, j-1}}{4 \Delta s \Delta v}\end{align}</script><p>代入原式则变换为</p><script type="math/tex; mode=display">\begin{align}&\frac{c_{i, j}^{n+1}-c_{i, j}^{n}}{\Delta t} = \left[\left(s_{i}\right)^{2} v_{j} \frac{c_{i+1, j}-2 c_{i, j}+c_{i-1, j}}{2(\Delta s)^{2}}+\rho \delta s_{i} v_{j} \frac{c_{i+1, j+1}+c_{i-1, j-1}-c_{i-1, j+1}-c_{i+1, j-1}}{4 \Delta s \Delta v}\right. \\&\left.+\delta^{2} v_{j} \frac{c_{i, j+1}-2 c_{i, j}+c_{i, j-1}}{2(\Delta v)^{2}}+r s_{i} \frac{c_{i+1, j}-c_{i-1, j}}{2 \Delta s}+\kappa\left(\theta-v_{j}\right) \frac{c_{i, j+1}-c_{i, j-1}}{2 \Delta v}-r c_{i, j}\right]^{n}\end{align}</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">Un</span>=<span class="hljs-title">hestonPDEprice</span><span class="hljs-params">(kappa,theta,delta,rho,T,dt,K,Y,I,J)</span></span><br>    <span class="hljs-comment">%hestonPDEprice(1.15,0.10,0.2,-0.4,4/52,4/(52*4000),40,1.0,80,40)</span><br>    nt=<span class="hljs-built_in">ceil</span>(T/dt);<br>    xmin = <span class="hljs-built_in">log</span>(<span class="hljs-number">1e-2</span>);<br>xmax = <span class="hljs-built_in">log</span>(<span class="hljs-number">2.0</span>*K);<br>    ymin = <span class="hljs-number">0</span>;<br>    ymax = Y*<span class="hljs-number">1.2</span>;<br>    dx = (xmax-xmin)/I; <span class="hljs-comment">%step length of x</span><br>    dx2 = dx*dx;<br>    dy = Y/J; <span class="hljs-comment">%step length of y</span><br>    dy2 = dy*dy;<br>    xvalue = xmin:dx:xmax; <span class="hljs-comment">%grid of x values</span><br>    yvalue = ymin:dy:ymax; <span class="hljs-comment">%grid of y values</span><br>    nx = <span class="hljs-built_in">length</span>(xvalue)<span class="hljs-number">-1</span>; <span class="hljs-comment">%number of entries in x axis - 1</span><br>    ny = <span class="hljs-built_in">length</span>(yvalue)<span class="hljs-number">-1</span>; <span class="hljs-comment">%number of entries in y axis - 1</span><br>    temp = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">exp</span>(xvalue)-K,<span class="hljs-number">0</span>); <span class="hljs-comment">%European call payoff: terminal condition</span><br>    uinitial = temp&#x27;*<span class="hljs-built_in">ones</span>(<span class="hljs-number">1</span>,ny+<span class="hljs-number">1</span>); <span class="hljs-comment">%x in row i, vol in col j</span><br>    U = uinitial; <span class="hljs-comment">% u in dimension of (nx+1)*(ny+1)</span><br>    <span class="hljs-keyword">for</span> n=<span class="hljs-number">1</span>:nt<br>        <span class="hljs-comment">%interior elements in cross derivative</span><br>        Upp = U(<span class="hljs-number">3</span>:nx+<span class="hljs-number">1</span>,<span class="hljs-number">3</span>:ny+<span class="hljs-number">1</span>); <span class="hljs-comment">%+1 in x, +1 in y</span><br>        Umm = U(<span class="hljs-number">1</span>:nx<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>:ny<span class="hljs-number">-1</span>); <span class="hljs-comment">%-1 in x, -1 in y</span><br>        Ump = U(<span class="hljs-number">1</span>:nx<span class="hljs-number">-1</span>,<span class="hljs-number">3</span>:ny+<span class="hljs-number">1</span>); <span class="hljs-comment">%-1 in x, +1 in y</span><br>        Upm = U(<span class="hljs-number">3</span>:nx+<span class="hljs-number">1</span>,<span class="hljs-number">1</span>:ny<span class="hljs-number">-1</span>); <span class="hljs-comment">%+1 in x, -1 in y</span><br>        Uxy = Upp+Umm-Ump-Upm;<br>        G0t = (rho*delta*dt/(<span class="hljs-number">4</span>*dx*dy))*<span class="hljs-built_in">ones</span>(<span class="hljs-number">1</span>,nx+<span class="hljs-number">1</span>)&#x27;*yvalue;<br>        G0 = G0t(<span class="hljs-number">2</span>:nx,<span class="hljs-number">2</span>:ny);        <br>        U1t = G0.*Uxy;<br>        U1 = [<span class="hljs-built_in">zeros</span>(<span class="hljs-number">1</span>,ny+<span class="hljs-number">1</span>);<span class="hljs-built_in">zeros</span>(nx<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>) U1t <span class="hljs-built_in">zeros</span>(nx<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>);<span class="hljs-built_in">zeros</span>(<span class="hljs-number">1</span>,ny+<span class="hljs-number">1</span>)];<span class="hljs-comment">% pad with zeros at the edge of domain</span><br>        <span class="hljs-comment">% dsdv 项以及其前面的系数</span><br>        <br>        <span class="hljs-comment">% elements in X direction</span><br>        C1 = <span class="hljs-built_in">ones</span>(<span class="hljs-number">1</span>,nx<span class="hljs-number">-1</span>)*(<span class="hljs-number">0.5</span>/dx2 + <span class="hljs-number">0.25</span>/dx);<br>        C1 = [C1&#x27;;<span class="hljs-number">0</span>;<span class="hljs-number">0</span>];<br>        A1 = -<span class="hljs-built_in">ones</span>(<span class="hljs-number">1</span>,nx<span class="hljs-number">-1</span>)/dx2; <br>        A1 = [<span class="hljs-number">0</span>;A1&#x27;;<span class="hljs-number">0</span>];<br>        E1 = <span class="hljs-built_in">ones</span>(<span class="hljs-number">1</span>,nx<span class="hljs-number">-1</span>)*(<span class="hljs-number">0.5</span>/dx2 - <span class="hljs-number">0.25</span>/dx);<br>        E1 = [<span class="hljs-number">0</span>;<span class="hljs-number">0</span>;E1&#x27;];<br>        <span class="hljs-comment">%sparse matrix with A1 on the diagonal, C1 one below &amp; D1 one above</span><br>        B = spdiags([C1 A1 E1],[<span class="hljs-number">-1</span> <span class="hljs-number">0</span> <span class="hljs-number">1</span>],nx+<span class="hljs-number">1</span>,nx+<span class="hljs-number">1</span>); <br>        <span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span>=<span class="hljs-number">2</span>:ny<br>            A = U(:,<span class="hljs-built_in">j</span>);<br>            G1 = dt*yvalue(<span class="hljs-built_in">j</span>)*B;<br>            U2t = G1*A; <span class="hljs-comment">% the interior elements along the j-th sub-vector.</span><br>            U2t(nx+<span class="hljs-number">1</span>) = <span class="hljs-number">0</span>; <br>            U2t(<span class="hljs-number">1</span>) = <span class="hljs-number">0</span>;<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">j</span>==<span class="hljs-number">2</span><br>                U2 = U2t;<br>            <span class="hljs-keyword">else</span><br>                U2 = [U2 U2t]; <span class="hljs-comment">% arrange in columns</span><br>                <span class="hljs-comment">% ds,(ds)^2项以及前面的系数</span><br>            <span class="hljs-keyword">end</span><br>        <span class="hljs-keyword">end</span><br>        U2 = [<span class="hljs-built_in">zeros</span>(nx+<span class="hljs-number">1</span>,<span class="hljs-number">1</span>) U2 <span class="hljs-built_in">zeros</span>(nx+<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)]; <span class="hljs-comment">%pad with zeros in the first and last columns</span><br>        <span class="hljs-comment">%</span><br>        <span class="hljs-comment">% elements in Y direction</span><br>        E1 = <span class="hljs-number">0.5</span>*delta^<span class="hljs-number">2</span>*yvalue(<span class="hljs-number">2</span>:ny)/dy2 - <span class="hljs-number">0.5</span>*kappa*(theta-yvalue(<span class="hljs-number">2</span>:ny))/dy;<br>        E1 = [E1&#x27;;<span class="hljs-number">0</span>;<span class="hljs-number">0</span>];<br>        A1 = -delta^<span class="hljs-number">2</span>*yvalue(<span class="hljs-number">2</span>:ny)/dy2;<br>        A1 = [<span class="hljs-number">0</span>;A1&#x27;;<span class="hljs-number">0</span>];<br>        F1 = <span class="hljs-number">0.5</span>*delta^<span class="hljs-number">2</span>*yvalue(<span class="hljs-number">2</span>:ny)/dy2 + <span class="hljs-number">0.5</span>*kappa*(theta-yvalue(<span class="hljs-number">2</span>:ny))/dy;<br>        F1 = [<span class="hljs-number">0</span>;<span class="hljs-number">0</span>;F1&#x27;];<br>        D = spdiags([E1 A1 F1],[<span class="hljs-number">-1</span> <span class="hljs-number">0</span> <span class="hljs-number">1</span>],ny+<span class="hljs-number">1</span>,ny+<span class="hljs-number">1</span>);<br>        <span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">2</span>:nx<br>            A = U(<span class="hljs-built_in">i</span>,:)&#x27;;<br>            U3t = dt*D*A;<br>            U3t(<span class="hljs-number">1</span>) = <span class="hljs-number">0</span>;<br>            U3t(ny+<span class="hljs-number">1</span>) = <span class="hljs-number">0</span>;<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">i</span>==<span class="hljs-number">2</span><br>                U3 = U3t&#x27;;<br>            <span class="hljs-keyword">else</span><br>                U3 = [U3; U3t&#x27;];<br>            <span class="hljs-keyword">end</span><br>        <span class="hljs-keyword">end</span><br>        U3 = [<span class="hljs-built_in">zeros</span>(<span class="hljs-number">1</span>,ny+<span class="hljs-number">1</span>);U3;<span class="hljs-built_in">zeros</span>(<span class="hljs-number">1</span>,ny+<span class="hljs-number">1</span>)];<br>        <span class="hljs-comment">% dv,(dv)^2项以及前面的系数</span><br>        Uy = U(:,<span class="hljs-number">1</span>); <span class="hljs-comment">% the first column of the previous U</span><br>        U = U + U1 + U2 + U3 ;<br>        <span class="hljs-comment">% 代入边界条件</span><br>        U(<span class="hljs-number">1</span>,:) = <span class="hljs-built_in">zeros</span>(<span class="hljs-number">1</span>, ny+<span class="hljs-number">1</span>); <span class="hljs-comment">%when x = xmin</span><br>        U(:,ny+<span class="hljs-number">1</span>) = <span class="hljs-built_in">exp</span>(xvalue)&#x27;; <span class="hljs-comment">%when y = ymax</span><br>        <span class="hljs-comment">% elements where y=0</span><br>        <span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">2</span>:nx<br>            U(<span class="hljs-built_in">i</span>,<span class="hljs-number">1</span>)=(Uy(<span class="hljs-built_in">i</span>)+kappa*theta*dt*U(<span class="hljs-built_in">i</span>,<span class="hljs-number">2</span>)/dy)/(<span class="hljs-number">1</span>+kappa*theta*dt/dy);<br>        <span class="hljs-keyword">end</span><br>        U(nx+<span class="hljs-number">1</span>,<span class="hljs-number">2</span>:ny) = <span class="hljs-built_in">exp</span>(xvalue(nx+<span class="hljs-number">1</span>))- K;<span class="hljs-comment">%when x = xmax</span><br>        <span class="hljs-comment">%U(nx+1,2:ny) = (2*dx*exp(xvalue(nx+1))+4*U(nx,2:ny)-U(nx-1,2:ny))/3;</span><br>    <span class="hljs-keyword">end</span><br>    Un = U(<span class="hljs-number">1</span>:I+<span class="hljs-number">1</span>,<span class="hljs-number">1</span>:J+<span class="hljs-number">1</span>);<br>    <br><span class="hljs-comment">%     p0 = zeros(nx+1,ny+1);    </span><br><span class="hljs-comment">%     for i=1:nx+1</span><br><span class="hljs-comment">%         for j=1:ny+1            </span><br><span class="hljs-comment">%             p0(i,j) = HestonCallQuad(kappa,theta,delta,rho,yvalue(j),0,T,exp(xvalue(i)),K);</span><br><span class="hljs-comment">%         end</span><br><span class="hljs-comment">%     end</span><br><span class="hljs-comment">%     p = p0(1:I+1,1:J+1);</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><p>以上代码是以 log(S) 为纵轴方向指标变换的，因此与文章中的代码有些不同。</p><p>其中矩阵 B 的样式为</p><p><img src="/2022/03/11/Lab_of_Applied_Computational_Finance/pic9-1.jpg" alt></p><p>矩阵 D 的样式为</p><p><img src="/2022/03/11/Lab_of_Applied_Computational_Finance/pic9-2.jpg" alt></p><blockquote><p>[2] Lin, S. (2008). Finite Difference Schemes for Heston Model. Master of Mathematical and Computational Finance Dissertation, University of Oxford</p></blockquote><h2 id="Week-10-Calibration-of-Dupire’s-model-to-market-data"><a href="#Week-10-Calibration-of-Dupire’s-model-to-market-data" class="headerlink" title="Week 10: Calibration of Dupire’s model to market data"></a>Week 10: Calibration of Dupire’s model to market data</h2><p>此部分对应笔记中的 <a href="https://achlier.github.io/2021/05/12/Applied_Computational_Finance/#Unit-2：Advanced-stochastic-models-and-their-calibration">Unit 2</a> 。主要运用两种方法来预测local volatility。 第一种是Dupire’s model 的原始公式，公式中参考的是 $q=0$ 的格式</p><script type="math/tex; mode=display">\sigma^2(T,K)=2\frac{C_T(T,K)+rKC_K(T,K)}{K^2C_{KK}(T,K)}</script><p>第二种方法是 Dupire’s model 的变换形式， 其中 $I(T,K)$ 是从 Black-Scholes 中逆向推导过来的 implied volatilities。</p><script type="math/tex; mode=display">\sigma^2(T,K)=\frac{\frac IT+2I_T+2rKI_K}{K^2(\frac1{K^2IT}+2\frac{d_+}{KI\sqrt{T}}I_K+\frac{d_+d_-}{I}I_K^2+I_{KK})}</script><p>如果运用第一种方法，需要使用大量数据进行偏导取值的趋近计算</p><p><img src="/2022/03/11/Lab_of_Applied_Computational_Finance/pic10-1.jpg" alt></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-comment">%In the data provided, there are non-zero call option prices for 0 maturity.</span><br><span class="hljs-comment">%In order to do the calculations, drop the values corresponding to 0 maturity. </span><br>T = <span class="hljs-number">0.9</span>;<br>n = <span class="hljs-number">8</span>;<br>num_step = <span class="hljs-number">2</span>^n;<br>S0 = <span class="hljs-number">100</span>;<br>r = <span class="hljs-number">0.0</span>;<br>dt = T/num_step;<br>dK = <span class="hljs-number">0.1</span>;<br>MaxCounter = <span class="hljs-number">100</span>; <span class="hljs-comment">%number of maximum iterations for implied vol inversion</span><br>MaxVolLevel = <span class="hljs-number">6.0</span>;<br>N = <span class="hljs-number">1000</span>; <span class="hljs-comment">%number of Monte Carlo sample paths</span><br>        <br>strk = load(<span class="hljs-string">&#x27;strikes.txt&#x27;</span>); <span class="hljs-comment">%strike vector length 401</span><br>mat = load(<span class="hljs-string">&#x27;maturities.txt&#x27;</span>); <span class="hljs-comment">%maturity vector length 257</span><br>mat = mat(<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span>); <span class="hljs-comment">%remove the maturity 0 entry</span><br>pr = load(<span class="hljs-string">&#x27;optionprices.txt&#x27;</span>); <span class="hljs-comment">%price is STRK * MAT </span><br>pr = pr(:,<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span>);<span class="hljs-comment">%remove the prices corresponding to maturity 0</span><br><span class="hljs-comment">%     </span><br>pr_T = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(pr));<br>pr_T(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span><span class="hljs-number">-1</span>) = (pr(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">3</span>:<span class="hljs-keyword">end</span>)-pr(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span><span class="hljs-number">-2</span>))/(<span class="hljs-number">2</span>*dt);<br>pr_T(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>) = (pr(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">2</span>)-pr(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>))/dt;<br>pr_T(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-keyword">end</span>) = (pr(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-keyword">end</span>)-pr(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-keyword">end</span><span class="hljs-number">-1</span>))/dt;<br><span class="hljs-comment">%</span><br>pr_K = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(pr));<br>pr_K(<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span><span class="hljs-number">-1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>) = (pr(<span class="hljs-number">3</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>)-pr(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span><span class="hljs-number">-2</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>))/(<span class="hljs-number">2</span>*dK);<br>pr_K(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>) = (pr(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>)-pr(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>))/dK;<br>pr_K(<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>) = (pr(<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>)-pr(<span class="hljs-keyword">end</span><span class="hljs-number">-1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>))/dK;<br><br>pr_KK = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(pr));<br>pr_KK(<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span><span class="hljs-number">-1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>) = (pr_K(<span class="hljs-number">3</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>)-pr_K(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span><span class="hljs-number">-2</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>))/(<span class="hljs-number">2</span>*dK);<br>pr_KK(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>) = (pr_K(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>)-pr_K(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>))/dK;<br>pr_KK(<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>) = (pr_K(<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>)-pr_K(<span class="hljs-keyword">end</span><span class="hljs-number">-1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>))/dK;<br><br>volsq1 = <span class="hljs-number">2.0</span>*(pr_T./(strk.^<span class="hljs-number">2.</span>*pr_KK)); <span class="hljs-comment">%Vol estimate from Dupire formula</span><br></code></pre></td></tr></table></figure><p>进行第二种方法的计算需要先求得 implied volatilities</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">callprice</span> = <span class="hljs-title">CallBS</span><span class="hljs-params">(S0,K,vol,T,r)</span> %<span class="hljs-title">Black</span>-<span class="hljs-title">Scholes</span> <span class="hljs-title">call</span> <span class="hljs-title">price</span> <span class="hljs-title">formula</span></span><br>matlen = <span class="hljs-built_in">length</span>(T);<br>callprice = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(vol));<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:matlen<br>    d1 = (<span class="hljs-built_in">log</span>(S0./K) + (r+<span class="hljs-number">0.5</span>*vol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>).^<span class="hljs-number">2</span>)*T(<span class="hljs-built_in">i</span>))./(vol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>)*T(<span class="hljs-built_in">i</span>)^<span class="hljs-number">0.5</span>);<br>    d2 = d1 - vol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>)*T(<span class="hljs-built_in">i</span>)^<span class="hljs-number">0.5</span>;<br>    callprice(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>) = S0*normcdf(d1)-K*<span class="hljs-built_in">exp</span>(-r*T(<span class="hljs-built_in">i</span>)).*normcdf(d2);<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">impvol</span> =  <span class="hljs-title">ImpVol</span><span class="hljs-params">(Price,Strike,Maturity,S0,r,MaxIter,MaxVolLevel)</span> %<span class="hljs-title">function</span> <span class="hljs-title">to</span> <span class="hljs-title">find</span> <span class="hljs-title">implied</span> <span class="hljs-title">vol</span></span><br><br>volmin = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(Price));<br>volmax = MaxVolLevel*<span class="hljs-built_in">ones</span>(<span class="hljs-built_in">size</span>(Price));<br>vol = <span class="hljs-number">0.5</span>*MaxVolLevel*<span class="hljs-built_in">ones</span>(<span class="hljs-built_in">size</span>(Price));<br>counter = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">while</span> counter &lt; MaxIter <span class="hljs-comment">% 由二分法进行运算</span><br>    CBSImp = CallBS(S0,Strike,vol,Maturity,r);<br>    temp1 = (CBSImp&lt;=Price);<br>    temp2 = (CBSImp&gt;Price);<br>    volmin = temp1.* vol + temp2.*volmin;<br>    volmax =  (CBSImp&lt;Price).* volmax + (CBSImp&gt;=Price).* vol;<br>    vol = (volmin + volmax)/<span class="hljs-number">2.0</span>;<br>    counter = counter + <span class="hljs-number">1</span>;<br><span class="hljs-keyword">end</span><br>impvol = vol;<br></code></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">ivol = ImpVol(pr,strk,mat,S0,<span class="hljs-number">0</span>,MaxCounter,MaxVolLevel);<br></code></pre></td></tr></table></figure><p>我们采用相同的方法来对 implied volatilities 的偏导进行运算。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs matlab">ivol_T = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(ivol));<br>ivol_T(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span><span class="hljs-number">-1</span>) = (ivol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">3</span>:<span class="hljs-keyword">end</span>)-ivol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span><span class="hljs-number">-2</span>))/(<span class="hljs-number">2</span>*dt);<br>ivol_T(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>) = (ivol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">2</span>)-ivol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>))/dt;<br>ivol_T(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-keyword">end</span>) = (ivol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-keyword">end</span>)-ivol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-keyword">end</span><span class="hljs-number">-1</span>))/dt;<br><br>ivol_K = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(ivol));<br>ivol_K(<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span><span class="hljs-number">-1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>) = (ivol(<span class="hljs-number">3</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>)-ivol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span><span class="hljs-number">-2</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>))/(<span class="hljs-number">2</span>*dK);<br>ivol_K(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>) = (ivol(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>)-ivol(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>))/dK;<br>ivol_K(<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>) = (ivol(<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>)-ivol(<span class="hljs-keyword">end</span><span class="hljs-number">-1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>))/dK;<br><br>ivol_KK = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(ivol));<br>ivol_KK(<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span><span class="hljs-number">-1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>) = (ivol_K(<span class="hljs-number">3</span>:<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>)-ivol_K(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span><span class="hljs-number">-2</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>))/(<span class="hljs-number">2</span>*dK);<br>ivol_KK(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>) = (ivol_K(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>)-ivol_K(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>))/dK;<br>ivol_KK(<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>) = (ivol_K(<span class="hljs-keyword">end</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>)-ivol_K(<span class="hljs-keyword">end</span><span class="hljs-number">-1</span>,<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>))/dK;<br><span class="hljs-comment">% </span><br>D1 = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(ivol));<br>D2 = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(ivol));<br>num = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(ivol));<br>den = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(ivol));<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:<span class="hljs-built_in">length</span>(mat)<br>    D1(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>) = (<span class="hljs-built_in">log</span>(S0./strk) + (r+<span class="hljs-number">0.5</span>*ivol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>).^<span class="hljs-number">2</span>)*mat(<span class="hljs-built_in">i</span>))./(ivol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>)*mat(<span class="hljs-built_in">i</span>)^<span class="hljs-number">0.5</span>);<br>    D2(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>) = D1(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>) - ivol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>)*mat(<span class="hljs-built_in">i</span>)^<span class="hljs-number">0.5</span>;<br>    num(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>) = ivol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>)/mat(<span class="hljs-built_in">i</span>) + <span class="hljs-number">2.0</span>*ivol_T(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>) + <span class="hljs-number">2</span>*r*strk.*ivol_K(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>);<br>    den(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>) = strk.^<span class="hljs-number">2.</span>*(<span class="hljs-number">1.</span>/(strk.^<span class="hljs-number">2.</span>*ivol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>)*mat(<span class="hljs-built_in">i</span>)) + <span class="hljs-number">2.0</span>*D1(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>).*ivol_K(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>)./(strk.*ivol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>)*mat(<span class="hljs-built_in">i</span>)^<span class="hljs-number">0.5</span>)... <br>    + D1(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>).*D2(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>).*ivol_K(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>).^<span class="hljs-number">2.</span>/ivol(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>) + ivol_KK(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>));<br><span class="hljs-keyword">end</span><br>volsq2 = num./den;<br></code></pre></td></tr></table></figure><p>求得结果后我们也可以使用线性插值来进行对 volatility 的预测，注意，K 最小只能到 80</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">interpvol</span> = <span class="hljs-title">LinInter</span><span class="hljs-params">(price,strk,VolEst,ixt,dK)</span> %<span class="hljs-title">linear</span> <span class="hljs-title">interpolation</span> <span class="hljs-title">for</span> <span class="hljs-title">the</span> <span class="hljs-title">volatility</span></span><br>    strk_cls = <span class="hljs-built_in">find</span>(price &lt;= strk);<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isempty</span>(strk_cls)<span class="hljs-comment">% no value of vol estimate exists</span><br>        tempx = <span class="hljs-built_in">length</span>(strk);<br>        temp = VolEst(tempx,ixt);<br>    <span class="hljs-keyword">elseif</span> strk_cls(<span class="hljs-number">1</span>) == <span class="hljs-number">80</span> <span class="hljs-comment">%this is the minimum entry in the strike array</span><br>        tempx = <span class="hljs-number">1</span>;<br>        temp = VolEst(tempx,ixt);<br>    <span class="hljs-keyword">else</span> <span class="hljs-comment">%linearly interpolate</span><br>        strk1 = strk(strk_cls(<span class="hljs-number">1</span>));<br>        strk2 = strk(strk_cls(<span class="hljs-number">1</span>)<span class="hljs-number">-1</span>);        <br>        temp = (VolEst(strk_cls(<span class="hljs-number">1</span>)<span class="hljs-number">-1</span>,ixt)*(price-strk1)+VolEst(strk_cls(<span class="hljs-number">1</span>),ixt)*(strk2 - price))/dK;<br>    <span class="hljs-keyword">end</span><br> interpvol = temp;<br></code></pre></td></tr></table></figure><p>验证结果时，我们可以通过 蒙特卡洛模拟计算 $\hat C(T_i,K_j):=\mathbb E[(\hat S(T_i)-K_j)^+]$ 并与实际值比较</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-params">[pr_Euler1,pr_Euler2]</span>= <span class="hljs-title">EulerPath</span><span class="hljs-params">(VolEst1,VolEst2,strk,mat,S0,dK,dt,N)</span></span><br>matlen = <span class="hljs-built_in">length</span>(mat);<br>BM = normrnd(<span class="hljs-number">0.0</span>,<span class="hljs-number">1.0</span>,[N,matlen+<span class="hljs-number">1</span>])*dt^<span class="hljs-number">0.5</span>;<br>pr_Euler1 = <span class="hljs-built_in">ones</span>(N,matlen+<span class="hljs-number">1</span>)*S0;<br>pr_Euler2 = <span class="hljs-built_in">ones</span>(N,matlen+<span class="hljs-number">1</span>)*S0;<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> =<span class="hljs-number">1</span>:matlen<br>    estvol1 = <span class="hljs-built_in">zeros</span>(N);<br>    estvol2 = <span class="hljs-built_in">zeros</span>(N);<br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span>=<span class="hljs-number">1</span>:N<br>        estvol1(<span class="hljs-built_in">j</span>) = LinInter(pr_Euler1(<span class="hljs-built_in">j</span>,<span class="hljs-built_in">i</span>),strk,VolEst1,<span class="hljs-built_in">i</span>,dK);<br>        estvol2(<span class="hljs-built_in">j</span>) = LinInter(pr_Euler2(<span class="hljs-built_in">j</span>,<span class="hljs-built_in">i</span>),strk,VolEst2,<span class="hljs-built_in">i</span>,dK);<br>    <span class="hljs-keyword">end</span><br>    pr_Euler1(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>+<span class="hljs-number">1</span>) = pr_Euler1(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>).*(<span class="hljs-number">1</span>+<span class="hljs-built_in">max</span>(estvol1,<span class="hljs-number">0.0</span>)^<span class="hljs-number">0.5</span>*BM(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>));<br>    pr_Euler2(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>+<span class="hljs-number">1</span>) = pr_Euler2(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>).*(<span class="hljs-number">1</span>+<span class="hljs-built_in">max</span>(estvol2,<span class="hljs-number">0.0</span>)^<span class="hljs-number">0.5</span>*BM(<span class="hljs-number">1</span>:<span class="hljs-keyword">end</span>,<span class="hljs-built_in">i</span>));        <br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Matlab</tag>
      
      <tag>Option Pricing</tag>
      
      <tag>Black Scholes Model</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】Recommender System:Social RS</title>
    <link href="/2022/03/11/Recommender-System_Social-RS/"/>
    <url>/2022/03/11/Recommender-System_Social-RS/</url>
    
    <content type="html"><![CDATA[<blockquote><p>重新整理出来的推荐系统相关的资料；</p><p>Social Recommendation 包括：</p><ol><li>加入了 Social Network 的 SoRec</li><li>与在前者基础上改进的 Social Trust</li></ol></blockquote><span id="more"></span><h1 id="SoRec"><a href="#SoRec" class="headerlink" title="SoRec"></a>SoRec</h1><blockquote><p>推荐阅读 《SoRec Social Recommendation using Probabilistic Matrix Factorization》^[1]^</p></blockquote><p>数据的稀疏性一直是推荐算法发展的一个巨大难题，作者考虑到了社交媒体在当今社会的发展，提出了一种加入 social network 的信息和评分记录来改进模型的方法。其主要思路是，用户对一件物品的评分很可能受关注的人/朋友的影响。</p><p><strong>假设有m个物品(item)，n个用户(user)，f个因子(factor)</strong></p><p>$U :$ 所有用户的集合</p><p>$I :$ 所有物品的集合</p><p>$P_{n\times f}: $ user-factor matrix </p><p>$Q_{m\times f}:$ item-factor matrix </p><p>$Z_{n\times f}:$ user-factor matrix in the social network graph</p><p>$R^f:$ 1$×$factor vector</p><p>$q_i:$ $Q$ 中物品 $i$ 所在行的向量</p><p>$p_u:$ $P$ 中用户 $u$ 所在的行的向量 </p><p>$\vartheta :$ social network graph</p><p>$\nu :$ all the users in a social network</p><p>$\varepsilon :$ the edge set in social network graph</p><script type="math/tex; mode=display">\vartheta = (\nu,\varepsilon)</script><p><img src="/2022/03/11/Recommender-System_Social-RS/pic1-1.jpg" alt></p><p>$C_{n\times n} :$ user-user matrix of $\vartheta$</p><p>$c_{uj}\in (0,1] :$ donate the weight associated with an edge from $\nu_{u}$ to $\nu_{j}$</p><p>这里特别注意，在 social network 中的信息是单项的。这代表一个用户 A 关注了另一个用户 B，但 用户 B 不一定知道用户 A。</p><p>$d^{+}(\nu_{u}) :$ the outdegree of $\nu_{u}$</p><p>$d^{-}(\nu_{u}) :$ the indegree of $\nu_{u}$</p><script type="math/tex; mode=display">c_{uj}^{*} = \sqrt{\frac{d^{-}(\nu_{j})}{d^{+}(\nu_{u})+d^{-}(\nu_{j})}}c_{uj}</script><p>如果将上式进行解释，就是一个用户 u 关注的其他的用户越多，那么他受某个特定用户 k 的影响就越少。如果特定用户 k 被很多人关注，那么用户 u 就会更加信任他。</p><p>$\kappa$ $:$ $\{ (u,i)|$  $r_{ui}$ is known $\}$</p><p>$\hat{r_{ui}}:$ 用户 $u$ 对物品 $i$ 的评分的预测值</p><script type="math/tex; mode=display">\hat{r_{ui}}=q_{i}^{T}p_{u}</script><p>$N(x|\mu,\sigma^2): $ 正态分布,均值为 $\mu$ , 方差为 $\sigma^2$</p><p>假设 P，Q，R，C，S 皆服从高斯分布，既：</p><script type="math/tex; mode=display">\begin{align}\\p(R|P,Q,\sigma_{R}^{2})&=\prod\limits_{u\in U}\prod\limits_{i\in I}N(r_{ui}|p_{u}^{T}q_{i},\sigma_{R}^{2})\\p(C|P,Z,\sigma_{C}^{2})&=\prod\limits_{u\in U}\prod\limits_{j\in U}N(c_{uj}|p_{u}^{T}z_{j},\sigma_{C}^{2})\\p(P|\sigma_{P}^{2})&=\prod\limits_{u\in U} N(p_{u}|0,\sigma_{P}^{2})\\p(Q|\sigma_{Q}^{2})&=\prod\limits_{i\in I} N(q_{i}|0,\sigma_{Q}^{2})\\p(Z|\sigma_{Z}^{2})&=\prod\limits_{u\in U} N(z_{u}|0,\sigma_{Z}^{2})\end{align}</script><p>使用极大似然估计，既希望最大化：</p><script type="math/tex; mode=display">\begin{align}p(P,Q|R,\overrightarrow{\theta})\qquad and \qquad p(P,Z|C,\overrightarrow{\theta})\end{align}</script><p>使用贝叶斯定理可知：</p><script type="math/tex; mode=display">\begin{align}&p(P,Q|R,\overrightarrow{\theta})\propto p(R|P,Q,\overrightarrow{\theta_{1}})p(P,Q|\overrightarrow{\theta_{2}})\\ =&p(P,Q|R,\overrightarrow{\theta})\propto p(R|P,Q,\overrightarrow{\theta_{1}})p(P|\overrightarrow{\theta_{2}})p(Q|\overrightarrow{\theta_{2}})\\ =&\prod\limits_{u\in U}\prod\limits_{i\in I}N(r_{ui}|p_{u}^{T}q_{i},\sigma_{R}^{2})\prod\limits_{u\in U} N(p_{u}|0,\sigma_{P}^{2})\prod\limits_{i\in I} N(q_{i}|0,\sigma_{Q}^{2})\end{align}</script><p>同理得出 $p(P,Z|C,\overrightarrow{\theta})$ 后进行 $log$ 处理，并且合并两个式子，得：</p><script type="math/tex; mode=display">\begin{align}&lnp(P,Q,Z|C,R,\sigma_{C}^{2},\sigma_{R}^{2},\sigma_{P}^{2},\sigma_{Q}^{2},\sigma_{Z}^{2})\\  =&-\frac{1}{2\sigma_{R}^{2}}\sum\limits_{u\in U}\sum\limits_{i\in I}(r_{ui}-p_{u}^{2}q_{i})^{2}-\frac{1}{2\sigma_{C}^{2}}\sum\limits_{u\in U}\sum\limits_{j\in U}(c_{uj}^{*}-p_{u}^{2}z_{j})^{2}\\  &-\frac{1}{2\sigma_{P}^{2}}\sum\limits_{u\in U}p_{u}^{T}p_{u}-\frac{1}{2\sigma_{Q}^{2}}\sum\limits_{i\in I}q_{i}^{T}q_{i}-\frac{1}{2\sigma_{Z}^{2}}\sum\limits_{u\in U}z_{u}^{T}z_{u}\\  &-\frac{1}{2}\sum\limits_{u\in U}\sum\limits_{i\in I}ln\sigma_{R}^{2}-\frac{1}{2}\sum\limits_{u\in U}\sum\limits_{i\in I}ln\sigma_{C}^{2}-\frac{1}{2}(n\times f ln\sigma_{P}^{2}+m\times f ln\sigma_{Q}^{2}+n\times f ln\sigma_{Z}^{2})\end{align}</script><p>$\lambda:$ 正则化系数</p><p>$\alpha:$ 学习速率(learning rate)</p><script type="math/tex; mode=display">C(q_{i},p_{u},z_{u})=\sum\limits_{(u,i)\in \kappa}(r_{ui}-\hat{r_{ui}})^{2}+\lambda(\sum\limits_{u\in \nu}\sum\limits_{j\in \nu}(c^{*}_{uj}-p_{u}^{T}z_{j})^{2}+\Arrowvert q_{i}\Arrowvert^{2}+\Arrowvert p_{u}\Arrowvert^{2}+\Arrowvert z_{u}\Arrowvert^{2})</script><script type="math/tex; mode=display">error=r_{ui}-\hat{r_{ui}}</script><script type="math/tex; mode=display">err = c^{*}_{uj}-p_{u}^{T}z_{j}</script><script type="math/tex; mode=display">\begin{align}q_{i}:&=q_{i}-\frac{\alpha}{2}\triangledown C(q_{i},p_{u},z_{u})\\ &=q_{i}-\frac{\alpha}{2}\frac{\partial C(q_{i},p_{u},z_{u})}{\partial q_{i}}\\ &=q_{i}-\frac{\alpha}{2}(2error\times(-p_{u})+2\lambda q_{i})\\ &=q_{i}+\alpha(error\times p_{u}-\lambda q_{i})\end{align}</script><script type="math/tex; mode=display">\begin{align}p_{u}:&=p_{u}-\frac{\alpha}{2}\triangledown C(q_{i},p_{u},z_{u})\\ &=p_{u}-\frac{\alpha}{2}\frac{\partial C(q_{i},p_{u},z_{u})}{\partial p_{u}}\\ &=p_{u}-\frac{\alpha}{2}(2error\times(-q_{i})+2err\times(-z_{u})+2\lambda p_{u})\\ &=p_{u}+\alpha(error\times q_{i}+err\times z_{u}-\lambda p_{u})\end{align}</script><script type="math/tex; mode=display">\begin{align}z_{u}:&=z_{u}-\frac{\alpha}{2}\triangledown C(q_{i},p_{u},z_{u})\\ &=z_{u}-\frac{\alpha}{2}\frac{\partial C(q_{i},p_{u},z_{u})}{\partial z_{u}}\\ &=z_{u}-\frac{\alpha}{2}(2err\times(-p_{u})+2\lambda p_{u})\\ &=z_{u}+\alpha(err\times p_{u}-\lambda z_{u})\end{align}</script><h1 id="Social-Trust"><a href="#Social-Trust" class="headerlink" title="Social Trust"></a>Social Trust</h1><blockquote><p>推荐阅读 《Learning to recommend with social trust ensemble》^[2]^</p></blockquote><p>这个模型是作者在上一个模型的基础改进的，主要思想是不再对用户在 social network 中关注的所有用户进行运算，而是挑选出几个用户最信任的朋友。</p><p><strong>假设有m个物品(item)，n个用户(user)，f个因子(factor)</strong></p><p>$P_{n\times f}: $ user-factor matrix </p><p>$Q_{m\times f}:$ item-factor matrix </p><p>$\vartheta :$ social network graph</p><p>$R^f:$ 1$×$factor vector</p><p>$q_i:$ $Q$ 中物品 $i$ 所在行的向量</p><p>$p_u:$ $P$ 中用户 $u$ 所在的行的向量 </p><p>$\nu :$ all the users in a social network</p><p>$\varepsilon :$ the edge set in social network graph</p><script type="math/tex; mode=display">\vartheta = (\nu,\varepsilon)</script><p>$S_{n\times n} :$ user-user matrix of $\vartheta$</p><p>$s_{uj}\in (0,1] :$ donate the weight associated with an edge from $\nu_{u}$ to $\nu_{j}$</p><p>$T(u) :$ the friends set that user $u$ trusts</p><script type="math/tex; mode=display">s_{uj}^{*} = \frac{s_{uj}}{|T(u)|}</script><p>$r_{ui}:$ 用户 $u$ 对物品 $i$ 的打分</p><p>$\kappa$ $:$ $\{ (u,i)|$  $r_{ui}$ is known $\}$</p><p>$\lambda:$ 正则化系数</p><p>$\alpha:$ 学习速率(learning rate)</p><p>$\gamma :$ controls how much do users trust themselves or their trusted friends</p><p>注意此处依旧有一个控制变量，来调节用户对朋友的信任度</p><script type="math/tex; mode=display">C(q_{i},p_{u})=\sum\limits_{(u,i)\in \kappa}(r_{ui}-(\gamma p_{u}^{T}q_{i}+(1-\gamma)\sum\limits_{j \in T(u)}s_{uj}^{*} p_{j}^{T} q_{i}))^{2}+\lambda(\Arrowvert q_{i}\Arrowvert^{2}+\Arrowvert p_{u}\Arrowvert^{2})</script><p>$\hat{r_{ui}}:$ 用户 $u$ 对物品 $i$ 的评分的预测值</p><script type="math/tex; mode=display">\hat{r_{ui}}=\gamma p_{u}^{T}q_{i}+(1-\gamma)\sum\limits_{j \in T(u)}s_{uj}^{*} p_{j}^{T} q_{i}</script><script type="math/tex; mode=display">error=r_{ui}-\hat{r_{ui}}</script><p>$B(u) :$ is the set that includes all the users who trust user $u$</p><script type="math/tex; mode=display">\begin{align}q_{i}:&=q_{i}-\frac{\alpha}{2}\triangledown C(q_{i},p_{u})\\ &=q_{i}-\frac{\alpha}{2}\frac{\partial C(q_{i},p_{u})}{\partial q_{i}}\\ &=q_{i}-\frac{\alpha}{2}(2error\times(-\gamma p_{u}-(1-\gamma)\sum\limits_{j \in T(u)}s_{uj}^{*} p_{j}^{T})+2\lambda q_{i})\\ &=q_{i}+\alpha(error\times(\gamma p_{u}+(1-\gamma)\sum\limits_{j \in T(u)}s_{uj}^{*} p_{j}^{T})-\lambda q_{i})\end{align}</script><script type="math/tex; mode=display">\begin{align}p_{u}:&=p_{u}-\frac{\alpha}{2}\triangledown C(q_{i},p_{u})\\ &=p_{u}-\frac{\alpha}{2}\frac{\partial C(q_{i},p_{u})}{\partial p_{u}}\\ &=p_{u}-\frac{\alpha}{2}(2error\times(-\gamma q_{i})+(1-\gamma)\sum\limits_{p\in B(u)}\sum\limits_{j\in T(u)}(-2error_{pi}\times s_{pj}^{*}q_{i}^{T}))+2\gamma p_{j})\\ &=p_{u}+\frac{\alpha}{2}(error\times(\gamma q_{i})+(1-\gamma)\sum\limits_{p\in B(u)}\sum\limits_{j\in T(u)}(error_{pi}\times s_{pj}^{*}q_{i}^{T}))-\gamma p_{j})\end{align}</script><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>Ma, H., Yang, H., Lyu, M.R., &amp; King, I. (2008). SoRec: social recommendation using probabilistic matrix factorization. <em>CIKM ‘08</em>.</li><li>Ma, H., King, I., &amp; Lyu, M.R. (2009). Learning to recommend with social trust ensemble. <em>Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval</em>.</li></ol>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Recommender System</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】Recommender System:Classical RS</title>
    <link href="/2022/03/08/Recommender-System_Classical-RS/"/>
    <url>/2022/03/08/Recommender-System_Classical-RS/</url>
    
    <content type="html"><![CDATA[<blockquote><p>重新整理出来的推荐系统相关的资料；</p><p>传统的推荐系统包括：</p><ol><li>基于用户的（User-based ）推荐系统</li><li>基于物品的（Item-based ）推荐系统</li><li>运用PMF（Probabilistic matrix factorization）技术的推荐系统</li></ol></blockquote><span id="more"></span><h1 id="导言"><a href="#导言" class="headerlink" title="导言"></a>导言</h1><p>推荐系统指的是依照用户过去的信息来判断用户的喜好，并且给用户未接触过的事物打分，将分数排序后将最高者推荐给用户。这在社交媒体发达的当今社会被广泛运用。</p><p>但是推荐算法的建立中有这么经典的两大问题-Sparsity and Scalability.</p><p>稀疏性指得是可用的训练数据在矩阵形式的表现中稀疏。这个方面还能扩展到冷启动问题，指对于一个新用户该如何推荐的难题。</p><p>可扩性指得是在小规模的运算中表现很好，但是当对大数量的数据进行运算时计算成本飞速增长。</p><p>当然对这些个问题现在都有了许多针推性的研究，不过在基础部分我们介绍的就只是经典的两种模型，以及一个可以作为推荐系统里程碑的算法。</p><p>Github 上有大佬整理出了所有推荐系统相关的文章，可以通过 <a href="https://github.com/hongleizhang/RSPapers/tree/master/02-General_RS">此处</a> 进行拓展阅读</p><h1 id="User-based"><a href="#User-based" class="headerlink" title="User-based"></a>User-based</h1><blockquote><p>推荐阅读 《GroupLens An Open Architecture for Collaborative Filtering of Netnews》^[1]^</p></blockquote><p>作为研究推荐系统的首几篇论文，GroupLens这篇文章更多的是在描述其系统在文章推荐的作用。不过我们的关注的点还是在算法的建立上。首先，进行基础的定义：</p><p>$U_{(i)}:$ 访问过物品 $i$ 的用户集合</p><p>$I_{(u)}:$ 用户 $u$ 访问过的物品集合</p><p>$|I_{u}|:$ 用户 $u$ 访问过的物品的个数</p><p>$r_{ui}:$ 用户 $u$ 对物品 $i$ 的打分</p><p>$R_{(u)}:$ 用户 $u$ 的打分集合</p><script type="math/tex; mode=display">R_{(u)} \in \{r_{ui}\ |\ i \in I_{(u)}\}</script><p>$\overline{r_{u}}:$ 用户 $u$ 的所有评分的均值</p><script type="math/tex; mode=display">\overline{r_{u}}=\frac{\sum\limits_{i\in I_{(u)}}r_{ui}}{|I_{(u)}|}</script><p>$\rho_{uj}:$ 用户 $u$ 与用户 $j$ 的相关系数</p><script type="math/tex; mode=display">\begin{align}\rho_{ui}&=\frac{Cov(R_{(u)},R_{(j)})}{\sigma_{R_{(u)}}\sigma_{R_{(j)}}}\\     &=\frac{\sum\limits_{i\in I_{(u)} \cap I_{(j)}}(r_{ui}-\overline{r_{u}})(r_{ji}-\overline{r_{j}})}{\sqrt{\sum\limits_{i\in I_{(u)} \cap I_{(j)}}(r_{ui}-\overline{r_{u}})^{2}}\sqrt{\sum\limits_{i\in I_{(u)} \cap I_{(j)}}(r_{ji}-\overline{r_{j}})^{2}}}\end{align}</script><p>$\hat{r_{ui}}:$ 用户 $u$ 对物品 $i$ 的打分的预测值</p><script type="math/tex; mode=display">\hat{r_{ui}}=\overline{r_{u}}+\frac{\sum\limits_{j\in U_{(i)}}(r_{ij}-\overline{r_{j}})\rho_{uj}}{\sum\limits_{j\in U_{(i)}}\rho_{uj}}</script><p>我们可以看到，定义中使用了 $\rho_{ui}$ 这个用户间的相关系数，而对未知物品的打分也最主要取决于这个值。用通俗的话来解释，如果 u 喜欢苹果，i 也喜欢苹果，那么这个相似的爱好会使两人之间的相关系数增大，当猜测 u 喜欢不喜欢梨子的时候，参考 i 的可信度也就越大。因此这个算法被称为 User-based。</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p><img src="/2022/03/08/Recommender-System_Classical-RS/pic1-1.jpg" alt></p><p>这是一个文章中给的例子，左边表格横轴是四个用户，纵轴是六个文章，又可以认作物品。而每个人和物品对应的值就是那个人对特定物品的评分。如果空白便是没有评分记录。如果问号便是我们待求的值。其中 K 代表 Ken，L 代表 Lee。我们可以轻松算得评分值。</p><p>但在现实中得到数据的会存在大量的空白值，导致矩阵稀疏且使结果不那么准确。同时用户的数量众多，运算量也巨大。为了减轻运算的压力，另一种模型被提出。</p><h1 id="Item-based"><a href="#Item-based" class="headerlink" title="Item-based"></a>Item-based</h1><blockquote><p>推荐阅读 《Item based Collaborative Filtering Recommendation Algorithms》^[2]^</p></blockquote><p>此文章不再局限于对于文字的推荐，而将视野放宽到了视频，电影，与音乐的领域。而在算法上也不再以用户间的相关系数为主，是以物品间的相关系数为主。</p><p>$U_{(i)}:$ 访问过物品 $i$ 的用户集合</p><p>$I_{(u)}:$ 用户 $u$ 访问过的物品集合</p><p>$|U_{(i)}|:$ 访问过物品 $i$ 的用户的个数</p><p>$r_{ui}:$ 用户 $u$ 对物品 $i$ 的打分</p><p>$R_{(i)}:$ 物品 $i$ 的打分集合</p><script type="math/tex; mode=display">R_{(i)} \in \{r_{ui}\ |\ u \in U_{(i)}\}</script><p>$\overline{r_{i}}:$ 物品 $i$ 的所有评分的均值</p><script type="math/tex; mode=display">\overline{r_{i}}=\frac{\sum\limits_{u\in U_{(i)}}r_{ui}}{|U_{(i)}|}</script><p>$\rho_{ki}:$ 物品 $k$ 与物品 $i$ 的相关系数</p><script type="math/tex; mode=display">\begin{align}\rho_{ki}&=\frac{Cov(R_{(k)},R_{(i)})}{\sigma_{R_{(k)}}\sigma_{R_{(i)}}}\\\quad&=\frac{\sum\limits_{u\in U_{(k)} \cap U_{(i)}}(r_{ui}-\overline{r_{i}})(r_{uk}-\overline{r_{k}})}{\sqrt{\sum\limits_{u\in U_{(k)} \cap U_{(i)}}(r_{uk}-\overline{r_{k}})^{2}}\sqrt{\sum\limits_{u\in U_{(k)} \cap U_{(i)}}(r_{ui}-\overline{r_{i}})^{2}}}\end{align}</script><p>$\hat{r_{ui}}:$ 用户 $u$ 对物品 $i$ 的打分的预测值</p><script type="math/tex; mode=display">\hat{r_{ui}}=\overline{r_{i}}+\frac{\sum\limits_{k\in I_{(u)}}(r_{uk}-\overline{r_{k}})\rho_{ki}}{\sum\limits_{k\in I_{(u)}}\rho_{ki}}</script><p>我们可以发现，两种算法在定义上很相似，而最大的区别就是 $\rho_{ki}$ 现在指的是物品间的相关系数。用通俗的话来解释，如果用户 u 喜欢苹果，因为梨子和苹果相似也属于水果，而坚果与苹果相差巨大，所以在评分时会更多地参考用户给梨子的评分。</p><p>作者认为，在系统中存在许多不活跃的用户，而即使是活跃的用户对物品评分的数量也仅仅占了所以物品的一小部分。因此作者将重点放在了物品的相关性上，并且提出可以预先进行相关性的判断得到一组静态的模型，来适应不断增大的用户数量。</p><h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><p>到此处最经典的两个已经被提出，而作为评估的方法在此时也有必要提及一下。Mean Absolute Error (MAE) 是一个被广泛运用的度量标准</p><script type="math/tex; mode=display">MAE=\frac{\sum_{i=1}^N|p_i-q_i|}{N}</script><p>其中 $p_i$ 指得是真实的评分 $q_i$ 指得是预测的评分。MAE 的值越低，推荐系统的评分越准确。</p><p> Root Mean Squared Error (RMSE) 是另一种被常用的度量方法</p><script type="math/tex; mode=display">RMAE=\sqrt{\frac{\sum_{i=1}^N(p_i-q_i)^2}{N}}</script><h1 id="PMF"><a href="#PMF" class="headerlink" title="PMF"></a>PMF</h1><blockquote><p>推荐阅读 《Matrix Factorization Techniques for Recommender Systems》^[3]^</p></blockquote><p>Probabilistic Matrix Factorization 的方法是推荐算法研究史上的一大突破。在 Netflix Prize competition 中，Koren 第一次将这个算法带到了舞台上。比起之前的两种算法，PMF在速度与准确度上有了显著的提升，一举成为推荐系统的主流算法。</p><p><strong>假定有 n个用户，m个物品，f个特征</strong></p><p><img src="/2022/03/08/Recommender-System_Classical-RS/pic1-2.jpg" alt></p><p>$P_{n\times f}: $ user-factor matrix </p><p>$Q_{m\times f}:$ item-factor matrix </p><p>$R^f:$ 1$×$factor vector</p><p>$q_i:$ $Q$ 中物品 $i$ 所在行的向量</p><p>$p_u:$ $P$ 中用户所在的行的向量 </p><p>$U_{(i)}:$ 访问过物品 $i$ 的用户集合</p><p>$I_{(u)}:$ 用户 $u$ 访问过的物品集合</p><p>$r_{ui}:$ 用户 $u$ 对物品 $i$ 的评分</p><p>$\kappa$ $:$ $\{ (u,i)|$  $r_{ui}$ is known $\}$</p><p>$|\kappa|:$ 已知的所有评分总数</p><p>$\mu:$ 所有评分的均值</p><script type="math/tex; mode=display">\mu = \frac{\sum\limits_{(u,i) \in \kappa} r_{ui}}{|\kappa|}</script><p>$b_i:$ 物品 $i$ 的平均分与整体评分均值的偏差</p><script type="math/tex; mode=display">b_i = \frac{ \sum\limits_{u \in U_{(i)}}(r_{ui} - \mu) }{ |U_{(i)}| }</script><p>$b_u:$ 用户 $u$ 的平均分与整体评分均值的偏差</p><script type="math/tex; mode=display">b_u = \frac{ \sum\limits_{i \in I_{(u)}}(r_{ui} - \mu - b_i) }{ |I_{(u)}| }</script><p>$b_{ui}:$ A baseline estimate for an unknown rating</p><script type="math/tex; mode=display">b_{ui} = \mu + b_i + b_u</script><p>$\hat{r_{ui}}:$ 用户 $u$ 对物品 $i$ 的评分的预测值</p><p>$\lambda:$ 正则化系数</p><p>$\alpha:$ 学习速率(learning rate)</p><script type="math/tex; mode=display">\hat{r_{ui}} = b_{ui} + q_i^T p_u \quad (q_i,p_u \in R^f ，下同)</script><script type="math/tex; mode=display">C(q_i, p_u, b_u, b_i) =\frac{1}{2} \sum\limits_{(u,i) \in \kappa}\{(r_{ui} - \hat{r}_{ui})^2 + \lambda(||q_i||^2 + ||p_u||^2 + b_u^2 + b_i^2)\}</script><script type="math/tex; mode=display">||q_i||^2 = q_i^T q_i \quad ||p_u||^2 = p_u^T p_u</script><p><strong>By Stochastic Gradient Descent(SGD):</strong></p><script type="math/tex; mode=display">\begin{align}error &= r_{ui} - \hat{r}_{ui}\end{align}</script><script type="math/tex; mode=display">\begin{align} b_u :&= b_u - \triangledown C  \\  &= b_u - \alpha \frac{\partial C}{\partial b_u}  \\  &= b_u - \frac{\alpha}{2} (error\cdot(-2) + \lambda \cdot 2b_u)  \\  &= b_u + \alpha(error - \lambda \cdot b_u)\end{align}</script><script type="math/tex; mode=display">\begin{align} b_i :&= b_i - \triangledown C  \\  &= b_i - \alpha \frac{\partial C}{\partial b_i}  \\  &= b_i - \frac{\alpha}{2} (error\cdot(-2) + \lambda \cdot 2b_i)  \\  &= b_i + \alpha(error - \lambda \cdot b_i)\end{align}</script><script type="math/tex; mode=display">\begin{align} p_u :&= p_u - \triangledown C  \\  &= p_u - \alpha \frac{\partial C}{\partial p_u}  \\  &= p_u - \frac{\alpha}{2} (error\cdot(-2)\cdot q_i + \lambda \cdot 2p_u)  \\  &= p_u + \alpha(error \cdot q_i - \lambda \cdot p_u)\end{align}</script><script type="math/tex; mode=display">\begin{align} q_i :&= q_i - \triangledown C  \\  &= q_i - \alpha \frac{\partial C}{\partial q_i}  \\  &= q_i - \frac{\alpha}{2} (error\cdot(-2)\cdot p_u + \lambda \cdot 2q_i)  \\  &= q_i + \alpha(error \cdot p_u - \lambda \cdot q_i)\end{align}</script><p>此算法的主要是将 “特征” 作为连接物品与用户评分的桥梁。作者评分矩阵 R 拆分为了 user-factor matrix 和 item-factor matrix，而每个 matrix 都包含对 f 个特征的评分，只有两个矩阵对应的特征分数都大时，最终的评分才会大。比如，《阿凡达》在科幻的特征上高分，在喜剧的特征上低分，而用户 u 偏爱科幻片，所以他在科幻的特征上高，在喜剧的特征上低。这样预测用户 u 对《阿凡达》的总体评分就会高，而其他喜剧片的分就偏低。其中，因为 P Q 矩阵的未知，需要机器学习利用历史数据结合梯度下降来进行训练得出。具体推算过程可以参考有关 <a href="https://achlier.github.io/2022/03/07/MLE_and_MAP/#4-新知识应用于pmf的推算">MAP</a> 的笔记。</p><p>作者还提出了后续几点改进的方向。</p><p>一是添加 Implicit Feedback ，即那些非评分分数，而是需要处理的，类似于浏览记录，购买记录等额外的信息。作者将 $N(u)$ 定义为那些用户在Implicit Feedback中提供了的所有项。$x_i$ 为用户 u 在 Implicit Feedback 中对物品 i 的偏好。另一种 Implicit Feedback 指的是已知的用户属性，如人口统计，性别，年龄，收入水平等。这些数据被包括在集合 $A(u)$ 中，$y_a$ 是一个特殊的值来描述用户的属性。最终预测公式可变为</p><script type="math/tex; mode=display">\hat{r_{ui}} = b_{ui} + q_i^T[ p_u+|N(u)|^{-0.5}\sum_{i\in N(u)}x_i+\sum_{a\in A(u)}y_a]</script><p>另一种是考虑到时间的因素，因为人的兴趣爱好可能会随着时间而改变。因此变量从定值变成了一个与时间有关的函数</p><script type="math/tex; mode=display">\hat{r_{ui}} =\mu + b_i(t) + b_u(t) + q_i^T p_u(t)</script><p>最后，作者考虑到了同样的评分不一定值得同样的权重与信息，因为有些物品的高分可能是短时期的广告宣传的影响，而在回过头来看，其实并不是那么优秀。因此，作者以观看节目或者购买某个物品的频率 $c_{ui}$ 作为置信度，作为优化函数的改进。</p><script type="math/tex; mode=display">C(q_i, p_u, b_u, b_i) =\sum\limits_{(u,i) \in \kappa}c_{ui}(r_{ui} - \hat{r}_{ui})^2 + \lambda(||q_i||^2 + ||p_u||^2 + b_u^2 + b_i^2)</script><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>Resnick, P., Iacovou, N., Suchak, M., Bergstrom, P., &amp; Riedl, J. (1994). GroupLens: an open architecture for collaborative filtering of netnews. <em>CSCW ‘94</em>.</li><li>Sarwar, B.M., Karypis, G., Konstan, J.A., &amp; Riedl, J. (2001). Item-based collaborative filtering recommendation algorithms. <em>WWW ‘01</em>.</li><li>Koren, Y., Bell, R.M., &amp; Volinsky, C. (2009). Matrix Factorization Techniques for Recommender Systems. <em>Computer, 42</em>.</li></ol>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Recommender System</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】MLE and MAP</title>
    <link href="/2022/03/07/MLE_and_MAP/"/>
    <url>/2022/03/07/MLE_and_MAP/</url>
    
    <content type="html"><![CDATA[<blockquote><p>重新整理出来的推荐系统相关的资料，曾经在赵鹏飞老师指导下进行的学习，与 <a href="https://sddthree.github.io/">青梅煮茶</a> 同学合作完成。</p></blockquote><span id="more"></span><h1 id="1-MLE-amp-MAP"><a href="#1-MLE-amp-MAP" class="headerlink" title="1. MLE &amp; MAP"></a>1. MLE &amp; MAP</h1><h1 id="MLE"><a href="#MLE" class="headerlink" title="MLE"></a>MLE</h1><blockquote><p><strong>背景</strong>：极大似然估计方法（Maximum Likelihood Estimate，MLE）也称为最大概似估计或最大似然估计，是求估计的另一种方法，最大概似是1821年首先由德国数学家高斯（C. F. Gauss）提出，但是这个方法通常被归功于英国的统计学家罗纳德·费希尔（R. A. Fisher），他在1922年的论文《On the mathematical foundations of theoretical statistics, reprinted in Contributions to Mathematical Statistics》$^{[1]}$ 中再次提出了这个思想，并且首先探讨了这种方法的一些性质.极大似然估计这一名称也是费希尔给的。这是一种目前仍然得到广泛应用的方法。</p><p><strong>原理</strong>：极大似然估计是建立在极大似然原理的基础上的一个统计方法，极大似然原理的直观想法是，一个随机试验如有若干个可能的结果A，B，C，… ，若在一次试验中，结果A出现了，那么可以认为实验条件对A的出现有利，也即出现的概率 $ P(A) $ 较大。 若概率由系数 $ \theta $ 影响，我们便取能使 $ P(A) $ 达到最大的 $ \theta $ 的值。以下举例：</p></blockquote><p>假设总体X为离散型，其概率分</p><script type="math/tex; mode=display">P(X=x)=P(x:\theta)</script><p>其中 $\theta$ 为未知参数，设 $(X_{1},X_{2}…X_{n})$ 是取自总体的样本容量为n的样本，则它的联合分布律为 $\prod\limits_{i=1}^{n}P(x_{i}:\theta)$ 。又设一组观测值为 $(x_{1},x_{2}…x_{n})$ ，易知样本 $(X_{1},X_{2}…X_{n})$ 取到观测值 $(x_{1},x_{2}…x_{n})$ 的概率为：</p><script type="math/tex; mode=display">L(\theta)=L(x_{1},x_{2}...x_{n}:\theta)=\prod\limits_{i=1}^{n}P(x_{i}:\theta)</script><p>这一概率随 $\theta$ 的取值而变化，它是 $\theta$ 的函数，称 $L(\theta)$ 为样本的<strong>似然函数</strong>。</p><p>极大似然估计法原理就是固定样本观测值 $(x_{1},x_{2}…x_{n})$ ，挑选参数 $\theta$ 使</p><script type="math/tex; mode=display">L(x_{1},x_{2}...x_{n}:\hat{\theta})=maxL(x_{1},x_{2}...x_{n}:\theta)</script><p>这样得到的 $\hat{\theta}$ 与样本值有关，$\hat{\theta}(x_{1},x_{2}…x_{n})$ 称为参数 $\theta$ 的<strong>极大似然估计值</strong>。</p><h1 id="MAP"><a href="#MAP" class="headerlink" title="MAP"></a>MAP</h1><blockquote><p><strong>背景</strong>：在贝叶斯统计学中，最大后验估计(Maximum A Posteriori，MAP)可以利用经验数据获得对未观测量的点态估计。它与Fisher的最大似然估计(Maximum Likelihood，ML)方法相近，不同的是它扩充了优化的目标函数，其中融合了预估计量的先验分布信息，所以最大后验估计可以看作是正则化(regularized)的最大似然估计。</p><p><strong>原理</strong>：最大后验概率是在极大似然估计的基础上根据贝叶斯方法，引入参数的先验概率，结合似然度选择最佳参数或模型的方法。</p></blockquote><p>首先，假设 $\theta$ 的先验分布为 $g(\theta)$ 。通过贝叶斯理论，对于 $\theta$ 的后验分布如下式所示：</p><script type="math/tex; mode=display">f( \theta| x )=\frac{f(x|\theta)g(\theta)}{\int_{-\infty}^{+\infty}f(x|\theta^{\prime})g(\theta^{\prime})d\theta^{\prime}}</script><p>最后验分布的目标为：</p><script type="math/tex; mode=display">L(\theta)=arg\max_{\theta} \frac{f(x|\theta)g(\theta)}{\int_{-\infty}^{+\infty}f(x|\theta^{\prime})g(\theta^{\prime})d\theta^{\prime}}=arg\max_{\theta} f( \theta| x )</script><p>其中我们称  $g(\theta)$ 为 prior（<strong>先验概率</strong>），$f( \theta| x )$ 为 posterior（<strong>后验概率</strong>）， 当先验概率与后验概率有共同形式的分布时，我们称 $g(\theta)$ 为 conjugate prior（<strong>共轭先验</strong>）。</p><h1 id="2-MAP运用于正则化的理解"><a href="#2-MAP运用于正则化的理解" class="headerlink" title="2. MAP运用于正则化的理解"></a>2. MAP运用于正则化的理解</h1><h3 id="原始的Linear-Regression"><a href="#原始的Linear-Regression" class="headerlink" title="原始的Linear Regression"></a>原始的Linear Regression</h3><p>假设有若干数据 $(x_{1},y_{1}),(x_{2},y_{2}),…,(x_{m},y_{m})$，我们要对其进行线性回归。也就是得到一个方程 :</p><script type="math/tex; mode=display">y=\omega^{T}x+\epsilon</script><p>$\epsilon$ 可以认为是，我们拟合的值和真实值之间的误差 ($ y - \hat{y}$) 。<br>我们将 $\epsilon$ 看成是一个随机变量，其服从高斯分布，即 $p(\epsilon)=N(0,\sigma^{2})p(\epsilon)=N(0,\sigma^{2})$ ，即：</p><script type="math/tex; mode=display">p(\epsilon_{i})=\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{\epsilon_{i}^{2}}{2\sigma^{2}})</script><p>则对于每一个数据点 $(x_{i},y_{i})$ ，我们用 $x_{i}$ 得到 $y_{i}$ 的概率为 :</p><script type="math/tex; mode=display">p(y_{i}|x_{i}:\omega)=\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y_{i}-\omega^{T}x_{i})^{2}}{2\sigma^{2}})</script><p>如果我们想要让这个概率最大，就得到了最大似然 :</p><script type="math/tex; mode=display">\begin{align}L(\omega)&=\prod\limits_{i=1}^{m} p(y_{i}|x_{i}:\omega)\\&=\prod\limits_{i=1}^{m} \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y_{i}-\omega^{T}x_{i})^{2}}{2\sigma^{2}})\end{align}</script><p>取对数 :</p><script type="math/tex; mode=display">\begin{align}logL(\omega)&=log\prod\limits_{i=1}^{m} \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y_{i}-\omega^{T}x_{i})^{2}}{2\sigma^{2}})\\&=\sum\limits_{i=1}^{m}log\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y_{i}-\omega^{T}x_{i})^{2}}{2\sigma^{2}})\\&=mlog\frac{1}{\sqrt{2\pi}\sigma}-\frac{1}{2\sigma^{2}}\sum\limits_{i=1}^{m}(y_{i}-\omega^{T}x_{i})^{2}\end{align}</script><p>由上式可以看出，最大化对数似然，也就是最小化均方误差。即 :</p><script type="math/tex; mode=display">\omega^{*}=arg\min_{\omega}\sum\limits_{i=1}^{m}(y_{i}-\omega^{T}x_{i})^{2}</script><p>这样， 就从最大似然的角度解释了均方误差。</p><h3 id="对-omega-引入高斯先验分布"><a href="#对-omega-引入高斯先验分布" class="headerlink" title="对 $\omega$ 引入高斯先验分布"></a>对 $\omega$ 引入高斯先验分布</h3><p>如果我们对 $\omega$ 引入高斯先验分布，也就是说 :</p><script type="math/tex; mode=display">p(\omega_{j})=\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{\omega_{j}^{2}}{2\sigma^{2}})</script><p>这样, $L(\omega)$ 的式子就变为：</p><script type="math/tex; mode=display">\begin{align}L(\omega)&=p(\omega)\prod\limits_{i=1}^{m} p(y_{i}|x_{i}:\omega)\\&=\prod\limits_{j=1}^{n}\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{\omega_{j}^{2}}{2\sigma^{2}})\prod\limits_{i=1}^{m} \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y_{i}-\omega^{T}x_{i})^{2}}{2\sigma^{2}})\\&=(\frac{1}{\sqrt{2\pi}\sigma})^{n}exp(-\frac{\sum_{j=1}^{n}\omega_{j}^{2}}{2\sigma^{2}})\prod\limits_{i=1}^{m} \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y_{i}-\omega^{T}x_{i})^{2}}{2\sigma^{2}})\\&=(\frac{1}{\sqrt{2\pi}\sigma})^{n}exp(-\frac{\omega^{T}\omega}{2\sigma^{2}})\prod\limits_{i=1}^{m} \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y_{i}-\omega^{T}x_{i})^{2}}{2\sigma^{2}})\end{align}</script><p>取对数:</p><script type="math/tex; mode=display">\begin{align}logL(\omega)&=log[(\frac{1}{\sqrt{2\pi}\sigma})^{n}exp(-\frac{\omega^{T}\omega}{2\sigma^{2}})\prod\limits_{i=1}^{m} \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y_{i}-\omega^{T}x_{i})^{2}}{2\sigma^{2}})]\\&=mlog\frac{1}{\sqrt{2\pi}\sigma}+nlog\frac{1}{\sqrt{2\pi}\sigma}-\frac{1}{2\sigma^{2}}\sum\limits_{i=1}^{m}(y_{i}-\omega^{T}x_{i})^{2}-\frac{\omega^{T}\omega}{2\sigma^{2}}\end{align}</script><p>最大化对数似然函数，就等价于：</p><script type="math/tex; mode=display">\omega^{*}=argmin_{\omega}\sum\limits_{i=1}^{m}(y_{i}-\omega^{T}x_{i})^{2}+\lambda \parallel \omega^{T}\omega \parallel</script><p>也就是说，为参数 $\omega$ 引入高斯先验分布的最大似然，相当于给均方误差函数加上正则项。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><blockquote><p>之所以推导这些，是向给解释正则化找个理由。有了贝叶斯的这种方式，我们可以说，引入先验分布是降低了模型的复杂度，或者说是拉普拉斯分布进行了一定的特征选择，而高斯分布式对不重要的特征进行了抑制。另外，还可以说是，在 $\omega$ 的空间搜索时，先验分布缩小了解空间，这样对求解速度也有好处。</p></blockquote><h1 id="3-多元高斯分布回顾"><a href="#3-多元高斯分布回顾" class="headerlink" title="3. 多元高斯分布回顾"></a>3. 多元高斯分布回顾</h1><p>如果一个n维随机变量 $X=[X_{1}…X_{n}]^{T}$ 服从多元正态分布，均值为 $\mu \in \Re^{n}$, 协方差矩阵为 $\Sigma$ ,它的概率密度公式为:</p><script type="math/tex; mode=display">p(x:\mu,\Sigma)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp(-\frac{1}{2}(x-\mu)^{T}\Sigma^{-1}(x-\mu))</script><p>我们把这个写作 $X \sim N(\mu,\Sigma)$ ，其中 $\Sigma$ 为:</p><script type="math/tex; mode=display">\Sigma=E[(X-\mu)(X-\mu)^{T}]=E[XX^{T}]-\mu\mu^{T}</script><h1 id="4-新知识应用于pmf的推算"><a href="#4-新知识应用于pmf的推算" class="headerlink" title="4. 新知识应用于pmf的推算"></a>4. 新知识应用于pmf的推算</h1><p>传统的协同过滤方法既不能处理大数据量的推荐，也不能处理只有很少评分的用户。而 Salakhutdinov 的论文 《Probabilistic matrix factorization》$^{[5]}$ 提出了著名的概率矩阵分解的方法来解决这个问题。具体如下：</p><p>假设有 $M$ 个电影和 $N$ 个用户。 $R_{ij}$ 表示第 $i$ 个用户对电影 $j$ 的评分。假设隐变量的维度是 $D$ ，那么我们希望将评分矩阵 $R$ 分解成两个矩阵，即用户隐矩阵 $U\in R^{D\times N}$ ，和电影隐矩阵 $V\in R^{D\times M}$ 。其中， $U_{i}$ 表示第 $i$ 个用户的隐向量， $V_{j}$ 表示第 $j$ 个电影的隐向量。假设评分是一个有高斯噪音的正态分布。那么我们的评分应当有如下公式：</p><script type="math/tex; mode=display">p(R|U,V,\sigma^{2})=\prod\limits_{i=1}^{N}\prod\limits_{j=1}^{N}[N(R_{ij}|U_{i}^{T}V_{j},\sigma^{2})]^{I_{ij}}</script><p>这里的 $N(R_{ij}|U_{i}^{T}V_{j},\sigma^{2})$ 是指高斯分布的概率密度函数。$I_{ij}$ 是指示函数，表明如果用户 $i$ 评论了电影 $j$ ，那么其结果等与1，否则就是0。因此，上面的结果就是所有已经被评论的电影得分的乘积，也就是似然函数了。</p><p>我们给每个用户和电影的隐向量（特征向量）一个均值为0的高斯先验。有：</p><script type="math/tex; mode=display">p(U|\sigma^{2}_{U})=\prod\limits_{i=1}^{N}N(U_{i}|0,\sigma_{U}^{2}I)</script><script type="math/tex; mode=display">p(V|\sigma^{2}_{V})=\prod\limits_{j=1}^{M}N(V_{j}|0,\sigma_{V}^{2}I)</script><p>这里的I是一个D维单位对角矩阵。那么，用户和电影特征的后验分布计算如下：</p><script type="math/tex; mode=display">\begin{align}p(U,V|R,\sigma^{2},\sigma^{2}_{V},\sigma^{2}_{U})&=\frac{p(R|U,V,\sigma^{2},\sigma^{2}_{V},\sigma^{2}_{U})\times p(U,V)}{p(R,\sigma^{2},\sigma^{2}_{V},\sigma^{2}_{U})}\\&\sim p(R|U,V,\sigma^{2},\sigma^{2}_{V},\sigma^{2}_{U})\times p(U,V)\\&=p(R|U,V,\sigma^{2},\sigma^{2}_{V},\sigma^{2}_{U})\times p(U)\times p(V)\\&=\prod\limits_{i=1}^{N}\prod\limits_{j=1}^{M}[N(R_{ij}|U_{i}^{T}V_{j},\sigma^{2})]^{I_{ij}}\times \prod\limits_{i=1}^{N}N(U_{i}|0,\sigma_{U}^{2}I) \times \prod\limits_{j=1}^{M}N(V_{j}|0,\sigma_{V}^{2}I)\end{align}</script><p>对两边取个ln（这是我们求解中常用的方法，取ln不改变函数凹凸性，极值点位置也不便，所以最优点的解也是一样的，同时，乘积形式变成求和形式，也简单很多）。</p><script type="math/tex; mode=display">lnp(U,V|R,\sigma^{2},\sigma^{2}_{V},\sigma^{2}_{U})=\sum\limits_{i=1}^{N}\sum\limits_{j=1}^{M}I_{ij}lnN(R_{ij}|U_{i}^{T}V_{j},\sigma^{2})+\sum\limits_{i=1}^{N}lnN(U_{i}|0,\sigma_{U}^{2}I)+\sum\limits_{j=1}^{M}lnN(V_{j}|0,\sigma_{V}^{2}I)</script><p>上面这三项都是形式完全一样，只是系数和均值方差不同，我们以其中一个为例，剩下都一样。即求解:</p><script type="math/tex; mode=display">lnN(U_{i}|0,\sigma^{2}_{U}I)</script><p>我们给出用户i的概率密度函数：</p><script type="math/tex; mode=display">N(U_{i}|0,\sigma_{U}^{2}I)=-\frac{1}{(2\pi)^{D/2}|\sigma_{U}^{2}I|^{1/2}}exp(-\frac{1}{2}U_{i}^{T}(\sigma_{u}^{2}I)^{-1}U_{i})</script><p>注意，由于 $I$ 是对角阵，那么 $(\sigma_{u}^{2}I)^{-1}=\frac{1}{\sigma_{u}^{2}}I$ ，所以：</p><script type="math/tex; mode=display">\begin{align}lnN(U_{i}|0,\sigma_{U}^{2}I)&=ln(-\frac{1}{(2\pi)^{D/2}|\sigma_{U}^{2}I|^{1/2}})-\frac{U_{i}^{T}U_{i}}{2\sigma_{u}^{2}}\\&=-ln(|\sigma_{U}^{2}I|^{1/2})-\frac{U_{i}^{T}U_{i}}{2\sigma_{u}^{2}}+C_{U}\\&=-\frac{1}{2}ln(\sigma_{U}^{2D})-\frac{U_{i}^{T}U_{i}}{2\sigma_{u}^{2}}+C_{U}\\&=-\frac{D}{2}ln(\sigma_{U}^{2})-\frac{U_{i}^{T}U_{i}}{2\sigma_{u}^{2}}+C_{U}\end{align}</script><p>类似地，我们可以得到进而我们可以得到最终的公式。公式如下：</p><script type="math/tex; mode=display">lnp(U,V|R,\sigma^{2},\sigma^{2}_{V},\sigma^{2}_{U})=-\frac{1}{2\sigma^{2}}\sum\limits_{i=1}^{N}\sum\limits_{j=1}^{M}I_{ij}(R_{ij}-U_{i}^{T}V_{j})^{2}-\frac{1}{2\sigma_{U}^{2}}\sum\limits_{i=1}^{N}U_{i}^{T}U_{i}-\frac{1}{2\sigma_{V}^{2}}\sum\limits_{j=1}^{M}V_{j}^{T}V_{j}-\frac{1}{2}((\sum\limits_{i=1}^{N}\sum\limits_{j=1}^{M}I_{ij})ln\sigma^{2}+NDln\sigma_{U}^{2}+MDln\sigma_{V}^{2})+C</script><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p>[1].<a href="https://royalsocietypublishing.org/cgi/doi/10.1098/rsta.1922.0009">R.A.Fisher (1950) <em>On the mathematical foundations of theoretical statistics, reprinted in Contributions to Mathematical Statistics</em> J.Wiley&amp;Sons New York</a></p><p>[2].<a href="https://blog.csdn.net/u014433413/article/details/78408983">Chester-zZz （2017） <em>从贝叶斯角度理解正则化缓解过拟合</em> CSDN</a></p><p>[3].<a href="http://cs229.stanford.edu/section/gaussians.pdf">Chuong B.Do （2018） <em>The Multivariate Gaussian Distribution</em></a></p><p>[4].<a href="https://blog.csdn.net/df19900725/article/details/78222076">数据学习（Datalearner） （2017） <em>推荐系统之概率矩阵分解的详细推导过程</em> CSDN</a></p><p>[5].<a href="https://github.com/hongleizhang/RSPapers/blob/master/02-Classical%20RS/2008-Probabilistic%20Matrix%20Factorization.pdf">Salakhutdinov (2008) <em>Probabilistic matrix factorization</em></a></p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Maximum Likelihood Estimate</tag>
      
      <tag>Maximum A Posteriori</tag>
      
      <tag>Probabilistic matrix factorization</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【课程】金融经济学二十五讲</title>
    <link href="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/"/>
    <url>/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于北大金融经济学公开课《金融经济学二十五讲》的笔记，此课程特别值得作为经济学入门，而有过基础的朋友也推荐阅读，适合对知识进行一个系统的梳理和扩充！</p></blockquote><span id="more"></span><h1 id="第-1-讲-金融经济学导论"><a href="#第-1-讲-金融经济学导论" class="headerlink" title="第 1 讲 金融经济学导论"></a>第 1 讲 金融经济学导论</h1><h3 id="1-什么是金融和金融经济学？"><a href="#1-什么是金融和金融经济学？" class="headerlink" title="1. 什么是金融和金融经济学？"></a>1. 什么是金融和金融经济学？</h3><ul><li>Financial economics: allocation of <strong>financial assets</strong><ul><li>Financial assets : 一种契约</li><li>Assets : claims of <strong>future</strong> economics benefit<ul><li>Future : 跨期的，在现在与未来交换资源，存在风险 (Risk)</li></ul></li></ul></li></ul><blockquote><p>货币的发行、流通和回笼，贷款的发放和收回，存款的存入和提取，汇兑的往来等经济活动属于货币经济学 (monetary economics)，是宏观经济学 (macroeconomics) 的一种分支</p></blockquote><h3 id="2-金融经济学的主要内容"><a href="#2-金融经济学的主要内容" class="headerlink" title="2. 金融经济学的主要内容"></a>2. 金融经济学的主要内容</h3><script type="math/tex; mode=display">\begin{matrix}& \text{Investment (Price)} &\\\text{Fund suppliers} & \rightleftharpoons & \text{Funds demenders}\\(\text{Asset buyers}) & \text{Return} & (\text{Asset sellers})\\\end{matrix}</script><ul><li><p>Supply and demand derived from human behavior (dynamic, uncertainty)</p><blockquote><p>对需求方单位为公司时，相关知识为 Corporates finance</p></blockquote><ul><li>Equilibrium pricing (Absolute pricing)</li><li>No-Arbitrage pricing</li><li>Financial frictions<ul><li>Maturity mismatch</li><li>信息不对称</li></ul></li></ul></li><li><p>Market efficiency - Fama 尤金·法马</p><ul><li>vs Shiller 罗伯特·席勒<ul><li>Behavior finance : irrationality, limited arbitrage</li></ul></li></ul></li></ul><blockquote><p>当年的诺贝尔经济学奖还颁给了汉森 (Lars Peter Hansen)，以表彰他发展了广义矩估计 (GMM) 这种计量方法的成就。GMM 方法可被用来检验资产价格是否有效。所以可以玩笑地说 2013 年诺贝尔经济学奖被颁给了一个相信有效市场的人，一个不信有效市场的人，以及一个检验市场是否有效的人。</p></blockquote><script type="math/tex; mode=display">E[\tilde{r}]=\frac{E[\tilde{X}]}{P}-1</script><ul><li>资产的期望回报率等于资产的期望支付除以其当前价格再减 1</li><li>资产当前价格越高，期望回报率越低。</li></ul><h4 id="例子1-圣彼得堡悖论（St-Petersburg-Paradox）"><a href="#例子1-圣彼得堡悖论（St-Petersburg-Paradox）" class="headerlink" title="例子1 : 圣彼得堡悖论（St. Petersburg Paradox）"></a>例子1 : 圣彼得堡悖论（St. Petersburg Paradox）</h4><p>假设有这么一个抛硬币的赌局。第 1 次抛硬币，如果出现正面，赢 1 块钱，赌局结束。如果出反面，则不输也不赢，再继续抛第 2 次。第 2 次如果抛出正面，赢 2 块钱，赌局结束。如果还是出反面，仍然不输不赢，再抛第 3 次。如此继续，只要没有抛到正面，就一直抛下去，直到出现正面为止。期间抛出反面都是不输不赢，但如果是第 <em>n</em> 次抛出正面，则赢 $2^{n-1}$ 块钱。请问在这个赌局中赌徒的期望收益是多少？你愿意为参与这个赌局支付多高的门票钱？</p><script type="math/tex; mode=display">\frac12\times 1+\frac14\times 2+...+\frac1{2^n}\times 2^{n-1}+...=+\infty</script><ul><li>但并没有考虑Risk</li><li>风险大的资产需要给予更大的因为风险而增加的期望回报率-<strong>风险溢价</strong>（risk premium）</li><li>效用并不随收益的增加而线性增加，存在边际效益递减的现象。贝努利用对数效用来衡量人从某一收益中得到的效用。这样一来，这个赌局带来的期望效用就是</li></ul><script type="math/tex; mode=display">\sum_{t=1}^\infty(\frac12)^t·ln(2^{t-1})=ln2\sum_{t=1}^\infty(\frac12)^t·(t-1)=ln2</script><h4 id="例子2"><a href="#例子2" class="headerlink" title="例子2"></a>例子2</h4><p>假设一家药品研发公司和一家钢铁公司的股票有相同的期望（红利）支付。但因为药品研发不确性很高，药品研发公司红利支付的波动性会更大。在这两家公司中，当前哪家的股票价格应该更高？</p><p>药品公司的分红波动确实更大，但这就说明药品公司风险更大了吗？在对风险的本质有更深刻认识后，我们就能知道其实相对而言，药品公司风险更小。风险主要关注的是 $\beta$ 值</p><h4 id="例子3"><a href="#例子3" class="headerlink" title="例子3"></a>例子3</h4><p>假设有甲和乙两个基金经理。在过去 3 年中，甲的投资回报率比乙更高，而且甲的回报率的波动也比乙更小，可不可说甲比乙更优秀？</p><p>必须考虑甲乙投资的领域，甲可能专注于蓝筹股，蓝筹股总体回报比普通股高。</p><h1 id="第-2-讲-金融市场概览"><a href="#第-2-讲-金融市场概览" class="headerlink" title="第 2 讲 金融市场概览"></a>第 2 讲 金融市场概览</h1><h3 id="1-金融市场的功能"><a href="#1-金融市场的功能" class="headerlink" title="1. 金融市场的功能"></a>1. 金融市场的功能</h3><p>金融市场（financial market）是通过交易金融资产来实现资金融通的市场机制</p><p><strong>三大功能</strong></p><ol><li>流动性 (Liquidity)</li><li>价格发现 (Price discovery)/ 信息透明</li><li>便利，降低成本</li></ol><h3 id="2-金融市场的分类"><a href="#2-金融市场的分类" class="headerlink" title="2. 金融市场的分类"></a>2. 金融市场的分类</h3><ul><li><p>按交易资产的特性</p><ul><li>权益市场 (equity market) - 股票市场</li><li>固定收益市场 (fixed-income market)</li></ul><blockquote><p>金融资产大致分为 : </p><ol><li>权益工具 (equity instrument) - 股票 (stock)</li><li>债务工具 (debt instrument) - 债券 (bond) </li></ol><p>股票市场和债券市场<strong>市值</strong>差不多，但股票的<strong>社会融资总量</strong> (total social financing) 远远低于债券</p></blockquote></li><li><p>按交易和发行的先后关系</p><ul><li><p>一级市场 (primary market) </p><blockquote><p>证券发行需要<strong>投资银行家</strong> (investment banker) 这种专业人士来协助。相关的证券发行业务便叫做投资银行业务。<strong>投资银行</strong> (investment bank) ，也叫做<strong>证券公司</strong> (security firm) ，就是专门从事这种业务的金融机构。在当前金融混业经营的大潮下，商业银行 (commercial bank) 也能从事投资银行业务</p></blockquote><ul><li><p>公开发行 (IPO/ public offering)，私募发行 (private placement)</p><blockquote><p>但因为证券发行给大量公众后影响比较大，所以监管者对发行主体的经营状况和信息披露有较高要求。而私募则是向数量有限的特定投资者（往往是经验丰富的机金融经济学构投资者）发行证券的方式。私募发行的<strong>门槛较低</strong>，但能够筹集的<strong>资金量相对较小</strong>。</p></blockquote></li></ul></li><li><p>二级市场 (secondary market)</p></li></ul></li><li><p>按交易分割时间</p><ul><li><p>现货市场 (spot market)</p></li><li><p>衍生品市场 (derivative market)</p><blockquote><p>衍生品的过度发展是 2008 年次贷危机 (Subprime Crisis) 发生的一个重要原因。</p></blockquote></li></ul></li><li><p>其他分类方式</p><ul><li>货币市场 (money market) 和资本市场 (capital market)<ul><li>短于一年-货币市场，长于一年-资本市场</li></ul></li><li>交易所市场 (exchange market) 和场外交易市场 (OTC)<ul><li>最大的场外交易市场-银行间市场</li><li>协商进行</li></ul></li></ul></li></ul><h3 id="3-主要金融机构"><a href="#3-主要金融机构" class="headerlink" title="3.主要金融机构"></a>3.主要金融机构</h3><ul><li><p>存款类金融机构 (银行) - 中农工建交</p><blockquote><p>商业银行的放贷能力主要受到两方面因素的影响</p><ul><li>第一，其手中握有的基础货币 （种子) 有多少</li><li>第二，给定手中的基础货币，商业银行放贷的能力有多大。这是由<strong>存款准备金率</strong> (required reserve ratio) 决定的</li></ul><p>如果减少基础货币数量，或升高存款准备金率，就能减少全社会货币总量。由于中央银行的重要任务就是调控全社会货币总量，所以中央银行还被称为<strong>货币当局</strong> (monetary authority)</p><p>从 2010 年开始，宏观政策逐步转向紧缩，对信贷投放的控制越来越严。在这种情况下，许多银行利用信托的通道，将之前的贷款转换为信托产品，从而规避监管者对信贷投放的管控。在这样的背景下，信托业务得到了大发展，规模高速跃进。但这也带来了影子银行 (shadow banking) 的风险</p><p>银行信贷是一种债权型的融资，并不适合所有非金融企业的融资需求。比如，新兴的成长性公司就更需要股权型融资的支持</p></blockquote></li><li><p>非存款类金融机构 : 证券公司，保险公司，信托公司，基金公司</p><ul><li><p>两高一剩行业：两高行业指高污染、高能耗的资源性的行业；一剩行业即产能过剩行业。主要包括钢铁、造纸、电解铝、平板玻璃。</p></li><li><p>两高一剩行业贷款被约束，通常会找证券公司放贷款</p><blockquote><p>证券公司 (简称券商) 也叫做投资银行，其主要功能是帮助证券发行者发行证券。换言之，证券公司干的就是把各种经济利益包装成金融资产出售。正因为此，证券公司也被叫做卖方（sell side）。基金公司、保险公司、养老金、主权基金是常见的买方机构。基金公司向广大公众募集资金，进而投资到金融市场中。</p><p>与基金公司相同，信托公司也是向外募集资金来投资。但信托公司募集来的资金的投向更广（基金公司主要投资于股票债券市场）。且信托公司能够做到破产隔离。某人如果将其资金投入到一个信托计划中，即使这人破产了，其信托计划中的资产也不会被清算。信托公司在一定程度上成为了其他金融机构（主要是银行）规避监管的手段。</p></blockquote></li></ul></li><li><p>金融监管机构</p><ul><li><p>人民银行</p></li><li><p>中国银行业监督管理委员会</p></li><li><p>中国银行保险监管委员会</p></li><li><p>中国证券监督管理委员会</p></li><li><p>行业协会</p></li><li><p>交易所</p><blockquote><p>2018年两会期间,根据公布的国务院机构改革方案,银监会与保监会职责整合组建中国银行保险监督管理委员会,简称银保监会,与中国人民银行、证监会合称”一行两会”</p></blockquote></li></ul></li></ul><h3 id="附录-A-真实世界中的货币创造过程"><a href="#附录-A-真实世界中的货币创造过程" class="headerlink" title="附录 A. 真实世界中的货币创造过程"></a>附录 A. 真实世界中的货币创造过程</h3><p><strong>A.1 货币的创造</strong></p><p>按照流动性的差异在不同的口径上统计货币的总量。最常用的口径是 M0、M1 (狭义货币) 和 M2 (广义货币)</p><ul><li>M0=流通中的货币</li><li>M1=M0+企业活期存款</li><li>M2=M1+企业定期存款+居民储蓄存款 (包括活期和定期)</li></ul><blockquote><p>央行所发行的货币<strong>只</strong>是直接投放给金融机构（主要是商业银行）。这里央行发行的货币被称为<strong>“基础货币”</strong> (base money) ，或者<strong>“高能货币”</strong> (high-powered money)。在中国金融统计体系中（也是 IMF 的数据统计体系中），基础货币对应着<strong>“储备货币”</strong> (reserve money) 这个统计口径。</p><p>商业银行通过以以基础货币数倍的规模向非金融企业和居民发放贷款创造货币。商业银行能够以基础货币多少倍的规模向外发放贷款，被称为<strong>“货币乘数”</strong>（monetary multiplier）。货币乘数高度受到央行所设定的存款准备金率的影响</p><p>所谓基础货币，其实就是商业银行（或其他金融机构）在中央银行的存款。但与个人与企业在银行的存款不一样，银行在央行的存款要分成两部分，其中一部分是央行规定的不可动用的部分，叫做<strong>“法定存款准备金”</strong> (required deposit reserve) ，另一部分银行可以自由使用，叫做<strong>“超额存款准备金”</strong> (excess reserve)。法定存款准备金是央行规定的，商业银行应该为其存款准备的备付金。法定存款准备金与存款之间的比例叫做<strong>“法定存款准备金率”</strong> (required reserve ratio，简称 RRR)</p></blockquote><p>如果央行设定的超额存款准备金率是 RRR，那么银行用规模为 H 的超额存款准备金能够发放的贷款总额就是如下等比数列之和</p><script type="math/tex; mode=display">H+(1-RRR)H+(1-RRR)^2H+...=\frac H{RRR}</script><p>其中的 $\frac 1{RRR}$ 就是货币乘数</p><h1 id="第-3-讲-利率及债券价值分析"><a href="#第-3-讲-利率及债券价值分析" class="headerlink" title="第 3 讲 利率及债券价值分析"></a>第 3 讲 利率及债券价值分析</h1><h3 id="1-真实世界中的利率"><a href="#1-真实世界中的利率" class="headerlink" title="1. 真实世界中的利率"></a>1. 真实世界中的利率</h3><p><strong>我国的几种代表性利率</strong></p><ul><li><p>银行间AA债券收益率</p></li><li><p>十年期国债收益率 (长期基准利率)</p></li><li><p>银行间7天回购利率</p></li><li><p>1年期定存基准利率</p><blockquote><p>这些债券收益率与无风险利率之间的差异就是<strong>信用利差</strong> (credit spread)，也可广义地叫做<strong>风险溢价</strong> (risk premium) 。市场中有专门的评级机构 (rating agency) 基于债券本身及发债主体的状况来做信用评级 (credit rating)</p><p>在我国国内，长期债券的最高信用评级是 AAA。AA 的债券收益率是一个较有代表性的风险利率。在国内，一个债券的评级如果低于 AA，愿意投资的机构数量就会大大下降。</p></blockquote></li></ul><h3 id="2-计息习惯"><a href="#2-计息习惯" class="headerlink" title="2. 计息习惯"></a>2. 计息习惯</h3><ul><li><p>Simple interest (单利) : 利息不计入本金 $A=(1+nr)$</p></li><li><p>Compound interest (复利) $A(1+r)^n$</p><ul><li>Compound m times per year $A(1+r/m)^{nm}$</li></ul></li><li><p>Continuous compounding $Ae^{nr}$</p></li></ul><blockquote><p>在计算利率时，有个叫“72 法则”的简单经验法则很好用。它说的是，在每年复利一次的情况下，如果需要知道多少年可以把本金翻番，只需要用 72 除以年利率，得到的商即是所求。举个例子，如果年利率是 6%。由于 72/6=12，所以只需要 12 年就能把本金翻番。如果年利率是 9%而非 6%，则本金翻番的年数就变成 8 年（=72/9）。这是一个近似法则，但多数情况下够用了。</p></blockquote><h3 id="3-金融决策"><a href="#3-金融决策" class="headerlink" title="3. 金融决策"></a>3. 金融决策</h3><ul><li><p>Net Present Value (NPV) : 全部现金流折算到现在</p></li><li><p>Internal Rate of Return (IRR) : 使得NPV为0的利率, 项目回报率</p><blockquote><p>内部收益率是对项目现金流状况的一个描述指标，与市场利率不是一回事。</p></blockquote></li><li><p>Reinvestment Risk : 需要确保产生的利息再投资能有和之前相同的利率</p><ul><li>在实业投资项目内可以忽略，因为利息能很快投入生产</li><li>债券再投资风险不可忽略</li></ul></li></ul><h3 id="4-Bond-Analysis-Government-Bond"><a href="#4-Bond-Analysis-Government-Bond" class="headerlink" title="4. Bond Analysis (Government Bond)"></a>4. Bond Analysis (Government Bond)</h3><ul><li><p>分析的第一指标 - Yield to Maturity 类似IRR</p></li><li><p>Bond price 会受到市场利率的影响</p></li><li><p>期限长，折现率 - 即期利率 (Spot rate) 高，因为市场预计未来利率会上升</p></li><li><p>计算 Bond price 时使用 Yield 通过 Bootstrap method 算 Spot</p></li><li><p>久期 (Duration) 决定了对市场利率变动的敏感性</p><ul><li><p>$D=\sum_{t=1}^nt_i[\frac{c_ie^{yt_i}}P]$</p></li><li><p>$\frac{\Delta P}P=-D·\Delta y$ </p></li><li><p>如果一年复利m次，修正久期 (modified duration) $D^*=\frac D{1+y/m}$ </p></li><li><p>$\frac{\Delta P}P=-D^*·\Delta y$</p><blockquote><p>如果利率变化的幅度较大，那就需要用到二阶甚至更高阶近似了。债券的曲率 (convexity) 就是用来做二阶近似的</p><p>如果投资者预期利率水平会上升，就缩短自己组合的久期（卖出长<br>债）以减少组合价值下跌的幅度。而如果投资者预期利率水平会下降，就拉长自己组合的久期（买入长债），以尽可能多地享受利率下降带来的债券价格上升的好处。</p></blockquote></li></ul></li></ul><h1 id="第-4-讲-股票价值分析"><a href="#第-4-讲-股票价值分析" class="headerlink" title="第 4 讲 股票价值分析"></a>第 4 讲 股票价值分析</h1><ul><li>Stock : Residual claim 剩余索取权</li></ul><blockquote><p>股票分成普通股 (common stock) 和优先股 (preferred stock)。优先股是一种承诺了固定股息回报，并在参与企业经营方面权力小于普通股的特殊股票。在我们这门课涉及到股票的时候，如未特别说明，指的都是普通股。</p></blockquote><ul><li>股票的贴现率一定比无风险利率高</li></ul><h3 id="1-股利贴现模型（dividend-discount-model，DDM）"><a href="#1-股利贴现模型（dividend-discount-model，DDM）" class="headerlink" title="1. 股利贴现模型（dividend discount model，DDM）"></a>1. 股利贴现模型（dividend discount model，DDM）</h3><ul><li>分红量 $D_t$</li><li>除红利价格 (ex-dividend price) : 分红后股价 $S_t$</li></ul><script type="math/tex; mode=display">S_0=\frac{D_1+S_1}{1+r}=\sum^{\infty}_{t=1}\frac{D_t}{(1+r)^t}+\lim_{t\to\infty}\frac{S_t}{(1+r)^t}=\sum^{\infty}_{t=1}\frac{D_t}{(1+r)^t}</script><ul><li><p>省略部分的假设叫做<strong>横截性条件</strong> (transversality condition)，又被叫做无泡沫条件 (no-bubble condition)。</p></li><li><p>假设 $D_t=D_1(1+g)^{t-1}$，且 $g&lt;r$，得到<strong>戈登增长模型</strong></p></li></ul><blockquote><p>这是因为 g 是红利预期中的平均增长速率。而实际中的红利增速应该会围绕这一预期的平均增速上下波动，存在不确定性。于是，市场将红利贴现回来的贴现率就应该高于 g，以获取风险补偿。</p></blockquote><script type="math/tex; mode=display">S_0=\sum^{\infty}_{t=1}\frac{D_1(1+g)^{t-1}}{(1+r)^t}=\frac{D_1}{1+g}[\frac{1+g}{1+r}/(1-\frac{1+g}{1+r})]=\frac{D_1}{r-g}</script><ul><li>当使用戈登增长模型后，两期间的回报率固定为 r</li></ul><h3 id="2-股票市盈率"><a href="#2-股票市盈率" class="headerlink" title="2. 股票市盈率"></a>2. 股票市盈率</h3><p>市盈率是市价盈利比率 (price earnings ratio) 的简称，也叫做 P/E ratio。市盈率是股票价格与每股盈利之比。</p><script type="math/tex; mode=display">D_t=kE_t</script><ul><li>t 时期股票每股盈利 $E_t$</li></ul><p>代入戈登增长模型</p><script type="math/tex; mode=display">\frac{S_0}{E_1}=\frac k{r-g}</script><ul><li>公司盈利增速预期的微小改变都会带来股价的大幅度变化</li></ul><blockquote><p>实际的市盈率有几种不同的计算方法。如果用最近 12 个月的累积利润来计算，可得到滚动市盈率（或者叫做市盈率 TTM，英文名 trailing P/E）</p><p>还有一种市盈率计算方法是用当前股价除以未来 12 个月盈利的预测数。这叫做动态市盈率（forward P/E）。</p><p>除了各种市盈率指标外，还有市净率（price-to-book ratio，简称 P/B）——股票价格与每股净资产之间的比率，市销率（price-to-sales ratio，简称 P/S）——股票价格与每股销售额之间的比率，以及其他很多财务估值比率。</p></blockquote><h3 id="3-股份公司的经营决策"><a href="#3-股份公司的经营决策" class="headerlink" title="3. 股份公司的经营决策"></a>3. 股份公司的经营决策</h3><script type="math/tex; mode=display">企业盈利（E）=企业投资（I）+企业分红（D）</script><p><img src="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/pic4-1.jpg" alt></p><ul><li><p><strong>分红可能性边界</strong>（也可以叫做生产可能性边界）</p></li><li><p>企业在 1 期最大可能的分红数量 $D_{1max}$</p></li><li>企业在 2 期最大可能的分红数量 $D_{2max}$</li></ul><p><img src="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/pic4-2.jpg" alt></p><ul><li><strong>市场机会线</strong></li></ul><p>当分红可能性边界、市场机会线和股东的无差异曲线放在一块</p><p><img src="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/pic4-3.jpg" alt></p><ul><li><p>股东 A 和 B 的无差异曲线与这根市场机会线的切点 A’与 B’，有着比之前无差异曲线和分红可能性边界切点（A 与 B）更高的效用水平。所以，不管股东如何偏好，他们都愿意让企业按照市场机会线与分红可能性边界的切点 P 来决策。</p></li><li><p>P点时企业经营的边际投资回报率（斜率）与市场利率相等</p></li><li><p>当分红可能性边界与市场机会线相切时，企业的两期分红用市场利率折算的现值</p><p>为最大。即 $D_1+\frac{D_2}{1+r}$, 为紫线与1期轴相交的点。</p></li></ul><blockquote><p> 企业股东（假设为消费者）在做决策时，包含两个相分离的步骤。第一步，让持有的企业遵循股票价值最大的目标来进行经营决策（投资、分红）。第二步，在资本市场上借贷，将企业所提供的红利流转换为符合自己偏好的消费流。这两步的决策相互独立，互不影响。这种投资决策和消费决策分离的结论叫做费雪分离定理（Fisher Separation Theorem），为费雪于 1930 年首次提出。</p><p>但在我国，A 股市场中有很多国有企业，其股份高度集中在国家手中。市场中的许多民营企业股权也集中于少数富豪手中。在这样的市场中，企业管理层受到的市场压力较小，其行为可能长期偏离市场的偏好（具体表现为企业长期不分红，投资低回报项目）。当市场中大量企业都是这样的时候，A 股市场中价值投资的氛围自然淡薄。炒作股票就成为了这个市场中主要的赚钱手段。</p></blockquote><h1 id="第-5-讲-均值方差分析"><a href="#第-5-讲-均值方差分析" class="headerlink" title="第 5 讲 均值方差分析"></a>第 5 讲 均值方差分析</h1><p>金融界第一次革命 : 1952年 Harry Markowitz 发表 《Portfolio Selection》</p><blockquote><p>提出问题 - 在关心回报率均值的同时，如果投资者还关心刻画了风险度的回报率波动方差呢？</p></blockquote><ul><li>事前回报率 (ex ante rate of return) - 预期回报率 (expected rate of return)</li><li>时候回报率  (ex post rate of return)</li><li>风险溢价（risk premium）- 风险资产的期望回报率超出无风险资产期望回报率的部分，是对风险资产 p 持有者承担风险的补偿 $E(r_p)-E(r_f)$</li></ul><h3 id="1-均值、方差和标准差的数学描述"><a href="#1-均值、方差和标准差的数学描述" class="headerlink" title="1. 均值、方差和标准差的数学描述"></a>1. 均值、方差和标准差的数学描述</h3><p>如果我们有某资产过去 N 个时期的回报率观测值</p><script type="math/tex; mode=display">\bar{r}=\frac1N\sum_{i=1}^N r_i</script><script type="math/tex; mode=display">\sigma_r^2=\frac1N\sum_{i=1}^N (r_i-\bar r)^2</script><script type="math/tex; mode=display">\sigma_{xy}=\frac1N\sum_{i=1}^N(x_i-\bar{x})(y_i-\bar{y})</script><script type="math/tex; mode=display">\rho_{xy}=\frac{\sigma_{xy}}{\sigma_x\sigma_y}</script><ul><li><strong>幸存者偏差</strong> (survivorship bias) - 在观察过去的历史数据时，我们没有看到巨灾状态的发生。<strong>因为那些遭遇了巨灾状态的资产已经退出资本市场了</strong>。</li></ul><h3 id="2-资产组合的均值方差特性"><a href="#2-资产组合的均值方差特性" class="headerlink" title="2. 资产组合的均值方差特性"></a>2. 资产组合的均值方差特性</h3><script type="math/tex; mode=display">\sum_{i=1}^N w_i=1</script><p><strong>2.1 一种无风险资产和一种风险资产的组合</strong></p><p>一般来说，没有信用风险（credit risk）的固定收益类（fixed income）资产可被视为无风险资产。而国债（government bond）正是这样的资产。假设持有风险资产 s</p><blockquote><p>欧元区的成立后，将区内各个国家的货币发行权上收到了欧央行（European Central Bank, ECB），因而剥夺了各国的货币发行权。这样，欧元区内各个国家的国债就从无风险资产变成了风险资产，出现了违约的风险。</p></blockquote><script type="math/tex; mode=display">\bar r_p=E[(1-w)r_f+wr_s]=(1-w)r_f+w\bar r_s= r_f+w(\bar r_s-r_f)</script><script type="math/tex; mode=display">\sigma_p^2=E[(1-w)r_f+wr_s-(1-w)r_f-w\bar r_s]^2=E[w^2(r_s-\bar r_s)^2]=w^2\sigma_s^2</script><p>组合在标准差—均值坐标系上画出一条连接无风险资产和风险资产的直线段。可得</p><script type="math/tex; mode=display">\bar r_p=r_f+\frac{\bar r_s-r_f}{\sigma_s}\sigma_p</script><p><img src="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/pic5-1.jpg" alt></p><p><strong>2.2 两种风险资产的组合</strong></p><script type="math/tex; mode=display">\bar r_p=E(r)=w\bar r_1+(1-w)\bar r_2</script><script type="math/tex; mode=display">\begin{aligned}\sigma_p^2 &=E[wr_1+(1-w)r_2-(w\bar r_1+(1-w)\bar r_2)]^2\\&=E[w(r_1-\bar r_1)+(1-w)(r_2-\bar r_2)]^2\\&=E[w^2(r_1-\bar r_1)^2+(1-w)^2(r_2-\bar r_2)^2+2w(1-w)(r_1-\bar r_1)(r_2-\bar r_2)]\\&=w^2\sigma^2_1+(1-w)^2\sigma_2^2+2w(1-w)\sigma_{12}\end{aligned}</script><p>组合在标准差—均值坐标系上画出一条连接两个资产的双曲线。曲线的最左侧点代表通过组合所能达到的最小波动率。这个组合被称为“最小方差组合”。我们可以求出最小方差组合中两类资产的权重。其一阶条件为</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial \sigma_p^2}{\partial w}&\Rightarrow2\sigma_1^2w^*-2\sigma_2^2(1-w^*)+2\sigma_{12}-4\sigma_{12}w^*=0\\&\Rightarrow2\sigma_1^2w^*-2\sigma_2^2+2\sigma_2^2w^*+2\sigma_{12}-4\sigma_{12}w^*=0\\&\Rightarrow\sigma_1^2w^*-\sigma_2^2+\sigma_2^2w^*+\sigma_{12}-2\sigma_{12}w^*=0\\&\Rightarrow(\sigma_1^2+\sigma_2^2-2\sigma_{12})w^*=\sigma_2^2-\sigma_{12}\\&\Rightarrow w^*=\frac{\sigma_2^2-\sigma_{12}}{\sigma_1^2+\sigma_2^2-2\sigma_{12}}\end{aligned}</script><p>代入原式得到方差最小的组合的均值为</p><script type="math/tex; mode=display">\bar r_p^*=\frac{\sigma_1^2\bar r_2+\sigma_2^2\bar r_1-\sigma_{12}(\bar r_1+\bar r_2)}{\sigma_1^2+\sigma_2^2-2\sigma_{12}}</script><p><img src="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/pic5-2.jpg" alt></p><p><img src="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/pic5-3.jpg" alt></p><p>如果存在不止两种的风险资产，投资组合的收益风险状况就不再是在一根曲线上，而变成了一片区域</p><p>若是三个资产，且给定回报率均值 $\bar r$, 选择组合权重来最小化组合回报率方差</p><script type="math/tex; mode=display">\begin{aligned}\min_{w_1,w_2,w_3} & w_1^2\sigma_1^2+w_2^2\sigma_2^2+w_3^2\sigma_3^2\\s.t.\quad &w_1\bar r_1+w_2\bar r_2+w_3\bar r_3=\bar r\\& w_1+w_2+w_3=1\end{aligned}</script><p>建立拉格朗日函数</p><script type="math/tex; mode=display">\mathcal{L}=w_1^2\sigma_1^2+w_2^2\sigma_2^2+w_3^2\sigma_3^2+\lambda[w_1\bar r_1+w_2\bar r_2+w_3\bar r_3-\bar r]+\mu[w_1+w_2+w_3-1]</script><p>一阶条件</p><script type="math/tex; mode=display">\frac{\partial\mathcal L}{\partial w_i}=0 \Rightarrow 2\sigma_i^2w_i+\lambda\bar r_i+\mu=0</script><p>在波动率均值坐标系上，多种风险资产形成的组合区域边界是开口向右、上下对称的双曲线。这条双曲线的上半边称为投资组合的<strong>“有效前沿”</strong>（efficient frontier）</p><h3 id="3-市场组合与共同基金定理"><a href="#3-市场组合与共同基金定理" class="headerlink" title="3. 市场组合与共同基金定理"></a>3. 市场组合与共同基金定理</h3><p><img src="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/pic5-4.jpg" alt></p><p>与双曲线上半支相切的射线有最高的期望收益。这条射线就是包含无风险资产后的组合有效前沿（前沿从一条双曲线变成了一条直线）。这根直线型的有效前沿在金融学中有一个专门的名字，叫做<strong>“资本市场线”</strong>（Capital Market Line，简称 CML）。资本市场线与双曲线的切点就是“市场组合”（market portfolio）</p><script type="math/tex; mode=display">\bar r-r_f=\frac\sigma\sigma_M(\bar r_M-r_f)</script><ul><li>理性的投资者只应该选择处在 CML 上的投资组合。而 CML 上的所有投资组合都可由“无风险资产”和“市场组合”组合得到。投资者 A 和 B 虽然有着不同的无差异曲线。但他们都会选择同样的风险资产组合，也即“市场组合”。他们之间的差异只是在资产分配在无风险资产和市场组合的比例不同而已。</li></ul><blockquote><p>投资经理在帮客户设计组合时，可以分成两步来完成。第一步，基于各种风险资产的收益风险特性，构建出“市场组合”。在这一步中，可以完全不考虑客户的偏好。第二步，根据客户的偏好，将客户的资产在无风险资产和市场组合之间做配置。这一结论，就是金融学中著名的<strong>“共同基金分离定理”</strong>（Mutual Fund Separation Theorem）</p><p>尽管我们是在包含无风险资产的情况下导出了共同基金定理，但其实在没有无风险资产，而只有风险资产时，共同基金定理也成立。只不过这时定理内容变成：<strong>任何有效前沿上的组合均可以由两个处在有效前沿上的组合得到</strong></p></blockquote><h1 id="第-6-讲-资本资产定价模型"><a href="#第-6-讲-资本资产定价模型" class="headerlink" title="第 6 讲 资本资产定价模型"></a>第 6 讲 资本资产定价模型</h1><p>在上一讲，我们假设资产的期望回报率等于其过去历史回报率的均值，即</p><script type="math/tex; mode=display">E(\tilde r_i)=\bar r_i</script><p>其中，字母上方加上波浪符号表明这是一个随机变量（random variable）</p><h3 id="1-CAPM-的第一种论证"><a href="#1-CAPM-的第一种论证" class="headerlink" title="1. CAPM 的第一种论证"></a>1. CAPM 的第一种论证</h3><p>再开始前引入如下几个假设</p><p>1) 没有交易成本（佣金、买卖价差等）<br>2) 没有税收<br>3) 所有资产都可以任意交易，并且无限可分<br>4) 完全竞争：所有人都是价格的接受者，没有影响价格的能力<br>5) 所有人都以均值方差的方式选择投资组合：偏好更高的期望回报率，以及更低的回报率波动率<br>6) 所有资产（包括无风险资产）都可以任意买空卖空。<br>7) 一致预期：所有人针对相同的时间区间（1 期）考虑投资问题，并对资产的预期回报率和预期波动率状况有相同预期。</p><p>我们假设只持有市场组合，完全不持有无风险资产的投资者的偏好以下面的效用函数来刻画</p><script type="math/tex; mode=display">u(r)=E(r)-A\sigma^2(r)</script><ul><li>A - 衡量风险厌恶程度的恰当常数（A 严格大于 0 以确保投资者是风险厌恶的）</li></ul><blockquote><p>不持有无风险资产的条件是为了简化运算，而效用函数的假设，是有因为其实对应着两种期望效用的特殊情况——回报率服从正态分布，或者消费者的对消费的效用函数呈二次型。当然效用函数可以采用其他方法规定，但是在CAPM模型中要求符合这一特性。所以说，CAPM是C-CAPM一种特例。</p><p>效用函数中的方差只能是投资者持有的最优资产组合的方差，而不是各个资产自己回报率的波动方差。</p></blockquote><p>在这个投资者已持有市场组合 M 的前提下，让他将其投资在 M 上的资产分一小部分 w 到其他任意一种资产 i 上，为投资者构建一个新的组合，效用为</p><script type="math/tex; mode=display">\begin{aligned}u(r_p)&=u[wr_i+(1-w)r_M]\\&=E[wr_i+(1-w)r_M]-A\sigma^2[wr_i+(1-w)r_M]\\&=wE(r_i)+(1-w)E(r_M)-A[w^2\sigma_i^2+(1-w)^2\sigma_M^2+2w(1-w)\sigma_{iM}]\\&=wE(r_i)+(1-w)E(r_M)-Aw^2(\sigma_i^2+\sigma_M^2-2\sigma_{iM})-2Aw(\sigma_{iM}-\sigma_{M}^2)-A\sigma_{M}^2\\\end{aligned}</script><p>将 w 份额的财富从市场组合 M 转换到资产 i 上，带给投资者的边际效用为</p><script type="math/tex; mode=display">\frac{du(r_p)}{dw}=E(r_i)-E(r_M)-2Aw(\sigma_i^2+\sigma_M^2-2\sigma_{iM})-2A(\sigma_{iM}-\sigma_M^2)</script><p>由于 M 是投资者的最优选择，所以在 w=0 处，边际效用应该等于 0</p><script type="math/tex; mode=display">E(r_i)-E(r_M)-2A(\sigma_{iM}-\sigma_M^2)=0</script><p>由于这个边际效用对任何一种资产都是 0，所以理应对无风险资产 $r_f$ 也是 0。将 rf代入上式可得</p><script type="math/tex; mode=display">\begin{aligned}r_f-E(r_M)+2A\sigma_M^2&=0\\\frac{E(r_M)-r_f}{2\sigma_M^2}&=A\end{aligned}</script><p>代回原式</p><script type="math/tex; mode=display">\begin{aligned}&E(r_i)-E(r_M)-\frac{E(r_M)-r_f}{\sigma_M^2}(\sigma_{iM}-\sigma_M^2)=0\\&\Rightarrow E(r_i)-E(r_M)+E(r_M)-r_f=\frac{\sigma_{iM}}{\sigma_M^2}[E(r_M)-r_f]\\&\Rightarrow E(r_i)-r_f=\frac{\sigma_{iM}}{\sigma_M^2}[E(r_M)-r_f]\end{aligned}</script><p>定义 $\beta_i=\frac{\sigma_{iM}}{\sigma_M^2}$, 则上式变形为常见的 CAPM 定价方程</p><script type="math/tex; mode=display">E(r_i)-r_f=\beta_i[E(r_M)-r_f]</script><h3 id="2-CAPM-的第二种论证"><a href="#2-CAPM-的第二种论证" class="headerlink" title="2. CAPM 的第二种论证"></a>2. CAPM 的第二种论证</h3><p>在均衡时，所有理性投资者所选择的投资组合都应该处在所谓的“资本市场线”（Capital Market Line, CML）上。容易得到 CML 的直线方程为</p><script type="math/tex; mode=display">E(r)=r_f+\frac{E(r_M)-r_f}{\sigma_M}\sigma</script><p>同样构建一个新组合</p><script type="math/tex; mode=display">E[r_w]=wE(r_i)+(1-w)E(r_M)=w[E(r_i)-E(r_M)]+E(r_M)</script><script type="math/tex; mode=display">\begin{aligned}\sigma(r_w)&=[w^2\sigma^2_i+(1-w)^2\sigma^2_M+2w(1-w)\sigma_{iM}]^{\frac12}\\&=[w^2(\sigma^2_i+\sigma^2_M-2\sigma_{iM})+2w(\sigma_{iM}-\sigma^2_M)+\sigma^2_M]^{\frac12}\\\end{aligned}</script><p>这个新的市场组合线与CML交于M点，又同时不高于 efficient frontier</p><p><img src="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/pic6-1.jpg" alt></p><p>这条曲线在这一点的斜率应该与资本市场线的斜率相等。即</p><script type="math/tex; mode=display">\frac{dE(r_w)}{d\sigma(r_w)}\bigg|_{x=0}=\frac{dE(r_w)}{dw}\bigg|_{x=0}\bigg/\frac{d\sigma(r_w)}{dw}\bigg|_{x=0}=\frac{E(r_M)-r_f}{\sigma_M}</script><p>从前两式可得</p><script type="math/tex; mode=display">\frac{dE(r_w)}{dw}=E(r_i)-E(r_M)</script><script type="math/tex; mode=display">\begin{aligned}\frac{d\sigma(r_w)}{dw}=&\frac12[w^2\sigma^2_i+(1-w)^2\sigma^2_M+2w(1-w)\sigma_{iM}]^{-\frac12}\\&\times[2w(\sigma^2_i+\sigma^2_M-2\sigma_{iM})+2(\sigma_{iM}-\sigma^2_M)]\end{aligned}</script><p>w = 0 代入上式得</p><script type="math/tex; mode=display">\frac{d\sigma(r_w)}{dw}\bigg|_{x=0}=\frac{\sigma_{iM}-\sigma^2_M}{\sigma_M}</script><p>回到开头等式</p><script type="math/tex; mode=display">\begin{aligned}&[E(r_i)-E(r_M)]\bigg/\frac{\sigma_{iM}-\sigma^2_M}{\sigma_M}=\frac{E(r_M)-r_f}{\sigma_M}\\&\Rightarrow \frac{\sigma_M[E(r_i)-E(r_M)]}{\sigma_{iM}-\sigma^2_M}=\frac{E(r_M)-r_f}{\sigma_M}\\&\Rightarrow \sigma_M^2E(r_i)-\sigma_M^2E(r_M)=\sigma_{iM}E(r_M)-\sigma_{iM}r_f-\sigma^2_ME(r_M)+\sigma^2_Mr_f\\&\Rightarrow E(r_i)-r_f=\frac{\sigma_{iM}}{\sigma_M^2}[E(r_M)-r_f]\end{aligned}</script><p>定义 $\beta_i=\frac{\sigma_{iM}}{\sigma_M^2}$, 则上式变形为常见的 CAPM 定价方程</p><script type="math/tex; mode=display">E(r_i)-r_f=\beta_i[E(r_M)-r_f]</script><p>在这第二种推导中，我们在分析是否可能通过将市场组合 M 与其他资产组合起来，以获得高于市场组合的<strong>夏普比</strong>（Sharpe Ratio，简写为 SR）。</p><script type="math/tex; mode=display">SR_i=\frac{E(r_i)-r_f}{\sigma(r_i)}</script><p>容易看出，在所有由风险资产所构成的组合中，市场组合 M 有最高的夏普比。市场组合 M 的夏普比就是资本市场线（CML）的斜率。</p><h3 id="3-证券市场线-vs-资本市场线"><a href="#3-证券市场线-vs-资本市场线" class="headerlink" title="3. 证券市场线 vs.资本市场线"></a>3. 证券市场线 vs.资本市场线</h3><p>CAPM 表明不同资产的期望回报率之间存在线性关系：$\beta$ 越大的资产，期望回报率应该越高。理论上，如果以 $\beta$ 为横坐标，资产期望回报率为纵坐标，表征不同资产的点应该处在一根斜率为正的直线上。这根直线就是证券市场线（Securities Market Line，简称 SML）。</p><p>证券市场线（SML）</p><script type="math/tex; mode=display">E(r_i)=r_f+\frac{\sigma_{iM}}{\sigma_M^2}[E(r_M)-r_f]</script><p>or</p><script type="math/tex; mode=display">E(r_i)=r_f+\beta[E(r_M)-r_f]</script><p>资本市场线（CML）</p><script type="math/tex; mode=display">E(r_i)=r_f+\frac{\sigma_{i}}{\sigma_M}[E(r_M)-r_f]</script><p>两个方程的差别在于</p><ol><li>在 SML 中，风险以 $\beta$ 度量；而在 CML中，风险以 $\sigma$ 衡量。</li><li>SML 对所有资产都成立。而 CML只对那些由所有资产（包括无风险资产及风险资产）组合起来的“有效组合”成立（完全分散化投资后）。</li></ol><h1 id="第-7-讲-对-CAPM-的讨论"><a href="#第-7-讲-对-CAPM-的讨论" class="headerlink" title="第 7 讲 对 CAPM 的讨论"></a>第 7 讲 对 CAPM 的讨论</h1><ul><li><p>决定资产期望回报率的不是资产回报率的波动率，而是资产回报率与市场组合波动的相关性（$\beta$）。<strong>如果某些不确定性可以通过投资者自己的处理而被消除，它就不应该算作真正的风险，市场也就不应该对持有这些不确定性给出奖励。</strong></p></li><li><p>分散投资的极致是所有资产合起来，就是市场组合。市场组合的波动率就是不能被分散的不确定性，是资产定价时需要加以补偿的风险，叫做<strong>系统性风险</strong>（systematic risk）。而各类资产所包含的可以通过分散化消除的波动叫做<strong>个体风险</strong>（idiosyncratic risk）。</p></li><li><p>有没有可能存在预期回报率低于无风险利率的风险资产？- 保险</p></li><li><p><strong>均值方差偏好只能用来做评价最优组合的判断标准</strong>。在这些最优组合中，所有可被分散的风险都已被分散，只存在系统风险。在这些最优组合中，如果两个组合期望回报率一样，而波动率有不同，那么投资者一定会选择波动率小的那个最优组合。而对（风险未被充分分散的）任意两种资产，不能用均值方差偏好来说投资者会选择一个，而不选择另一个。</p></li><li><p><strong>夏普比只应该被用来衡量那些被提供给最终投资者的投资组合的表现</strong>。对单个资产来计算夏普比的意义很小。原因在于单个资产并未享受到分散化带来的好处，其夏普比理应低于市场组合</p></li><li><p>在现实世界中，还有些基金只专注于投资某一个有限的领域。这些基金在设立之时就明确表示不会尽可能地做分散投资。这些基金的客户（主要是投资领域广泛的基金）会在这些行业基金的基础之上，再来构造自己的基金。<strong>“母基金”</strong>（Fund of Funds，简称 FOF）就是一类这种投资于其他基金的基金。<strong>对于这些行业性或局域性的基金，夏普比不是一个公允的考核指标。因为这些行业性基金本来就不会试图去尽可能分散投资。对这些基金来说，$\beta$ 而非波动率是更合适的风险刻画指标。</strong>1968 年，Michael Jensen 利用 CAPM 的思想构造了一个衡量共同基金表现的指标——詹森阿尔法（Jensen’s Alpha）。这个指标又被称为<strong>“詹森指数”</strong>（Jensen Index）。简单来说，詹森阿尔法是某支共同基金平均回报率相对证券市场线的垂直偏离。</p></li></ul><script type="math/tex; mode=display">\text{Jensen's Alpha}=(\bar r_i-r_f)-\beta_i(\bar r_M-r_f)</script><ul><li><p>如果能够找到一个正 Alpha 的基金，可以把这个基金与市场组合再组合一下，获得比原来的市场组合更高的夏普比。但在实践中，其实不用那么复杂，我们完全可以在组合构建中把这个正的Alpha给提取出来。这种策略叫做<strong>Alpha与 Beta分离</strong>（Alpha Beta Separation）。这个分离出来的 Alpha 可以被加到其他组合中以帮助其他组合获得更高的回报率。所以这种策略又叫做 <strong>Alpha 转移</strong>（Alpha transport），或者叫可携 Alpha（portable Alpha）。</p></li><li><p>CAPM 只研究资产市场中的均衡，而<strong>将资产市场所处的宏观大环境当成外生给定</strong>。此外，CAPM 还是一个静态模型，<strong>只研究单期决策的问题</strong>。这样，CAPM就难以把资产价格和宏观经济的各种因素联系起来，无法探究资产价格的最终决定因素。另外，用 CAPM 也没法分析资产价格的动态变化规律。基于消费的资本资产定价模型（C-CAPM） 和跨期资本资产定价模型（ICAPM）就是针对这两点不足所发展出来的更成熟的定价理论。</p></li></ul><h1 id="第-8-讲-期望效用理论"><a href="#第-8-讲-期望效用理论" class="headerlink" title="第 8 讲 期望效用理论"></a>第 8 讲 期望效用理论</h1><p>从理论上来看，可以从两个方面改善 CAPM。这两方面的改进会把我们带到基于消费的资本资产定价模型（Consumption based CAPM），一个基于更合理偏好假设的一般均衡定价理论体系。</p><p><strong>第一个方向是投资者偏好的假设</strong></p><p>经济分析（当然也包含金融分析）的基础是对人选择行为的研究。而人要能够做出选择，首先得有能力对不同选择的优劣做排序。人这种对选择排序的能力在经济学中用偏好来体现。</p><blockquote><p>为什么 $u(r)=E(r)-A\sigma^2(r)$ 不适用于做偏好？ 从概率论上解释，任何一个随机变量 x 都可以定义其 k 阶矩 为 $E[x-c]^k$ 。均值为一阶矩，方差是二阶矩。仅用均值和方差来比较随机变量，丢失了随机变量三阶矩（偏度 Skewness）、四阶矩（峰度 Kurtosis）及更高阶矩的信息。</p></blockquote><p>介绍人在风险下决策的理论体系。其核心是冯•诺伊曼与摩根斯坦 1944 年所创立的<strong>“期望效用理论”</strong>（expected utility theory）。</p><p><strong>定义 8.1（理性偏好）：</strong>一种偏好关系 $\succeq$ 被称为理性，当且仅当它满足以下两个条件：</p><ol><li>完备性：对任意 $x,y\in X,x\succeq y$ 与 $y\succeq x$ 至少有一个成立。</li><li>传递性：对任意 $x,y,z\in X$ 如果有 $x\succeq y$ 与 $y\succeq z$ 则必有 $x\succeq z$ 成立。</li></ol><p><strong>定义 8.2（连续性）：</strong>一种偏好关系 $\succeq$ 如果在极限下也能保留，就被称为连续的。具体来说，如果对一系列 $\{(x^n,y^n)\}_{n=1}^\infty$ 有 $x^n\succeq y^n (\forall n)$那么对 $x=\lim_{n\to\infty}x^n$ 与 $y=\lim_{n\to\infty}y^n$ 必有 $x\succeq y$。</p><p><strong>命题 8.3：</strong>如果一个偏好 $\succeq$ 是理性且连续的，那么它可以用一个连续函数 $u(x)$ 来表示。</p><p><strong>定义 8.4（简单彩票 simple lottery）：</strong> 一张简单彩票 $L$ 为一串数字 $L=(p_1, … ,p_N)$。其中 $p_n$ 为第 $n$ 种结果出现的概率。对所有的 $n$，有 $p_n \ge0$，且 $\sum_np_n=1$。</p><p><strong>定义 8.5（复合彩票 compound lottery）：</strong>如果有 $K$ 张简单彩票 $L_k=(p_1^k<br>,…,p_N^k)，k=1,…,K$，以及概率 $\alpha_k\ge0 （\sum_k\alpha_k=1）$，复合彩票$(L_1,…,L_K; \alpha_1,…, \alpha_K)$ 以 $\alpha_k$ 为概率产生结果 $L_k$。</p><p>由于复合彩票可以被化为简单彩票，所以我们就把简单彩票作为人在不确定状况下面临的可选对象，并把所有可选的简单彩票所组成的集合叫做彩票空间（space of lotteries），标记为 $\mathscr L$。</p><p><strong>定义 8.6（独立性公理 independence axiom）：</strong>称对彩票的一种偏好关系<br>$\succeq$ 满足独立性公理，如果对任意 3 张彩票 A、B 和 C 和任意 0 到 1 之间的数 $\alpha$，以下条件总是成立</p><script type="math/tex; mode=display">A\succeq B\Leftrightarrow\alpha A+(1-\alpha)C\succeq\alpha B+(1-\alpha)C</script><p><strong>命题 8.7（期望效用定理）：</strong>如果定义在彩票空间 $\mathscr L$ 上的偏好 $\succeq$ 是理性和连续的，并且满足独立性公理，那么这样的偏好可用期望效用函数的形式表述出来。也就是说，我们可以为每种结果 $n=1, …, N$ 指定一个效用值 $u_n$，使得对任意两个彩票 $L=(p_1, …, p_N)$与 $L’=(p_1’, …, p_N’)$来说，必然有</p><script type="math/tex; mode=display">L\succeq L'\Leftrightarrow\sum_{n=1}^Np_nu_n\ge\sum_{n=1}^Np_n'u_n</script><p>期望效用定理意味着，满足理性、连续性、以及独立性公理的偏好可以表示为期望效用的形式</p><script type="math/tex; mode=display">U(L)=\sum_{n=1}^Np_nu(x_n)</script><p>这样的效用函数被称为“冯诺伊曼-摩根斯坦效用函数”。由于这个名字实在太长，我们一般简称其为“vNM 效用函数”，或是<strong>“期望效用函数”</strong>。</p><blockquote><p>对独立性公理最著名的反驳是阿莱斯于 1953 年提出来的。这一反驳是如此有名，以至于经济学中专门出现了一个名词叫<strong>“阿莱斯悖论”</strong>（Allais Paradox）。</p><p>对阿莱斯悖论通常会有 4 种的回应：（1）在阿莱斯悖论中，人的选择不理性；（2）阿莱斯悖论涉及非常接近 0 或 1 的概率，因而不是普遍的；（3）在理论中加入“后悔”；（4）放弃独立性公理，从而构建更弱的理论。阿莱斯悖论及对其的回应已经激发出了更多的研究。但从简便性上来说，新的理论都还没有超过期望效用理论。所以目前期望效用仍然是研究不确定下人的行为的主要工具。</p></blockquote><p>期望效用是将效用定义在结果，而非收益之上的。也就是说，不管投资者初始的财富是多少，最终同样的收益和消费水平会带来同样的效用。因此，在定义效用时，似乎<strong>有必要把当前的状况与某个基准来做比较</strong>。Kahneman 与Tversky 于 1979 年提出展望理论（prospect theory）。他们认为，<strong>失去一笔钱带来的效用损失的幅度，比得到同一数额的钱带来效用增进的幅度要更大。</strong></p><p><img src="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/pic8-1.jpg" alt></p><h3 id="8-1-风险厌恶程度的度量"><a href="#8-1-风险厌恶程度的度量" class="headerlink" title="8.1 风险厌恶程度的度量"></a>8.1 风险厌恶程度的度量</h3><p><img src="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/pic8-2.jpg" alt></p><p>图中画出了两根效用函数曲线，$u(•)$ 与 $v(•)$。其中，$v(•)$对应的曲线曲率更大（更加弯曲）。消费者的消费存在不确定性，有50%的可能性获得 $c+\Delta$，50%的可能性获得 $c-\Delta$。尽管消费者的期望消费为 $c$，但因为不确定性的存在，他们的效用低于 $u(c)$ 与 $v(c)$，只能分别达到$Eu(c)=\frac12•u(c-\Delta)+\frac12•u(c+\Delta)$与$Ev(c)=\frac12•v(c-\Delta)+\frac12•v(c+\Delta)$ 的水平。</p><p>通过方程 $u(ce_u)=Eu(c)$ 与 $v(ce_v)=Ev(c)$，可以找出与不确定性消费效用相等的确定性消费水平，将其称为<strong>确定性等值</strong>（certainty equivalent）$ce_u$ 与 $ce_v$。从图中可以看到 $ce_u$ 与 $ce_v$ 均小于 $c$ 。它们与 $c$ 之间的距离就是消费者愿意为消除不确定性而牺牲的期望消费，也就是消费者愿意支付的“风险溢价”（risk premium）。由于 v(•)的曲线曲率更大，所以$ce_v&lt;ce_u$ 。消费者 $v$ 为了消除不确定性，愿意牺牲更多的消费。</p><p>风险溢价就可用来衡量消费者的风险厌恶程度。但是，这种形式的风险溢价与期望消费量以及消费的波动幅度都有关，使用起来不方便。我们希望找到一种与具体消费状况无关的，只是刻画消费者主观风险厌恶态度的指标。</p><p><strong>假设</strong></p><ul><li>水平 $y$ 的投资者</li><li>以 $\pi$ 概率赢得数额为 $h$ 的货币</li><li>以 $1-\pi$ 概率输掉数额为 $h$ 的货币</li><li>$\pi^*$ 为使得投资者在参与和不参与投资之间完全无差异的临界值 (也可以视为对投资者风险厌恶度的一个度量)</li></ul><script type="math/tex; mode=display">u(y)=\pi^*u(y+h)+(1-\pi^*)u(y-h)</script><p>将 $u(y+h)$ 与 $u(y-h)$ 在 $y$ 处做泰勒展开</p><script type="math/tex; mode=display">u(y+h)=u(y)+hu'(y)+\frac{h^2}2u''(y)+o_1(h^2)</script><script type="math/tex; mode=display">u(y-h)=u(y)-hu'(y)+\frac{h^2}2u''(y)+o_2(h^2)</script><p>代入</p><script type="math/tex; mode=display">u(y)=\pi^*[u(y)+hu'(y)+\frac{h^2}2u''(y)]+(1-\pi^*)[u(y)-hu'(y)+\frac{h^2}2u''(y)]</script><p>化简</p><script type="math/tex; mode=display">0=(2\pi^*-1)hu'(y)+\frac{h^2}2u''(y)</script><p>解得</p><script type="math/tex; mode=display">\pi^*=\frac12+\frac h4[-\frac{u''(y)}{u'(y)}]</script><p>我们定义</p><script type="math/tex; mode=display">R_A(y)\equiv-\frac{u''(y)}{u'(y)}</script><p>这就是<strong>绝对风险厌恶系数</strong>（coefficient of absolute risk aversion）。它也被称为Arrow–Pratt measure of absolute risk-aversion（简称 ARA），因为这种方法最先由 Pratt 与 Arrow提出。</p><p>类似的，我们可以推导一个应用更为广泛的风险厌恶程度指标—<strong>“相对风险厌恶系数”</strong>（coefficient of relative risk aversion）。这一指标又被称为 Arrow-Pratt-De Finetti measure of relative risk-aversion（简称 RRA）。</p><p>与上述不同的是，此时定义</p><ul><li>以 $\pi$ 概率赢得数额为 $\theta y$ 的货币</li><li>以 $1-\pi$ 概率输掉数额为 $\theta y$ 的货币</li></ul><script type="math/tex; mode=display">u(y)=\pi^*u(y+\theta y)+(1-\pi^*)u(y-\theta y)</script><p>将 $u(y+\theta y)$ 与 $u(y-\theta y)$ 在 $y$ 处做泰勒展开，并去掉二阶以上的高阶余项</p><script type="math/tex; mode=display">u(y+\theta y)=u(y)+\theta yu'(y)+\frac{\theta^2 y^2}2u''(y)</script><script type="math/tex; mode=display">u(y-\theta y)=u(y)-\theta yu'(y)+\frac{\theta^2 y^2}2u''(y)</script><p>代入</p><script type="math/tex; mode=display">u(y)=\pi^*[u(y)+\theta yu'(y)+\frac{\theta^2 y^2}2u''(y)]+(1-\pi^*)[u(y)-\theta yu'(y)+\frac{\theta^2 y^2}2u''(y)]</script><p>化简</p><script type="math/tex; mode=display">0=(2\pi^*-1)\theta u'(y)y+\frac{\theta^2}2u''(y)y^2</script><p>解得</p><script type="math/tex; mode=display">\pi^*=\frac12+\frac \theta4[-\frac{yu''(y)}{u'(y)}]</script><p>我们定义</p><script type="math/tex; mode=display">R_R(y)\equiv-\frac{yu''(y)}{u'(y)}</script><p>即为相对风险厌恶系数</p><h3 id="8-2-几种常见的效用函数"><a href="#8-2-几种常见的效用函数" class="headerlink" title="8.2 几种常见的效用函数"></a>8.2 几种常见的效用函数</h3><ol><li><p><strong>CARA：</strong>常绝对风险厌恶型效用函数（constant absolute risk aversion）</p><script type="math/tex; mode=display">u(c)=-e^{-\alpha c}</script><p>其对应的绝对风险厌恶系数为 $R_A(c)=\alpha$</p></li><li><p><strong>CRRA：</strong>常相对风险厌恶型效用函数（constant relative risk aversion）</p><script type="math/tex; mode=display">u(c)=\frac{c^{1-\gamma}-1}{1-\gamma}</script><p>其对应的绝对风险厌恶系数为 $R_R(c)=\gamma$</p><p>当 $\gamma=1$ 的时候，CRRA 函数退化为对数效用函数 $u(c)=lnc$ 在经济学中，我们通常把 $ln$ 写成 $log$。所以，对数效用函数一般写为 $u(c)=logc$</p><script type="math/tex; mode=display">\lim_{\gamma\to1}\frac{c^{1-\gamma}-1}{1-\gamma}=\lim_{\gamma\to1}\frac{-c^{1-\gamma}\ln c}{-1}=\ln c</script></li><li><p><strong>HARA：</strong>双曲绝对风险厌恶型效用函数（hyperbolic absolute risk aversion）。这种效用函数对应的绝对风险厌恶系数为</p><script type="math/tex; mode=display">R_A(c)=\frac{1}{ac+b}</script><p>解此微分方程，并舍弃解中的常数项和系数，可得对应的效用函数形式为</p><script type="math/tex; mode=display">u(c)=\frac{(c-c_s)^{1-\gamma}}{1-\gamma}</script><p>其中，$\gamma=1/a，c_s=-b/a$。当 $a=0$ 的时候，HARA 退化为 CARA。当 $b=0$ 的时候，HARA 退化为 CRRA。当 $\gamma=-1$ 的时候，HARA 退化为二次型效用函数。</p></li><li><p><strong>线性效用函数（风险中性）：</strong></p><script type="math/tex; mode=display">u(c)=\alpha c</script><p>其中  $\alpha$ 为大于 0 的常数。由于 $u’(c)=\alpha，u’’(c)=0$，所以其绝对风险厌恶系数和相对风险厌恶系数都为 0。</p></li></ol><h3 id="8-3-作为期望效用特例的均值方差偏好"><a href="#8-3-作为期望效用特例的均值方差偏好" class="headerlink" title="8.3 作为期望效用特例的均值方差偏好"></a>8.3 作为期望效用特例的均值方差偏好</h3><p><strong>二次型效用</strong></p><script type="math/tex; mode=display">u(c)=c-Ac^2</script><script type="math/tex; mode=display">\begin{aligned}Eu(c)&=E[c-Ac^2]\\&=E(c)-A(E[c])^2-Avar(c)\\&=(1-AE[c])E[c]-Avar(c)\end{aligned}</script><p> <strong>CARA 效用</strong></p><script type="math/tex; mode=display">u(c)=-e^{-\alpha c}</script><script type="math/tex; mode=display">Eu(c)=E[-e^{-\alpha c}]=-e^{\alpha E[c]+\frac12\alpha^2var[c]}</script><p>最大化以上的期望效用，等价于最大化</p><script type="math/tex; mode=display">E[c]+\frac12\alpha var[c]</script><p>这便是上讲在证明 CAPM 定价方程式所用到的效用函数形式</p><h1 id="第-9-讲-风险偏好与投资储蓄行为"><a href="#第-9-讲-风险偏好与投资储蓄行为" class="headerlink" title="第 9 讲 风险偏好与投资储蓄行为"></a>第 9 讲 风险偏好与投资储蓄行为</h1><h3 id="9-1-投资者组合配置优化问题"><a href="#9-1-投资者组合配置优化问题" class="headerlink" title="9.1 投资者组合配置优化问题"></a>9.1 投资者组合配置优化问题</h3><p><strong>证明： 只要风险资产的期望收益率比无风险利率高，风险厌恶的投资者就会将其一部分财富投资于风险资产。</strong></p><ul><li>初始财富 $w_0$</li><li>无风险利率 $r_f$</li><li>风险资产收益利率 $\tilde r$</li><li>投资者从初始财富中拿出 $\alpha$ 投资于风险资产</li><li>投资者从初始财富中拿出 $w_0-\alpha$ 投资于无风险资产</li></ul><p>在期末，投资者的财富变为</p><script type="math/tex; mode=display">\begin{align}\tilde w&=(1+r_f)(w_0-\alpha)+\alpha(1+\tilde r)\\&= w_0(1+r_f)+\alpha(\tilde r-r_f)\end{align}</script><p>$u(•)$ 是效用函数。由于效用函数总是增函数（财富越多，效用越高），所以必有 $u’(•)&gt;0$。投资者风险厌恶且其效用函数可导, 因此 $u’’(•)&lt;0$</p><p>投资者通过选择 $\alpha$ 来最大化他期末财富带来的期望效用。</p><script type="math/tex; mode=display">\max_\alpha Eu(\tilde w)=\max_\alpha Eu(w_0(1+r_f)+\alpha(\tilde r-r_f))</script><script type="math/tex; mode=display">E[u'(w_0(1+r_f)+\alpha^*(\tilde r-r_f))(\tilde r-r_f)]=0</script><p><strong>命题 9.1：</strong>如果 $a^*$ 是优化一阶条件式的解，那么有以下 3 个等价关系成立：</p><ol><li>$a^*&gt;0$ 当且仅当 $E\tilde r&gt;r_f$</li><li>$a^*=0$ 当且仅当 $E\tilde r=r_f$</li><li>$a^*&lt;0$ 当且仅当 $E\tilde r&lt;r_f$</li></ol><p><strong>证明：</strong>我们定义值函数如下</p><script type="math/tex; mode=display">V(a)=Eu(w_0(1+r_f)+a(\tilde r-r_f))</script><p>投资者最优化的一阶条件可以写为</p><script type="math/tex; mode=display">V'(a^*)=E[u'(w_0(1+r_f)+a^*(\tilde r-r_f))(\tilde r-r_f)]=0</script><p>由于投资者是风险厌恶的，所以必然有 $u’’(•)&lt;0$。因此对任何 $a$ 都有</p><script type="math/tex; mode=display">V''(a)=E[u''(w_0(1+r_f)+a(\tilde r-r_f))(\tilde r-r_f)^2]<0</script><p>这意味着 $V’(a^<em>)$ 是一个减函数。所以当且仅当 $V’(0)&gt;0$ 时才有 $a^</em>&gt;0$。因为如果 $V’(0)&lt;0$，那么随 $a$ 从 0 开始增大，$V’(0)$会变得更小，一阶条件就不可能成立。而 $V’(0)$ 可以写为</p><script type="math/tex; mode=display">\begin{aligned}V'(0)&=E[u'(w_0(1+r_f))(\tilde r-r_f)]\\&=u'(w_0(1+r_f))E[(\tilde r-r_f)]\end{aligned}</script><p>要使得 $V’(0)&gt;0$，就必须要有</p><script type="math/tex; mode=display">E[(\tilde r-r_f)]>0</script><p>这样，就证明了等价关系 1 。另两个等价关系类似可证。命题得证</p><blockquote><p>对一个之前完全持有无风险资产的投资者来说，把一些财富重新分配到风险资产上的行为会对投资者效用带来两方面的影响。一方面，由于风险资产的期望回报率会高于无风险利率，所以消费者的效用会因为其总投资期<strong>望回报率的上升而上升</strong>。另一方面，由于风险资产的回报存在不确定性，所以投资者效用会因为这种<strong>不确定性的上升而下降</strong>。如果将投资者投入到风险资产上的财富量记为 $a$，则可通过 Arrow-Pratt 近似推导出，当 $a$ 很小的时候，<strong>期望回报率上升带来的效用上升幅度与 $a$ 成正比</strong>。<strong>而回报不确定性上升带来的效用下降幅度与 $a^2$ 成正比</strong>。这样，当 $a$ 很小的时候，期望回报率上升带来的正面效应。总是压倒不确定性上升带来的负面效应。所以，只要风险资产的期望回报率高于无风险利率，投资者就一定会在风险资产上投入一些资产。</p></blockquote><h3 id="9-2-风险资产上的投资量"><a href="#9-2-风险资产上的投资量" class="headerlink" title="9.2 风险资产上的投资量"></a>9.2 风险资产上的投资量</h3><p><strong>命题 9.2：</strong>如果 $a^*$ 是优化一阶条件式的解，那么有以下 3 个等价关系成立：</p><ol><li>$a^{*’}(w_0)&gt;0$ 当且仅当 $R_A’(•)&lt;0$ (DARA)</li><li>$a^{*’}(w_0)=0$ 当且仅当 $R_A’(•)=0$ (CARA)</li><li>$a^{*’}(w_0)&lt;0$ 当且仅当 $R_A’(•)&gt;0$ (IARA)</li></ol><p>初始财富越大，投资者投资于风险资产上的财富量越大（$a^<em>$对 $w_0$的一阶导数大于 0）。我们将这样的偏好称为<strong>绝对风险厌恶下降型偏好</strong>（decreasing absolute risk aversion，简称 DARA）。类似的，对<strong>绝对风险厌恶不变</strong>（CARA）的投资者，投资在风险资产上的财富量与初始财富无关。而表现出<em>*绝对风险厌恶上升</em></em>（increasing absolute risk aversion，简称 IARA）的投资者，由于风险厌恶程度随初始财富增加而增加，所以财富越多，投资在风险资产上的财富量越小</p><p><strong>证明：</strong>我们先来证明 DARA</p><script type="math/tex; mode=display">E[u'(\tilde w)(\tilde r-r_f)]=0</script><script type="math/tex; mode=display">\tilde w= w_0(1+r_f)+a^*(\tilde r-r_f)</script><p>左右两边对 $w_0$ 求导，并注意到 $a^*$ 本身是 $w_0$ 的函数，可得</p><script type="math/tex; mode=display">E[u''(\tilde w)(\tilde r-r_f)[(1+r_f)+(\tilde r-r_f)\frac{da^*}{dw_0}]]=0</script><script type="math/tex; mode=display">(1+r_f)E[u''(\tilde w)(\tilde r-r_f)]+E[u''(\tilde w)(\tilde r-r_f)^2\frac{da^*}{dw_0}]=0</script><p>由于 $da^*/dw_0$ 不是随机变量</p><script type="math/tex; mode=display">\frac {da^*}{dw_0}=-\frac{(1+r_f)E[u''(\tilde w)(\tilde r-r_f)]}{E[u''(\tilde w)(\tilde r-r_f)^2]}</script><p>用绝对风险规避系数来替换效用的二阶导数 $u’’=-R_Au’$</p><script type="math/tex; mode=display">E[u''(\tilde w)(\tilde r-r_f)]=E[-u'(\tilde w)R_A(\tilde w)(\tilde r-r_f)]</script><p>号用连加号写开</p><script type="math/tex; mode=display">E[-u'(\tilde w)R_A(\tilde w)(\tilde r-r_f)]=\sum_{n=1}^Np_n(-u'(w_n))R_A(w_n)(r_n-r_f)</script><p>由于 $a^*&gt;0$，所以如果 $r_n\ge r_f$，则必有 $w_n\ge w_0(1+r_f)$。所以如果 $r_n\le r_f$，则必有 $w_n\le w_0(1+r_f)$。</p><p>因此对任何 n，都有以下不等式成立</p><script type="math/tex; mode=display">(-u'(w_n))R_A(w_n)(r_n-r_f)\ge (-u'(w_n))R_A(w_0(1+r_f))(r_n-r_f)</script><p>又由于风险资产的回报率不是无风险利率，所以在某些可能性下，会有 $r_n\ne r_f$</p><script type="math/tex; mode=display">\sum_{n=1}^Np_n(-u'(w_n))R_A(w_n)(r_n-r_f)>\sum_{n=1}^Np_n(-u'(w_n))R_A(w_0(1+r_f))(r_n-r_f)</script><script type="math/tex; mode=display">\sum_{n=1}^Np_n(-u'(w_n))R_A(w_0(1+r_f))(r_n-r_f)=-R_A(w_0(1+r_f))E[u'(\tilde w)(\tilde r-r_f)]=0</script><p>上面最后等于 0 的这一步用到了一阶条件式。所以 $E[u’’(\tilde w)(\tilde r-r_f)]&gt;0$, $\frac {da^*}{dw_0} &gt;0$。这样便证明了 DARA 情形下的结论。</p><h3 id="9-3-风险资产投资占总财富的比重"><a href="#9-3-风险资产投资占总财富的比重" class="headerlink" title="9.3 风险资产投资占总财富的比重"></a>9.3 风险资产投资占总财富的比重</h3><p>从现实世界的观察来推断，人们大概应该都是绝对风险厌恶程度下降（DARA）的。对这样的人来说，其分配在风险资产上的财富比例会怎样随财富量的变化而变化？即初始财富 $w_0$ 增加 1%的情况下，$a^*$ 会增加百分之多少。</p><p>定义 $a^*$ 对初始财富的弹性为 $e(w_0)$</p><script type="math/tex; mode=display">e(w_0)\stackrel{\Delta}{=}\frac{da^*}{a^*}\bigg/\frac{dw_0}{w_0}=\frac{w_0}{a^*}\frac{da^*}{dw_0}</script><p>这个弹性与初始财富 $w_0$ 之间的关系可总结为如下的命题。</p><p><strong>命题 9.3：</strong>如果 a*是优化一阶条件(9.1)式的解</p><ol><li>$e(w_0)&gt;1$ 当且仅当 $R_A’(•)&lt;0$ (DARA)</li><li>$e(w_0)=1$ 当且仅当 $R_A’(•)=0$ (CARA)</li><li>$e(w_0)&lt;1$ 当且仅当 $R_A’(•)&gt;0$ (IARA)</li></ol><p><strong>证明 ：</strong>利用命题 2 证明过程中推导出来的式子可知</p><script type="math/tex; mode=display">e(w_0)=\frac{w_0}{a^*}\frac{da^*}{dw_0}=-\frac{w_0(1+r_f)E[u''(\tilde w)(\tilde r-r_f)]}{a^*E[u''(\tilde w)(\tilde r-r_f)^2]}</script><script type="math/tex; mode=display">\begin{aligned}e(w_0)-1&=-\frac{w_0(1+r_f)E[u''(\tilde w)(\tilde r-r_f)]+a^*E[u''(\tilde w)(\tilde r-r_f)^2]}{a^*E[u''(\tilde w)(\tilde r-r_f)^2]}\\&=-\frac{E[u''(\tilde w)(\tilde r-r_f)(w_0(1+r_f)+a^*(\tilde r-r_f))]}{a^*E[u''(\tilde w)(\tilde r-r_f)^2]}\\&=-\frac1{a^*}\frac{E[u''(\tilde w)(\tilde r-r_f)\tilde w]}{E[u''(\tilde w)(\tilde r-r_f)^2]}\\&=-\frac1{a^*}\frac{E[-u(\tilde w)R_R(\tilde w)(\tilde r-r_f)]}{E[u''(\tilde w)(\tilde r-r_f)^2]}\end{aligned}</script><p>其中最后一个等式用到了相对风险规避系数的定义。从这里往下的推导过程就与命题9.2 的证明类似。因此命题得证。</p><h3 id="9-4-风险与储蓄"><a href="#9-4-风险与储蓄" class="headerlink" title="9.4 风险与储蓄"></a>9.4 风险与储蓄</h3><p>购买资产是通过牺牲当前的消费来获取未来的消费（因为现金可以买来消费品）。所以，购买资产本质上是一种储蓄行为。</p><p><strong>确定性情况</strong></p><ul><li>消费者在今天拥有初始财富 $w$</li><li>储蓄量为 $s$</li><li>总回报率 $R=1+r$</li><li>今天与明天之间消费者的主观时间偏好为 $\delta (0&lt;\delta&lt;1)$ 。消费者站在今天来看，明天 1 单位的效用只值今天 $\delta$ 单位的效用。</li></ul><p>可以把消费者的优化问题写成</p><script type="math/tex; mode=display">\max_su(w-s)+\delta u(sR)</script><p>一阶条件为</p><script type="math/tex; mode=display">u'(w-s)=\delta Ru'(sR)</script><p>上式左右两边同时对 $R$ 求导，并注意到 $s$ 是 $R$ 的函数，可以得到</p><script type="math/tex; mode=display">\begin{aligned}-u''(w-s)\frac{ds}{dR}&=\delta u'(sR)+\delta Ru''(sR)(s+R\frac{ds}{dR})\\\frac{ds}{dR}&=\frac{\delta u'(sR)+\delta sRu''(sR)}{-u''(w-s)-\delta R^2u''(sR)}\end{aligned}</script><p>上式中的分母因而总是大于 0 的。这样 $ds/dR$ 的符号就由分子的符号决定。可以将分子简单变形为</p><script type="math/tex; mode=display">\begin{aligned}\delta u'(sR)+\delta sRu''(sR)&=\delta u'(sR)[1+\frac{sRu''(sR)}{u'(sR)}]\\&=\delta u'(sR)[1+R_R(sR)]\end{aligned}</script><p>当 $R_R(sR)<1$ 时，$ds dr>0$。这时，储蓄会随回报率的增加而增加。类似可知，当 $R_R(sR)&gt;1$ 时，储蓄随回报率增加而下降，而当 $R_R(sR)=1$ 时，储蓄与回报率无关。</1$></p><p><strong>不同时间与状态间的平滑配置</strong></p><p>回报率的上升会给消费者带来两重影响。一方面，R 越高，今天的储蓄在明天产生的财富更多，促使消费者今天多储蓄、少消费——<strong>这是替代效应</strong>（substitution effect）。另一方面，R 越高，今明两天可用来消费的总财富就更多，今天就应该消费更多——<strong>这是收入效应</strong>（income effect）。最终储蓄会怎样随 R 的变化而变化，取决于替代效应与收入效应谁更强。</p><p>假设消费者可以把一定量的资源在今天与明天自由配置</p><script type="math/tex; mode=display">\max_{w_1,w_2}u(w_1)+\delta u(w_2)</script><script type="math/tex; mode=display">s.t.\quad w_1+w_2=w</script><p>的一阶条件为</p><script type="math/tex; mode=display">u'(w_1)=\delta u'(w_2)</script><p>这说明，在考虑了贴现的因素后，消费者会尽量在两个时点之间平滑财富的配置。</p><blockquote><p>在假设消费者可以在两个不确定的状态中自由配置财富时结果相似，在考虑了概率之后，消费者会尽量在两个状态之间平滑财富的配置。这不是偶然。这是因为我们假设的跨期效用和这个目标函数形式与期望效用函数的形式是类似的，差别只是在前者以贴现率为权重相加，后者以概率为权重相加。</p><p>然而，消费者在不同时间平滑配置的倾向，与在不同状态间平滑配置的倾向是不一样的两个概念。但在这里数学框架中，他们都用相对风险规避系数<br>这一个指标来刻画。这不会带来 “风险溢价难题”（risk premium puzzle）</p></blockquote><p>在前面提到的两种效应中，替代效应会促使人在不同时间做出非平滑的配置——哪个时点配置价值更高就多配那里。而收入效应会促使人在不同时间做平滑配置。对那些风险规避程度更高的人来说，其平滑配置的意愿更大，收入效应就会压倒替代效应，因而回报率越高，储蓄越少。</p><p><strong>不确定的状况</strong></p><p>假设资产的总回报率 $\tilde R$ 是一个随机变量。这里，我们关心的问题是当 $\tilde R$ 的期望不变，但风险变得更大的时候，消费者现在的储蓄会怎样变化。</p><p>如果回报率的风险度上升，那么意味着储蓄的价值下降（可能更容易碰上不好的回报率实现值）。这时还不如减少储蓄，增加当前确定的消费。我们可以把这种回报率风险度上升压低储蓄的倾向理解为一种<strong>替代效应</strong>。但另一方面，还有人可能会认为正因为未来不确定性上升，所以更应该多储蓄来为未来可能出现的不利局面做好准备。这种因为风险度上升而增加储蓄的动机叫做<strong>预防性储蓄</strong>（precautionary saving）动机。</p><p>可以把消费者的优化问题写成</p><script type="math/tex; mode=display">\max_su(w-s)+\delta E[u(s\tilde R)]</script><p>一阶条件为</p><script type="math/tex; mode=display">u'(w-s)=\delta E[\tilde Ru'(s\tilde R)]</script><p>假设当储蓄 s 增加时，左边变大，因此右边也需要同时增大。如果定义函数 $g(R)\equiv Ru’(sR)$ , s 增大时 $g(R)$ 期望取需变大，因此为凸函数。</p><p><img src="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/pic9-1.jpg" alt></p><p>可以计算</p><script type="math/tex; mode=display">\begin{align}g'(R)&=u'(sR)+sRu''(sR)\\g''(R)&=2su'(sR)+s^2Ru''(sR)\\\end{align}</script><p>这里我们引入 Kimball 于 1990 年首次提出的<strong>“审慎”</strong>（prudence）的概念。定义绝对审慎系数 $P_A(y)$ 为</p><script type="math/tex; mode=display">P_A(y)\stackrel{\Delta}{=}-\frac{u'''(y)}{u''(y)}</script><p>相对审慎系数 $P_R(y)$ 为</p><script type="math/tex; mode=display">P_R(y)\stackrel{\Delta}{=}-\frac{yu'''(y)}{u''(y)}</script><p>于是</p><script type="math/tex; mode=display">g''(R)=su''(sR)(2+\frac{sRu'''(sR)}{u''(sR)})=su''(sR)(2-P_R(sR))</script><p>只有 $P_R(sR)&gt;2$ 时，$g’’(R)&gt;0$，此时回报率 $\tilde R$ 风险的扩大将增大一<br>期的储蓄 s。相反，如果 $P_R(sR)&lt;2$，回报率风险的扩大将减少一期的储蓄。</p><p><strong>命题 9.4：</strong>令 $\tilde R_A$与 $\tilde R_B$ 是两个随机收益，且 $\tilde R_B$ 是 $\tilde R_A$ 的保均展形（$\tilde R_B$风险更高）。若 $s_A$ 与 $s_B$ 分别是初始财富为 w 的风险厌恶投资者分别在面对 $\tilde R_A$ 与 $\tilde R_B$ 两种情况时做出的储蓄，那么有以下三个等价关系成立：</p><ol><li>$s_A&gt;s_B$，当且仅当 $P_R(sR)&lt;2$</li><li>$s_A=s_B$，当且仅当 $P_R(sR)=2$</li><li>$s_A<s_B$，当且仅当 $p_r(sr)2>$</s_B$，当且仅当></li></ol><p>越是审慎的人（相对审慎系数越大）越会增加储蓄。对这些审慎的人，预防性储蓄的动机压过了替代效应。</p><p> <strong>CRRA 效用函数的绝对审慎系数</strong></p><script type="math/tex; mode=display">\begin{aligned}u'(c)&=c^{-\gamma}\\u''(c)&=-\gamma c^{-\gamma-1}\\u'''(c)&=\gamma(\gamma+1)c^{-\gamma-2}\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}P_A(c)&=\frac{u'''(c)}{u''(c)}=-\frac{\gamma(\gamma+1)c^{-\gamma-2}}{-\gamma c^{-\gamma-1}}=\frac{\gamma+1}c\\P_B(c)&=cP_A(c)=\gamma+1\end{aligned}</script><h1 id="第-10-讲-求解完备市场中的一般均衡"><a href="#第-10-讲-求解完备市场中的一般均衡" class="headerlink" title="第 10 讲 求解完备市场中的一般均衡"></a>第 10 讲 求解完备市场中的一般均衡</h1><h3 id="10-1-不确定性的模型描述"><a href="#10-1-不确定性的模型描述" class="headerlink" title="10.1 不确定性的模型描述"></a>10.1 不确定性的模型描述</h3><ul><li><p>状态 s (共 S 种可能)</p></li><li><p>s 发生的概率 $\pi_s$ ($0&lt;\pi_s\le 1, \sum_s\pi_s=1$)</p></li><li><p>$\Pi=\{\pi_s,s\in S\}$ 概率测度（probability measure）</p></li><li><p>风险资产的回报率 $(r_1,r_2,…,r_S)^T$</p></li><li><p>在 1 时期状态 s 中的支付  $x_s$</p></li><li><p>资产 j 的支付 $X^j=(x_1^j,x_2^j,…,x_S^j)^T$</p></li><li><p>市场中共有 J 种可交易的资产，整个资产市场的支付矩阵（payoff matrix）</p><script type="math/tex; mode=display">X\stackrel{\Delta}{=}\begin{bmatrix}x_1^1&...&x_1^J\\...&...&...\\x_S^1&...&x_S^J\end{bmatrix}</script><p>或者 $ X=[X^1\quad…\quad X^j]$</p></li><li><p>资产组合（portfolio）$\theta = (\theta_1,…,\theta_J)^T$</p></li><li><p>资产组合在各个状态下的支付</p><script type="math/tex; mode=display">\begin{bmatrix}\sum_{j=1}^Jx_1^j\theta_j\\...\\\sum_{j=1}^Jx_S^j\theta_j\end{bmatrix}=X\theta</script></li><li><p>J 种资产在0期的价格 $P\stackrel{\Delta}{=}[p_1\quad…\quad p_J]$</p></li><li><p>资产组合 $\theta$ 在0期的价值 $\sum_{j=1}^Jp_j\theta_j$</p></li><li><p>1 期的消费计划 $C=(x_1,…,c_s)^T$, $c_s=\sum_{j=1}^Jx_s^j\theta_j$</p></li></ul><h3 id="10-2-完备市场和-Arrow-Debreu-市场"><a href="#10-2-完备市场和-Arrow-Debreu-市场" class="headerlink" title="10.2 完备市场和 Arrow-Debreu 市场"></a>10.2 完备市场和 Arrow-Debreu 市场</h3><p><strong>定义 10.1：</strong>我们称一个资产市场 X 是<strong>完备</strong>（complete）的，如果任何一个 1 期的消费计划都可以通过某个资产组合来实现。</p><p>如果资产的数目 J 还不如状态的数目 S 多，那么方程数目就多于未知数的数目，方程组就无解。所以，一个完备的市场中，资产的数目至少要和状态的数目一样多。<strong>从经济学意义上来说，所谓完备市场，就是消费者可以通过买卖市场上的资产，在任何两个状态之间调配资源。而从数学上来看，完备市场就是可以从市场上找到与状态数同样多的资产，这些资产支付构成了一个满秩（可逆）的方阵。</strong> 因此，检验一个市场是否完备的更简单方法是直接看描述这个市场的支付矩阵$X$ 是否是可逆的。</p><p>有与状态数目一样多的资产，且每种资产都分别仅在一种状态中有 1 的支付，而在其他状态中无支付。这种资产市场被叫做 <strong>Arrow—Debreu 市场</strong>（Arrow—Debreu Market）。</p><script type="math/tex; mode=display">I\stackrel{\Delta}{=}\begin{bmatrix}1&0&...&0\\0&1&...&0\\...&...&...&...\\0&0&...&1\end{bmatrix}</script><p>Arrow-Debreu 市场中的资产叫做 Arrow 证券（Arrow security）。Arrow 证券就是只在某一状态中有 1 单位支付，而在其他状态的支付为 0。我们以 $I_s$ 来代表在 s 状态下有 1 单位支付的 Arrow 证券。其支付向量可以写成</p><script type="math/tex; mode=display">I_s=\begin{bmatrix}0\\...\\1\\...\\0\end{bmatrix}</script><p>我们将 Arrow 证券 $I_s$ 在当前（0 期）的价格记为 $\varphi_s$。所有Arrow 证券的价格可以合起来写成 $\varphi\stackrel{\Delta}{=}[\varphi_1\quad…\quad\varphi_S]$</p><p>Arrow 证券的价格有一个专门的名称叫做<strong>状态价格</strong>（state price）。因为它给出了 1 期某个状态下 1 单位支付在 0 期的价格。</p><p>Arrow 证券价格是资产定价的关键。由于任何一个资产都可以表示成为 Arrow 证券的一个组合，因此知道了所有 Arrow 证券的价格，就知道了所有资产的价格。</p><p>支付向量为 $x_j$ 的资产当前的价格为</p><script type="math/tex; mode=display">p_j=\varphi X^j =\sum_{s=1}^S\varphi_sx_s^j</script><p>所有 J 种资产的价格向量可写为</p><script type="math/tex; mode=display">P=\varphi X=[\varphi X^1\quad...\quad\varphi X^S]=[\sum_{s=1}^S\varphi_sx_s^1\quad...\quad\sum_{s=1}^S\varphi_sx_s^J]</script><p>无风险资产是在各个状态中支付都为 1 的资产，如果记无风险资产在 0 期的价格为 $\rho$，它必然等于所有 Arrow 证券的价格之和</p><script type="math/tex; mode=display">\rho=\varphi 1=\sum_{s=1}^S\varphi_s</script><h3 id="10-3-完备市场中的均衡"><a href="#10-3-完备市场中的均衡" class="headerlink" title="10.3 完备市场中的均衡"></a>10.3 完备市场中的均衡</h3><p>我们假设消费者具有如下的 vNM 效用函数</p><script type="math/tex; mode=display">u(c_0)+\delta\sum_{s=1}^S\pi_su(c_s)</script><p>假设消费者在 0 期有消费品禀赋 $e_0$</p><p>消费者的优化问题可以写为</p><script type="math/tex; mode=display">\max_{\theta_1,...,\theta_J} u(c_0)+\delta\sum_{s=1}^S\pi_su(c_s)</script><script type="math/tex; mode=display">\begin{aligned}s.t.\qquad c_0&=e_0-\sum_{j=1}^Jp_j\theta_j\\c_s&=e_s+\sum_{j=1}^Jx_s^j\theta_j\quad (s=1,...,S)\end{aligned}</script><p>由于我们讨论的是完备的市场，所以消费者对 J 种资产的组合选择问题可以简化为对 S 种Arrow 证券的选择。而前面我们已经看到，Arrow 证券在 1 期的支付是非常简单的。这样，消费者的优化问题的约束可以改写为</p><script type="math/tex; mode=display">\begin{aligned}s.t.\qquad c_0&=e_0-\sum_{s=1}^S\varphi_s\theta_s\\c_s&=e_s+\theta_s\quad (s=1,...,S)\end{aligned}</script><p>将 1 期的预算约束代入 0 期的预算约束中，消去所有的 $\theta_s$，消费者的优化问题的约束可改写为</p><script type="math/tex; mode=display">s.t.\qquad c_0+\sum_{s=1}^S\varphi_s(c_s-e_s)=e_0</script><p>建立拉格朗日函数为</p><script type="math/tex; mode=display">\mathcal L=u(c_0)+\delta\sum_{s=1}^S\pi_su(c_s)+\lambda(e_0-c_0-\sum_{s=1}^S\varphi_s(c_s-e_s))</script><p>其一阶条件为</p><script type="math/tex; mode=display">\begin{aligned}&\frac{\partial\mathcal L}{\partial c_0}=0:\quad u'(c_0)=\lambda\\&\frac{\partial\mathcal L}{\partial c_s}=0:\quad \delta\pi_su'(c_s)=\lambda\varphi_s\qquad s=1,...,S\end{aligned}</script><p>将一阶条件代入预算约束 $c_0+\sum_{s=1}^S\varphi_s(c_s-e_s)=w_0$ 可得</p><script type="math/tex; mode=display">u'^{-1}(\lambda)+\sum_{s=1}^S\varphi_s(u'^{-1}(\lambda\varphi_s/\delta\pi_s)-e_s)=e_0</script><p>这是一个只包含拉格朗日乘子 $\lambda$ 的方程，因而可以从中解出 $\lambda$。将其带入一阶条件，即可求出消费者的 Arrow 证券组合选择。它是 Arrow 证券价格的函数。再代入市场出清条件——在每个时间每个状态下经济中的总消费都应该等于总禀赋——就能求出 Arrow 证券的价格。这样，消费者的组合选择和消费也就都能确定下来，均衡就完全求出了。</p><p>额外的讨论，对于一阶条件，有</p><script type="math/tex; mode=display">\frac{\delta\pi_su'(c_s)}{u'(c_0)}=\varphi_s</script><p>以及</p><script type="math/tex; mode=display">\frac{\pi_su'(c_s)}{\pi_{s'}u'(c_{s'})}=\frac{\varphi_s}{\varphi_{s'}}</script><p>这意味着 Arrow 证券价格与对应状态发生的概率，以及消费者在这一状态中的边际效用成正比。</p><h1 id="第-11-讲-完备市场中一般均衡的性质"><a href="#第-11-讲-完备市场中一般均衡的性质" class="headerlink" title="第 11 讲 完备市场中一般均衡的性质"></a>第 11 讲 完备市场中一般均衡的性质</h1><p>经济学家用一个不包含哲学层面价值判断意义的标准来评价一个均衡的结果是好还是不好——<strong>帕累托最优</strong>（Pareto Optimality）。帕累托最优用对资源的利用效率来做评价标准。简单来说，如果在不降低其他所有人福利（效用）的前提下，增加经济中某个人的福利（效用），那当前的状况就不是帕累托最优。这表明，在当前的状况下，有经济资源没有充分地被利用起来。从经济的角度来看，当前的状况就不能算是“最好”。</p><p>在这里，我们要利用的最重要条件是消费者的跨期优化条件。它将资产价格与消费者的消费联系了起来。正因为此，这里所阐述的资产定价逻辑叫做基于消费的<strong>资本资产定价模型</strong>（Consumption based CAPM，简称C-CAPM）。</p><h3 id="11-1-最优风险分担"><a href="#11-1-最优风险分担" class="headerlink" title="11.1 最优风险分担"></a>11.1 最优风险分担</h3><p>在经济和金融分析中，我们用一个宗教气息没有那么浓的称谓来称呼前面说的这个上帝，我们将其称为<strong>中央计划者</strong>（central planner）。这个中央计划者有无限的信息获取和资源配置权，并且关心所有人的福利。中央计划者会做出的资源配置就是帕累托最优。</p><p>我们假设经济中存在 K 位消费者。每位消费者在中央计划者心中的相对重要性以权重 $\mu_k$ 衡量。中央计划者在全社会预算总约束内（总消费不能超过总禀赋）任意调配资源，以最大化所有人的加权期望效用和。中央计划者的最优化问题可以写为</p><script type="math/tex; mode=display">\max_{\{c_{k0},c_{k1},...,c_{kS}\}_{k=1}^K}\sum_{k=1}^K\mu_k[u_k(c_{k0})+\delta_k\sum_{s=1}^S\pi_su_k(c_{ks})]</script><script type="math/tex; mode=display">\begin{aligned}s.t.\qquad \sum_{k=1}^Kc_{k0}&=\sum_{k=1}^Ke_{k0}\\\sum_{k=1}^Kc_{ks}&=\sum_{k=1}^Ke_{ks}\quad (s=1,...,S)\end{aligned}</script><p>由此可以看出，我们在通过中央计划者问题求解帕累托最优时，并不涉及任何有关收入分配的价值判断。帕累托最优只要求没有资源被浪费而已。中央计<br>划者在宽泛约束下所选择的资源分配（以及福利状况）就代表了任何资源配置机制所可能达到的福利状况的上限。</p><p>为了求解中央计划者问题，设立拉格朗日函数如下</p><script type="math/tex; mode=display">\mathcal L=\sum_{k=1}^K\mu_k[u_k(c_{k0})+\delta_k\sum_{s=1}^S\pi_su_k(c_{ks})]+\eta_0[\sum_{k=1}^Ke_{k0}-\sum_{k=1}^Kc_{k0}]+\sum_{s=1}^S\eta_s[\sum_{k=1}^Ke_{ks}-\sum_{k=1}^Kc_{ks}]</script><p>其一阶条件为</p><script type="math/tex; mode=display">\begin{aligned}&\frac{\partial\mathcal L}{\partial c_{k0}}=0:\quad \mu_ku_k'(c_{k0})=\eta_0\\&\frac{\partial\mathcal L}{\partial c_{ks}}=0:\quad \mu_k\delta_k\pi_su_k'(c_{ks})=\eta_s\qquad s=1,...,S\end{aligned}</script><p>从中可以解出</p><script type="math/tex; mode=display">\begin{aligned}c_{k0}&=u_k'^{-1}(\eta_0/\mu_k)\\c_{ks}&=u_k'^{-1}(\eta_s/\mu_k\delta_k\pi_s)\end{aligned}</script><p>在上一讲中我们曾经在一般均衡的框架下求解过消费者的最优化问题。其优化一阶条件为</p><script type="math/tex; mode=display">\begin{aligned}&u_k'(c_{k0})=\lambda_k\\&\delta_k\pi_su_k'(c_{ks})=\lambda_k\varphi_s\qquad s=1,...,S\end{aligned}</script><p>从中可以解出</p><script type="math/tex; mode=display">\begin{aligned}c_{k0}&=u_k'^{-1}(\lambda_k)\\c_{ks}&=u_k'^{-1}(\lambda_k\varphi_s/\delta_k\pi_s)\end{aligned}</script><p>比较可以发现，如果令 $\lambda_k=\eta_0/\mu_k，\varphi_s=\eta_s/\eta_0$，那么由中央计划者问题得到的配置和相应财富分布下的均衡配置完全一样。换言之，如果将各个消费者的初始财富调整到适当的水平（这相当于在调整 λk），就可以通过均衡来实现中央计划者问题中求取的最优风险分担。因此，有如下<strong>福利经济学第二定理</strong>（Second Theorem of Welfare Economics）在金融市场均衡中的版本。</p><p><strong>定理 11.1（福利经济学第二定理）：</strong>在完备市场中，任何一个帕累托最优配置都可以由某个对应某种财富初始分配的市场均衡来达到。<br><strong>定理 11.2（福利经济学第一定理）：</strong>在完备市场中，任何一个由市场均衡所形成的资源分配都是帕累托最优的。</p><h3 id="11-2-最优风险分担的特性"><a href="#11-2-最优风险分担的特性" class="headerlink" title="11.2 最优风险分担的特性"></a>11.2 最优风险分担的特性</h3><p>下面，我们就来研究最优风险分担下——同时也是均衡下——各个消费者的消费状况。</p><script type="math/tex; mode=display">c_s=\sum_{k=1}^Kc_{ks}=\sum_{k=1}^Ku_k'^{-1}(\eta_s/\mu_k\delta_k\pi_s)</script><p>可以用上面的方程把 $\eta_s$ 表示为状态 s 下的总消费（$c_s$）的函数</p><script type="math/tex; mode=display">\eta_s=g(c_s)=g(e_s)</script><p>其中第二个等号用到了市场出清条件,代回得</p><script type="math/tex; mode=display">c_{ks}=u_k'^{-1}(g(e_s)/\mu_k\delta_k\pi_s)</script><p>在决定 $c_{ks}$ 的函数自变量中，有状态下的总禀赋 $e_s$（所有消费者在这个状态下的禀赋之和），而没有消费者 k 自己在这个状态下的禀赋 $e_{ks}$ 。</p><p>我们中央计划者问题中表示各消费者权重的$\mu_k$应该按照一般均衡中各个消费者的财富多寡来设定。而消费者财富可以理解为她在各期和各状态中禀赋的 0 期现值和。从这个意义上来说，式中的$\mu_k$ 里还是包含了消费者个人的禀赋 $e_{ks}$  的。但要严格写出来，$\mu_k$的函数应该写成</p><script type="math/tex; mode=display">\mu_k(e_{k0}+\sum_{s=1}^S\varphi_se_{ks})</script><p>所以，消费者 k 在 s 状态下的消费只与总禀赋 $e_s$ 和消费者自己的财富有关。而与自己的财富在各个时期的波动无关。</p><p><strong>定理 11.3：</strong>完备市场中达到均衡时，消费者在不同状态中消费的波动，只与各个状态中总禀赋的波动有关，而与这个消费者自己禀赋在各个状态中的波动无关。</p><p><strong>定理 11.4：</strong>对于任意两个状态 s 与 s’，如果有 $c_s&gt;c_s’$，则对任意消费者 k，必有 $c_{ks}&gt;c_{ks’}$。</p><p>不过，所有消费者的消费在不同状态中虽然同向波动，但波动的幅度却未必是一样的。可以直观地想到，那些风险厌恶度更大的消费者，更愿意平滑其不同状态下的消费（让各个状态下的消费差异变小）。反过来，那些风险厌恶度较小的消费者就没有那么强的平滑消费的动力。因此，那些风险厌恶度小的消费者，其不同状态下消费的离散程度应该更大。相应地，他们就承担了更多的总体风险。而通过承担更多的总体风险，他们也能获得更高的期望消费。</p><p><strong>定理 11.5（Wilson 定理）：</strong>每位消费者所承担的边际总体风险等于他的绝对风险容忍度占所有消费者绝对风险容忍度总和的比重。如果定义<strong>绝对风险容忍度</strong>（absolute risk tolerance）T为绝对风险规避系数的倒数。即</p><script type="math/tex; mode=display">T(c)\stackrel{\Delta}{=}\frac1{R_A(c)}=-\frac{u'(c)}{u''(c)}</script><p>则消费者在某状态下的消费因总禀赋的变化而变化的幅度，等于其绝对风险容忍度占社会总风险容忍度的比重</p><script type="math/tex; mode=display">\frac{dc_{ks}}{de_s}=\frac{T_k(x_{ks})}{\sum_{k=1}^KT_k(c_{ks})}</script><p>Wilson 定理的证明在本讲附录中。这个定理说明，绝对风险容忍度越高（绝对风险厌恶系数越小）的消费者，其消费在不同状态下的波动性会更大。反过来，绝对风险容忍度越低的消费者，其消费在不同状态下的波动会更小。因此，实现最优风险分担的时候，那些风险容忍度高的人会承担更多的风险。如果有一位消费者是风险中性的，她的绝对风险厌恶系数应该等于 0，她的绝对风险容忍度会是无穷大。因此，如果这位风险中性的消费者的财富足够大，她会承担经济中的所有风险——只有她不同状态下的消费会有波动，而其他所有人的消费都不随状态的变化而变化。</p><p>这是分散风险这一概念在一般均衡框架下的体现。在一般均衡中，总禀赋在不同状态下的波动被称为<strong>总体风险</strong>（aggregated risk）。而消费者各自禀赋在不同状态下的波动可能大于总禀赋的波动。这部分叫做<strong>个体风险</strong>（idiosyncratic risk）。通过完备的金融市场，消费者可以通过分散化消除掉那些个体风险，而让自己只承受总体风险。</p><h3 id="11-3-代表性消费者"><a href="#11-3-代表性消费者" class="headerlink" title="11.3 代表性消费者"></a>11.3 代表性消费者</h3><p>从 C-CAPM 的名字能看出来，这是一个把资产定价和消费联系在一起的理论。其核心思想是，资产不过是在不同时间和不同状态下调整资源配置的工具。而消费者配置资源的目的是为了尽可能提升自己从消费中获得的效用。这样一来，消费者的消费行为就和资产价格之间有了紧密联系，可以用消费来决定资产价格。</p><p>上一讲给出的消费者优化问题</p><script type="math/tex; mode=display">\max_{\theta_1,...,\theta_J} u(c_0)+\delta\sum_{s=1}^S\pi_su(c_s)</script><script type="math/tex; mode=display">\begin{aligned}s.t.\qquad c_0&=e_0-\sum_{j=1}^Jp_j\theta_j\\c_s&=e_s+\sum_{j=1}^Jx_s^j\theta_j\quad (s=1,...,S)\end{aligned}</script><p>为了直接看到每种资产的价格，这里我们不把这个问题转化为对 Arrow 证券的选择问题。将约束条件带入目标函数，可以将优化问题化为</p><script type="math/tex; mode=display">\max_{\theta_1,...,\theta_J} u(e_0-\sum_{j=1}^Jp_j\theta_j)+\delta\sum_{s=1}^S\pi_su(e_s+\sum_{j=1}^Jx_s^j\theta_j)</script><p>一阶条件为</p><script type="math/tex; mode=display">p_ju'(c_0)=\delta\sum_{s=1}^S\pi_su'(c_s)x_s^j</script><p>$x_j^s/p_j$ 应该等于资产 j 在 s 状态下的（事后）总回报率 $1+r_s$</p><script type="math/tex; mode=display">1=\delta\sum_{s=1}^S\pi_s\frac{u'(c_s)}{u'(c_0)}(1+r_s)</script><p>将连加号的形式改写为期望的形式，上式可以改写为</p><script type="math/tex; mode=display">1=E[\delta\frac{u'(\tilde c_1)}{u'(c_0)}(1+\tilde r_j)]</script><p>把表示消费者的下标 k 加回到上面这个式子，可得</p><script type="math/tex; mode=display">1=E[\delta\frac{u_k'(\tilde c_{k,1})}{u_k'(c_{k,0})}(1+\tilde r_j)]</script><p>这个式子给出了各种资产期望回报率应该满足的条件，因而也是资产定价的方程。这个方程就是 C-CAPM 的核心定价方程。</p><p>所谓<strong>代表性消费者</strong>（representative consumer），是我们为了金融和经济分析，人为构造出来的一个虚拟消费者。代表性消费者的消费和禀赋是经济中的总消费和总禀赋。代表性消费者的偏好是所有消费者偏好的平均。这样，我们就可以通过代表性消费者将资产价格和宏观数据联系起来。</p><p>当然，要将所有消费者加总成为一个代表性消费者，需要一定前提条件。禀赋在不同消费者之间做不同的分布，所产生的均衡资产价格有可能是不同的。而在将所有消费者加总为代表性消费者的过程中，禀赋和消费在不同消费者之间的分布<strong>信息也必然会损失掉。</strong>由于金融关注的对象是资产价格，我们因而希望能够找到一种消费者的偏好形式，<strong>使得在这种偏好之下，禀赋在不同消费者之间的分布并不影响资产价格。</strong>这样，我们通过代表性消费者求得的资产价格，就会等同于非加总情况下求取的资产价格。1974 年，Rubinstein 给出了这个条件。其结论用定理的形式陈述如下。</p><p><strong>定理 11.6：</strong>如果所有消费者具有如下的 HARA 型效用函数</p><script type="math/tex; mode=display">u_k(c_k)=\frac{(c_k-d_K)^{1-\gamma}}{1-\gamma}</script><p>其中 $\gamma&gt;0$，那么这些消费者的行为可以用效用函数如下的代表性消费者来加以概括</p><script type="math/tex; mode=display">u(c)=\frac{(c-d)^{1-\gamma}}{1-\gamma}</script><p>代表性消费者的消费为所有消费者的总消费（$c=\sum_kc_k$），禀赋为所有消费者的总禀赋。</p><h3 id="11-4-均衡中的资产价格"><a href="#11-4-均衡中的资产价格" class="headerlink" title="11.4 均衡中的资产价格"></a>11.4 均衡中的资产价格</h3><p>有了代表性消费者之后，我们可以用她来替代一般均衡模型中的所有消费者。相应地，资产定价的方程就变成代表性消费者的优化一阶条件</p><script type="math/tex; mode=display">1=E[\delta\frac{u'(\tilde c_1)}{u'(c_0)}(1+\tilde r_j)]</script><p>定义 $\tilde m$ 为</p><script type="math/tex; mode=display">\tilde m\stackrel{\Delta}{=}\delta\frac{u'(\tilde c_1)}{u'(c_0)}</script><p>式可被改写为</p><script type="math/tex; mode=display">1=E[\tilde m(1+\tilde r_j)]</script><p>$\tilde m$ 是个非常重要的随机变量，叫<strong>随机折现因子</strong>（stochastic discount factor）</p><p>对于无风险资产</p><script type="math/tex; mode=display">1=E[\tilde m(1+r_f)]</script><p>与前式相减</p><script type="math/tex; mode=display">0=E[\tilde m(\tilde r_j-r_f)]</script><p>式可改写为</p><script type="math/tex; mode=display">\begin{aligned}0&=E[\tilde m]E[\tilde r_j-r_f]+cov(\tilde m,\tilde r_j-r_f)\\\Rightarrow 0&=E[\tilde m](E[\tilde r_j]-r_f)+cov(\tilde m,\tilde r_j)\\\Rightarrow 0&=\frac{E[\tilde r_j]-r_f}{1+r_f}+cov(\tilde m,\tilde r_j)\end{aligned}</script><p>上式进一步整理，就得</p><script type="math/tex; mode=display">E[\tilde r_j]-r_f=-(1+r_f)cov(\tilde m,\tilde r_j)</script><p>即是 C-CAPM 定价公式的又一种表达。</p><p>为了让这个式子的经济学含义更加清楚，我们将随机折现因子的形式写出来，即</p><script type="math/tex; mode=display">\begin{aligned}E[\tilde r_j]-r_f&=-(1+r_f)cov(\delta\frac{u'(\tilde c_1)}{u'(c_0)},\tilde r_j)\\&=-\frac{\delta(1+r_f)}{u'(c_0)}cov(u'(\tilde c_1),\tilde r_j)\end{aligned}</script><p>某项资产的回报率与未来消费边际效用的协方差越高（这意味着回报率与未来消费的协方差越低）,这项资产的期望超额回报率就越低。</p><blockquote><p>一种资产如果在消费比较低，消费边际效用比较高的状态时有较高的回报，说明它在消费者最需要消费的时候提供较多回报，属于雪中送炭型资产。消费者自然会更愿意持有这种资产，从而令这种资产的风险溢价和期望回报率较低，价格较高。相反，如果一种资产在消费很多的时候回报较高，那就算锦上添花型资产，消费者对其的评价不会太高，资产的风险溢价就会比较高，当前的价格就会较低。</p></blockquote><p>对回报率的定义式（$\tilde r_j=\tilde x_j/p_j-1$）两边取期望，有</p><script type="math/tex; mode=display">E[\tilde r_j]=E[\frac{\tilde x_j}{p_j}-1]\Rightarrow E[\tilde r_j]=\frac{E[\tilde x_j]}{p_j}-1</script><p>变形可得</p><script type="math/tex; mode=display">p_j=\frac{E[\tilde x_j]}{1+E[\tilde r_j]}=E[\tilde x_j]/[1+r_f-\frac{\delta(1+r_f)}{u'(c_0)}cov(u'(\tilde c_1),\tilde r_j)]</script><p>这就是给出了资产当前价格的“现值公式”</p><p><strong>作为</strong> <strong>C-CAPM</strong> <strong>一个特例的</strong> <strong>CAPM</strong></p><p>如果假设消费者的效用函数为二次型（quadratic utility），即 $u(c)=-ac^2+bc (a&gt;0)$。 则消费者的边际效用为线性函数 $u’(c)=-2ac+b$。令市场组合 M 为对经济中的总禀赋的要求权——组合 M 的回报就是经济的总禀赋（$x_s^M=e_s=c_s$）。将其代入随机折现因子的定义式</p><script type="math/tex; mode=display">\tilde m\stackrel{\Delta}{=}\delta\frac{u'(\tilde c_1)}{u'(c_0)}=\delta\frac{-2a\tilde c_1+b}{-2ac_0+b}</script><p>将其代入 C-CAPM 定价公式</p><script type="math/tex; mode=display">E[\tilde r_j]-r_f=-(1+r_f)cov(\delta\frac{-2a\tilde c_1+b}{-2ac_0+b},\tilde r_j)=\delta\frac{2a(1+r_f)}{-2ac_0+b}cov(\tilde c_1,\tilde r_j)</script><p>$\tilde r_M=\tilde c_1/p_M-1$ 代入</p><script type="math/tex; mode=display">\begin{aligned}E[\tilde r_j]-r_f&=\delta\frac{2a(1+r_f)p_M}{-2ac_0+b}cov(\frac{\tilde c_1}{p_M}-1,\tilde r_j)\\&=\delta\frac{2a(1+r_f)p_M}{-2ac_0+b}cov(\tilde r_M,\tilde r_j)\end{aligned}</script><p>上面这个式子对市场组合 <em>M</em> 本身也成立，所以有 </p><script type="math/tex; mode=display">E[\tilde r_M]-r_f=\delta\frac{2a(1+r_f)p_M}{-2ac_0+b}var(\tilde r_M)</script><p>上两式相除可得</p><script type="math/tex; mode=display">\frac{E[\tilde r_j]-r_f}{E[\tilde r_M]-r_f}=\frac{cov(\tilde r_M,\tilde r_j)}{var(\tilde r_M)}</script><p>定义 $\beta_j=\frac{cov(\tilde r_M,\tilde r_j)}{var(\tilde r_M)}$, 可得CAPM定价方程</p><script type="math/tex; mode=display">E[\tilde r_j]-r_f=\beta_j(E[\tilde r_M]-r_f)</script><h1 id="第-12-讲-C-CAPM-及其讨论"><a href="#第-12-讲-C-CAPM-及其讨论" class="headerlink" title="第 12 讲 C-CAPM 及其讨论"></a>第 12 讲 C-CAPM 及其讨论</h1><p>在一般均衡的框架下推导出了如下的资产定价方程</p><script type="math/tex; mode=display">p_j=E[\delta\frac{u'(\tilde c_1)}{u'(c_0)}\tilde x_j]</script><p>或者不那么严格，但却更加简略地写成</p><script type="math/tex; mode=display">p=E(mx)</script><p>任何一种资产定价理论都可最终化成这样的形式。因此，资产定价问题也就归结为如何找出随机折现因子的问题。一个资产定价理论就是一种确定随机折现因子的方法：在理论上，必须要给出随机折现因子构造的方法，说明它反映了何种影响资产价格的力量；而在实践中，需要将随机折现因子和现实世界中可观测的指标联系起来，从而可以实际运用其来给各类资产定价。由于在这里，决定随机折现因子的核心因素是消费，且 CAPM 可以作为一个特例而包括在这一框架中，所以这一资产定价理论就叫做基于消费的资本资产定价模型（C-CAPM）。</p><p>对于式子，可以从两个方向来理解。一方面，在已知消费（$c_0，\tilde c_1$）和支付（$\tilde x_j$）的前提下，这个式子可以告诉我们资产当前价格（$p_j$）应该是多少。另一方面，这个式子还可以稍微变形成</p><script type="math/tex; mode=display">u'(c_0)=E[\delta u'(\tilde c_1)(1+\tilde r_j)]</script><p>上式告诉了我们消费者会如何选择消费</p><p><strong>在一般均衡中，所有因素都相互影响,任意两个内生变量之间都存在着双向的因果关系。</strong></p><p>理清了 C-CAPM 的思路后，下面我们用这个模型来分析一些重要的金融问题。我们知道，资产的期望回报率由无风险利率和资产的风险溢价共同决定。所以，对资产定价的研究需要从无风险利率和风险溢价两方面切入。</p><h3 id="12-1-无风险利率的决定"><a href="#12-1-无风险利率的决定" class="headerlink" title="12.1 无风险利率的决定"></a>12.1 无风险利率的决定</h3><p>如果无风险利率为 $r_f$，则有</p><script type="math/tex; mode=display">1=E[\tilde m(1+r_f)]\Rightarrow r_f=\frac1{E[\tilde m]}-1</script><p>定义消费的增长率为</p><script type="math/tex; mode=display">\tilde g\equiv\frac{\tilde c_1}{c_0}-1</script><p>因此，随机折现因子可以利用二阶泰勒展开变形为</p><script type="math/tex; mode=display">\begin{aligned}\tilde m&=\delta\frac{u'(c_0(1+\tilde g))}{u'(c_0)}\\&\approx\frac\delta{u'(c_0)}[u'(c_0)+u''(c_0)c_0\tilde g+\frac12u'''(c_0)c_0^2\tilde g^2]\\&=\delta[1-(-\frac{c_0u''(c_0)}{u'(c_0)})\tilde g+\frac12(-\frac{c_0u''(c_0)}{u'(c_0)})(-\frac{c_0u'''(c_0)}{u''(c_0)})\tilde g^2]\\&=\delta(1-R_R\tilde g+\frac12R_RP_R\tilde g^2)\end{aligned}</script><p>其中，$R_R$ 是相对风险规避系数，$P_R$ 是相对审慎系数。注意，相对风险规避系数与相对审慎系数都应是 $c_0$ 的函数。但为了书写简便，这里我们略去了 $c_0$。</p><p>于是，随机折现因子的期望为</p><script type="math/tex; mode=display">E[\tilde m]\approx E[\delta(1-R_R\tilde g+\frac12R_RP_R\tilde g^2)]=\delta(1-R_RE(\tilde g)+\frac12R_RP_RE(\tilde g^2))</script><p>定义$\bar g\equiv E[\tilde g]$为消费增长率的期望值。又因为</p><script type="math/tex; mode=display">var(\tilde g)=E[\tilde g-\bar g]^2=E[\tilde g^2]-2\bar g E[\tilde g]+\bar g^2=E[\tilde g^2]-\bar g^2</script><p>在 $\bar g$ 比较小的时候，$\bar g^2$ 会很接近于 0，所以有</p><script type="math/tex; mode=display">E[\tilde g^2]=var(\tilde g)+\bar g^2\approx var(\tilde g)</script><p>将其代入</p><script type="math/tex; mode=display">E[\tilde m]\approx \delta(1-R_R\bar g+\frac12R_RP_R\sigma_g^2)</script><p>于是，无风险利率可以表示为</p><script type="math/tex; mode=display">\begin{aligned}r_f&=\frac1{E[\tilde m]}-1\approx\frac1{\delta(1-R_R\bar g+\frac12R_RP_R\sigma_g^2)}-1\\&=\frac{1-\delta+\delta R_R\bar g-\frac12\delta R_RP_R\sigma_g^2}{\delta(1-R_R\bar g+\frac12R_RP_R\sigma_g^2)}\\&\approx\frac{1-\delta}{\delta}+R_R\bar g-\frac12R_RP_R\sigma_g^2\end{aligned}</script><p>上式中的最后一个约等号是因为$\bar g$ 与 $\sigma_g^2$ 都是较小的数，所以在分母中忽略去它们，将分母直接变成 $\delta$。如果再定义消费者的主观贴现率为 $\rho\equiv 1/\delta-1$，则上式可以简洁地写成</p><script type="math/tex; mode=display">r_f=\rho+R_R\bar g-\frac12 R_RP_R\sigma_g^2</script><p>注意，在我们的模型中，一直是用消费品做的计价物。所以模型中的各个变量都是不包含货币通胀因素的<strong>真实变量</strong>（real variables），而非<strong>名义变量</strong>（nominal variables）。这里给出的无风险利率也是真实无风险利率。</p><p>式表明（真实）无风险利率由<strong>三股力量</strong>所决定。<strong>第一股是消费者的“不耐”</strong>（impatience），由消费者的主观贴现率 $\rho\equiv 1/\delta-1$ 所衡量。消费者越不耐心，主观贴现率 $\rho$ 就越大（贴现因子 $\delta$ 相应越小），无风险利率就应该越高。这是因为当消费者越不耐心的时候，就需要越高的利率来激励其进行储蓄。</p><p>决定无风险利率的<strong>第二股力量是经济增长</strong>。这由式中相对风险规避系数 RR 与消费增长平均速 $\bar g$ 的乘积来刻画。经济增长速度越快，就意味未来的消费会更多，储蓄就越发没有必要。在这种情况下，就需要更高的无风险利率来平衡消费者减少储蓄的动机。而经济增速对无风险利率影响的强度由消费者的相对风险规避系数来决定。这是因为在我们所使用的效用函数设定中，相对风险规避系数同时决定了消费者在不同时间、以及不同状态间平滑消费的意愿强度。相对风险规避系数越高，消费者就越愿意在现在与未来之间平滑消费。这时，经济增长所造成的消费者降低储蓄的动机就越强。为了平衡这种更强的降低储蓄的动机，无风险利率就需要更高。</p><p>决定无风险利率的<strong>第三股力量是预防性储蓄</strong>（precautionary savings）动机。我们在前面讨论风险下决策的时候已经碰到过这个概念。在式中，预防性储蓄动机由 $-0.5R_RP_R\sigma_g^2$  所刻画。如果经济增长的波动性加大（$\sigma_g^2$ 增大），那么消费者会有出于预防性储蓄动机而增加储蓄的动力。这样，无风险利率就会相应降低来与更强的储蓄动机相匹配。预防性储蓄动机的强度由消费者的相对风险规避系数与相对审慎系数共同决定。</p><blockquote><p>这几讲的模型中不存在货币，计价物是消费品。所以模型中所有变量都是真实变量（real variable），无风险利率的决定中并不包含货币因素。而在真实世界中，无风险利率往往指国债利率（因为国家有印钞机做后盾，总能保证国债的偿付）。国债利率作为一个名义变量，与真实利率之间差了一个通胀的预期——通胀预期越高，名义利率比真实利率高得更多。如果要把我们这里推导出的无风险利率对应到现实世界中，比较好的对象应该算国债利率减去通胀预期（或者简单地就减去通胀率）。</p></blockquote><h1 id="第-13-讲-多因子模型与-APT"><a href="#第-13-讲-多因子模型与-APT" class="headerlink" title="第 13 讲 多因子模型与 APT"></a>第 13 讲 多因子模型与 APT</h1><p>前面从均值方差分析开始一直到 C-CAPM 模型，都可以算成是“均衡资产定价”（equilibrium asset pricing）的理论。就其目标来说，是试图从消费者偏好、禀赋分配等最基本的前提条件，推导出所有资产的价格。而从其结果来说，均衡定价可从基本的偏好、禀赋假设，从无到有地定出所有资产的价格。也正因为此，均衡定价理论也被称为<strong>“绝对定价”</strong>。</p><p>在金融业的实务中，在投资银行每天给各种资产定价的实践中，应用得更多的是“无套利定价”（no-arbitrage asset pricing）的理论。这套理论不像均衡定价理论那样雄心勃勃，并不试图从无到有地给所有资产定出价格来，而只是问：在已知某些资产的价格之后，怎样给其他一些相关的资产定价。从这个意义上来说，无套利定价理论也可被称为<strong>“相对定价”</strong>。</p><p>罗斯于 1976 年首次提出的“套利资产定价理论”（Arbitrage Pricing Theory，<br>简称 APT）。这一理论是对 CAPM 在逻辑上的自然延伸，同时又包含了一些无套利的思想。在这里介绍，以作为从均衡定价理论向无套利定价理论的过渡</p><h3 id="13-1-从单因子到多因子"><a href="#13-1-从单因子到多因子" class="headerlink" title="13.1 从单因子到多因子"></a>13.1 从单因子到多因子</h3><p>在实践中，可用如下的 OLS 回归方程来估计各种资产的 $\beta_{Mj}$。</p><script type="math/tex; mode=display">\tilde r_j-r_f=\alpha_j+\beta_{M,j}(\tilde r_M-r_f)+\tilde \varepsilon_j</script><p>所谓因子模型，就是认为资产的期望回报率由一些共同的因素所决定。这些公共的因素就是因子（factor）。CAPM 认为，所有资产的期望回报率由市场组合回报率这一个因素决定。与市场组合回报率的相关性（beta）决定了资产期望回报率的高低。所以，CAPM 给出的定价方程可叫做<strong>单因子模型</strong>（single index model）。</p><p>尽管 CAPM 在理论上看上去很漂亮，但它与现实数据的拟合效果却不太理想。从计量经济学的思路来思考，模型解释力不够，那就增加解释变量好了。在这方面，是 Fama 与 French 提出的三因子模型（Fama，French，1993）具有开创性。在这个模型中，Fama 与 French 用市场组合的<strong>超额收益率、规模、和账面市值比</strong> 3 个因子来解释不同资产回报率的不同。其模型方程为</p><script type="math/tex; mode=display">\tilde r_i-r_f=\alpha_i+\beta_{iM}(\tilde r_M-r_f)+\beta_{is}\tilde SMB+\beta_{ih}\tilde HML+\tilde\varepsilon_i</script><p>其中的 $\tilde SMB$是市值因子，表征了上市公司的规模大小，$\tilde HML$ 是账面市值比（book to market），是公司的账面价值除以公司股票总市值。</p><h3 id="13-2-多因子模型的直觉"><a href="#13-2-多因子模型的直觉" class="headerlink" title="13.2 多因子模型的直觉"></a>13.2 多因子模型的直觉</h3><p><strong>C-CAPM 框架下的单因子模型</strong></p><p>在前面我们介绍的 C-CAPM 中，代表性消费者的优化问题可以写成</p><script type="math/tex; mode=display">\max u(c_0)+\delta E[u(\tilde c_1)]</script><script type="math/tex; mode=display">s.t.\qquad\tilde c_1=(1+\tilde r_w)(w_0-c_0)</script><p>一阶条件为</p><script type="math/tex; mode=display">1=E[\delta\frac{u'(\tilde c_1)}{u'(c_0)}(1+\tilde r_w)]</script><p>我们假设消费者的效用函数为二次型</p><script type="math/tex; mode=display">u(c)=-\frac12(a-c)^2</script><p>在这样的效用函数下，边际效用为</p><script type="math/tex; mode=display">u'(c)=a-c</script><p>为确保消费的边际效用一直为正，我们要求消费 c 一直小于 a（即 a 很大）</p><script type="math/tex; mode=display">\tilde m=\delta\frac{a-\tilde c_1}{a-c_0}=\delta\frac{a-(1+\tilde r_w)(w_0-c_0)}{a-c_0}=\delta\frac a{a-c_0}-\delta\frac{w_0-c_0}{a-c_0}(1+\tilde r_w)</script><p>如果定义常数 A 和 B 为</p><script type="math/tex; mode=display">A=\delta\frac a{a-c_0}-\delta\frac{w_0-c_0}{a-c_0},B=\delta\frac{w_0-c_0}{a-c_0}</script><p>则随机折现因子可以写成如下的线性（linear）形式</p><script type="math/tex; mode=display">\tilde m=A-B\tilde r_w</script><p>我们知道</p><script type="math/tex; mode=display">1=E[\tilde m(1+\tilde r_j)]\Rightarrow 1=E[\tilde m](1+E[\tilde r_j])+cov(\tilde m,\tilde r_j)</script><p>将随机折现因子的线性表达式代入</p><script type="math/tex; mode=display">\begin{aligned}E[\tilde r_j]&=\frac 1{E[\tilde m]}-1-\frac{cov(\tilde m,\tilde r_j)}{E[\tilde m]}=r_f-\frac{cov(\tilde m,\tilde r_j)}{E[\tilde m]}\\&=r_f-\frac{cov(A-B\tilde r_w,\tilde r_j)}{E[\tilde m]}\\&=r_f+\frac{cov(\tilde r_w,\tilde r_j)}{var(\tilde r_w)}\frac{Bvar(\tilde r_w)}{E[\tilde m]}\end{aligned}</script><p>如果定义</p><script type="math/tex; mode=display">\beta_{j,w}\stackrel{\Delta}{=}\frac{cov(\tilde r_w,\tilde r_j)}{var(\tilde r_w)}</script><script type="math/tex; mode=display">\lambda_w=\frac{Bvar(\tilde r_w)}{E[\tilde m]}</script><p>则资产 j 的期望回报率可以写成</p><script type="math/tex; mode=display">E[\tilde r_j]=r_f+\beta_{j,w}\lambda_w</script><p>这便是描述资产回报率的单因子模型，也即 CAPM 的定价方程</p><p><strong>C-CAPM 框架下的多因子模型</strong></p><p>现在我们假设消费者除了拥有初始财富 $w_0$ 外，还在 0 期与 1 期分别拥有工资性收入 $y_0$ 与 $\tilde y_1$。我们还假设 1 期的工资收入与资产市场总回报相互独立（$cov(\tilde y_1,\tilde r_w)=0$）。这样，消费者的优化问题变成</p><script type="math/tex; mode=display">\max u(c_0)+\delta E[u(\tilde c_1)]</script><script type="math/tex; mode=display">s.t.\qquad\tilde c_1=(1+\tilde r_w)(w_0+y_0-c_0)+\tilde y_1</script><p>如果消费者的效用函数仍然是二次型，那么随机折现因子可写为</p><script type="math/tex; mode=display">\tilde m=\delta\frac{a-(1+\tilde r_w)(w_0+y_0-c_0)-\tilde y_1}{a-c_0}=\delta\frac a{a-c_0}-\delta\frac{w_0+y_0-c_0}{a-c_0}(1+\tilde r_w)-\delta\frac a{a-c_0}\tilde y_1</script><p>如果定义三个常数 A’、B’、C’分别为</p><script type="math/tex; mode=display">A'=\delta\frac a{a-c_0}-\delta\frac{w_0+y_0-c_0}{a-c_0},B'=\delta\frac{w_0+y_0-c_0}{a-c_0},C'=\delta\frac{a}{a-c_0}</script><p>随机折现因子可以写成如下线性形式</p><script type="math/tex; mode=display">\tilde m=A'-B'\tilde r_w-C'\tilde y_1</script><p>与之前的表达式相比，现在随机折现因子除了受到 $\tilde r_w$ 的影响外，还受到工资收入 $\tilde y_1$ 的影响。将这一线性表达式代入</p><script type="math/tex; mode=display">\begin{aligned}E[\tilde r_j]&=r_f-\frac{cov(\tilde m,\tilde r_j)}{E[\tilde m]}\\&=r_f-\frac{cov(A'-B'\tilde r_w-C'\tilde y_1)}{E[\tilde m]}\\&=r_f+\frac{B'cov(\tilde r_w,\tilde r_j)}{E[\tilde m]}+\frac{C'cov(\tilde y_1,\tilde r_j)}{E[\tilde m]}\\&=r_f+\frac{cov(\tilde r_w,\tilde r_j)}{var(\tilde r_w)}\frac{B'var(\tilde r_w)}{E[\tilde m]}+\frac{cov(\tilde y_1,\tilde r_j)}{var(\tilde y_1)}\frac{C'var(\tilde y_1)}{E[\tilde m]}\\&=r_f+\beta'_{j,w}\lambda_w'+\beta'_{j,y}\lambda_y'\end{aligned}</script><p>如果定义</p><script type="math/tex; mode=display">\begin{aligned}\beta'_{j,w}=\frac{cov(\tilde r_w,\tilde r_j)}{var(\tilde r_w)}&,\beta'_{j,y}=\frac{cov(\tilde y_1,\tilde r_j)}{var(\tilde y_1)}\\\lambda_w'=\frac{B'var(\tilde r_w)}{E[\tilde m]}&,\lambda_y'=\frac{C'var(\tilde y_1)}{E[\tilde m]}\end{aligned}</script><p>则有</p><script type="math/tex; mode=display">E[\tilde r_j]=r_f+\beta'_{j,w}\lambda_w'+\beta'_{j,y}\lambda_y'</script><p>现在，决定资产期望回报率的，既有资产回报率与市场总回报率之间的相关性，也有资产回报率与工资收入之间的相关性。</p><h3 id="12-3-ATP"><a href="#12-3-ATP" class="headerlink" title="12.3 ATP"></a>12.3 ATP</h3><p>多因子模型的理论根基其实是 Ross 提出的套利资产定价理论（APT）。</p><p>应用多因子模型的投资者需要自行决定哪些因子是重要的，需要用来分析资产回报率。而各个资产对因子的敏感性，也需要投资者自己用经验数据来加以估计。当所有资产的期望回报率都由一组共同的因子所决定的时候，基于无套利的思想，不同资产期望回报率之间会具有某种线性关系——这便是 APT 的思想。</p><p>在因子模型中，因子反映了系统风险，我们将其称为<strong>因子风险</strong>（factor risk）。因子前的系数 $\beta$ 叫做资产对因子的<strong>载荷</strong>（loading）。与因子风险无关的剩余风险 $\tilde \varepsilon_i$叫做<strong>个体风险</strong>（idiosyncratic risk）。</p><p>我们可以把 CAPM 视为 APT 的一个特例。就 CAPM 看来，所有资产的期望回报率只有一个因子决定，就是市场组合的回报率。</p><p><strong>精确单因子模型</strong></p><p>我们先用一个简单的单因子模型作为引子，来展现 APT 推导的思路。我们假设只有一个风险因子，且所有资产的个体风险都为 0</p><script type="math/tex; mode=display">\begin{aligned}&\tilde{r}_{i}=\bar{r}_{i}+\beta_{i} \tilde{f} \\&\tilde{r}_{j}=\bar{r}_{j}+\beta_{j} \tilde{f}\end{aligned}</script><p>其中，$\tilde f$ 是因子风险。为了简化分析，我们假设 $E[\tilde f]=0$。这并非一个根本性的假设，放松它也不会改变后面将得出的结论。假设存在资产 i 与 j，$\beta i$ 与 $\beta_j$均非 0，且 $\beta_i\ne\beta_j$。</p><p>我们可以构造一个组合 $\tilde r_p$，把我们正规化为 1 的总财富分配到两类资产上。</p><script type="math/tex; mode=display">\begin{aligned}\tilde{r}_{p} &=w \tilde{r}_{i}+(1-w) \tilde{r}_{j} \\&=[w \bar{r}_{i}+(1-w) \bar{r}_{j}]+[w \beta_{i}+(1-w) \beta_{j}] \tilde{f}\end{aligned}</script><p>当组合的因子载荷为 0 时，组合的回报率中就不含有不确定性。我们将这样的组合权重叫做 $w_0$。</p><script type="math/tex; mode=display">w_{0} \beta_{i}+(1-w_{0}) \beta_{j}=0</script><p>解出</p><script type="math/tex; mode=display">w_{0}=\frac{\beta_{j}}{\beta_{j}-\beta_{i}}</script><p>将这个权重 $w_0$ 代回组合 $\tilde r_p$的表达式，可得到一个无风险组合 $p_0$，其回报率为</p><script type="math/tex; mode=display">\tilde{r}_{p_{0}}=w_{0} \tilde{r}_{i}+(1-w_{0}) \tilde{r}_{j}=\frac{\beta_{j}}{\beta_{j}-\beta_{i}} \bar{r}_{i}+(1-\frac{\beta_{j}}{\beta_{j}-\beta_{i}}) \bar{r}_{j}=\frac{\beta_{j} \bar{r}_{i}-\beta_{i} \bar{r}_{j}}{\beta_{j}-\beta_{i}}</script><p>由于 $p_0$ 是无风险组合，所以当市场不存在套利机会的时候，其期望回报率应该与无风险利率 $r_f$相等。所以，</p><script type="math/tex; mode=display">\frac{\beta_{j} \bar{r}_{i}-\beta_{i} \bar{r}_{j}}{\beta_{j}-\beta_{i}}=r_{f} \Rightarrow \frac{\bar{r}_{i}-r_{f}}{\beta_{i}}=\frac{\bar{r}_{j}-r_{f}}{\beta_{j}}</script><p>所以我们可以定义一个常数 $\lambda$ 为</p><script type="math/tex; mode=display">\lambda \triangleq \frac{\overline{r}_{i}-r_{f}}{\beta_{i}}=\frac{\overline{r}_{j}-r_{f}}{\beta_{j}}</script><p>这样一来，对任意资产 i，其期望回报率必然满足</p><script type="math/tex; mode=display">\bar{r}_{i}=r_{f}+\beta_{i} \lambda \quad \forall i</script><p>要运用式来做资产定价，我们还得知道 $\lambda$ 是多少。我们可以通过选择 $w$，来构造另外一个组合 $p_1$，使得 $p_1$ 的因子载荷正好为 1</p><script type="math/tex; mode=display">w_{1} \beta_{i}+(1-w_{1}) \beta_{j}=1 \quad \Rightarrow \quad w_{1}=\frac{1-\beta_{j}}{\beta_{i}-\beta_{j}}</script><p>代回</p><script type="math/tex; mode=display">\begin{aligned}\tilde{r}_{p_{1}} &=[\frac{1-\beta_{j}}{\beta_{i}-\beta_{j}} \bar{r}_{i}+(1-\frac{1-\beta_{j}}{\beta_{i}-\beta_{j}}) \bar{r}_{j}]+\tilde{f} \\&=[\frac{1-\beta_{j}}{\beta_{i}-\beta_{j}}+\frac{\beta_{i}-1}{\beta_{i}-\beta_{j}} \bar{r}_{j}]+\tilde{f} \\&=\frac{\bar{r}_{i}-\beta_{j} \bar{r}_{i}+\beta_{i} \bar{r}_{j}-\bar{r}_{j}}{\beta_{i}-\beta_{j}}+\tilde{f} \\&=\frac{\beta_{i} \bar{r}_{j}-\beta_{j} \bar{r}_{i}}{\beta_{i}-\beta_{j}}+\frac{\bar{r}_{i}-\bar{r}_{j}}{\beta_{i}-\beta_{j}}+\tilde{f} \\&=r_{f}+\lambda+\tilde{f}\end{aligned}</script><p>对上式两边取期望</p><script type="math/tex; mode=display">\lambda=\bar r_{p_1}-r_f</script><p>$\lambda$ 是那个因子载荷为 1 的资产的超额回报率。我们将风险载荷为 1 的组合叫做<strong>因子组合</strong>（factor portfolio），其风险溢价 $\lambda$ 叫做因子溢价（factor premium）。</p><p>于是，在这个精确单因子模型中，任何资产的期望收益率都可以表示为</p><script type="math/tex; mode=display">\overline{r}_{i}=r_{f}+\beta_{i}(\bar{r}_{p_{1}}-r_{f})</script><p>由此可见，资产的期望超额回报率就等于资产的因子载荷乘以因子风险溢价。</p><p><strong>多因子模型下的 APT</strong></p><p>现在我们来考虑更为一般的情况，包含多个因子，且存在个体风险。我们假设有 K 个会影响资产回报率的因子。此外，市场中还存在 N 种资产。每种资产的回报率都同时受到 K个因子的共同影响。我们还假设资产的数量远远比因子的数量多（N 远大于 K）。于是，任意一种资产 i 的回报率可以用如下形式的方程来描述</p><script type="math/tex; mode=display">\tilde{r}_{i}=\bar{r}_{i}+\sum_{k=1}^{K} \beta_{i, k} \tilde{f}_{k}+\tilde{\varepsilon}_{i} \quad i=1,2, \cdots, N</script><p>为了简化分析，我们假设因子和个体风险的期望均为 0，我们还假设因子方差为 1，个体风险的波动方差相等，且不是无穷大。我们考虑由所有 N 种资产形成的组合 p</p><script type="math/tex; mode=display">\tilde{r}_{p}=\sum_{i=1}^{N} w_{i} \tilde{r}_{i}=\sum_{i=1}^{N} w_{i} \bar{r}_{i}+(\sum_{i=1}^{N} w_{i} \beta_{i, 1}) \tilde{f}_{1}+\cdots+(\sum_{i=1}^{N} w_{i} \beta_{i, K}) \tilde{f}_{K}+\sum_{i=1}^{N} w_{i} \tilde{\varepsilon}_{i}</script><p>类似前面的思路，我们想办法选择权重，来将组合 p 中的因子风险完全消除掉。为了做到这<br>一点，要有</p><script type="math/tex; mode=display">\left\{\begin{array}{c}\sum_{i=1}^{N} w_{i} \beta_{i, 1}=0 \\\vdots \\\sum_{i=1}^{N} w_{i} \beta_{i, K}=0\end{array}\right.</script><p>在 $N&gt;K$ 的时候，这个方程组是有解的（解可能不止一组）。将解出的权重代回式，可以得到</p><script type="math/tex; mode=display">\tilde{r}_{p_0}=\sum_{i=1}^{N} w_{i} \bar{r}_{i}+\sum_{i=1}^{N} w_{i} \tilde{\varepsilon}_{i}</script><p>上面这个式子的右边还包含着个体风险。但是我们知道所有个体风险的方差都为 $\sigma_\varepsilon^2$，所以 $\tilde r_{p_0}$ 的方差就是</p><script type="math/tex; mode=display">\sigma^{2}\left(\tilde{r}_{p_0}\right)=\left(w_{1}^{2}+w_{2}^{2}+\cdots+w_{N}^{2}\right) \sigma_{\varepsilon}^{2}</script><p>当资产的数量很大时（N 很大），每个权重就大概为 1/N。</p><script type="math/tex; mode=display">(\frac{1}{N})^{2} \times N \times \sigma_{\varepsilon}^{2}=\frac{\sigma_{\varepsilon}^{2}}{N}</script><p>只要个体风险的方差不是无穷大，当 $N \rightarrow \infty $ 时，$\sigma^{2}(\tilde{r}_{p_0}) \rightarrow 0$。这意味着当资产数量很大时，消除了因子风险的组合几乎是无风险的，它的回报率就应该等于无风险利率，即</p><script type="math/tex; mode=display">\tilde{r}_{p_0} \approx \sum_{i=1}^{N} w_{i} \bar{r}_{i}=r_{f}</script><p>注意，上式中的 $w_i$ 均为各个 $\beta$ 的函数</p><p>采取前面单因子模型的推导思路，可以证明在这样的前提下，各个资产的期望回报率可以表示为</p><script type="math/tex; mode=display">\bar{r}_{i}=r_{f}+\sum_{k=1}^{K} \beta_{i, k} \lambda_{k}</script><p>其中的 $\lambda k$ 为第 k 个因子的因子溢价——即对因子 k 的载荷为 1，而对其他因子载荷为 0 的组合的风险溢价。</p><blockquote><p>在多因子建模时，选取的因子可以是那些直接可观测的变量，比如 GDP 增速，通胀数据，资本市场指数等，也可以是无法观测的因子。这些不可观测的因子称为潜在因子（latent factor）。对隐性因子的因子载荷和因子溢价的估计方法，这里我们不做介绍。大家只需要知道存在这样的方法可以估计出来就行了。在研究债券收益率曲线的三因子模型中，三个因子（水平、斜率和曲度三个因子）就都是潜在因子</p></blockquote><h1 id="第-14-讲-无套利定价初探"><a href="#第-14-讲-无套利定价初探" class="headerlink" title="第 14 讲 无套利定价初探"></a>第 14 讲 无套利定价初探</h1><p>此部分与之前的笔记相似，因为本课程更偏向入门，所以可以通过其他笔记来进行学习。</p><ol><li><a href="https://achlier.github.io/2021/04/22/Financial_Markets_Securities_and_Derivatives/#Unit-2-Forwards-Futures-and-Options">Forwards, Futures and Options</a></li><li><a href="https://achlier.github.io/2021/04/25/Mathematical_Finance/">Mathematical_Finance</a></li></ol><p>不过值得注意的是本课程特别提出了<strong>风险中性世界</strong>（risk neutral world）的描述。作者认为风险中性世界与真实世界有着相同的资产市场结构和资产价格。但与真实世界不同的是，风险中性世界中的投资者都是风险中性的。我们知道，风险中性的投资者会以资产未来支付的期望值折现来给资产定价。如果有一位消费者是风险中性的，她的绝对风险厌恶系数应该等于 0，她的绝对风险容忍度会是无穷大。但这在现实中是很难存在的。</p><script type="math/tex; mode=display">u(c)=\alpha c</script><p>另外，虽然真实世界概率并不存在于定价公式中，但它的影响已经体现在了当前和未来的股价之中。也就是说，0 时刻的股价之所以是 $S_0$ 而不是其他的数，是因为 1 时刻股价有 $p$ 的概率变成 $uS_0$，$1-p$ 的概率变成 $dS_0$。从这个角度来说，前面给出的定价方程其实隐含了真实世界的概率 $p$ 。</p><h1 id="第-15-讲-无套利定价理论基础"><a href="#第-15-讲-无套利定价理论基础" class="headerlink" title="第 15 讲 无套利定价理论基础"></a>第 15 讲 无套利定价理论基础</h1><ul><li>所有资产 1 期的支付可以用如下支付矩阵来描述</li></ul><script type="math/tex; mode=display">X \triangleq\begin{bmatrix}x_{1}^{1} & \cdots & x_{1}^{J} \\\vdots & \ddots & \vdots \\x_{S}^{1} & \cdots & x_{S}^{J}\end{bmatrix}</script><ul><li><p>资产组合（portfolio）$\theta = (\theta_1,…,\theta_J)^T$</p></li><li><p>资产组合在各个状态下的支付</p><script type="math/tex; mode=display">X\theta=\begin{bmatrix}\sum_{j=1}^Jx_1^j\theta_j\\...\\\sum_{j=1}^Jx_S^j\theta_j\end{bmatrix}</script></li><li><p>J 种资产在0期的价格 $P\stackrel{\Delta}{=}[p_1\quad…\quad p_J]$</p></li><li><p>资产组合 $\theta$ 在0期的价值 $\sum_{j=1}^Jp_j\theta_j$</p></li></ul><p><strong>定义 15.1（套利）：</strong>同时满足下列 3 个条件的资产组合 $\theta$ 叫做套利（arbitrage）：</p><ol><li>$p\theta\le0$；</li><li>$x\theta\ge0$；</li><li>前两个不等式中至少有一个是严格不等式。</li></ol><p>根据这一定义，可以将套利分为三类：</p><ul><li>$p\theta&lt;0$ 且 $x\theta=0$</li><li>$p\theta=0$ 且 $x\theta&gt;0$</li><li>$p\theta<0$ 且 $x\theta>0$</0$></li></ul><h3 id="15-1-资产定价基本定理"><a href="#15-1-资产定价基本定理" class="headerlink" title="15.1 资产定价基本定理"></a>15.1 资产定价基本定理</h3><p>给出了套利的严格定义之后，下面我们介绍无套利定价理论的基础——<strong>资产定价基本定理</strong>（Fundamental Theorem of Asset Pricing）。</p><p>在均衡定价理论中，我们推导出了所有资产都需要满足的定价方程</p><script type="math/tex; mode=display">p_{j}=E[\tilde{m} \tilde{x}^{j}]</script><p>$\tilde m$ 是<strong>随机折现因子</strong>（stochastic discount factor）。随机折现因子还被称为<strong>定价核</strong>（pricing kernel）。可以将期望符号用概率的形式写出来，得到</p><script type="math/tex; mode=display">p_{j}=\sum_{s=1}^{S} \pi_{s} m_{s} x_{s}^{j}</script><p>如果定义 $\varphi_s=\pi_sm_s$</p><script type="math/tex; mode=display">p_{j}=\sum_{s=1}^{S} \varphi_{s} x_{s}^{j}</script><p>这表明，任何资产的价格都是其未来各个状态下支付的一个加权平均，权重为 $\varphi_s$。在资产定价理论中，我们给 $\varphi_s$ 一个专门的名字，叫做<strong>状态价格</strong>（state price）。事实上，状态价格就是各个状态对应的 Arrow 证券的价格。</p><p>资产定价基本定理讲的就是，只要资产市场中不存在套利机会，所有资产的价格就都可以表示为式这样的形式。下面我们将这一结论严格地写出来。</p><p><strong>定义 15.2（状态价格向量）：</strong>状态价格向量 $\varphi =(\varphi_1, …, \varphi_S)^T$ 为一组正数（$\varphi_s&gt;0，\forall s$），使得对于任意资产 j 都有 $p_j=\sum_{s=1}^S\varphi_sx_s^j$ 成立<br><strong>定理 15.3（资产定价基本定理）：</strong>资产市场中不存在套利机会，当且仅当存在状态价格向量。</p><p>要证明需要用到<strong>超平面分离定理</strong>（Separating Hyperplane Theorem）。假设在二维平面上有两个互不相交的凸集合 A 和 B（交集为空集），那么我们一定可以用二维平面上的一根直线把这两个集合分开，让 A 与 B 分处这根直线的两边。这根切开了 A 和 B 的直线可以写成方程 $\alpha_1x+\alpha_2y=z$。其中的 $\alpha_1$，$\alpha_2$ 与 z 都是常数。由于点只有在分离了 A 和 B 两个集合的那根直线上这个函数左侧才为 z，所以 A 与 B 上的两点所对应的函数值一定是一个大于 z、一个小于 z。推而广之，任何两个在 <em>S</em> 维空间中的分离凸集，都可以用一个 $S-1$ 维的超平面将其分割开来。</p><p>用数学的语言来描述上面的思想，就是任给两个 S 维空间中相互分离的凸集合 A 和 B（二者的交集为空集），在这两个凸集合中分别任取一点，$\forall a\in A$，$\forall b\in B$，一定可以找到一个<strong>线性函数</strong> $F(x)=\alpha_1x_1+\alpha_2x_2+…+\alpha_Sx_S$（其中的 $\alpha_1、\alpha_2、…… \alpha_S$ 都是常数），使得 $F(a)&lt;F(b)$。特别要注意，由于 F 是线性函数，所以对任意实数 $\mu$，它满足性质 $F(\mu a)=\mu F(a)$。</p><p><strong>资产定价基本定理的证明思路</strong></p><p>给定资产的支付矩阵 x 与资产的价格向量 p。定义如下集合 A</p><script type="math/tex; mode=display">A \triangleq\{(-\sum_{j=1}^{J} p_{j} \theta_{j}, \sum_{j=1}^{J} x_{1}^{j} \theta_{j}, \cdots, \sum_{j=1}^{J} x_{S}^{j} \theta_{j}): \theta_{j} \text { 为实数, } \forall j=1, \cdots, J\}</script><p>再定义另一个集合 B</p><script type="math/tex; mode=display">B \triangleq\{(b_{0}, b_{1}, \cdots, b_{S}): b_{i} \geq 0, \forall i=0,1, \cdots, S\}</script><p>直观上来看，集合 B 是一个锥（cone）。在二维的情况下，集合 B 就是二维坐标系的第一象限（包含坐标轴）。</p><p>由前面给出的套利的定义。资产市场中如果没有套利机会，则集合 A 和集合 B 只相交于 $0=(0, 0, …, 0)$ 这一点。也就是说 $A\cap B=\{0\}$。这很容易理解。如果 A 和 B 还相交于非 0 的点，就意味着集合A存在某点使其内的所有元素都非负，至少有一个元素严格为正。这就构成了前面定义的套利。</p><p>由超平面分离定理可以知道，可以找到一个线性的函数 $F(x)=\alpha_0x_0+\alpha_1x_1+…+\alpha_sx_s$，使得 $F(a)&lt;F(b)，\forall a\in A,b\in B-\{0\}$</p><p>我们还注意到，如果某个元素 $a\in A$，则任给一个实数 $\mu$，必有 $\mu a\in A$。直观来说，如果一个投资组合的当期价格和未来支付组成的向量在集合 A 中，那么把投资组合各项权重全部乘以 $\mu$ 得到一个新的投资组合。这个新的投资组合的当期价值和未来支付组成的向量也必然在集合 A 中。</p><p>因此，对任意 $a\in A$，必然有 $F(a)=0$。如果存在某个 $a_0\in A$，使得 $F(a_0)\ne0$，当 $\mu\to\infty$的时候（如果 $F(a_0)&lt;0$，则让 $\mu\to-\infty$），必然有 $F(\mu a_0)\to\infty$。而由于前面已经得出了，任意从 B 集合中找出一个元素 $b\in B$ 固定下来，都应该有 $F(\mu a_0)&lt;F(b)$。当 $F(\mu a_0)\to\infty$ 时，这个不等式显然不能成立。这就产生了矛盾。所以可得结论，对任意 $a\in A$，必然有 $F(a)=0$。</p><script type="math/tex; mode=display">\begin{aligned}F(a) &=F(-\sum_{j=1}^{J} p_{j} \theta_{j}, \sum_{j=1}^{J} X_{1}^{j} \theta_{j}, \cdots, \sum_{j=1}^{J} X_{S}^{j} \theta_{j})=0\\\Rightarrow&-\alpha_{0} \sum_{j=1}^{J} p_{j} \theta_{j}+\alpha_{1} \sum_{j=1}^{J} X_{1}^{j} \theta_{j}+\cdots+\alpha_{S} \sum_{j=1}^{J} X_{S}^{j} \theta_{j}=0\end{aligned}</script><p>由于权重 $\theta$ 可以任意选择，我们完全可以将其设定为某种资产 j 的权重为 1，其它资产的权重全部为 0。所以对任意一种资产 j，都有</p><script type="math/tex; mode=display">-\alpha_{0} p_{j}+\alpha_{1} x_{1}^{j}+\cdots+\alpha_{S} x_{S}^{j}=0</script><p>变形为</p><script type="math/tex; mode=display">p_{j}=\sum_{s=1}^{S} \frac{\alpha_{s}}{\alpha_{0}} x_{s}^{j}</script><p> 对 任 意 的 $b\in B-\{0\}$ ，必有 $F(b)&gt;0$。因此，对线性函数 $F(x)=\alpha_0x_0+\alpha_1x_1+…+\alpha_Sx_S$ 来说，必有 $\alpha_i&gt;0（i=0,1,…,S）$。 所以 $\alpha_s/\alpha_0（s=1,…,S）$全是正数，就是所要寻找的状态价格。定理充分性得证。</p><p><strong>定理 15.4：</strong>（第二资产定价基本定理）在一个完备的资产市场中如果不存在套利机会，则存在唯一的状态价格向量。</p><h3 id="15-2-风险中性概率"><a href="#15-2-风险中性概率" class="headerlink" title="15.2 风险中性概率"></a>15.2 风险中性概率</h3><script type="math/tex; mode=display">p=\sum_{s=1}^{S} \pi_{s} \frac{\varphi_{s}}{\pi_{s}} x_{s}=\sum_{s=1}^{S} \pi_{s} m_{s} x_{s}=E[\tilde{m} \tilde{x}]</script><p>从这里可以看出，前面介绍的随机折现因子（定价核）其实就是状态价格除以状态发生的物理概率。由于有这种关系，随机折现因子又叫做<strong>状态价格密度</strong>（state price density），或者叫做<strong>状态价格核</strong>（state price kernel）。在 C-CAPM中，状态价格密度就是消费者的跨期边际效用比 $\delta u’(\tilde c_1)/u’(c_0)$。</p><p>无风险资产在未来（1 期）各个状态的支付都为 1 单位消费品。因此，无风险资产在现在（0 期）的价格应该为无风险利率的倒数</p><script type="math/tex; mode=display">e^{-r}=\sum_{s=1}^{S} \varphi_{s}</script><p>定义</p><script type="math/tex; mode=display">q_{s} \triangleq \frac{\varphi_{s}}{\sum_{s=1}^{S} \varphi_{s}}=e^{r} \varphi_{s},\quad\sum_sq_s=1</script><script type="math/tex; mode=display">p=\sum_{s=1}^{S} \varphi_{s} x_{s}=e^{-r} \sum_{s=1}^{S} e^{r} \varphi_{s} x_{s}=e^{-r} \sum_{s=1}^{S} q_{s} x_{s}</script><p>可以用 $E^Q[\tilde x]$来表示以 $q_1、…、q_S$ 为概率，所计算的随机变量 $\tilde x$的数学期望。期望符号加上上标 Q，用以区分于用真实世界概率 $\pi_1、…、\pi_S$ 计算的数学期望 $E[\tilde x]$。运用这样的符号，上式可以写为</p><script type="math/tex; mode=display">p=e^{-r}E^Q[\tilde x]</script><p>上式对所有资产都成立。它意味着，在这个构造出来的假想概率世界 Q 中，所有资产的价格都等于其未来支付在风险中性概率下的期望，再用无风险利率折现的现值。也就是说，在这个假想的世界中，所有消费者看起来都是风险中性的（所以资产价格等于用无风险利率贴现的期望支付）。所以，构造的这个概率（$q_1、…、q_S$）叫做<strong>风险中性概率</strong>。在构造这个风险中性概率之后，资产定价就变成了一个求取数学期望的简单问题。由于资产在 1 期各个状态下的价格就是其支付，所以用无风险利率折现后的折现资产价格也应该满足鞅性。</p><p><strong>风险中性概率的经济含义</strong></p><p>为了解释风险中性概率的经济含义，我们现在来研究均衡市场对应的风险中性概率。在C-CAPM 中有如下的资产定价方程</p><script type="math/tex; mode=display">p_j=E[\delta\frac{u'(\tilde c_1)}{u'(c_0)}\tilde x_j]=\sum_{s=1}^S\pi_s\delta\frac{u'(c_s)}{u'(c_0)}x_s</script><p>对应于状态 s 的风险中性概率为</p><script type="math/tex; mode=display">q_{s}=\delta \pi_{s} \frac{u^{\prime}(c_{s})}{u^{\prime}(c_{0})}\bigg/(\sum_{s^{\prime}=1}^{S} \delta \pi_{s^{\prime}} \frac{u^{\prime}(c_{s^{\prime}})}{u^{\prime}(c_{0})})=\frac{\pi_{s} u^{\prime}(c_{s})}{\sum_{s^{\prime}=1}^{S} \pi_{s^{\prime}} u^{\prime}(c_{s^{\prime}})}</script><p>由上式能够看出，风险中性概率（$q_s$）其实是对真实世界概率（$\pi_s$）的调整。调整的依据就是各个状态所对应的消费边际效用。边际效用高（也就是消费水平低）的状态，其风险中性概率就相对更大一些。<strong>在风险中性概率中，那些消费更为宝贵（消费边际效用更高）的状态已经在计算概率时获得了增大。</strong></p><h1 id="第-16-讲-多期二叉树定价"><a href="#第-16-讲-多期二叉树定价" class="headerlink" title="第 16 讲 多期二叉树定价"></a>第 16 讲 多期二叉树定价</h1><p>本章比较简单，主要对二叉树模型进行讲解，在此就不记录了。</p><p>不过作者在此章节中提出了一个问题：$\sigma$ 是用真实世界的股价数据估计出来的。而为什么我们能用其代替风险中性世界中的方差。这两个方差计算所用的概率都是不一样的，把它们等在一起又有什么意义？</p><p>这与一个名叫<strong>哥萨诺夫定理（Girsanov’s Theorem）</strong>的结果有关。这个定理告诉我们，当我们在做概率测度变换的时候（比如从真实世界概率换到风险中性概率），资产价格收益率的均值一般会发生变化，但其波动率却不变。也就是说，不管用什么概率测度来算，波动率都是一样的。所以前面的方程是成立的。</p><p>关于此定理的更多内容可以阅读之前的笔记。</p><h1 id="第-17-讲-最优停时"><a href="#第-17-讲-最优停时" class="headerlink" title="第 17 讲 最优停时"></a>第 17 讲 最优停时</h1><p>本章依旧建议通过其他笔记来进行学习，主要进行的是美式期权提前行权的判断。</p><p>值得注意的几个点是：如果标的资产是不分红的股票（没有股利），那么美式买入期权永远都不会被提前行权</p><p>依照 Put-Call Parity</p><script type="math/tex; mode=display">\begin{aligned}C&=P+S_0-Ke^{-rT}\\&=(S_0-K)+P+K(1-e^{-rT})\end{aligned}</script><blockquote><p>买权卖权的平价关系对非欧式期权未必成立。但这不妨碍我们用它来对美式期权做一些定性的分析</p></blockquote><p>这告诉我们，买入期权的价值来自三部分：第一部分是<strong>期权的内在价值</strong>（intrinsic value），即期权现在马上行权能够得到的支付（$S_0-K$）；第二部分是对应卖出期权的价格（P）；第三部分是行权价的时间价值，即等到到期日再行权而不是现在行权能够节省的行权金额的现值（$K(1-e^{-rT})$）。</p><p>由于卖出期权的价格 P 不可能比 0 小，行权价的时间价格 $K(1-e^{-rT})$ 也一定严格为正，所以从式可以看出，此时期权的价格会严格高于行权带来的支付，即必有</p><script type="math/tex; mode=display">C>S_0-K</script><p>而对于卖出期权</p><script type="math/tex; mode=display">\begin{aligned}P&=C+Ke^{-rT}-S_0\\&=(K-S_0)+C-K(1-e^{-rT})\end{aligned}</script><p>股价越低或是无风险利率 r 越高，美式卖出期权越可能被提前行权。</p><h1 id="第-18-讲-连续时间金融与-Black-Scholes-公式"><a href="#第-18-讲-连续时间金融与-Black-Scholes-公式" class="headerlink" title="第 18 讲 连续时间金融与 Black-Scholes 公式"></a>第 18 讲 连续时间金融与 Black-Scholes 公式</h1><p>本章看似简单，深入会考虑到测度变换等复杂的理论，如果要了解可以参考之前的。</p><p><a href="https://achlier.github.io/2021/03/14/Feynman-Kac_To_Black-Scholes-PDE/">Feynman-Kac_To_Black-Scholes-PDE</a></p><p><a href="https://achlier.github.io/2021/02/28/Black_Scholes_Model%E6%8E%A8%E5%AF%BC/">Black_Scholes_Model推导</a></p><p><a href="https://achlier.github.io/2021/06/16/Black_Scholes_Model%E6%8E%A8%E5%AF%BC_%E8%BF%9B%E9%98%B6%E7%89%88/">Black_Scholes_Model推导_进阶版</a></p><h1 id="第-19-讲-动态对冲"><a href="#第-19-讲-动态对冲" class="headerlink" title="第 19 讲 动态对冲"></a>第 19 讲 动态对冲</h1><p>本章依旧建议通过之前的笔记来进行学习，在此就不重复记录了。</p><p><a href="https://achlier.github.io/2021/03/05/Option_Greeks/">Option_Greeks</a></p><p>但作者提到了几个扩充的点。</p><ul><li><p>如果一个期权卖出者不做任何对冲，而只持有期权的空头，称其持有一个<strong>裸头寸</strong>（naked position）。与裸头寸相反的，期权卖出者可以在卖出期权的同时买入对应数量的标的资产。这种情况称为<strong>抵补头寸</strong>（covered position）。</p></li><li><p>动态对冲的实现有赖于市场的持续交易。市场参与者在买入或卖出衍生品之后，需要持续不断的交易来对冲掉衍生品头寸带来的风险。这个过程中，如果市场交易停止（比如因为 911 这样的重大突发事件），那么动态对冲就无法实现，将会让很多之前衍生品头寸变成裸头寸，极大增加市场参与者所面临的风险。因此，越是发生重大突发事件的时候，越需要确保具有充足的流动性可以完成参与者的交易。这是市场监管者在重大事件发生时的首要责任。否则，容易引发市场参与者的大面积破产，引发系统性金融危机</p></li><li>观察上面对冲期权空头的股票头寸。当股价上涨的时候，股票头寸反而要增加，看起来有“追涨杀跌”（越涨越买、越跌越卖）的特性。这是因为要对冲的衍生品空头在股价越高的时候，带来的亏损越多，因而需要越多的股票多头来对冲。所以，这里的追涨杀跌是完全理性的行为。但在特定的市场状况下，这会加大市场的波动。</li><li>金融机构一般都会对其持有的组合给出各种希腊字母的上限。当某个组合达到某个希腊字母上限时，就会触发调整。</li><li>组合保险很可能放大市场波动。为了对冲股票头寸的下跌风险，需要提前卖出一部分股票头寸。在动态对冲的过程中，如果股票价格持续下跌，依照前面的组合保险策略，就需要不断卖出股票头寸，从而形成越跌越卖的格局。在有些时候，这会放大市场的波动。</li></ul><h1 id="第-20-讲-道德风险与信贷配给"><a href="#第-20-讲-道德风险与信贷配给" class="headerlink" title="第 20 讲 道德风险与信贷配给"></a>第 20 讲 道德风险与信贷配给</h1><p>尽管阿罗德布鲁世界给出了不少分析真实世界的洞察，但它太过理想化，无法被用来讨论很多现实世界中重要的金融现象。在真实世界中，广泛存在着各种各样的<strong>金融摩擦</strong>（financial frictions）。这些摩擦包括<strong>信息不对称</strong>（asymmetric information）、<strong>期限错配</strong>（maturity mismatch）、<strong>交易成本</strong>（transaction cost）等。这些金融摩擦的广泛存在，让许多在阿罗德布鲁世界中可以进行的交易在真实世界中无法发生。将这些摩擦忽略掉，很多真实世界中的金融现象就无从分析。</p><p>比如，在阿罗德布鲁世界中，所有金融交易都通过一个统一的市场直接完成，无需依赖银行等金融中介机构的协助。换言之，在阿罗德布鲁世界中没有金融中介机构存在的空间。自然，也就无法用阿罗德布鲁模型来分析金融机构。而在真实世界中，像商业银行这样的金融机构往往是金融市场的中心，有时也是金融动荡乃至金融危机发生的源头。为了分析真实世界中的这些重要的金融现象，我们有必要跳出阿罗德布鲁的框架。</p><h3 id="20-1-信息不对称与委托代理"><a href="#20-1-信息不对称与委托代理" class="headerlink" title="20.1 信息不对称与委托代理"></a>20.1 信息不对称与委托代理</h3><p>在许多经济学研究领域中，都有信息不对称的身影，以至于经济学中专门出现了<strong>信息经济学</strong>（information economics）这一分支。信息不对称可以分为两大类。第一类是<strong>事后</strong>（ex-post）的信息不对称——发生在交易合约签订之后的信息不对称——叫做<strong>道德风险</strong>（moral hazard）。另一类是<strong>事前</strong>（ex-ante）的信息不对称——存在于交易合约签订之前的信息不对称——叫做<strong>逆向选择</strong>（adverse selection）。</p><p>所谓<strong>道德风险，具体是指当交易一方的行为不为另一方所知，且行为的成本由另一方承担时，做出行为的一方会变得更加不审慎。</strong>比如，一个为自己房屋保了全额火灾险的人，可能更加疏于防范火灾。而所谓<strong>逆向选择，具体是说当交易的双方存在不对称信息时，有私人信息的一方可能会选择性地进行那些对自己有利的交易，而不进行对自己不利的交易，从而让另一方受损。</strong>比如，那些身体不好的人会有更强的动力去参与医疗保险，而那些身体健康的人反而可能不太愿意买保险。于是，保险公司就会承担更高的赔付风险。</p><p>分析信息不对称的常用工具是<strong>委托代理模型</strong>（principal-agent model）。模型中有两个主体：掌握信息的<strong>代理方</strong>（agent）与没有信息的<strong>委托方</strong>（principal）。代理方掌握的私人信息对双方的福利都有影响。如果不做更多的假设，委托与代理双方的讨价还价很容易产生多重均衡（多种结果都可能产生），因而无法得到有意义的结论。为此，在委托——代理模型中，假设所有讨价还价的权力都在委托方。<strong>委托方会设计一个合约</strong>，代理方只能选择接受还是不接受，而不能提出自己的合约。这样一来，委托——代理模型就描述了一个 Stackelberg 博弈。委托方是先行者（leader），代理方是跟随者（follower）。委托代理模型已经发展成了经济学的一个专门分支——<strong>契约理论</strong>（contract theory）</p><h3 id="20-2-信贷配给"><a href="#20-2-信贷配给" class="headerlink" title="20.2 信贷配给"></a>20.2 信贷配给</h3><p><strong>信贷配给，是指借款者即使愿意支付资金出借人所要求的利率水平（甚至更高），仍无法获得贷款的现象。</strong>与转型国家的行政管制不同，这些国家的信贷配给往往产生于借贷双方信息的不对称。这种因<strong>非对称信息</strong>（asymmetric information）而生的金融摩擦广泛存在，是许多现实世界中金融运行与理想状况发生偏差的关键。</p><p>接下来介绍的是让·梯若尔（Jean Tirole）给出的信贷配给基本模型。</p><blockquote><p>“有一位厨师掌握了技术，可以把面粉烤成美味的大饼。厨师自有的面粉数量有限。为了烤出尽可能大的饼，需要找别人借入面粉。但在烤饼的过程中，厨师可以通过偷懒来减轻自己的劳累。而厨师如果偷懒，烤饼的成功率会下降。厨师是否偷懒只有厨师自己知道，是厨师的私人信息。换句话说，当烤饼失败了，借出面粉的人并不知道这是因为厨师偷了懒，还是纯粹就因为这次烤饼时运气不好。”</p></blockquote><ul><li>按照委托代理理论，<strong>借出面粉的人应当是委托方，厨师应当是代理方</strong>。为了维护自己的利益，委托方。会想办法让厨师也在乎饼是否能够烤成功。而要做到这一点，委托方必须要保证在烤饼的面粉中，厨师自己的面粉占了足够大的比例，使得烤饼失败带给厨师的损失，大于厨师偷懒所获得的收益。</li></ul><p><strong>模型设定</strong></p><ul><li>初始投资 $I\in[0,+\infty]$</li><li><p>成功时初始投资可以产生 RI 的总回报，失败则0</p></li><li><p>市场利率为 0，并且资金出借方进行完全竞争，因而获得 0 利润</p></li><li>借款人拥有 A 的初始资金，借款人需要从出借人那里借入 I-A 的资金量来启动项目</li><li>当项目成功时，出借人和借款人分别获得 $R_l$ 与 $R_b$（$R_l+R_b=R_I$）</li><li>借款人获得借款之后，有两种选择 (“努力”（behaving）/ “偷懒”（misbehaving))</li><li>偷懒使得借款人从项目中获得 BI 的私人收益，但代价是项目成功的概率从 $p_H$ 下降到 $p_L=p_H-\Delta p&lt;p_H$</li></ul><p>当借款人努力时，投资项目有正的净现值（NPV）——项目期望总回报率高于无风险资产的总回报率</p><script type="math/tex; mode=display">p_HR>1</script><p>当借款人偷懒时，即使将项目带给借款人的私人收益算上，项目也只有负的净现值。</p><script type="math/tex; mode=display">P_LR+B<1</script><p>也就是说，只有当借款人努力的时候，项目才值得投资。而当借款人偷懒的时候，投资项目只是浪费资源，没有投资价值。</p><p>要激励借款者努力工作，努力时的预期收益必须大于后者</p><script type="math/tex; mode=display">p_HR_b\ge p_LR_b+BI\quad\Rightarrow\quad(\Delta p)R_b\ge BI</script><p>这被称为<strong>激励相容约束</strong>（incentive compatibility constraint）。这个条件的意思是，必须要让借款人在投资项目这张大饼中分得足够大的份额，才会让他有动力努力把项目做好，而不是偷懒来获取私人收益。</p><p>借款人要在项目大饼中分得足够大的份额，就意味着出借人从项目收益中拿走的份额不能太大。所以必然有</p><script type="math/tex; mode=display">R_l=RI-R_b\le(R-\frac B{\Delta p})I</script><p>此时出借人从项目中获得的期望收益为 $p_HR_l$。出借人愿意提供借款的前提条件是期望收益不低于提供的贷款数量</p><script type="math/tex; mode=display">p_HR_l\ge I-A</script><p>这被称为出借人的<strong>参与约束</strong>（participation constraint），或者叫做出借人的<strong>个人理性约束</strong>（individual rationality constraint）。</p><p>我们假设借人处于完全竞争之中，所以他们应该获得 0 利润，不等号应取等号。将 $R_l$ 的不等式代入</p><script type="math/tex; mode=display">I-A=p_HR_l\le p_H(R-\frac B{\Delta p})I</script><p>从中可以解出</p><script type="math/tex; mode=display">I\le kA</script><p>其中</p><script type="math/tex; mode=display">k=\frac1{1-p_HR+p_HB/\Delta p}</script><p>为了保证投资项目的规模总是有限的，我们要求 k 的分母是个大于零的的有限数，这一不等式可以化为</p><script type="math/tex; mode=display">p_HR-1<p_HB/\Delta p</script><p>它说的是<strong>每单位投资的期望回报率小于每单位投资的代理成本</strong>。如果这个条件不满足，就意味着代理成本比较小，资金出借方愿意借无限的资金给项目方，因而不存在信贷配给现象。在现实中，投资项目的边际回报一定是递减的，而不会像我们这个模型里假定的这样不变。所以投资项目规模有限的性质自然能满足。</p><p>又由前面对项目净现值的假设可知</p><script type="math/tex; mode=display">p_LR+B<p_HR\quad\Rightarrow\quad R>B/\Delta p</script><p>这意味着 $k&gt;1$。这说明借款者可以利用借入的资金来加杠杆杠，杆倍数就是 k。</p><p>只有借款人自己持有的初始资金比较多，出借人才会相信借款人会努力工作，因而才敢把资金借给借款人。于是，尽管成功的项目总能带来正的回报，出借人也仅会按照借款人的自有资金（A），提供有限的贷款（$(k-1)A$）。其中的 k 称为<strong>资本乘数</strong>（equity multiplier）。</p><p>当私人收益率 B 越小的时候，借款人偷懒的动力越小，资本乘数就越大。而当努力与偷懒表现在项目上的差异越大的时候（$\Delta p$）越大，借款人也越有动力努力，资本乘数也越大。如果一个借款人有从来不偷懒的声誉，那么他可以借入无限的资金，从而获得无限的回报。</p><h3 id="20-3-信贷配给理论的应用"><a href="#20-3-信贷配给理论的应用" class="headerlink" title="20.3 信贷配给理论的应用"></a>20.3 信贷配给理论的应用</h3><p>存在信贷配给时，企业资本的多寡（或者说企业的资产负债表状况）决定了企业的融资能力。这样，就形成了金融波动（尤其是资产价格的波动）向经济波动传导的机制。经济中资产价格的上升放松了企业的融资约束，导致银行信贷投放增加。而这更多的信贷投放往往又会进一步推升资产价格，并进一步放松融资约束。这样，资产价格泡沫和经济过热就伴随而生。而在经济衰退期，以上链条会反向运行。资产价格下降收紧企业融资约束。随之而来的信贷紧缩会令资产价格进一步走低，从而进一步压缩信贷投放。这样，资产价格的波动就成为了放大经济波动的原因。</p><p><strong>债务悬挂（debt overhang）</strong></p><p>债务悬挂指借款人因为已经债台高筑，所以无法为可以获得盈利的投资项目获取融资。</p><p><strong>债务通缩（debt deflation）</strong></p><p>1932 年欧文·费雪（lrving Fisher）在《繁荣与萧条》一书中，首次提出。</p><p>假设一项投资项目最低需要 $\bar I$ 的投资量启动。借款人是否能够获取融资来启动投资项目，关键取决于其净资产（扣除了债务之后的资产）是否超过了启动项目所需要的最低资本金 $\bar A=\bar I/k$。而借款人的资产 A 受到资产价格（股价、房价等）的影响很大，名义价值很容易表现出极大的波动性。而负债则经常是固定收益类的产品（贷款、债券等），名义价值比资产更有“刚性”。因此，在经济周期向下的时候，资产价值往往明显下降，导致企业净资产缩水。这会导致企业的融资约束收紧，经济中信贷增长减速，经济活动进一步走弱，物价进一步下降，资产价格进一步缩水，企业净资产的进一步缩水……在这样的情况下，经济陷入债务通缩状况。</p><p><strong>我国银行对国企和民企在融资方面的差别对待</strong></p><p>一个可能的解释是，相比民营企业来说，国有企业的代理成本更小。因为对国企员工来说，从项目偷懒里面获得的私人收益可能更低一些。这可能是因为国企规章制度更为严格，所以职工谋取私利的难度更大，也可能是因为国营企业行事相对正规，还可能是国企与银行之间的信息不对称程度更低。从这个角度来说，国有企业面临比民营企业更松的融资约束也有一定道理。</p><p><strong>财政和货币政策配合</strong></p><p>宽松的货币政策需要宽松的财政政策来配合。如果财政政策力度不足，宽松货币政策就难以有效缓解实体经济的融资难问题。</p><h1 id="第-21-讲-逆向选择与资本结构"><a href="#第-21-讲-逆向选择与资本结构" class="headerlink" title="第 21 讲 逆向选择与资本结构"></a>第 21 讲 逆向选择与资本结构</h1><p>逆向选择指由于信息不对称所导致的在市场中劣质商品驱除优质商品的现象。在严重情况下，逆向选择会摧毁整个市场。</p><p>对募集资金所能获得的投资回报率，公司比市场上的投资者了解得更清楚，因而带来了信息不对称的问题。投资者会怀疑公司募集资金时可能会吹嘘其投资回报率，以便获得融资。当投资者存在这样的怀疑时，即使那些投资回报率确实很不错的公司可能也无法获得融资。极端情况下，所有的企业都可能无法获得投资者的融资支持，导致<strong>市场崩溃</strong>（market breakdown）。就算市场没有崩溃，也会产生<strong>交叉补助</strong>（cross-subsidization）的问题，即因为存在公司欺骗投资者的可能，即使高回报的公司要融资，也必须要接受更为苛刻的融资条件。</p><h3 id="21-1-资本结构的经验事实"><a href="#21-1-资本结构的经验事实" class="headerlink" title="21.1 资本结构的经验事实"></a>21.1 资本结构的经验事实</h3><p>一个公司的融资结构就是它的资本结构（capital structure）。学术界有大量对资本结构的实证研究。用美欧等国的数据，研究者得到了以下一些大家基本都能认可的经验事实。</p><ul><li>盈利越多的公司借债越少。</li><li>有形资产较多的公司（如厂房、机床等）债务率较高；无形资产（intangible assets）较多的公司借债较少。无形资产一般用公司的研发和广告等费用占收入的比重来衡量。</li><li>公司增发股票时股价会下跌。</li><li>公司发行债券时股价的下跌并不明显。</li><li>公司在做资本结构变换时（比如发行股票来还债，或是借债来回购股票），公司的价值会随负债率的上升而上升。</li></ul><p>除了这些没太大争议的事实总结外，还有些目前仍存争议的经验发现。其中最重要的是公司融资的<strong>啄序偏好</strong>（pecking order preference）。有人发现，公司在筹措资金时，首先会选择内部融资（留存收益），其次是发行债券，再次是发行股票。</p><h3 id="21-2-MM-定理"><a href="#21-2-MM-定理" class="headerlink" title="21.2 MM 定理"></a>21.2 MM 定理</h3><p>1958 年，Modigliani 和 Miller 两人发表了研究资本结构的文章。这是公司金融理论奠基性的文章。他们在文章中指出，在完美的市场中公司价值与资本结构无关。换言之，在完美的市场中讨论资本结构是没有意义的。这便是“MM 定理”的结论。</p><p>记公司的价值为 V，公司股票的总价值为 E，公司发行债券的总价值为 D。公司的总价值应当等于其股票价值和债券价值之和。</p><script type="math/tex; mode=display">V=E+D</script><p>设公司的利润（息税前利润 EBIT）为 $\pi$ ，公司为债务支付的利息为 I。</p><p>假设有两家公司 A 和 B 除了资本结构不同之外，其他完全相同。A 公司完全不借债，只靠发行股票融资。B 公司则既发行股票也借债。我们还可以将 A 和 B 两个公司理解为同一家公司不借债和借债的两种状态。</p><script type="math/tex; mode=display">\begin{aligned}V_A&=E_A\\V_B&=E_B+D_B\end{aligned}</script><p>在真实世界中，债务的利息会被计入企业成本，在税前支付。如果公司所得税率为 t 的话，企业就能通过发行债券而节省 $tI$ 的所得税支付。$tI$ 就被称为<strong>税盾</strong>（tax shield）。把税盾效应考虑进来，在股权与债权两种融资方式下，企业会更偏好于债权融资。这种情况下，企业的资本结构就与公司价值有关了。</p><p>尽管多借债能增大税盾，但也会令企业破产风险上升，增加企业的破产成本。破产成本分为直接破产成本和间接破产成本。直接破产成本包括破产过程中的律师费、会计费等。间接破产指当企业面临较大破产风险时所遭受的损失，如雇员流失、客户和供应商流失、以及更高的融资成本等。</p><p>把税盾效应和破产成本考虑进来，企业就会有一个最优的股权与债权融资的比例。这便是资本结构的<strong>权衡理论</strong>（tradeoff theory）。这时，负债的 B 公司的价值就不再等于 A 公司的价值，而是要加上税盾的现值，并减去破产成本的现值</p><script type="math/tex; mode=display">V_B=V_A+PV(税盾)-PV(破产成本)</script><h3 id="21-3-信息不对称条件下的资本结构"><a href="#21-3-信息不对称条件下的资本结构" class="headerlink" title="21.3 信息不对称条件下的资本结构"></a>21.3 信息不对称条件下的资本结构</h3><p>融资市场中存在大量风险中性的企业。它们手里都没有自有资金，需要从市场上的投资者那里借入</p><ul><li>企业对资金的需求量是 I</li><li>如果项目成功，获得 R 的回报</li><li>市场中还存在大量风险中性且完全竞争的投资者，均获得 0 利润</li><li>好企业有 p 的概率让投资项目成功，坏企业只有 q 的概率令项目成功，且 $p&gt;q$</li><li>项目是值得投资的，有正的净现值 $pR&gt;I$</li><li>好企业的比例为 $\alpha$ ，坏企业的比例 $1-\alpha$ 。</li></ul><p>从投资者的角度来看，将资金借给一个企业后项目成功的概率为</p><script type="math/tex; mode=display">m\triangleq \alpha p+(1-\alpha)q</script><p>假设企业与投资者之间只能签订这样的合同：规定企业在项目成功时获得 $R_f\ge0$ 的回报，而在项目失败时获得 0 回报。由于投资者无法分辨企业的类型，且坏企业不会向投资者揭示其类型，所以所有的企业都会用同样的合约来从市场获得融资。这样，投资者从合约中获得的期望收益将为</p><script type="math/tex; mode=display">m(R-R_f)-I=[\alpha p+(1-\alpha)q](R-R_f)-I</script><p><strong>市场中无借贷（ $mR&lt;I$ ）：市场崩溃</strong></p><p>如果坏企业项目的净现值为负，且坏企业的占比足够大</p><script type="math/tex; mode=display">\alpha<\alpha^*,\quad \alpha^*pR+(1-\alpha^*)qR=I</script><p>这时，投资者从融资契约中获得的期望收益不可能大于 0，因而她不会给任何企业提供融资。市场中没有任何融资行为，融资市场崩溃。由于此时即使好企业也无法获得融资，所以相比对称信息的状况，此时<strong>投资不足</strong>（under-investment）</p><p><strong>市场中有借贷（$mR\ge I$）：交叉补贴</strong></p><p>此时，所有企业都可以获得投资者的融资支持。项目成功时企业所能获得的收益由下面的投资者 0 利润条件决定</p><script type="math/tex; mode=display">m(R-R_f)=I</script><p>上式可以化为</p><script type="math/tex; mode=display">\alpha[p(R-R_f)-I]+(1-\alpha)[q(R-R_f)-I]=0</script><p>这意味着投资者从好企业那里获得了正的利润（$p(R-R_f)&gt;I$），从坏企业那里得到了负利润（$q(R-R_f)&lt;I$）。容易看出，好企业在信息不对称情况下得到的收益小于信息对称情况下的收益。而坏企业则在信息不对称情况下获得了比信息对称时更高的收益。这便形成了好企业对坏企业的交叉补贴。代价则是好企业的收益受损。此外，即使如果坏企业投资项目的净现值小于0，坏企业仍然能够获得融资来建成投资项目。从而导致了<strong>过度投资</strong>（over-investment）。</p><p><strong>啄序假说</strong></p><p>可以给不同融资方式按照信息强度（information intensity）的从低到高来排序：内部融资（企业自有现金、留存收益）、债券、股票。信息强度可被理解为对某种融资方式的价值评估在多大程度与获取的信息相关。站在企业的外部来看，信息强度越高的融资方式，越需要获取更多信息来评估其价值。这也意味着在信息强度越高的融资方式中，企业越可能利用自己的信息优势来占外部投资者的便宜。考虑到这一点，外部投资者对信息强度越高的融资方式会越审慎，越是会要求更高的回报率。这样，那些质地优良的企业就会倾向于选择信息强度低的融资方式来获取融资，以降低自己的融资成本。所以，企业在融资方式的选择上会有一个按信息强度从低到高的偏好关系。这便是啄序假说的基本观点。</p><p>为了区分债券与股票两种融资方式，现在我们假设投资项目在失败时也会带来正的回报 $R^F&gt;0$ 。而在项目成功时，项目回报为 $R^S=R^F+\Delta R&gt;R^F$。</p><p>在之前的基础上我们假设市场并未因为信息不对称而崩溃，即</p><script type="math/tex; mode=display">mR^S+(1-m)R^F>I</script><p>令 $\{R_f^S,R_f^F\}$ 为融资合约中规定的，在项目成功及失败两种情况下企业所获的收益。好企业会选择 $R_f^S$ 与 $R_f^F$，使得在满足投资者 0 利润条件的前提下，企业自身所得的期望收益尽可能的高。于是，好企业的契约优化问题可写为</p><script type="math/tex; mode=display">\max_{R_f^S,R_f^F} pR_f^S+(1-p)R_f^S</script><script type="math/tex; mode=display">s.t.\quad m(R_S-R_f^S)+(1-m)(R_F-R_f^F)-I=0</script><p>上面这个优化问题的约束条件可化为</p><script type="math/tex; mode=display">[p-(1-\alpha)(p-q)](R^{S}-R_{f}^{S})+[1-p+(1-\alpha)(p-q)](R^{F}-R_{f}^{F})-I=0</script><p>可以进一步变形为</p><script type="math/tex; mode=display">\underbrace{p R_{f}^{S}+(1-p) R_{f}^{F}}_{\text {好企业的期望收益 }}=\underbrace{[p R^{S}+(1-p) R^{F}-I]}_{\text {好企业的净现值 }}-\underbrace{(1-\alpha)(p-q)[(R^{S}-R_{f}^{S})-(R^{F}-R_{f}^{F})]}_{\text {逆向选择带来的折扣 }}</script><p>逆向选择的折扣是 $R_f^S$ 的减函数，$R_f^F$ 的增函数。于是对好企业来说，最优的契约一定是</p><script type="math/tex; mode=display">R_f^F=0</script><p>即项目失败时企业没有任何收益。而项目成功时的企业收益则由投资者 0 利润条件决定</p><script type="math/tex; mode=display">m(R^S-R_f^S)+(1-m)R^F=I</script><p>从直觉上可以这样来理解这一结果：逆向选择折扣体现了好企业向坏企业所做的补贴。为了减小这个补贴，好企业会愿意把收益尽可能多地放在只有自己容易获得的地方。相比坏企业，好企业成功的概率更大，而失败的概率更小。自然地，好企业有动力把项目成功时的收益 $R_f^S$  设定得高一些，而项目失败时的概率 $R_f^F$ 设定得小一些。</p><p>对投资者来说，在项目失败时她获得 $R^F$ 作为回报。而在项目成功时，投资者的回报为</p><script type="math/tex; mode=display">R^S-R_f^S=R^F+\frac{I-R^F}m</script><p>一定有 $I&gt;R^F$ 。否则项目一定会给出严格为正的投资回报率，市场利率就不可能是 0。所以投资者在项目成功时获得的回报一定大于项目失败时获得的回报（$R^F$）。</p><p>让我们来看看前面求解出来的这个最优契约意味着什么。投资者的回报可以分为两部分。一部分是 $R_F$，无论项目成功还是失败都能得到。这部分可以被认为是无风险的债券。另一部分是$(I-R^F)/m$，只有在项目成功时才会有。这部分可被看作股票，回报是不确定的。所以在融资时，企业会先发行无风险的债券来筹资。不足的部分再用股票来弥补。这便是啄序假说的结论。</p><h3 id="21-4-分离均衡与增发股票带来的股价下跌"><a href="#21-4-分离均衡与增发股票带来的股价下跌" class="headerlink" title="21.4 分离均衡与增发股票带来的股价下跌"></a>21.4 分离均衡与增发股票带来的股价下跌</h3><p>在前面对啄序假说的模型分析中，我们看到坏企业总是想伪装成好企业。这种投资者无法分辨两类企业的均衡叫做<strong>混合均衡</strong>（pooling equilibrium）。有人可能会想知道，有没有可能坏企业会自己向投资者揭示其类型，从而在市场均衡时让投资者可以把两类企业区分开来？对这个问题的答案是肯定的。这样的均衡叫做<strong>分离均衡</strong>（separating equilibrium）。</p><p>现在我们来考虑企业深化投资（investment deepening）的融资决策。假设两类企业都可以通过再投资 I 来将自己的成功概率提升 $\tau$ 的幅度。这里的一个关键假设是深化投资的回报无法与原来项目的回报区分开来。也就是说，企业无法把这个深化投资产生的现金流单拎出来寻求融资。</p><p>在这种情况下，投资者的 0 利润条件可以写成</p><script type="math/tex; mode=display">[\alpha(p+\tau)+(1-\alpha)(1+\tau)]R_l=I</script><p>可将其变形为</p><script type="math/tex; mode=display">(m+\tau)R_l=I</script><p>深化投资之后好企业的收益应该不低于不进行深化投资的情形</p><script type="math/tex; mode=display">(p+\tau)(R-R_l)\ge pR</script><p>代入上式可得</p><script type="math/tex; mode=display">(p+\tau) R-(p+\tau) \frac{I}{m+\tau} \geq p R \quad \Rightarrow \quad \tau R \geq \frac{p+\tau}{m+\tau} I</script><p>当 $\tau$ 足够大时，上面这个不等式总是能够成立的。这意味着如果深化投资带来的效果足够好，好企业是会愿意稀释自己的股权来做深化投资的。</p><p>坏企业愿意进行深化投资的条件是</p><script type="math/tex; mode=display">(q+\tau)(R-R_l)\ge qR</script><p>它等价于</p><script type="math/tex; mode=display">\tau(R-R_l)\ge qR_l</script><p>同理好公司的条件也可等于</p><script type="math/tex; mode=display">\tau(R-R_l)\ge pR_l</script><p>所以，如果好企业深化投资的条件成立，坏企业深化投资的条件必然也成立。也就是说，如果好企业愿意进行深化投资，坏企业也一定愿意。但这个结论反过来则未必成立。</p><p>投资者无法从增发股票这个行为来分辨企业类型。所以，在股票增发前后，好坏两类企业的股票总价值都是</p><script type="math/tex; mode=display">(m+\tau)R-I</script><p>如果好企业深化投资的条件不成立。</p><script type="math/tex; mode=display">(p+\tau)(R-R^B_l)\le pR</script><p>此时，好企业不愿意增发股票来进行深化投资，而坏企业则愿意增发股票。不过，此时投资者会知道只有坏企业会增发股票，所以会要求在项目成功时获得更多的回报以满足其 0 利润条件，即</p><script type="math/tex; mode=display">(q+\tau)R_l^B=I\quad\Rightarrow\quad R_l^B=\frac I{q+\tau}>R_l</script><p>企业股票增发前后的股票总价值差为</p><script type="math/tex; mode=display">\begin{aligned}V_{0}-V_{1} &=\alpha[p R]+(1-\alpha)[(q+\tau) R-I]-[(q+\tau) R-I] \\&=\alpha[p R-(q+\tau) R+I]\end{aligned}</script><p>这个差是正是负取决于方括号这部分的符号。而我们可以推得</p><script type="math/tex; mode=display">p R>(p+\tau)(R-R_{l}^{B})=(p+\tau)(R-\frac{I}{q+\tau})>(q+\tau)(R-\frac{I}{q+\tau})=(q+\tau) R-I</script><p>所以必有</p><script type="math/tex; mode=display">V_0>V_1</script><p>即股票增发的消息会让企业的股票总价值下降。从信息的角度，我们能看出这背后的道理。公司增发股票所做的投资性项目确实可能带来正的净现值。但是，公司增发股票的行为却可能向投资者揭示了自己的类型，改变了投资者的信息。信息的改变令投资者对公司的估价发生变化，从而让股价下跌。</p><h1 id="第-22-讲-银行与期限错配"><a href="#第-22-讲-银行与期限错配" class="headerlink" title="第 22 讲 银行与期限错配"></a>第 22 讲 银行与期限错配</h1><p>克服信息不对称虽然是金融中介的重要功能之一，但绝非其唯一功能。金融中介机构还会从其他方面发挥促进市场运行，提升资源配置效率的功能。这里面最重要的功能就是通过金融机构的<strong>期限错配</strong>（maturity mismatch）来发挥<strong>期限转换</strong>（maturity transformation）的作用，从而为金融市场提供<strong>流动性</strong>（liquidity）。</p><h3 id="22-1-Diamond-Dybvig-银行模型（DD-模型）"><a href="#22-1-Diamond-Dybvig-银行模型（DD-模型）" class="headerlink" title="22.1 Diamond-Dybvig 银行模型（DD 模型）"></a>22.1 Diamond-Dybvig 银行模型（DD 模型）</h3><p>Diamond 与 Dybvig 这篇经典文章从流动性的角度探讨了银行的功能。如果所有的消费者处在自给自足的状况（autarky），那么他们就会因为流动性冲击的可能，而不敢把太多资源放到高回报的长期项目上，从而失去了获取高收益的机会。就算在流动性冲击发生之后给消费者相互交易的机会，也无法实现最优的资源配置。只有引入银行这种机构才能实现最优配置。但这样做并非全无代价，而会带来银行挤兑的风险。</p><p>在 DD 模型中，流动性被赋予以下两个含义。第一，一种资产如果能够及时、且无损失地转化为消费品，我们就称其为<strong>流动性资产</strong>（liquid asset）。第二，如果消费者不能确定其消费的时间，因而渴望持有流动性资产，我们称这样的消费者具有<strong>流动性偏好</strong>（liquidity preference）。</p><p><strong>DD 模型设定</strong></p><p>DD 模型设定一个包含三个时刻的模型。模型中仅存在一种消费品，既可以用来消费，也可以用来投资。在 0 的时刻，每位消费者均有 1 单位的消费品禀赋。在 1, 2 时刻，消费者不再获得新的禀赋。在各个时刻之间，消费者的主观贴现因子均为 1。</p><p>存在两种资产可被用来做投资。消费者可以用它们来将 0 时刻的消费品转移到 1 或 2<br>时刻。两种资产分别是：</p><ul><li><strong>短期资产（流动性资产）：</strong>短期资产是一种储藏技术。它可以将 t 时刻的 1 单位消费品转化为 t+1 时刻的 1 单位消费品。</li><li><strong>长期资产（非流动性资产）：</strong>长期资产需要两期才能获得收益。在 0 时刻将 1 单位消费品投资到长期资产上，在 2 的时刻可以产生 R（&gt;1）单位的消费品。为了分析的简便，我们在讨论银行挤兑之前，都假设长期资产不能在 1 时刻提前变现。这并不会给我们的分析带来实质性的变化，但能简化推理。</li></ul><p>与短期资产相比，长期资产牺牲了流动性（灵活性），但可以获得更高的投资收益。这种流动性与回报率之间的权衡（tradeoff）在现实世界中非常普遍。</p><p><img src="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/pic22-1.jpg" alt></p><p><strong>流动性偏好</strong></p><p>消费者在消费时间的偏好上存在不确定性。消费者有 $\lambda$ 的概率是一个“前期消费者”（无耐心），只能够通过 1 时刻的消费获得效用。消费者还有 $1-\lambda$ 的概率是一个“后期消费者”（有耐心），只能通过 2 时刻的消费获得效用。因此，对前期（后期）消费者来说，2 时刻（1时刻）的消费没有价值。消费者的效用函数为</p><script type="math/tex; mode=display">U(c_{1}, c_{2})=\bigg\{\begin{array}{ll}u(c_{1}) & \text { 概率为 } \lambda \\u(c_{2}) & \text { 概率为 } 1-\lambda\end{array}</script><p>在 0 时刻决策时，消费者需要通过对禀赋的配置来最大化其期望效用</p><script type="math/tex; mode=display">EU=\lambda u(c_1)+(1-\lambda)u(c_2)</script><p> <strong>自给自足状况（autarky）下的配置</strong></p><p>令 $\theta$ 为消费者在 0 时刻投资在短期资产中的禀赋比例。自然，0 时刻投资在长期资产中的比例就为 $1-\theta$。</p><script type="math/tex; mode=display">\left\{\begin{array}{l}c_{1} & = \theta \\c_{2} & = \theta+(1-\theta) R\end{array}\right.</script><p>将其代入消费者的期望效用函数可得</p><script type="math/tex; mode=display">EU(\theta) = \lambda u(\theta)+(1-\lambda) u(\theta+(1-\theta) R)</script><p>在内点解上,  $\theta$  的最优值满足</p><script type="math/tex; mode=display">\lambda u^{\prime}(c_{1}^{A T K})= (1-\lambda)(R-1) u^{\prime}(c_{2}^{A T K})</script><p>假设 $\theta^{ATK}$ 为上式的解。将其代入消费者 0 时刻的期望效用函数，可得这种情况下的效用水平 $EU^{ATK}$。$EU^{ATK}$ 可被视为消费者的保留效用。如果其他的安排无法达到这个效用水平，消费者就会退回到自给自足的状态。这是我们接下来福利比较的一个基准。</p><p><strong>最佳配置（中央计划者配置）</strong></p><p>大数定律告诉我们，不管单个消费者的类型是怎样的，总人口中总有λ 比例的前期消费者，以及 $1-\lambda$ 比例的后期消费者。因此，如果让一个中央计划者（central planner）来配置资源，可以让每个消费者都达到最高的 0 时刻的期望效用。这将产生最佳的配置。我们假设经济中有总数量为 N 的消费者（N 足够大，以使得大数定律生效）。则经济中 0 时刻消费品总禀赋为 N。经济中前期消费者的数量为 $\lambda N$，后期消费者数量为$(1-\lambda)N$。这样，1 时刻经济中消费品的需求量为 $\lambda Nc_1$，2 时刻消费品需求总量为$(1-\lambda)Nc_2$。经济中消费品的总需求量是确定的，不存在不确定性。因此，中央计划者会选择投资组合，精确地在 1 和 2 时刻满足经济中的消费品需求量。所以，</p><script type="math/tex; mode=display">\left\{\begin{array}{l}\lambda Nc_{1} & = \theta N\\(1-\lambda)Nc_{2} & =(1-\theta)NR\end{array}\right.</script><p>最大化所有消费者的总效用 (目标函数以及约束条件中可以把 <em>N</em> 去掉，而不影响优化问题的本质)</p><script type="math/tex; mode=display">\max_\theta EU= \lambda u(c_1)+(1-\lambda)u(c_2)</script><script type="math/tex; mode=display">\begin{aligned}\text { s.t. } & \lambda c_{1}=\theta \\& (1-\lambda) c_{2}=(1-\theta) R\end{aligned}</script><p>题的约束条件代入目标函数可得</p><script type="math/tex; mode=display">E U=\lambda u(\frac{\theta}{\lambda})+(1-\lambda) u(\frac{(1-\theta) R}{1-\lambda})</script><p>这一优化问题的一阶条件为</p><script type="math/tex; mode=display">u^{\prime}\left(c_{1}^{B S T}\right)=u^{\prime}\left(c_{2}^{B S T}\right) R</script><p>由于 $R&gt;1$，所以必然有 $c_1^{BST}&lt;c_2^{BST}$。假设 $\theta^{BST}$ 为上式的解。对应的中央计划者情况下，消费者的期望效用为 $EU^{ATK}$。$EU^{ATK}$ 就是消费者可能达到的最高效用水平。</p><p><strong>市场均衡（market equilibrium）</strong></p><p>在模型中真正可能实现的市场是在 1 时刻，当消费者获知了自己的类型之后，前期消费者和后期消费者在市场上交易其资产。前期消费者将自己手中的长期资产出售给后期消费者，换取后期消费者手中的短期资产。如果以消费品为计价单位的长期资产的价格为 p，则前期和后期消费者的人均消费分别为</p><script type="math/tex; mode=display">\left\{\begin{array}{l}c_{1} & = \theta +(1-\theta)p\\c_{2} & = (1-\theta+\frac\theta p) R\end{array}\right.</script><p><strong>命题 22.1：</strong>在 1 时刻的市场中，长期资产的价格一定为 1（p=1）</p><p>代入可知 $c_1^{MKT}=1,c_2^{MKT}=R$。市场均衡下消费者在 0 时刻的期望效用为</p><script type="math/tex; mode=display">EU^{MKT}=\lambda u(1)+(1-\lambda)u(R)</script><p>而在自给自足的情况下</p><script type="math/tex; mode=display">\left\{\begin{array}{l}c_{1}^{MKT} & \le 1\\c_{2}^{MKT} & \le R\end{array}\right.</script><p>且两个不等式不可能同时取等号。因此，市场均衡下的消费（1 时刻和 2 时刻）严格占优于自给自足时的消费状况。所以，必然有 $EU^{MKT}&gt;EU^{ATK}$。</p><p>前面已经计算出来了，在中央计划者的安排中，1 和 2 时刻的人均消费量</p><script type="math/tex; mode=display">\left\{\begin{array}{l}c_{1} & = \frac\theta\lambda\\c_{2} & = \frac{(1-\theta) R}{1-\lambda}\end{array}\right.</script><p><img src="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/pic22-2.jpg" alt></p><p>容易验证，($c_1=1, c_2=R$)这个点在直线上（$\theta=\lambda$ 时）。中央计划者可以在这根直线上选择配置，以达成最优条件。因此，在一般情况下，$EU^{BST}&gt;EU^{MKT}$。只有在 $u’(1)=u’(R)R$ 这一特殊情况下（也就是效用函数为对数效用时），。还需要$EU^{BST}=EU^{MKT}$ 注意上图只是示意性的。根据前面的计算，在最优的资源配置下（$BST、<br>BNK$）应该有 $c_1&lt;c_2$。但为了让图形看起来更清楚，我们在上图中并未严格照此绘图。</p><blockquote><p>在时刻 1 的资产市场中，长期资产的价格对交易数量完全不敏感。但这恰恰说明了市场对流动性的提供是无效率的。</p></blockquote><h3 id="22-2-银行"><a href="#22-2-银行" class="headerlink" title="22.2 银行"></a>22.2 银行</h3><p>与前面介绍的这种 1 时刻开放的市场相比，银行可以做得更好。银行业是自由进入，完全竞争的。银行之间的竞争使得银行取得零利润。而为了尽可能地争取储户，银行会愿意给储户提供尽可能高的 0 期期望效用，从而形成与中央计划者完全一致的优化目标函数。</p><p>由于银行配置与中央计划者配置完全一样，所以必然有 $c_1^{BNK}&lt;c_2^{BNK}$。因此，后期消费者没有动力伪装成前期消费者，在时刻 1 从银行提款。如果他这样做了，他只能在 2 时刻获得 $c_1^{BNK}$（而非 $c_2^{BNK}$）的消费量。他的效用会因此而降低。</p><p>尽管银行这一机制看上去很不错，但它存在一个内生的脆弱性——<strong>银行挤兑</strong>（bank run）。用经济学的术语来说，在银行这一制度安排下存在多重均衡——除了前面给出的前期与后期消费者分期取款，进而达成各自消费的最大化这一均衡之外，还存在着另外的银行挤兑均衡。</p><p>在银行这一制度安排下，有两个纳什均衡：<br>1) <strong>正常均衡：</strong>所有后期消费者相信别的后期消费者都会等到 2 时刻去提款，所有后期消费者就会等到 2 时刻提款。这样，最优的资源配置可以达成。<br>2) <strong>银行挤兑均衡：</strong>所有后期消费者相信别的后期消费者会抢在 1 时刻去提款。在这种信念之下，所有后期消费者都会在 1 时刻提款。此时发生银行挤兑。</p><p>决定这两个均衡哪个会变为现实的，是后期消费者的信念（belief）。无论是“没有挤兑”的信念，还是“有挤兑”的信念，都会<strong>自我实现</strong>（self-fulfilling），即信念会将信念自己所预期的结果给生成出来。仅靠银行自身是不能消除银行挤兑这种风险的。因此，银行体系的稳定需要外力来加以保证。这种外力的关键是稳定后期消费者的预期，让他们没有提前提款的动力。一种常见的方式是设立<strong>存款保险</strong>（deposit insurance），保证后期消费者即使在银行出现问题的时候也能在 2 时刻确定地获得其应得的支付。这样一来，后期消费者就没有动力抢在 1 时刻提款，银行挤兑也就不会发生。</p><h1 id="第-23-讲-行为金融学初探"><a href="#第-23-讲-行为金融学初探" class="headerlink" title="第 23 讲 行为金融学初探"></a>第 23 讲 行为金融学初探</h1><p>市场中的价格总是反映了资产的基本面价值，价格总是正确的（prices are right）——这便是所谓的<strong>有效市场</strong>（efficient market）。弗里德曼早在 1953 年就在文章中阐述了这一逻辑。我们将非理性的交易者（投资者）称为<strong>噪声交易者</strong>（noise traders），而将理性的投资者称为<strong>套利者</strong>（arbitrageurs）。我们还将<strong>套利</strong>（arbitrage）称为无风险获取收益的机会。用这样的语言来翻译弗里德曼的逻辑，就是：一旦噪声交易者让资产价格偏离了基本面价值，就马上在市场上创造了套利机会，从而吸引套利者进入。套利者在收取套利收益的同时也让资产价格回归基本面。</p><p>以上的逻辑有两点需要仔细分析。首先，是不是噪声交易者一旦推动资产价格偏离了基本面，套利行为就一定会让资产价格快速回归基本面？第二，类似噪声交易者这样的非理性行为是否会在市场上长期存在？对这两个问题的回答分别属于有限套利和非理性偏差的内容。这二者便是<strong>行为金融学</strong>（behavioral finance）的两大主体内容。</p><h3 id="23-1-投资绩效约束下的有限套利"><a href="#23-1-投资绩效约束下的有限套利" class="headerlink" title="23.1 投资绩效约束下的有限套利"></a>23.1 投资绩效约束下的有限套利</h3><p>行为金融学认为，市场中存在诸多因素，有可能使得套利仅能在有限的程度上展开。这种<strong>有限套利</strong>（limits to arbitrage）可能导致资产价格偏离基本面价值。大体来说，对套利的限制来自<strong>基本面风险</strong>（fundamental risk）、<strong>实施成本</strong>（implementation costs）和<strong>噪声交易者风险</strong>（noise trader risk）等因素。除了上面提到的这些妨碍套利的风险之外套利还可能面临模型风险（model-based risk）。</p><p>有限套利产生的原因有很多种。在这里，我们利用 Shleifer 与 Vishny（1997）给出的模型来介绍一种特殊的有限套利来源——投资绩效约束下的有限套利。</p><p><strong>模型设定</strong></p><p>模型中有三个时刻。三个时刻之间没有折现，无风险利率为 0。经济中存在一种总供给量被正规化为 1 的资产。该资产在时刻 1 和 2 没有支付（payoff），但在时刻 3 会确定性地带来支付 V。经济中存在两种投资者：噪声交易者（noise traders）与风险中性的套利者（arbitrageurs）。在时刻 3，两类投资者都清楚无误地知道资产的支付 V。因此，时刻 3 的资产价格 $p_3$必定为 V。</p><p>不过，噪声交易者在时刻 1 与时刻 2 可能会对资产在时刻 3 的支付产生错误的认识。在时刻 1 和 2，噪声交易者认为时刻 3 的资产支付为 $V-S_t（S_t\ge 0）$。其中的 $S_t$ 为噪声交易者对资产支付的误判程度。$S_t$ 前面的负号意味着我们假设噪声交易者总是悲观（pessimistic）的。给定噪声交易者的错误认知，在 $t=1,2$ 时，噪声交易者对资产的总需求为</p><script type="math/tex; mode=display">N(t)=\frac{V-S_t}{p_t}</script><p>在时刻 1，套利者知道当期噪声交易者的认知偏差为 $S_1$。套利者在做时刻 1 的投资决策时，可以利用这一信息。但是，套利者在时刻 1 并不清楚时刻 2 噪声交易者的认知偏差 $S_2$ 会是多少，而只知道 $S_2$ 有如下的概率分布</p><script type="math/tex; mode=display">S_2=\bigg\{\begin{array}{ll}S>S_1 & \text { 概率为 } q \\0 & \text { 概率为 } 1-q\end{array}</script><p><img src="/2022/01/27/%E9%87%91%E8%9E%8D%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AE%B2/pic23-1.jpg" alt></p><p>在时刻 1，套利者有外生给定的 $F_1$ 的资金可用来投资到资产上。在时刻 2，套利者的可用资金将变成 $F_2$。套利者 2 时刻所拥有的资金量 $F_2$ 由其 1、2 两时刻间的投资绩效所决定。因为资产的总供给量为 1，所以有</p><script type="math/tex; mode=display">\frac{V-S_2}{p_2}+\frac{F_2}{p_2}=1</script><p>解出</p><script type="math/tex; mode=display">p_2=V-S_2+F_2</script><p>我们假设 $F_2&lt;S_2$，即套利者所拥有的资金量不足以使 2 时刻的资产价格回到其基本面所对应的价格 V。</p><p>在 1 时刻，套利者不一定会愿意把所有的资金 $F_1$ 都投入到资产中。假设在 1 时刻，套利者投入 $D_1$ 的资金量（$D_1\le F_1$）在资产上，则类似前面计算 2 时刻资产价格的方式，可以计算出 1 时刻的资产价格为</p><script type="math/tex; mode=display">p_1=V-S_1+D_1</script><p>我们继续假设 $F_1&lt;S_1$，即 1 时刻的价格也无法被套利者推回至基本面对应的价格 V。</p><p><strong>基于投资绩效的套利</strong></p><p>套利者的套利能力受到其投资绩效的约束（performance-based arbitrage，简称 PBA）。这是模型中只存在有限套利的原因。我们可以把套利者设想为基金经理。他们从资产管理场上募集资金进行套利活动。他们第 2 时刻能够获取的资金量 $F_2$ 与其第 1 时刻投资所获得的投资总回报率（假设为 R）正相关。具体地，我们假设</p><script type="math/tex; mode=display">\begin{aligned}F_{2} &=F_{1}(1+a(R-1)) \\&=F_{1}(a R+1-a)\end{aligned}</script><p>其中，$a\ge 1$为一个参数。这一函数形式意味着如果套利者第1时刻的投资回报率为正（$R-1&gt;0$），则套利者第 2 期可掌握的资金量会多于第 1 期。反之，如果投资回报率为负（$R-1&lt;0$），则套利者会遭遇基金赎回，第 2 期能掌握的资金量将低于 1 期。而如果投资回报率为 0（$R-1=0$），则套利者两期可支配资金量相等。</p><p>对套利者来说，他们 1 时刻投资的总回报为</p><script type="math/tex; mode=display">R=\frac{D_1}{F_1}·\frac{p_2}{p_1}+\frac{F_1-D_1}{F_1}</script><p>代入得</p><script type="math/tex; mode=display">\begin{aligned}F_{2} &=F_{1}(a R+1-a) \\&=F_{1} a(\frac{D_{1}}{F_{1}}·\frac{p_{2}}{p_{1}}+\frac{F_{1}-D_{1}}{F_{1}})+(1-a) F_{1} \\&=a(\frac{D_{1}·p_{2}}{p_{1}}+F_{1}-D_{1})+(1-a) F_{1} \\&=F_{1}+a D_{1}(\frac{p_{2}}{p_{1}}-1)\end{aligned}</script><p><strong>套利者的优化问题</strong></p><p>我们假设套利者以恒定的管理费率收取资金管理费。其目标是最大化第 3 期所收取的管理费。这等价于最大化第 3 期所掌管的资金量。</p><p>根据前面的设定，模型中只有一个不确定性的来源，就是第 2 期噪声交易者的认知误差——以 q 的概率进一步增大为 S；或是完全消失。当噪声交易者时刻 2 的认知误差完全消除时，资产价格会在第 2 期就回到 V。此时，无论投资者在第 2 时刻是将所有资金都投入资产，还是以现金方式留在手中，都会得到相同的时刻 3 资金量</p><script type="math/tex; mode=display">W=F_1+aD_1(\frac V{p_1}-1)</script><p>当噪声交易者时刻 2 的认知误差增大时，时刻 3 的套利者资金量为</p><script type="math/tex; mode=display">W=\frac V{p_2}[F_1+aD_1(\frac {p_2}{p_1}-1)]</script><p>于是，套利者在时刻 3 资金量的期望为</p><script type="math/tex; mode=display">EW=(1-q)[F_1+aD_1(\frac V{p_1}-1)]+q\frac V{p_2}[F_1+aD_1(\frac {p_2}{p_1}-1)]</script><p>套利者是在约束条件 $0\le D_1\le F_1$ 的约束下，最大化目标函数式。这是带不等式约束的优化问题，可以用库恩—塔克方法求解。不过，用经济学直觉也能求出其解。期望资金量对 $D_1$ 的偏导数为</p><script type="math/tex; mode=display">\frac{\partial E W}{\partial D_{1}}=a(1-q)(\frac{V}{p_{1}}-1)+a q \frac{V}{p_{2}}(\frac{p_{2}}{p_{1}}-1)</script><p>式中得这个偏导数代表了在时刻 1 边际上增加一块钱投资在资产上的资金，带给时刻 3 期望资金量的边际增量。它由两项组成。第一项是时刻 1 每增加一块钱在资产上，当 2 时刻资产价格回归基本面 V 时的收益。第二项是当 2 时刻噪声交易者的悲观认知误差进一步加剧时，在资产上投资带来的损失。</p><p><strong>套利者全投资情形</strong></p><p>为了简化分析，我们只研究套利者在 1 时刻把所有资金都投入资产的情形</p><script type="math/tex; mode=display">p_1=V-S_1+F_1</script><script type="math/tex; mode=display">F_2=F_{1}[1+a(\frac{p_{2}}{p_{1}}-1)]</script><p>这说明，1 时刻和 2 时刻之间资产价格涨幅越大，2 时刻套利者能支配的资金量越多。</p><p>我们来分析 2 时刻噪声交易者悲观认知进一步加大的情形。</p><script type="math/tex; mode=display">\begin{aligned}p_{2} &=V-S+F_{2} \\&=V-S+F_{1}[1+a(\frac{p_{2}}{p_{1}}-1)]\end{aligned}</script><p>从中可以解出</p><script type="math/tex; mode=display">p_{2}=\frac{p_{1}[V-S+F_{1}(1-a)]}{p_{1}-a F_{1}}</script><p>我们关心的是在不同情况下，噪声交易者的认知偏差 S 对时刻 2 资产价格的影响。由上式可知</p><script type="math/tex; mode=display">\frac{d p_{2}}{d S}=-\frac{p_{1}}{p_{1}-a F_{1}}<-1</script><p>而如果经济中完全不存在套利者（$F_1=0$），2 时刻资产价格为 $p_2=V-S$。此时 $dp_2/d_S=-1$。所以，当存在套利行为受限的套利者时，2 时刻的资产价格反而对噪声交易者的认知误差更加敏感（$dp_2/d_S$ 绝对值更大）。换句话说，受限套利者的存在反而加大了 2 时刻资产价格的波动。进一步说，套利者时刻 2 资金量对其投资业绩越敏感（a 越大），时刻 2 资产价格对噪声交易者的认知误差越敏感（$dp_2/d_S$ 绝对值越大）。而如果经济中存在不受资金约束的套利者（其资金量无限），那么不管 2 时刻噪声交易者的认知偏差是多少，2 时刻的资产价格将必定为 V，此时 $dp_2/d_S=0$。</p><p>上面这个结论用大白话来说就是，不受任何约束的套利者，可以将资产价格推回其基本面对应的水平，从而降低资产价格的波动。但如果套利者受到投资绩效的约束，那么他们的存在反而会放大资产价格的波动，反而让资产价格的波动性比不存在套利者时更高。之所以会这样，是因为噪声交易者所带来的短期不利价格波动让套利者短期亏损，从而让套利者的套利能力受损。这样，套利者对资产价格的需求也按照价格运动的方向来变化，从而放大了价格的波动。换言之，噪声交易者 2 时刻的认知偏差越大，就会让套利者在 1、2 两个时刻间的亏损越严重，从而导致套利者 2 时刻能够用来套利的资金量越小。这样，在最好套利机会出现的时候（2 时刻资产价格进一步下降时），套利的力量反而下降。</p><h3 id="23-2-非理性的信念与偏好"><a href="#23-2-非理性的信念与偏好" class="headerlink" title="23.2 非理性的信念与偏好"></a>23.2 非理性的信念与偏好</h3><p>心理学研究发现人通常表现出如下的行为偏差。</p><ul><li><strong>过度自信（overconfidence）：</strong>人们在做出判断时往往过度自信。比如，当人被要求对未来某些事件的发生给出概率预期时，人认为未来一定会发生的事情其实只有大概 80%的概率会出现。而那些人们认为一定不会发生的事情，发生的概率大概有 20%。</li><li><strong>乐观与一厢情愿（Optimism and wishful thinking）：</strong>研究者发现，当要求人们对自己的能力做出评价时，有超过 90%的人认为自己属于前 1/2。而这显然是不可能的。</li><li><strong>信念保持（belief perseverance）：</strong>当人们形成了自己的观点时，往往对这些观点过于坚持。人们一方面不太愿意去搜索那些与自己观点相反的证据。另一方面，就算发现了这样的证据，人们对待这些证据的态度也过于审慎。</li></ul><p>除了信念之外，行为金融学也提出了与期望效用理论不一样的偏好理论。正因为人对损失特别敏感，因而会表现出“损失规避”（loss aversion）的行为。相应地，人会对那些会带来确定收益的东西更加看重，从而表现出“确定性效应”（certainty effect）。人也讨厌那些未来概率分布不确定的赌博，表现出“模糊规避”（ambiguity aversion）。</p><p>而从逻辑上来看，行为金融学的发展还存在一个巨大障碍。对理性行为的最优对策是理性的行为。在金融市场中，如果你确定除你自己以外的所有交易者都是理性的，那么理性是你自己最好的选择。但是对非理性的行为偏差的最优对策不是非理性。因此，一旦行为金融学所引为前提的这些行为偏差为人所广泛知晓（行为金融学本身就起到了宣传这些行为偏差的作用），那么这些偏差是否会为其他理性投资者所利用，从而被打败和消失，存在很大疑问。</p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>笔记在此便结束了，接下来的次贷危机部分光几句话是无法说得经常的，建议通过原书以及作者的公开课来进行了解。</p><p>本课程虽然被称为入门课程，但是对经济学进行了一个系统地学习以及介绍。作为一个上了多年金融，但依旧有很多疑惑的地方的‘入门学生’，听完此课程可谓是打通了任通二脉，所有知识点一下联系在了一起。本课程比起数学推导其实更注重解释和联系现实。同时每讲课程引用了许多案例，并将中国股市背景结合在教学中，还推荐了许多文章给感兴趣的学生进一步阅读。可以说作者真的是尽心竭力地将我们往研究经济学这条路上引，并且可以说是非常成功！</p><p>最后再次感谢本书的作者以北大公开课的主讲人徐高教授，此次经济学之旅让我受益匪浅！如有机会定会大力推荐给其他经济学人！</p>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Financial Economics</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】Poisson Process</title>
    <link href="/2021/06/20/Poisson_Process/"/>
    <url>/2021/06/20/Poisson_Process/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于B站 up Jerry Xu 的视频<a href="https://www.bilibili.com/video/BV16C4y1a7EW?spm_id_from=333.999.0.0">《Poisson过程》</a>；</p><p>为了跳变打铺垫；</p></blockquote><span id="more"></span><h2 id="指数分布"><a href="#指数分布" class="headerlink" title="指数分布"></a>指数分布</h2><p>If $\tau\sim Exp(\lambda)$</p><script type="math/tex; mode=display">\ f_\tau(t)=\begin{cases}\lambda e^{-\lambda t}&t\ge 0\\0&t<0\end{cases}</script><script type="math/tex; mode=display">F_\tau(t)=\begin{cases}1-e^{-\lambda t}&t\ge0\\0&t<0\end{cases}</script><script type="math/tex; mode=display">\mathbb E\tau=\int_0^\infty tf_\tau(t)dt=\frac1\lambda</script><script type="math/tex; mode=display">\mathbb E\tau^2=\int_0^\infty t^2f\tau(t)dt=\frac2{\lambda^2}</script><script type="math/tex; mode=display">Var\tau=\frac1{\lambda^2}</script><blockquote><p>分部积分</p></blockquote><ul><li><p>Memorylessness</p><p>$\mathbb P(\tau&gt;u)=\mathbb P(\tau&gt;u+v|\tau&gt;v)$</p></li></ul><h2 id="泊松过程"><a href="#泊松过程" class="headerlink" title="泊松过程"></a>泊松过程</h2><ul><li><p>$\{\tau_k\}_{k=1}^\infty$：Interarrival times</p></li><li><p>$S_n=\sum_{k=1}^n\tau_k$：Arrival times $\sim Gamma(n,\lambda)$</p><script type="math/tex; mode=display">g_{S_n}(S)=\frac{(\lambda S)^{n-1}}{(n-1)!}\lambda e^{-\lambda S}</script></li><li><p>$\lambda$：Intensity</p></li><li><p>$N(t)$：The number of jumps that occur at or before$\sim Poisson(\lambda t)$</p><script type="math/tex; mode=display">\mathbb P(N(t)=k)=\frac{(\lambda t)^k}{k!}e^{-\lambda t}</script><ul><li>$N(t_{j+1})-N(t_j)\sim Poi((t_{j+1}-t_j)\lambda)$ is stationary</li><li>$\mathbb E[N(t)-N(s)]=\lambda(t-s)$</li><li>$Var[N(t)-N(s)]=\lambda(t-s)$</li></ul></li></ul><h4 id="证明-S-n-密度函数（归纳法）"><a href="#证明-S-n-密度函数（归纳法）" class="headerlink" title="证明 $S_n$ 密度函数（归纳法）"></a>证明 $S_n$ 密度函数（归纳法）</h4><ol><li><script type="math/tex; mode=display">S_1=\tau_1=\lambda e^{-\lambda t}\sim Gamma(1,\lambda)</script></li><li><p>证明当 $S_k$ 符合时，$S_{k+1}$ 也符合</p></li></ol><p>PDF：</p><script type="math/tex; mode=display">g_{\tau_{k+1}}(u)=\lambda e^{-\lambda u}</script><script type="math/tex; mode=display">g_{S_k}=\frac{(\lambda S)^{k-1}}{(k-1)!}\lambda e^{-\lambda S}</script><p>Joint PDF：</p><script type="math/tex; mode=display">g_{S_k\tau_{k+1}}(S,u)=g_{S_k}g_{\tau_{k+1}}(u)=\lambda e^{-\lambda u}\frac{(\lambda S)^{k-1}}{(k-1)!}\lambda e^{-\lambda S}</script><p>CDF：</p><script type="math/tex; mode=display">\begin{align}G_{S_{k+1}}(x)&=\mathbb P(S_{k+1}\leq x)=\mathbb P(S_k+\tau_{k+1}\leq x)\\&=\int\int_{s+u\leq x}\lambda e^{-\lambda u}\frac{(\lambda S)^{k-1}}{(k-1)!}\lambda e^{-\lambda S}dSdu\\&=\frac{(\lambda)^{k+1}}{(k-1)!}[\int_0^x e^{-\lambda S}S^{k-1}dS\int_0^{x-S} e^{-\lambda u}du]\\&=\frac{(\lambda)^{k}}{(k-1)!}[\int_0^x e^{-\lambda S}S^{k-1}dS[e^{-\lambda u}|^0_{x-S}]]\\&=\frac{(\lambda)^{k}}{(k-1)!}[\int_0^x e^{-\lambda S}S^{k-1}(1-e^{\lambda(S-x)})dS]\\&=\frac{(\lambda)^{k}}{(k-1)!}[\int_0^x e^{-\lambda S}S^{k-1}-e^{\lambda(S-x)}e^{-\lambda S}S^{k-1}dS]\\&=\frac{(\lambda)^{k}}{(k-1)!}[\int_0^x e^{-\lambda S}S^{k-1}-e^{-\lambda x}S^{k-1}dS]\\&=\frac{(\lambda)^{k}}{(k-1)!}[\int_0^x e^{-\lambda S}S^{k-1}dS-\frac1ke^{-\lambda x}S^k|_0^x]\\&=\frac{(\lambda)^{k}}{(k-1)!}[\int_0^x e^{-\lambda S}S^{k-1}dS-\frac{e^{-\lambda x}x^k}k]\\\end{align}</script><p>PDF：$S_{k+1}$</p><script type="math/tex; mode=display">\begin{align}g_{S_{k+1}}(x)&=\frac d{dx}G_{S_{k+1}}(x)\\&=\frac{(\lambda)^{k}}{(k-1)!}[e^{-\lambda x}x^{k-1}-\frac{ke^{-\lambda x}x^{k-1}-\lambda e^{-\lambda x}x^k}k]\\&=\frac{(\lambda)^{k}}{(k-1)!}\frac{\lambda e^{-\lambda x}x^k}k\\&=\frac{(\lambda x)^{k}}{k!}\lambda e^{-\lambda x}\\\end{align}</script><p>结论成立</p><h4 id="证明-N-t-的分布"><a href="#证明-N-t-的分布" class="headerlink" title="证明 $N(t)$ 的分布"></a>证明 $N(t)$ 的分布</h4><blockquote><p>$N(t)\ge k\Rightarrow S_k\leq t$</p></blockquote><script type="math/tex; mode=display">\begin{align}\mathbb P(N(t)\ge k)&=\mathbb P(S_k\leq t)\\&=\int_0^t \frac{(\lambda S)^{k-1}}{(k-1)!}\lambda e^{-\lambda S} ds\end{align}</script><script type="math/tex; mode=display">\begin{align}\mathbb P(N(t)\ge k+1)&=\mathbb P(S_{k+1}\leq t)\\&=\int_0^t \frac{(\lambda S)^k}{k!}\lambda e^{-\lambda S} ds\\&=\frac{(\lambda)^k}{k!}\int_t^0 S^k de^{-\lambda S}\\&=\frac{(\lambda)^k}{k!}(S^ke^{-\lambda S}|_t^0-\int_t^0 kS^{k-1} e^{-\lambda S}dS)\\&=\frac{(\lambda)^k}{k!}(-t^ke^{-\lambda t}+k\int_0^t S^{k-1} e^{-\lambda S}dS)\\&=-\frac{(\lambda)^k}{k!}t^ke^{-\lambda t}+\frac{(\lambda)^k}{(k-1)!}\int_0^t S^{k-1} e^{-\lambda S}dS)\\\end{align}</script><script type="math/tex; mode=display">\mathbb P(N(t)=k)=\mathbb P(N(t)\ge k)-\mathbb P(N(t)\ge k+1)=\frac{(\lambda t)^k}{k!}e^{-\lambda t}</script><h3 id="Compensated-Poisson-Process"><a href="#Compensated-Poisson-Process" class="headerlink" title="Compensated Poisson Process"></a>Compensated Poisson Process</h3><blockquote><p>转变成鞅</p></blockquote><ul><li>$M(t)=N(t)-\lambda t$</li></ul><h4 id="证明鞅-s-lt-t"><a href="#证明鞅-s-lt-t" class="headerlink" title="证明鞅 (s&lt;t)"></a>证明鞅 (s&lt;t)</h4><script type="math/tex; mode=display">\begin{align}\mathbb E[M(t)|M(s)]&=\mathbb E[N(t)-\lambda t|\mathscr F(s)]\\&=\mathbb E[N(t)|\mathscr F(s)]-\lambda t\\&=\mathbb E[N(t)-N(s)+N(s)|\mathscr F(s)]-\lambda t\\&=\mathbb E[N(t)-N(s)|\mathscr F(s)]+\mathbb E[N(s)|\mathscr F(s)]-\lambda t\\&=\lambda (t-s)+N(s)-\lambda t\\&=N(s)-\lambda s=M(s)\end{align}</script><h3 id="Compound-Poisson-Process"><a href="#Compound-Poisson-Process" class="headerlink" title="Compound Poisson Process"></a>Compound Poisson Process</h3><blockquote><p>跳了不确定的值</p></blockquote><ul><li><p>$Q(t)=\sum_{i=1}^{N(t)}Y_i$：总跳变距离</p><ul><li><p>$N(t)\sim Poi(\lambda t)$</p></li><li><p>$Y_1,Y_2,…$ be a sequence of iid with mean $\beta$</p></li><li><p>$Q(t_{j+1})-Q(t_j)$ is stationary</p><blockquote><p>$Y_i$ 不影响时间轴上的随机性</p></blockquote></li></ul></li></ul><h4 id="求期望"><a href="#求期望" class="headerlink" title="求期望"></a>求期望</h4><blockquote><p>期望迭代法则/全概率公式</p></blockquote><script type="math/tex; mode=display">\mathbb E[Q(t)|N(t)=k]=k\beta</script><script type="math/tex; mode=display">\begin{align}\mathbb E[\mathbb E[Q(t)|W(t)]]&=\sum_{k=1}^\infty k\beta·\mathbb P(N(t)=k)\\&=\sum_{k=1}^\infty k\beta\frac{(\lambda t)^k}{k!}e^{-\lambda t}\\&=\sum_{k=1}^\infty \beta\frac{(\lambda t)^k}{(k-1)!}e^{-\lambda t}\\(l=k-1)&=\sum_{l=0}^\infty \beta\lambda t\frac{(\lambda t)^l}{l!}e^{-\lambda t}\\&=\beta\lambda t\end{align}</script><h4 id="如果-Y-i-为离散随机变量"><a href="#如果-Y-i-为离散随机变量" class="headerlink" title="如果 $Y_i$ 为离散随机变量"></a>如果 $Y_i$ 为离散随机变量</h4><blockquote><p>$Y_i$ 只能取 M 个定值</p></blockquote><ul><li>$Q(t)=\sum_{i=1}^{N(t)}Y_i$</li><li>$N(t)=\sum_{m=1}^MN_m(t)$<ul><li>$N_1,N_2…$ 所有的次数相和等于总次数</li></ul></li><li>$Q(t)=\sum_{m=1}^MY_mN_m(t)$<ul><li>$Y_1,Y_2…$所有距离乘对应次数相加之后等于总距离</li></ul></li></ul><hr><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><p><a href="https://blog.csdn.net/u010164190/article/details/81043856">浅谈全概率公式和贝叶斯公式</a></p></li><li><p><a href="https://www.zhihu.com/question/22996373">期望迭代法则具体指的是什么？</a></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Poisson_Process</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【练习】BS Model To BS PDE</title>
    <link href="/2021/06/20/Exercise_2/"/>
    <url>/2021/06/20/Exercise_2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于B站 up Jerry Xu 的视频<a href="https://www.bilibili.com/video/BV1ct4y1y7b8?spm_id_from=333.999.0.0">《Ito积分练习题(Part 1)》</a>；</p><p>从 BS model 反向推符合 PDE</p></blockquote><span id="more"></span><h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><p>For a European Call option at time T, with strike price K.</p><script type="math/tex; mode=display">c(t,x) = xN(d_+)- Ke^{-r(T-t)}N(d_-)</script><p>where</p><script type="math/tex; mode=display">d_+=\frac{ln\frac{x}{K}+(r + \frac{1}{2}\sigma^2)(T-t)}{\sigma \sqrt{T-t}}</script><script type="math/tex; mode=display">d_-=\frac{ln\frac{x}{K}+(r - \frac{1}{2}\sigma^2)(T-t)}{\sigma \sqrt{T-t}}</script><p>Show that this function satisfies the BS-PDE</p><script type="math/tex; mode=display">rc(t,x)=c_t+\frac12\sigma^2x^2c_{xx}+rxc_x</script><p>with</p><script type="math/tex; mode=display">\lim_{t\to T}c(t,x)=max\{x-K,0\},x>0,x\ne K</script><script type="math/tex; mode=display">\lim_{x\to 0}c(t,x)=0,\ \lim_{x\to \infty}[c(t,x)-(x-e^{r(T-t)}K)=0,\  0\leq t<T</script><h3 id="Step"><a href="#Step" class="headerlink" title="Step"></a>Step</h3><p>(1) Show that $Ke^{-r(T-t)}N’(d_-)=xN’(d_+)$;</p><script type="math/tex; mode=display">N'(x)=\frac1{\sqrt{2\pi}}e^{-\frac{x^2}{2}}</script><p>原问题可以转换为</p><script type="math/tex; mode=display">e^{\frac{d_+^2-d_-^2}{2}}=\frac xKe^{r(T-t)}</script><p>where </p><script type="math/tex; mode=display">d_+^2-d_-^2=\frac{[ln\frac{x}{K}+(r + \frac{1}{2}\sigma^2)(T-t)]^2-[ln\frac{x}{K}+(r - \frac{1}{2}\sigma^2)(T-t)]^2}{\sigma^2(T-t)}</script><p>Set $A=ln\frac xK+r(T-t)$, $B=\frac12\sigma^2(T-t)$</p><script type="math/tex; mode=display">(A+B)^2-(A-B)^2=4AB</script><script type="math/tex; mode=display">d_+^2-d_-^2=\frac{4(ln\frac xK+r(T-t))\frac12\sigma^2(T-t)}{\sigma^2(T-t)}=2(ln\frac xK+r(T-t))</script><script type="math/tex; mode=display">e^{\frac{d_+^2-d_-^2}{2}}=e^{ln\frac xK+r(T-t)}=\frac xKe^{r(T-t)}</script><p>(2) Show that Delta $c_x(t,x)=N(d_+)$</p><script type="math/tex; mode=display">c_x(t,x)=N(d_+)+xN'(d_+)\frac{\partial d_+}{\partial x}-ke^{-r(T-t)}N'(d_-)\frac{\partial d_-}{\partial x}</script><script type="math/tex; mode=display">\frac{\partial d_+}{\partial x}=\frac{\partial d_-}{\partial x}=\frac{1}{\sigma \sqrt{T-t}}\frac{K}{x}\frac1K=\frac{1}{x\sigma \sqrt{T-t}}</script><script type="math/tex; mode=display">c_x(t,x)=N(d_+)+\frac{xN'(d_+)-ke^{-r(T-t)}N'(d_-)}{x\sigma \sqrt{T-t}}=N(d_+)+0</script><blockquote><p>行权价值附近，斜率最大，Delta 约等于 1/2</p></blockquote><script type="math/tex; mode=display">c_{xx}=\frac{\partial N(d_+)}{\partial x}=\frac{N'(d_+)}{x\sigma \sqrt{T-t}}</script><p>(3) Show $c_t(t,x)=-rKe^{-r(T-t)}N(d_-)-\frac{\sigma x}{2\sqrt{T-t}}N’(d_+)$</p><script type="math/tex; mode=display">C_t(t,x)=xN'(d_+)\frac{\partial d_+}{\partial t}- rKe^{-r(T-t)}N(d_-)- Ke^{-r(T-t)}N'(d_-)\frac{\partial d_-}{\partial t}</script><script type="math/tex; mode=display">\begin{align}\frac{\partial d_+}{\partial t}&=\frac{-(r + \frac{1}{2}\sigma^2)\sigma \sqrt{T-t}+\frac12\sigma (T-t)^{-1/2}(ln\frac{x}{K}+(r + \frac{1}{2}\sigma^2)(T-t))}{\sigma^2(T-t)}\\&=\frac{-\frac12(r + \frac{1}{2}\sigma^2)\sigma \sqrt{T-t}+\frac12\sigma (T-t)^{-1/2}ln\frac{x}{K}}{\sigma^2(T-t)}\\&=-\frac{(r + \frac{1}{2}\sigma^2)}{2\sigma \sqrt{T-t}}+\frac{ln\frac{x}{K}}{2\sigma(T-t)^{3/2}}\\&=\frac{1}{2\sigma\sqrt{T-t}}[\frac{ln\frac{x}{K}}{T-t}-(r + \frac{1}{2}\sigma^2)]\end{align}</script><script type="math/tex; mode=display">\frac{\partial d_-}{\partial t}=\frac{1}{2\sigma\sqrt{T-t}}[\frac{ln\frac{x}{K}}{T-t}-(r - \frac{1}{2}\sigma^2)]</script><script type="math/tex; mode=display">\begin{align}C_t(t,x)&=- rKe^{-r(T-t)}N(d_-)+x\frac{N'(d_+)}{2\sigma\sqrt{T-t}}[\frac{ln\frac{x}{K}}{T-t}-(r + \frac{1}{2}\sigma^2)]- Ke^{-r(T-t)}\frac{N'(d_-)}{2\sigma\sqrt{T-t}}[\frac{ln\frac{x}{K}}{T-t}-(r - \frac{1}{2}\sigma^2)]\\&=- rKe^{-r(T-t)}N(d_-)-x\frac{N'(d_+)}{2\sigma\sqrt{T-t}}\frac{1}{2}\sigma^2- Ke^{-r(T-t)}\frac{N'(d_-)}{2\sigma\sqrt{T-t}}\frac{1}{2}\sigma^2\\&=- rKe^{-r(T-t)}N(d_-)-\frac{\sigma x N'(d_+)}{2\sqrt{T-t}}\end{align}</script><p>(4) Prove that satisfies</p><script type="math/tex; mode=display">\begin{align}&c_t+\frac12\sigma^2x^2c_{xx}+rxc_x\\=&- rKe^{-r(T-t)}N(d_-)-\frac{\sigma xN'(d_+)}{2\sqrt{T-t}}+\frac{\sigma xN'(d_+)}{2\sqrt{T-t}}+rxN(d_+)\\=& rxN(d_+)- rKe^{-r(T-t)}N(d_-)=rc(t,x)\end{align}</script><p>(5) Calculate $\lim_{t\to T}d_+$ and $\lim_{t\to T}d_-$ for $x&gt;0$, $x\ne K$.</p><script type="math/tex; mode=display">\lim_{t\to T}d_+=\lim_{t\to T}d_-=\lim_{t\to T}\frac{ln\frac{x}{K}+(r + \frac{1}{2}\sigma^2)(T-t)}{\sigma \sqrt{T-t}}=\frac{ln\frac{x}{K}}0</script><script type="math/tex; mode=display">\lim_{t\to T}c(t,x)=\lim_{t\to T}[xN(d_+)- Ke^{-r(T-t)}N(d_-)]</script><p>If $x&gt;K$：</p><script type="math/tex; mode=display">\lim_{t\to T}[xN(d_+)- Ke^{-r(T-t)}N(d_-)]=xN(+\infty)- KN(+\infty)=x-K</script><p>If $x&lt;K$：</p><script type="math/tex; mode=display">\lim_{t\to T}[xN(d_+)- Ke^{-r(T-t)}N(d_-)]=xN(-\infty)- KN(-\infty)=0</script><p>(6) Calculate $\lim_{x\to 0}d_+$ and $\lim_{x\to 0}d_-$ for $0\leq t&lt;T$.</p><script type="math/tex; mode=display">\lim_{x\to 0}d_+=\lim_{x\to 0}d_-=\lim_{x\to 0}\frac{ln\frac{x}{K}+(r + \frac{1}{2}\sigma^2)(T-t)}{\sigma \sqrt{T-t}}=\frac{-\infty}{\sigma \sqrt{T-t}}</script><script type="math/tex; mode=display">\lim_{x\to 0}c(t,x)=xN(-\infty)- Ke^{-r(T-t)}N(-\infty)=0</script><p>(7) Calculate $\lim_{x\to \infty}d_+$ and $\lim_{x\to \infty}d_-$ for $0\leq t&lt;T$.</p><script type="math/tex; mode=display">\lim_{x\to \infty}d_+=\lim_{x\to \infty}d_-=\frac{+\infty}{\sigma \sqrt{T-t}}</script><script type="math/tex; mode=display">\lim_{x\to 0}c(t,x)=xN(+\infty)- Ke^{-r(T-t)}N(+\infty)=x- Ke^{-r(T-t)}</script><p>Hint for (7)：From the formula of $d_+$, we can obtain that</p><script type="math/tex; mode=display">x=Kexp(\sigma\sqrt{T-t}d_+-(T-t)(r+\frac12\sigma^2))</script>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Black Scholes Model</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】Brownian Motion</title>
    <link href="/2021/06/20/Brownian_Motion/"/>
    <url>/2021/06/20/Brownian_Motion/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于B站 up <a href="https://space.bilibili.com/275959084">Jerry Xu</a> 的视频；</p><p>跨了一些视频，收集了一些关于BM的点；</p></blockquote><span id="more"></span><h2 id="对称随机游走S-R-W"><a href="#对称随机游走S-R-W" class="headerlink" title="对称随机游走S.R.W"></a>对称随机游走S.R.W</h2><p>基本定义</p><script type="math/tex; mode=display">X_i=\begin{cases}1&Head\\-1&Tail\end{cases}</script><script type="math/tex; mode=display">M_k=M_0+\sum_{i=1}^kX_i</script><script type="math/tex; mode=display">\mathbb E[X_i]=1\times\frac 12-1\times\frac 12=0</script><script type="math/tex; mode=display">Var(X_i)=(1-0)^2\times\frac12+(-1-0)^2\times\frac12=1</script><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><h4 id="Indipendent-increments"><a href="#Indipendent-increments" class="headerlink" title="Indipendent increments"></a>Indipendent increments</h4><blockquote><p>增量直接独立</p></blockquote><script type="math/tex; mode=display">\mathbb E[M_{k_{i+1}}-M_{k_i}]=0</script><script type="math/tex; mode=display">Var(M_{k_{i+1}}-M_{k_i})=k_{i+1}-k_i</script><h4 id="Martingle-Property"><a href="#Martingle-Property" class="headerlink" title="Martingle Property"></a>Martingle Property</h4><p>Set $k&lt;l$</p><script type="math/tex; mode=display">\begin{align}\mathbb E[M_l|\mathscr F_k]&=\mathbb E[M_l-M_k+M_k|\mathscr F_k]\\&=\mathbb E[M_l-M_k|\mathscr F_k]+\mathbb E[M_k|\mathscr F_k]\\&=0+M_k\end{align}</script><blockquote><p>if $k&gt;l$ 采用高等概率中正态分布的条件概率公式</p></blockquote><h4 id="Quadratic-Variation"><a href="#Quadratic-Variation" class="headerlink" title="Quadratic Variation"></a>Quadratic Variation</h4><script type="math/tex; mode=display">[M,M]_k=\sum_{j=1}^k(M_j-M_{j-1})^2=K\times 1=K</script><blockquote><p>与 $Var(M_{k}-M_{0})$ 不同的是，上式考察的是每一步，而 $Var$ 考察的是在最后的点的 $\sigma$</p></blockquote><h2 id="Scaled-Random-Walk-n"><a href="#Scaled-Random-Walk-n" class="headerlink" title="Scaled Random Walk (n)"></a>Scaled Random Walk (n)</h2><p>单位时间内走 $n$ 步, 一共 $nt$ 步, 每步 $\frac1{\sqrt n}$</p><script type="math/tex; mode=display">W^n(t)=\frac1{\sqrt n}M_{nt}</script><script type="math/tex; mode=display">\mathbb E[W^n(t)-W^n(s)]=\mathbb E[\frac1{\sqrt n}\sum_{j=ns+1}^{nt}x_j]=0</script><script type="math/tex; mode=display">Var(W^n(t)-W^n(s))=\frac1nVar(M_{nt}-M_{ns})=t-s</script><h3 id="特性-1"><a href="#特性-1" class="headerlink" title="特性"></a>特性</h3><h4 id="Indipendent-increments-1"><a href="#Indipendent-increments-1" class="headerlink" title="Indipendent increments"></a>Indipendent increments</h4><h4 id="Martingle-Property-1"><a href="#Martingle-Property-1" class="headerlink" title="Martingle Property"></a>Martingle Property</h4><h4 id="Quadratic-Variation-1"><a href="#Quadratic-Variation-1" class="headerlink" title="Quadratic Variation"></a>Quadratic Variation</h4><script type="math/tex; mode=display">\begin{align}[W^n,W^n]_t&=\sum_{i=1}^{nt}(W^n(\frac in)-W^n(\frac {i-1}n))^2\\&=\sum_{i=1}^{nt}(\frac1{\sqrt n}(M_{i}-M_{i-1}))^2\\&=\sum_{i=1}^{nt}\frac1n=t\end{align}</script><h2 id="Brownian-motion"><a href="#Brownian-motion" class="headerlink" title="Brownian motion"></a>Brownian motion</h2><h4 id="Moment-Generating-Function-矩生成函数"><a href="#Moment-Generating-Function-矩生成函数" class="headerlink" title="Moment Generating Function 矩生成函数"></a>Moment Generating Function 矩生成函数</h4><p>$W^n(t)$ 的 MGF ：$\phi_n(u)$</p><script type="math/tex; mode=display">\begin{align}\phi_n(u)&=\mathbb E[e^{uW^n(t)}]=\mathbb E[exp(\frac u{\sqrt n}M_{nt})]\\&=\mathbb E[exp(\frac {uX_1}{\sqrt n})exp(\frac {uX_2}{\sqrt n})...exp(\frac {uX_{nt}}{\sqrt n})]\\&=(\frac12(e^{\frac u{\sqrt n}}+e^{\frac {-u}{\sqrt n}}))^{nt}\\\end{align}</script><script type="math/tex; mode=display">\begin{align}ln\phi_n(u)&=nt\ln(\frac12(e^{\frac u{\sqrt n}}+e^{\frac {-u}{\sqrt n}}))\\(Set\ \frac1{\sqrt{n}}=\lambda) &\Rightarrow \frac t{\lambda^2}\ln(\frac12(e^{\lambda u}+e^{-\lambda u}))\\(泰勒展开)&=\frac t{\lambda^2}\ln(1+\frac12\lambda^2u^2+o(\lambda^2))\\(If\ x\to 0,\ln(1+x)\sim x)&=\frac t{\lambda^2}(\frac12\lambda^2u^2+o(\lambda^2))\\&=\frac t2u^2+to(\lambda^4)=\frac t2u^2\end{align}</script><p>当 $n\to\infty$</p><script type="math/tex; mode=display">\phi_n(u)=exp(\frac t2u^2)</script><p>If $Y\sim N(0,t)$</p><script type="math/tex; mode=display">PDF:\frac1{\sqrt{2\pi t}}exp(-\frac{x^2}{2t})</script><script type="math/tex; mode=display">\begin{align}W^n(t)的MGF:\mathbb E[e^{uY}]&=\int_{-\infty}^\infty e^{ux}\frac1{\sqrt{2\pi t}}exp(-\frac{x^2}{2t})dx\\&=\int_{-\infty}^\infty\frac1{\sqrt{2\pi t}}exp(-(\frac{x^2}{2t}-ux+\frac{u^2t}2)+\frac{u^2t}2)dx\\&=\int_{-\infty}^\infty\frac1{\sqrt{2\pi t}}exp(-\frac1{2t}(x-ut)^2+\frac{u^2t}2)dx\\&=e^{\frac{u^2t}2}\int_{-\infty}^\infty\frac1{\sqrt{2\pi t}}exp(-\frac1{2t}(x-ut)^2)dx\\&=e^{\frac{u^2t}2}\end{align}</script><p><strong>$W^n(t)$ 的 MGF 趋于 $N(0,t)$ 的 MGF</strong></p><h4 id="First-Order-Variation"><a href="#First-Order-Variation" class="headerlink" title="First-Order Variation"></a>First-Order Variation</h4><script type="math/tex; mode=display">FV_T(f)=\int_0^t|f'(t)|dt</script><h4 id="Quadratic-Variation-2"><a href="#Quadratic-Variation-2" class="headerlink" title="Quadratic Variation"></a>Quadratic Variation</h4><script type="math/tex; mode=display">[f,f](T)=\lim_{||\pi||\to0}\sum_{j=0}^{n-1}(f(t_{j+1})-f(t_j))^2</script><p>where $||\pi||=max(t_{j+1}-t_j)$</p><blockquote><p>如果一个函数是连续的，它的Quadratic Variation为0</p></blockquote><p>对于Brownian motion $W(t)$ 设</p><script type="math/tex; mode=display">Q_{\pi}=\sum_{j=0}^{n-1}(W(t_{j+1})-W(t_j))^2</script><script type="math/tex; mode=display">\begin{align}\mathbb E[Q_\pi]&=\sum_{j=0}^{n-1}\mathbb E[(W(t_{j+1})-W(t_j))^2]\\&=\sum_{j=0}^{n-1}Var(W(t_{j+1})-W(t_j))\\&=\sum_{j=0}^{n-1}(t_{j+1}-t_j)=T\end{align}</script><script type="math/tex; mode=display">\begin{align}Var[Q_\pi]&=\sum_{j=0}^{n-1}Var[(W(t_{j+1})-W(t_j))^2]\\&=\sum_{j=0}^{n-1}\mathbb E[(W(t_{j+1})-W(t_j))^4]-(t_{j+1}-t_j)^2\\&=\sum_{j=0}^{n-1}2(t_{j+1}-t_j)^2\\&\leq 2||\pi||T\to 0\end{align}</script><p>所以波动趋近于 0, $Q_{\pi}$ 趋近于 $T$</p><blockquote><p>$E(x^4)$ 的解法可参考 <a href="https://achlier.github.io/2021/06/17/Normal_Distribution_and_E(x4">正态分布与矩母函数</a>)</p></blockquote><h2 id="Ito-Integral"><a href="#Ito-Integral" class="headerlink" title="Ito Integral"></a>Ito Integral</h2><p><a href="https://achlier.github.io/2021/06/11/Ito_Integral/">Ito_Integral</a></p><h2 id="Stratonovich-Integral"><a href="#Stratonovich-Integral" class="headerlink" title="Stratonovich Integral"></a>Stratonovich Integral</h2><blockquote><p>采用取中值 $t^*$ 求积分</p></blockquote><p>它的 Half-sample quadratic variation 是</p><script type="math/tex; mode=display">Q_{\pi/2}=\sum_{j=0}^{n-1}[W(t_j^*)-W(t_j)]^2=\frac{T}{2}</script><p>而</p><script type="math/tex; mode=display">\int_{T_0}^TW_t \circ dW_t=\lim_{||\pi||\to 0}\sum_{j=0}^{n-1}W(t_j^*)[W(t_{j+1})-W(t_j)]=\frac12 W^2(T)</script><p>为了求这个值，可以提出一个由 $t^*$ 划分的 Ito 积分</p><script type="math/tex; mode=display">(Ito)\sum_{j=0}^{n-1}W(t_j)[W(t_j^*)-W(t_j)]+\sum_{j=0}^{n-1}W(t_j^*)[W(t_j)-W(t_j^*)]</script><p>为了合成 Stratonovich Integral 要加上</p><script type="math/tex; mode=display">\sum_{j=0}^{n-1}W(t_j^*)^2-2W(t_j)W(t^*_j)+W(t_j)^2=Q_{\pi/2}</script><p>得到</p><script type="math/tex; mode=display">\int_{T_0}^TW_t \circ dW_t=\int_{T_0}^TW_tdW_t+Q_{\pi/2}=W(T)^2-\frac{T}{2}+\frac{T}{2}</script><h2 id="Ito-与-Stratonovich-转换"><a href="#Ito-与-Stratonovich-转换" class="headerlink" title="Ito 与 Stratonovich 转换"></a>Ito 与 Stratonovich 转换</h2><p>We have</p><script type="math/tex; mode=display">\int_0^Tf(t,X_t)\circ dB_t=\int_0^T f(t,X_t)dB_t+\frac12\int_0^Tb(t,X_t)f_x(t,X_t)dt</script><p>If we set two Equivalent function</p><script type="math/tex; mode=display">(Ito)\quad dX_t=a(t,X_t)dt+b(t,X_t)dB_t</script><script type="math/tex; mode=display">(Stra)\quad dX_t=\tilde a(t,X_t)dt+\tilde b(t,X_t)\circ dB_t</script><p>Put $b(t,X_t)$ into first equation</p><script type="math/tex; mode=display">b(t,X_t)\circ dB_t=b(t,X_t)dB_t+\frac12 b(t,X_t)b_x(t,X_t)dt</script><p>So</p><script type="math/tex; mode=display">\begin{align}dX_t&=a(t,X_t)dt+b(t,X_t)\circ dB_t-\frac12 b(t,X_t)b_x(t,X_t)dt\\&=(a(t,X_t)-\frac12 b(t,X_t)b_x(t,X_t))dt+b(t,X_t)\circ dB_t\end{align}</script><p>Where</p><script type="math/tex; mode=display">\tilde a(t,X_t)=a(t,X_t)-\frac12 b(t,X_t)b_x(t,X_t)</script><script type="math/tex; mode=display">\tilde b(t,X_t)=b(t,X_t)</script><p>【Example】</p><script type="math/tex; mode=display">dX_t=\frac12f(X_t)f'(X_t)dt+f(X_t)dB_t</script><script type="math/tex; mode=display">\tilde a(t,X_t)=0,\quad \tilde b(t,X_t)=f(X_t)</script><p>So the Equivalent SDE</p><script type="math/tex; mode=display">dX_t=f(X_t)\circ dB_t</script><p>Analogue</p><script type="math/tex; mode=display">\begin{align}dl(t)&=f(l(t))dc(t)\\\frac{dl(t)}{f(l(t))}&=dc(t),\quad [0,t]\\\int_{l(0)}^{l(t)}\frac{du}{f(u)}&=c(t)-c(0)\end{align}</script><p>If $g’(u)=\frac1{f(u)}$</p><script type="math/tex; mode=display">g(l(t))-g(l(0))=c(t)-c(0)</script><script type="math/tex; mode=display">g(X_t)-g(X_0)=B_t-B_0</script><h2 id="额外的点"><a href="#额外的点" class="headerlink" title="额外的点"></a>额外的点</h2><h3 id="联合分布"><a href="#联合分布" class="headerlink" title="联合分布"></a>联合分布</h3><p>求 $P(W_1\leq0,W_2\leq0…)$ 可运用联合正态分布</p><p>首先已知 $W_t\sim N(0,t)$, with $0&lt;s&lt;t$</p><script type="math/tex; mode=display">\begin{align}Var(W_s,W_t)&=E(W_sW_t)-E(W_s)E(W_t)\\&=E(W_s(W_t-W_s)+W_s^2)-0\\&=0+E(W_s^2)=s\end{align}</script><p>可得知 $[W_1,W_2,…,W_n]$ 的协方差矩阵为</p><script type="math/tex; mode=display">\Sigma=\begin{bmatrix}1&1&1&...&1\\1&2&2&...&2\\1&2&3&...&3\\...&...&...&...&...\\1&2&3&...&n\\\end{bmatrix}</script><p>代入联合高斯分布</p><script type="math/tex; mode=display">f(x)=\frac1{(\sqrt{2\pi})^n|\Sigma|^\frac12}e^{-\frac{(x-\mu_x)'(\Sigma)^{-1}(x-\mu_x)}2}</script><p>并求多重积分</p><h4 id="Log-normal"><a href="#Log-normal" class="headerlink" title="Log normal"></a>Log normal</h4><p>求 GBM 期望的时候</p><script type="math/tex; mode=display">\mathbb E(S_t)=S_0exp((\mu-\frac12\sigma^2)t)\mathbb E[e^{\sigma W_t}]</script><p>需要运用到 Log normal 的特性，我们可以用 GBM 的方法求</p><p>GMB：这里的 $\sigma^2$ 是服从的正态分布的 VAR</p><script type="math/tex; mode=display">M_x(t)=\mathbb E(e^{tx})=e^{\frac{t^2\sigma^2}2+\mu t}</script><p>所以 $\mathbb E[e^{\sigma W_t}]= e^{\frac{\sigma^2t}2}$</p><blockquote><p>如果 x 服从对数正态分布 with $ln(x)\sim N(\mu,\sigma^2)$</p><p>$\mathbb E(x)=e^{\mu+\sigma^2/2}$, $D(x)=(e^{\sigma^2}-1)e^{2\mu+\sigma^2}$ </p></blockquote><h3 id="额外的理解"><a href="#额外的理解" class="headerlink" title="额外的理解"></a>额外的理解</h3><p>已知两个定义</p><script type="math/tex; mode=display">dW(t)=\epsilon\sqrt{dt},\ \epsilon\sim N(0,1)</script><script type="math/tex; mode=display">dW(t)dW(t)=dt</script><p>这两个公式都是不完美的定义，因为 W(t) 实际上是处处不可导的</p><p>对于第一个公式，可以理解为在 T 时的分布成正态分布</p><script type="math/tex; mode=display">W(T)=\epsilon\sqrt T</script><script type="math/tex; mode=display">W(T)-W(0)=\epsilon\sqrt T</script><script type="math/tex; mode=display">W(t+\Delta t)-W(t)=dW(t)=\epsilon\sqrt {\Delta T}</script><p>对于第二个公式，可以理解为去除了随机性，是由 Quadratic Variation 推出的</p><script type="math/tex; mode=display">\lim_{||\pi||\to0}\sum_{j=0}^{n-1}(W(t_{j+1})-W(t_j))^2=T</script><script type="math/tex; mode=display">\int_0^TdW(t)dW(t)=\int_0^Tdt</script><script type="math/tex; mode=display">dW(t)dW(t)=dt</script>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Brownian Motion</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】Normal Distribution and Ex4</title>
    <link href="/2021/06/17/Normal_Distribution_and_Ex4/"/>
    <url>/2021/06/17/Normal_Distribution_and_Ex4/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于各种笔记的总结归纳；</p><p>原目的是求正态分布下的E(x^4)，结果找到了许多之前遗忘的知识点。</p></blockquote><span id="more"></span><h3 id="正态分布"><a href="#正态分布" class="headerlink" title="正态分布"></a>正态分布</h3><script type="math/tex; mode=display">f(x)=\frac1{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}</script><p>我们知道求标准正态分布下的 $E(x^k)$ 有很多种方法，可以用极坐标转换推，本文章的第一步就先把这两种基础方法不快乐地各推一遍，再引入矩母函数用更快乐更多样的方法求值.</p><h3 id="极坐标转换第一种"><a href="#极坐标转换第一种" class="headerlink" title="极坐标转换第一种"></a>极坐标转换第一种</h3><p>为了简单按 $N(0,1)$ 为例子，但可以套用其他系数（虽然过程会特别麻烦）</p><script type="math/tex; mode=display">\begin{align}E(x)&=\int x^4\frac1{\sqrt{2\pi}}e^{-\frac{x^2}{2}}dx\\&=\frac1{\sqrt{2\pi}}\int x^4e^{-\frac{x^2}{2}}dx\\(换元t=\frac{x}{\sqrt2})&=\frac1{\sqrt{2\pi}}\int 4t^4e^{-t^2}\sqrt 2dt\\&=\frac4{\sqrt{\pi}}\int t^4e^{-t^2}dt\\\end{align}</script><p>换元的这一步主要是把$exp$上面的系数换掉，如果存在$\mu$,也要加上去，虽然会变得比较麻烦.</p><p>接下来极坐标转换, 注意转换的时候要乘$\rho$</p><script type="math/tex; mode=display">\begin{bmatrix}\frac{\partial x}{\partial\theta}&\frac{\partial x}{\partial \rho}\\\frac{\partial y}{\partial\theta}&\frac{\partial y}{\partial \rho}\end{bmatrix}=\begin{bmatrix}-\rho sin\theta&cos\theta\\\rho cos\theta&sin\theta\end{bmatrix}=\rho</script><blockquote><p>Jacobian Matrix</p></blockquote><script type="math/tex; mode=display">\begin{align}E(x)&=\int x^4e^{-x^2}dx\int y^4e^{-y^2}dy\\&=\int\int x^4y^4e^{-(x^2+y^2)}dxdy\end{align}</script><script type="math/tex; mode=display">x=\rho cos\theta,\quad y=\rho sin\theta</script><script type="math/tex; mode=display">\begin{align}E(x)&=\int_0^\infty\int_0^{2\pi} \rho^8cos\theta^4sin\theta^4e^{-\rho^2}\times\rho\ d\theta  d\rho\\&=\frac12\int_0^\infty\rho^8e^{-\rho^2} d\rho^2\int_0^{2\pi} cos\theta^4sin\theta^4d\theta \\\end{align}</script><p>接下来分成两部分相乘，主要如果原分布含有$\mu$, 此时会有许多相加的项，但也按同样的方法分成两部分计算</p><p><strong>第一部分</strong></p><p>令 $t=\rho^2$</p><script type="math/tex; mode=display">\begin{align}&\int_0^\infty t^4e^{-t}dt\\=&-\int_0^\infty t^4de^{-t}\\=&-t^4e^{-t}|_0^\infty+4\int_0^\infty e^{-t}t^3dt\\=&-4\int_0^\infty t^3de^{-t}\\=&-4t^3e^{-t}|_0^\infty+4\times3\int_0^\infty e^{-t}t^2dt\\=&4!\int_0^\infty e^{-t}dt\\=&-4!e^{-t}|_0^\infty=4!=24\end{align}</script><p>可以得到规律</p><script type="math/tex; mode=display">\int_0^\infty t^{n}e^{-t}dt=n!</script><p>当我们的次数 $n$ 变换时也可以直接套用</p><p><strong>第二部分</strong></p><p>当存在 $\mu$ 时，这部分会有不同的组合，可能会遍历 $sin^n x \times cos^m x,\quad m,n\in (1,2,…,k)$  的所有可能. 但由于其从0到2pi的定积分有以下特性：</p><ol><li><p>当n为奇数时,被积函数是奇函数,所以积分等于0</p></li><li><p>当m为奇数时, $m=2k+1$, 原式化为$sin^n x * (1-sin^2 x)^k dsinx$  在-pi到+pi的积分,然后这个式子等于0</p></li></ol><p>因此只取 $n,m$ 都为双数和整数的部分，如果 $k=4$, 只取 $x^2$,$y^2$,$x^4$,$y^4$,$x^2y^2$,$x^2y^4$,$x^4y^2$,$x^4y^4$和整数的部分.</p><p>然后争取把所有项凑成 $m,n$ 相同的形式，配合 <a href="https://wenku.baidu.com/view/d1b29418fad6195f312ba64c.html">常用三角函数公式大全</a> ，$sin\theta^2cos\theta^2=(\frac{sin2\theta}{2})^2$，,$sin\theta^4cos\theta^4=(\frac{sin2\theta}{2})^4$</p><script type="math/tex; mode=display">\begin{align}&\int_0^{2\pi}(\frac{sin2\theta}{2})^4d\theta\\=&\frac 1{16}\int_0^{2\pi}sin2\theta^4d\theta\\=&\frac 1{16}\int_0^{2\pi}(\frac{1-cos4\theta}2)^4d\theta\\=&\frac 1{64}\int_0^{2\pi}(1-2cos4\theta+\frac{1+cos8\theta}2)d\theta\\=&\frac 1{64}\times\frac 32\times2\pi=\frac{3}{64}\pi\end{align}</script><p>最终得到</p><script type="math/tex; mode=display">E(x)=\frac4{\sqrt{\pi}}\times\sqrt{\frac12\times 24\times\frac{3}{64}\pi}=3</script><blockquote><p>运用好 Matlab 的 符号运算 和 simplify(f)  对符号表达式进行化简</p></blockquote><h3 id="极坐标转换第二种"><a href="#极坐标转换第二种" class="headerlink" title="极坐标转换第二种"></a>极坐标转换第二种</h3><p>为了简单按 $N(0,1)$ 为例子，但可以转到 $N(0,\sigma^2)$</p><p>If $X\sim N(0,\sigma^2)$, $Y=\frac{x-0}\sigma=\frac x\sigma\sim N(0,1)$</p><script type="math/tex; mode=display">\mathbb E[\frac{x^4}{\sigma^4}]=3\Rightarrow E[x^4]=3\sigma^4</script><p>开始求</p><script type="math/tex; mode=display">\begin{align}&\int_{-\infty}^\infty x^4\frac1{\sqrt{2\pi}}e^{-\frac{x^2}2}dx\\=&2\int_0^\infty x^4\frac1{\sqrt{2\pi}}e^{-\frac{x^2}2}dx\\=&(-2)\int_0^\infty x^3\frac1{\sqrt{2\pi}}de^{-\frac{x^2}2}\\=&-\frac2{\sqrt{2\pi}}(x^3e^{-\frac{x^2}2}|_0^\infty-3\int_0^\infty e^{-\frac{x^2}2}x^2dx)\\=&\frac6{\sqrt{2\pi}}\int_0^\infty e^{-\frac{x^2}2}x^2dx\\=&-\frac6{\sqrt{2\pi}}\int_0^\infty xde^{-\frac{x^2}2}\\=&-\frac6{\sqrt{2\pi}}(xe^{-\frac{x^2}2}|_0^\infty-\int_0^\infty e^{-\frac{x^2}2}dx)\\=&\frac6{\sqrt{2\pi}}\int_0^\infty e^{-\frac{x^2}2}dx\end{align}</script><blockquote><p>这部分感觉能直接说是 CDF 的一半，就是 $\frac 12$，结果等于 3 , 但是up主继续求了，不确定有没有坑.</p></blockquote><p>极坐标转换</p><script type="math/tex; mode=display">\begin{align}&\int_0^\infty\int_0^\infty e^{-\frac{x^2}2} e^{-\frac{y^2}2} dxdy\\(只在第一象限)=&\int_0^\frac{\pi}2\int_0^\infty e^{-\frac{r^2}2}rdrd\theta\\=&\int_0^\frac{\pi}2 [e^{-\frac{r^2}2}|_\infty^0]d\theta\\=&\frac\pi2\end{align}</script><p>原式子等于</p><script type="math/tex; mode=display">\frac6{\sqrt{2\pi}}\sqrt{\frac{\pi}2}=3</script><h3 id="矩母函数"><a href="#矩母函数" class="headerlink" title="矩母函数"></a>矩母函数</h3><script type="math/tex; mode=display">M_x(t)=\mathbb E(e^{tx})</script><p>对于正态分布 $x\sim N(\mu,\sigma^2)$</p><script type="math/tex; mode=display">\begin{align}M_x(t)&=\int\frac1{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}+tx}dx\\&=\int\frac1{\sqrt{2\pi}\sigma}e^{-\frac{x^2+\mu^2-2(\mu+t\sigma^2)x}{2\sigma^2}}dx\\&=\int\frac1{\sqrt{2\pi}\sigma}e^{-\frac{[x-(\mu+t\sigma^2)]^2+\mu^2-(\mu+t\sigma^2)^2}{2\sigma^2}}dx\\&=e^{-\frac{\mu^2-(\mu^2+t^2\sigma^4+2\mu\sigma^2 t)}{2\sigma^2}}\int\frac1{\sqrt{2\pi}\sigma}e^{-\frac{[x-(\mu+t\sigma^2)]^2}{2\sigma^2}}dx\\&=e^{\frac{t^2\sigma^2}2+\mu t}\end{align}</script><p>通过 Moment Generating Function 的特性可知</p><script type="math/tex; mode=display">e^{uY}=1+uY+\frac{u^2Y^2}{2!}+\frac{u^3Y^3}{3!}+...</script><script type="math/tex; mode=display">M_Y(u)=\mathbb E[e^{uY}]=1+u\mathbb E(Y)+\frac{u^2\mathbb E(Y^2)}{2!}+\frac{u^3\mathbb E(Y^3)}{3!}+...</script><script type="math/tex; mode=display">M_Y^{(k)}(0)=E(Y^k)</script><p><strong>【补充】</strong></p><p><img src="/2021/06/17/Normal_Distribution_and_Ex4/pic1-1.png" alt></p><p><img src="/2021/06/17/Normal_Distribution_and_Ex4/pic1-2.png" alt></p><h3 id="补充使用-Ito-求-mathbb-E-W-6-T-的方法"><a href="#补充使用-Ito-求-mathbb-E-W-6-T-的方法" class="headerlink" title="补充使用 Ito 求$\mathbb E(W^6(T))$的方法"></a>补充使用 Ito 求$\mathbb E(W^6(T))$的方法</h3><p>如果要求 $\mathbb E(W^6(T))$, 设 $f(t,x)=x^6$, $f_t=0, f_x=6x^5, f_{xx}=30x^4$</p><script type="math/tex; mode=display">\begin{align}df(t,W(t))=dW^6(T)&=6W(t)^5dW(t)+\frac1230W(t)^4dW(t)dW(t)\\&=6W(t)^5dW(t)+15W(t)^4dt\end{align}</script><script type="math/tex; mode=display">W^6(T)-W^6(0)=I_W[6W^5](T)+\int_0^T15W^4(t)dt</script><script type="math/tex; mode=display">\mathbb E[W^6(T)]=0+\int_0^T15·3t^2dt=15T^3</script><blockquote><p>当然也可以直接查表</p></blockquote><hr><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://blog.csdn.net/sinat_41895958/article/details/103827936">标准正态分布的E(X^4)积分求解</a></li><li><a href="https://www.bilibili.com/video/BV1fb411V7Gg">[金融工程][Jerry Xu的金工小知识]Stochastc Calculus布朗运动(Part 3)</a></li><li><a href="https://zhuanlan.zhihu.com/p/61828433">矩母函数、正态分布、二次型</a></li><li><a href="https://www.bilibili.com/video/BV1NC4y1a7XY">Ito积分练习题(Part 2)</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Normal Distribution</tag>
      
      <tag>Moment Generating Function</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【推导】Black Scholes Model 进阶版</title>
    <link href="/2021/06/16/Black_Scholes_Model%E6%8E%A8%E5%AF%BC_%E8%BF%9B%E9%98%B6%E7%89%88/"/>
    <url>/2021/06/16/Black_Scholes_Model%E6%8E%A8%E5%AF%BC_%E8%BF%9B%E9%98%B6%E7%89%88/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于B站 up <a href="https://space.bilibili.com/275959084">Jerry Xu</a> 的系列视频；</p><p>考虑测度变换的知识进行推导；</p><p>采用等价鞅测度的定价方法；</p></blockquote><span id="more"></span><blockquote><p>这个在 $\mathbb P$ 测度下过程一样，为什么要转换测度？</p><p>按照up主的解释，$\mathbb P$ 测度下的鞅是不存在的，只能转换到 $\mathbb Q$ 去求</p><p>在 $\mathbb P$ 测度下考虑到期权必定存在非系统的风险，且此测度并非是风险中性，因此定价过程中会对风险进行补偿，鞅不存在。</p></blockquote><h3 id="Step1"><a href="#Step1" class="headerlink" title="Step1"></a>Step1</h3><p>我们设 $S_t^*$ 是 $S_t$ 折现后的价值，其中 $S_t$ 存在于 $\mathbb P$ 测度下, 而折现后在 $\mathbb Q$ 测度下是鞅</p><script type="math/tex; mode=display">S^*_t=S_te^{-rt}</script><script type="math/tex; mode=display">\begin{align}dS_t^*&=d(S_te^{-rt})=S_tde^{-rt}+e^{-rt}dS_t+dS_tde^{-rt}\\&=-re^{-rt}S_tdt+e^{-rt}(\mu S_tdt+\sigma S_tdW_t)\\&=(\mu-r)S_t^*dt+\sigma S_t^*dW_t\end{align}</script><p>因为 $\mu&gt;r$ 永远存在，所以在 $\mathbb P$ 测度下永远不可能得到鞅，因此要换测度</p><h4 id="Novikov-condition"><a href="#Novikov-condition" class="headerlink" title="Novikov condition"></a>Novikov condition</h4><p>若 $\theta^2$ 可积，存在一个 process $M^\theta$</p><script type="math/tex; mode=display">M_t^\theta=exp(-\int_0^t\theta_sdX_s-\frac12\int_0^t\theta_s^2ds)</script><p>是一个鞅</p><h4 id="Girsanov‘s-Theorem"><a href="#Girsanov‘s-Theorem" class="headerlink" title="Girsanov‘s Theorem"></a>Girsanov‘s Theorem</h4><p>可以通过 Radon Nicodym 导数</p><script type="math/tex; mode=display">\frac{d\mathbb Q}{d\mathbb P}=exp(-\int_0^t\theta_sdW_s-\frac12\int_0^t\theta_s^2ds)</script><p>得到在 $\mathbb Q$ 测度下的布朗运动</p><script type="math/tex; mode=display">W_t^\mathbb Q=W_t+\int_0^t\theta(s)ds</script><script type="math/tex; mode=display">dW_t^\mathbb Q=dW_t+\theta_tdt</script><blockquote><p>只有随机变量在不同概率测度下才会有影响</p></blockquote><p>详细见 <a href="https://achlier.github.io/2021/05/23/Change_of_Measure/">概率测度变换笔记</a></p><p>得到替换后的在 $\mathbb Q$ 测度下的 $dS_t^*$</p><script type="math/tex; mode=display">\begin{align}dS_t^*&=(\mu-r)S_t^*dt+\sigma S_t^*(dW_t^\mathbb Q-\theta_tdt)\\&=(\mu-r-\sigma\theta_t)S_t^*dt+\sigma S_t^*dW_t^\mathbb Q\end{align}</script><p>为了取鞅 $\theta_t=\frac{\mu-r}{\sigma}$，此时</p><script type="math/tex; mode=display">dS_t^*=\sigma S_t^*dW_t^\mathbb Q</script><p>对于一个投资组合</p><script type="math/tex; mode=display">dV_t=\phi_t^SdS_t+\phi_t^BdB_t,\quad B_t=B_0e^{rt}</script><script type="math/tex; mode=display">\begin{align}dV_t^*&=V_tde^{-rt}+e^{-rt}dV_t\\&=-re^{-rt}(\phi_t^SS_t+\phi_t^BB_t)dt+e^{-rt}(\phi_t^SdS_t+\phi_t^BdB_t)\\&=\phi_t^S(-re^{-rt}S_tdt+e^{-rt}dS_t)+\phi_t^B(-re^{-rt}B_tdt+e^{-rt}dB_t)\\&=\phi_t^S(S_tde^{-rt}+e^{-rt}dS_t)+\phi_t^B(-re^{-rt}B_tdt+e^{-rt}rB_tdt)\\&=\phi_t^SdS_te^{-rt}=\phi_t^SdS_t^*=\phi_t^S\sigma S_t^*dW_t^\mathbb Q\end{align}</script><p>也是一个 $\mathbb Q$ 鞅</p><script type="math/tex; mode=display">\mathbb E^\mathbb Q[V_T^*|\mathscr{F}_t]=V_t^*</script><p>设 $G(S_T)$ 为期权到期日的收益，因为 $V_T$ 是一个复制期权的组合</p><script type="math/tex; mode=display">\mathbb E^\mathbb Q[V_T^*|\mathscr{F}_t]=\mathbb E^\mathbb Q[G(S_T)e^{-rT}|\mathscr{F}_t]</script><p>最后能得到</p><script type="math/tex; mode=display">V_t^*=\mathbb E^\mathbb Q[G(S_T)e^{-rT}|\mathscr{F}_t]</script><p><strong>初步的定价公式</strong></p><script type="math/tex; mode=display">V_t=V_t^*e^{rt}=e^{-r(T-t)}\mathbb E^\mathbb Q[G(S_T)|\mathscr{F}_t]</script><h3 id="Step2"><a href="#Step2" class="headerlink" title="Step2"></a>Step2</h3><p>已知对于看涨期权初步的定价公式</p><script type="math/tex; mode=display">C=V_t^*e^{rt}=e^{-rT}\mathbb E^\mathbb Q[(S_T-K,0)^+]</script><p>引入示性函数 $\mathbb I$</p><script type="math/tex; mode=display">\begin{align}C&=e^{-rT}\mathbb E^\mathbb Q[(S_T-k)\mathbb I_{\{S_T\ge K\}}]\\&=e^{-rT}(\mathbb E^\mathbb Q[S_T\mathbb I_{\{S_T\ge K\}}]-\mathbb E^\mathbb Q[k\mathbb I_{\{S_T\ge K\}}])\end{align}</script><p>Under $\mathbb Q$ with $\theta=\frac{\mu-r}\sigma$</p><script type="math/tex; mode=display">dW_t=dW_t^\mathbb Q-\theta_tdt</script><script type="math/tex; mode=display">\begin{align}dS_t&=\mu S_tdt+\sigma S_t(dW_t^\mathbb Q-\theta_tdt)\\&=rS_tdt+\sigma S_tdW_t^\mathbb Q\end{align}</script><script type="math/tex; mode=display">\begin{align}S_t &= S_0exp((r - \frac{\sigma^2}{2})t +\sigma W_t^\mathbb Q)\\&= S_0exp((r - \frac{\sigma^2}{2})t +\sigma \epsilon\sqrt t)\end{align}</script><p>推导一个特性</p><script type="math/tex; mode=display">\epsilon\sim N(0,1)\qquad m,\lambda,a\ constant</script><script type="math/tex; mode=display">\begin{align}&\mathbb E[e^{m+\lambda\epsilon}\mathbb I_{\{\epsilon\ge a\}}]\\=&\int_{-\infty}^\infty e^{m+\lambda x}\mathbb I_{\{x\ge a\}}\frac1{\sqrt{2\pi}}e^{-\frac{x^2}2}dx\\=&\int_{a}^\infty e^{m+\lambda x}\frac1{\sqrt{2\pi}}e^{-\frac{x^2}2}dx\\=&\frac1{\sqrt{2\pi}}\int_{a}^\infty e^{m+\lambda x-\frac{x^2}2}dx\\=&\frac1{\sqrt{2\pi}}\int_{a}^\infty e^{m-(\frac{x^2}2-\lambda x+\frac{\lambda^2}2)+\frac{\lambda^2}2}dx\\=&\frac1{\sqrt{2\pi}}\int_{a}^\infty e^{m-\frac{(x-\lambda)^2}{\sqrt{2}}+\frac{\lambda^2}2}dx\\=&\frac1{\sqrt{2\pi}}e^{m+\frac{\lambda^2}2}\int_{a}^\infty e^{-\frac{(x-\lambda)^2}{\sqrt{2}}}dx\\(set\ y=x-\lambda)=&\frac1{\sqrt{2\pi}}e^{m+\frac{\lambda^2}2}\int_{a-\lambda}^\infty e^{-\frac{y^2}{\sqrt{2}}}dy\\&=e^{m+\frac{\lambda^2}2}(N(\infty)-N(a-\lambda))\\&=e^{m+\frac{\lambda^2}2}(1-N(a-\lambda))\end{align}</script><p>With $N(x)+N(-x)=1$</p><script type="math/tex; mode=display">\mathbb E[e^{m+\lambda\epsilon}\mathbb I_{\{\epsilon\ge a\}}]=e^{m+\frac{\lambda^2}2}N(\lambda-a)</script><h4 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h4><p>求第一项</p><script type="math/tex; mode=display">\begin{align}&e^{-rT}\mathbb E^\mathbb Q[S_T\mathbb I_{\{S_T\ge K\}}]\\=&e^{-rT}\mathbb E^\mathbb Q[S_0exp((r - \frac{\sigma^2}{2})T +\sigma \epsilon\sqrt T)\mathbb I_{\{S_0exp((r - \frac{\sigma^2}{2})T +\sigma \epsilon\sqrt T)\ge K\}}]\\=&e^{-rT}S_0e^{(r - \frac{\sigma^2}{2})T}\mathbb E^\mathbb Q[e^{\sigma \epsilon\sqrt T}\mathbb I_{\{\epsilon\ge \frac{ln(K/S_0)-(r - \frac{\sigma^2}{2})T}{\sigma\sqrt T}\}}]\\=&e^{-rT}S_0e^{(r - \frac{\sigma^2}{2})T}e^{\frac{\sigma^2T}2}N(\sigma\sqrt T- \frac{ln(K/S_0)-(r - \frac{\sigma^2}{2})T}{\sigma\sqrt T})\\=&S_0N(\frac{ln(S_0/K)+(r + \frac{\sigma^2}{2})T}{\sigma\sqrt T})=S_0N(d_1)\\\end{align}</script><p>或者可以再次用测度变换使得</p><script type="math/tex; mode=display">\frac{d \tilde{\mathbb Q}}{d\mathbb Q}=e^{-\frac{\sigma^2}{2}t +\sigma W_t}</script><script type="math/tex; mode=display">\tilde W_t=W_t-\sigma t</script><script type="math/tex; mode=display">\begin{align}&e^{-rT}\mathbb E^\mathbb Q[S_T\mathbb I_{\{S_T\ge K\}}]\\=&e^{-rT}\mathbb E^\mathbb Q[S_0exp((r - \frac{\sigma^2}{2})T +\sigma W_T)\mathbb I_{\{S_0exp((r - \frac{\sigma^2}{2})T +\sigma W_T)\ge K\}}]\\=&S_0\mathbb E^\mathbb{\tilde Q}[\mathbb I_{\{S_0exp((r - \frac{\sigma^2}{2})T +\sigma\tilde W_T+\sigma^2T)\ge K\}}]\\=&S_0\mathbb E^\mathbb{\tilde Q}[\mathbb I_{\{-\frac{\tilde W_T}{\sqrt{T}}\leq \frac{ln(S_0/K)+(r + \frac{\sigma^2}{2})T}{\sigma\sqrt{T}}\}}]\\=&S_0\tilde{\mathbb Q}(-\frac{\tilde W_T}{\sqrt{T}}\leq \frac{ln(S_0/K)+(r + \frac{\sigma^2}{2})T}{\sigma\sqrt{T}})\\=&S_0N(\frac{ln(S_0/K)+(r + \frac{\sigma^2}{2})T}{\sigma\sqrt{T}})=S_0N(d_1)\end{align}</script><p>求第二项</p><script type="math/tex; mode=display">\begin{align}&e^{-rT}\mathbb E^\mathbb Q[K\mathbb I_{\{S_T\ge K\}}]\\=&Ke^{-rT}\mathbb E^\mathbb Q[\mathbb I_{\{\epsilon\ge \frac{ln(K/S_0)-(r - \frac{\sigma^2}{2})T}{\sigma\sqrt T}\}}]\\=&Ke^{-rT}\mathbb Q(\epsilon\ge \frac{ln(K/S_0)-(r - \frac{\sigma^2}{2})T}{\sigma\sqrt T})\\=&Ke^{-rT}N(\frac{ln(S_0/K)+(r - \frac{\sigma^2}{2})T}{\sigma\sqrt T})=e^{-rT}N(d_2)\\\end{align}</script><p>额外连接-<a href="https://doc.mbalib.com/view/6bc8a7cf6e12e3f22ee075b7f2541831.html">等价鞅测度和鞅定价方法</a></p>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Black Scholes Model</tag>
      
      <tag>Black Scholes PDE</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】期权定价的零散笔记</title>
    <link href="/2021/06/16/%E9%87%91%E8%9E%8D%E5%B7%A5%E7%A8%8B%E9%9B%B6%E6%95%A3%E7%9A%84%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/06/16/%E9%87%91%E8%9E%8D%E5%B7%A5%E7%A8%8B%E9%9B%B6%E6%95%A3%E7%9A%84%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于B站 up <a href="https://space.bilibili.com/275959084">Jerry Xu</a> 的视频；</p><p>主要复习基础部分一些遗忘的，或是未观察到的点；</p></blockquote><span id="more"></span><h1 id="金融数学"><a href="#金融数学" class="headerlink" title="金融数学"></a>金融数学</h1><h4 id="Calculus"><a href="#Calculus" class="headerlink" title="Calculus"></a>Calculus</h4><ul><li>Real Analysis<ul><li>Functional Analysis</li><li>ODE<ul><li>PDE<ul><li>SDE</li></ul></li></ul></li><li>Convex Opt</li><li>Measure Theory</li></ul></li></ul><h4 id="Linear-Algebra"><a href="#Linear-Algebra" class="headerlink" title="Linear Algebra"></a>Linear Algebra</h4><p>《线性代数导论》- Gilbert Strang</p><ul><li><p>Matrix Analysis</p><p>张贤达</p></li><li><p>Numerical Analysis</p><p>Timothy Sauer</p><p>《金融学与经济学中的数学方法——基于Matlab》- Paolo Brandimarte</p></li></ul><h4 id="Prob-Theory"><a href="#Prob-Theory" class="headerlink" title="Prob Theory"></a>Prob Theory</h4><ul><li><p>Stochastic Process</p><p>《应用随机过程概率模型导论》- Sheldon M.Ross</p><p>《金融随机分析》- Shreve</p><ul><li>Time Series</li></ul></li><li><p>Stochastic Calculus</p><ul><li>《Stochastic Calculus for Finance》 - Shreve</li></ul></li></ul><h1 id="期权定价"><a href="#期权定价" class="headerlink" title="期权定价"></a>期权定价</h1><ul><li>二叉树</li><li>BS model</li><li>Monte Carlo</li><li>Finite-difference</li></ul><h2 id="BS-model-定价"><a href="#BS-model-定价" class="headerlink" title="BS model 定价"></a>BS model 定价</h2><p>已知</p><script type="math/tex; mode=display">dS_t=\mu S_tdt+\sigma S_tdW_t</script><p>按公式分为两种方法建立 BS model</p><ol><li>建立投资组合消去 $dW_t$，保留 $dt$ (对冲 Hedge)</li><li>消去 $dt$，保留 $dW_t$ 构造一个鞅的过程</li></ol><blockquote><p>鞅是一个很好的性质，如果在第一个方法，只能形成上鞅或者下鞅，因此它可能会跑到 BS-PDE 的那边去，用换元+傅里叶变换解热传导方程.</p></blockquote><p><strong>针对第一个方法详细见 <a href="https://achlier.github.io/2021/03/14/Feynman-Kac_To_Black-Scholes-PDE/#2-对冲版推导">Feynman-Kac_To_Black-Scholes-PDE</a></strong> + 还没有补的PDE到BS过程</p><p><strong>针对第二个方法详细见 <a href="https://achlier.github.io/2021/06/16/Black_Scholes_Model%E6%8E%A8%E5%AF%BC_%E8%BF%9B%E9%98%B6%E7%89%88/">Black_Scholes_Model推导_进阶版</a></strong></p><h2 id="二叉树定价"><a href="#二叉树定价" class="headerlink" title="二叉树定价"></a>二叉树定价</h2><p>二叉树的定价也可以分为两种</p><ol><li>对冲 Hedge (Risk)</li><li>复制 (Replicate Option)</li></ol><p><strong>详细见 <a href="https://achlier.github.io/2021/04/25/Mathematical_Finance/">Mathematical_Finance</a></strong></p><h3 id="二叉树向BS的转换"><a href="#二叉树向BS的转换" class="headerlink" title="二叉树向BS的转换"></a>二叉树向BS的转换</h3><p>设 $I$ 为向上走的次数, 默认$p$为无风险概率, 以下都存在于风险中性中</p><script type="math/tex; mode=display">\mathbb P(I=i)=\binom iN p^i(1-p)^{N-i},\ 0\leq i\leq N</script><p>$\Rightarrow I \sim B(N,p)$, 当 $N\to\infty$ 二项分布趋近于正态分布</p><p><strong>De Moivre - Laplace CLT（棣莫弗-拉普拉斯中心极限定理）</strong></p><p>$x_n\sim B(n,p), 0&lt;p&lt;1$ For $\forall x$, we have</p><script type="math/tex; mode=display">\mathbb P(\frac{x_n-np}{\sqrt{np(1-p)}}\leq a)=\int_{-\infty}^a\frac1{\sqrt{2\pi}}e^{-\frac{t^2}2}dt=N(a)</script><p>引入股价</p><script type="math/tex; mode=display">\begin{align}\mathbb P(S_N\ge K)&=\mathbb P(ln(S_N)\ge ln(K))\\&=\mathbb P(lnS_0+Ilnu+(N-I)lnd\ge ln(K))\\&=\mathbb P(lnS_0+Iln\frac ud+Nlnd\ge ln(K))\\&=\mathbb P(I\ge \frac{ln\frac k{S_0}-Nlnd}{ln\frac ud})\\&=\mathbb P(\frac{I-Np}{\sqrt{Np(1-p)}}\ge \frac{\frac{ln\frac k{S_0}-Nlnd}{ln\frac ud}-Np}{\sqrt{Np(1-p)}})\\\end{align}</script><p>代入</p><script type="math/tex; mode=display">u=e^{\sigma\sqrt{\Delta t}}, d=e^{-\sigma\sqrt{\Delta t}}</script><script type="math/tex; mode=display">p=\frac{e^{r\Delta t}-d}{u-d}, 1-p=\frac{u-e^{r\Delta t}}{u-d}</script><p>并让 $\Delta t\to 0$, 最终可推导</p><script type="math/tex; mode=display">\mathbb P(S_N\ge K)=\mathbb P(\frac{I-Np}{\sqrt{Np(1-p)}}\ge -d_2)=N(d_2)</script><p>定价模型</p><script type="math/tex; mode=display">\begin{align}V&=e^{-rt}\mathbb E[(S_N-k)\mathbb I_{\{S_N\ge k\}}]\\&=e^{-rt}\mathbb E[S_N\mathbb I_{\{S_N\ge k\}}]-e^{-rt}\mathbb E[k\mathbb I_{\{S_N\ge k\}}]\\&=e^{-rt}\mathbb E[S_N\mathbb I_{\{S_N\ge k\}}]-e^{-rt}k\mathbb Q(S_N\ge K)\\&=e^{-rt}\mathbb E[S_N\mathbb I_{\{S_N\ge k\}}]-e^{-rt}kN(d_2)\\\end{align}</script><p>第一项</p><script type="math/tex; mode=display">\begin{align}e^{-rt}\mathbb E[S_N\mathbb I_{\{S_N\ge k\}}]&=e^{-rt}\sum_{i=0}^N\binom inp^i(1-p)^{N-i}S_0u^id^{N-i}I_{\{S_0u^id^{N-i}\ge k\}}\\&=S_0\sum_{i=0}^N\binom in(pue^{-r\Delta t})^i((1-p)de^{-r\Delta t})^{N-i}I_{\{S_0u^id^{N-i}\ge k\}}\\\end{align}</script><p>将系数代入下式可得</p><script type="math/tex; mode=display">pue^{-r\Delta t}+(1-p)S_0de^{-r\Delta t}=1</script><p>将 $p^<em>=pue^{-r\Delta t}$, $(1-p^</em>)=(1-p)S_0de^{-r\Delta t}$ 代入</p><script type="math/tex; mode=display">\begin{align}e^{-rt}\mathbb E[S_N\mathbb I_{\{S_N\ge k\}}]&=S_0\sum_{i=0}^N\binom in(p^*)^i(1-p^*)^{N-i}I_{\{S_0u^id^{N-i}\ge k\}}\\&=S_0\mathbb E^{P^*}[I_{\{S_0u^id^{N-i}\ge k\}}]\\&=S_0\mathbb P^*(S_N\ge k)\end{align}</script><p>用之前的方法可证</p><script type="math/tex; mode=display">\mathbb P^*(S_N\ge K)=N(d_1)</script><p>总结得</p><script type="math/tex; mode=display">V=S_0N(d_1)-e^{-rt}kN(d_2)\\</script><p>证明 $lnS_N$ 的正态性</p><script type="math/tex; mode=display">\begin{align}\mathbb P(S_N\leq x)&=\mathbb P(lnS_0+Ilnu+(N-I)lnd\leq x)\\&=\mathbb P(I\leq \frac{K-Nlnd-lnS_0}{ln\frac ud})\\&=\mathbb P(\frac{I-Np}{\sqrt{Np(1-p)}}\leq \frac{\frac{x-Nlnd-lnS_0}{ln\frac ud}-Np}{\sqrt{Np(1-p)}})\\&=N(\frac{x-lnS_0-(r-\frac12\sigma^2)T}{\sigma\sqrt T})\end{align}</script><p>求导得</p><script type="math/tex; mode=display">\mathbb P_{lnS_N}(x)=\frac{1}{\sqrt{2\pi}}exp(-\frac{(x-lnS_0-(r-\frac12\sigma^2)T)^2}{2\sigma^2T})\times \frac1{\sigma\sqrt T}</script><p>符合一个 $N(lnS_0+(r-\frac12\sigma^2)T,\sigma^2T)$</p><h3 id="二叉树向BS-PDE的转换"><a href="#二叉树向BS-PDE的转换" class="headerlink" title="二叉树向BS-PDE的转换"></a>二叉树向BS-PDE的转换</h3><p>假设在某个时刻一个投资组合</p><script type="math/tex; mode=display">V-\Delta S</script><p>下一时刻</p><script type="math/tex; mode=display">\begin{align}V_u-\Delta uS&=V_d-\Delta dS\\V_u-\frac{V_u-V_d}{(u-d)S}uS&=V_d-\frac{V_u-V_d}{(u-d)S}dS\\\frac{(u-d)V_u-u(V_u-V_d)}{(u-d)}&=\frac{(u-d)V_d-d(V_u-V_d)}{(u-d)}\\\frac{-dV_u+uV_d}{(u-d)}&=\frac{uV_d-dV_u}{(u-d)}\end{align}</script><p>得到</p><script type="math/tex; mode=display">V-\Delta S=\frac{uV_d-dV_u}{(u-d)}e^{-r\Delta t}</script><p>Set $D=e^{-r\Delta t}$, 代入 $\Delta$</p><script type="math/tex; mode=display">(u-d)V\frac 1D=(u-\frac 1D)V_d+(\frac 1D-d)V_u</script><p>泰勒展开</p><script type="math/tex; mode=display">u=e^{\sigma\sqrt{\Delta t}}\approx 1+\sigma\sqrt{\Delta t}+\frac 12 \sigma^2\Delta t</script><script type="math/tex; mode=display">d=e^{-\sigma\sqrt{\Delta t}}\approx 1-\sigma\sqrt{\Delta t}+\frac 12 \sigma^2\Delta t</script><script type="math/tex; mode=display">\frac 1D=e^{r\Delta t}\approx 1+r\Delta t</script><script type="math/tex; mode=display">V_u=V+\frac{\partial V}{\partial t}\Delta t+\frac{\partial V}{\partial S}\Delta S_u+\frac 12\frac{\partial^2 V}{\partial S^2}(\Delta S_u)^2</script><script type="math/tex; mode=display">V_d=V+\frac{\partial V}{\partial t}\Delta t+\frac{\partial V}{\partial S}\Delta S_d+\frac 12\frac{\partial^2 V}{\partial S^2}(\Delta S_d)^2</script><script type="math/tex; mode=display">\Delta S_u=(u-1)S\approx(\sigma\sqrt{\Delta t}+\frac 12 \sigma^2\Delta t) S</script><script type="math/tex; mode=display">\Delta S_d=(d-1)S\approx(-\sigma\sqrt{\Delta t}+\frac 12 \sigma^2\Delta t) S</script><script type="math/tex; mode=display">(\Delta S_u)^2\approx \sigma^2S^2\Delta t</script><script type="math/tex; mode=display">(\Delta S_d)^2\approx \sigma^2S^2\Delta t</script><script type="math/tex; mode=display">(u-\frac 1D)V_d\approx(\sigma\sqrt{\Delta t}+(\frac 12 \sigma^2-r)\Delta t)(V+\frac{\partial V}{\partial t}\Delta t+\frac{\partial V}{\partial S}(-\sigma\sqrt{\Delta t}+\frac 12 \sigma^2\Delta t) S+\frac 12\frac{\partial^2 V}{\partial S^2}\sigma^2S^2\Delta t)</script><script type="math/tex; mode=display">(\frac 1D-d)V_u\approx((r-\frac 12 \sigma^2)\Delta t+\sigma\sqrt{\Delta t})(V+\frac{\partial V}{\partial t}\Delta t+\frac{\partial V}{\partial S}(\sigma\sqrt{\Delta t}+\frac 12 \sigma^2\Delta t) S+\frac 12\frac{\partial^2 V}{\partial S^2}\sigma^2S^2\Delta t)</script><script type="math/tex; mode=display">\begin{align}(u-\frac 1D)V_d+(\frac 1D-d)V_u&=(2\sigma r-\sigma^3)S(\Delta t)^{1.5}\frac{\partial V}{\partial S}+(2\sigma\sqrt{\Delta t}V+2\sigma(\Delta t)^{1.5}\frac{\partial V}{\partial t}+S\sigma^3(\Delta t)^{1.5}\frac{\partial V}{\partial S}+\sigma^3S^2(\Delta t)^{1.5}\frac{\partial^2 V}{\partial S^2})\\&=2\sigma rS(\Delta t)^{1.5}\frac{\partial V}{\partial S}+(2\sigma\sqrt{\Delta t}V+2\sigma(\Delta t)^{1.5}\frac{\partial V}{\partial t}+\sigma^3S^2(\Delta t)^{1.5}\frac{\partial^2 V}{\partial S^2})\end{align}</script><p>代入</p><script type="math/tex; mode=display">\begin{align}2\sigma\sqrt{\Delta t}(1+r\Delta t)V&\approx2\sigma rS(\Delta t)^{1.5}\frac{\partial V}{\partial S}+(2\sigma\sqrt{\Delta t}V+2\sigma(\Delta t)^{1.5}\frac{\partial V}{\partial t}+\sigma^3S^2(\Delta t)^{1.5}\frac{\partial^2 V}{\partial S^2})\\r(\Delta t)V&\approx rS(\Delta t)\frac{\partial V}{\partial S}+(\Delta t)\frac{\partial V}{\partial t}+\frac 12\sigma^2S^2(\Delta t)\frac{\partial^2 V}{\partial S^2}\\0&\approx\Delta t(\frac{\partial V}{\partial t}+rS\frac{\partial V}{\partial S}+\frac 12\sigma^2S^2\frac{\partial^2 V}{\partial S^2}-rV)\\0&=\frac{\partial V}{\partial t}+rS\frac{\partial V}{\partial S}+\frac 12\sigma^2S^2\frac{\partial^2 V}{\partial S^2}-rV+(\Delta t)^{\alpha-1}\ with\ \alpha>1\end{align}</script><p>当 $\Delta t\to0$</p><script type="math/tex; mode=display">0=\frac{\partial V}{\partial t}+rS\frac{\partial V}{\partial S}+\frac 12\sigma^2S^2\frac{\partial^2 V}{\partial S^2}-rV</script><blockquote><p>因为我们省略的 $\Delta t$ 最高阶是 1，所以 $\alpha$ 最低取 1</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Financial Engineering</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】Ito Integral</title>
    <link href="/2021/06/11/Ito_Integral/"/>
    <url>/2021/06/11/Ito_Integral/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于 知乎 <a href="https://www.zhihu.com/people/wei-zhi-3-47">埃格先生</a> 的文章的笔记;</p><p>对 Ito公式 进行了有逻辑的推导，很适合初学者学习;</p></blockquote><span id="more"></span><h2 id="Ito-积分"><a href="#Ito-积分" class="headerlink" title="Ito 积分"></a>Ito 积分</h2><p>在时间 [$T_0,T$], 布朗运动 {$W_t$}$_{t\in[T_0,T]}$. 将时间分成 $N$段, 所以有 $\Delta t=(T-T_0)/N$. 定义 $W_j=w_1+w_2+…+w_j$, 其中 $\omega_i=\xi_i\sqrt{\Delta t}$. {$\xi_i$} 是一列独立同分布的随机变量，它们的均值为 0, 方差为 1,  且满足如下伯努利分布：$P(\xi_i=1)=P(\xi_i=-1)=\frac{1}{2}$</p><p>有 $W(t)-W(s)\sim N(0,t-s)$</p><p>Ito 积分一般写为</p><script type="math/tex; mode=display">\int_{T_0}^Tf_tdW_t</script><p>接下来我们采用如下的固定范式来讨论：</p><ol><li>固定 $N$</li><li>令 $N\to\infty$</li></ol><h4 id="随机徘徊的离散-Ito-积分"><a href="#随机徘徊的离散-Ito-积分" class="headerlink" title="随机徘徊的离散 Ito 积分"></a>随机徘徊的离散 Ito 积分</h4><p>设 {$f_j$}$_{j=0}^N$ 对 {$W_j$}$_{j=0}^N$ 适应, 我们定义其离散 Ito 积分 $I_W[f]$ 是如下随机变量:</p><script type="math/tex; mode=display">I_W[f]=\sum_{i=0}^{N-1}f_i(W_{i+1}-W_i)=\sum_{i=0}^{N-1}f_iw_{i+1}</script><p>例如，取 $f_j=W_j$</p><script type="math/tex; mode=display">\omega_i^2=(\xi_i\sqrt{\Delta t})^2=\Delta t</script><script type="math/tex; mode=display">\begin{align}I_W[f]&=\sum_{i=0}^{N-1}W_iw_{i+1}=\sum_{i=1}^{N}(\sum_{j=0}^{i-1}w_j)w_i=\sum_{j<i\leq N}w_iw_j\\&=\frac{1}{2}(\sum_{i=1}^{N}w_i)^2-\frac{1}{2}\sum_{i=1}^{N}w_i^2=\frac{1}{2}W_N^2-\frac{T-T_0}{2}\end{align}</script><p>$I_W[f]$ 具有如下性质：</p><ol><li><p>$\mathbb{E}I_W[f]=0$</p><blockquote><p>用 Tower property 证鞅，然后 $I_W$[$f$]$(0)=0$</p></blockquote></li><li><p>$\mathbb{E}(I_W[f])^2=\mathbb{E}[f_t^2]\mathbb E[(W_{t+1}-W_t)^2]=\mathbb{E}$[$f_t^2$]$(T-T_0)=\mathbb{E}(\frac{T-T_0}{N}\sum_{i=0}^{N-1}f_i^2)$</p></li></ol><h4 id="连续时间的-Ito-积分"><a href="#连续时间的-Ito-积分" class="headerlink" title="连续时间的 Ito 积分"></a>连续时间的 Ito 积分</h4><script type="math/tex; mode=display">I_W[f]=\int_{T_0}^Tf_tdW_t</script><p>取 $f_j=W_j$</p><script type="math/tex; mode=display">\int_{T_0}^TW_tdW_t=\frac{1}{2}W_T^2-\frac{T-T_0}{2}</script><blockquote><p>如果 $W_{T_0}\ne 0$, 则多一项 $-W_{T_0}^2/2$</p><p>这题也可以用另一个角度解</p></blockquote><script type="math/tex; mode=display">f(t,x)=\frac12 x^2,\ f_t(t,x)=0,\ f_x(t,x)=x,\ f_{xx}(t,x)=1</script><script type="math/tex; mode=display">df(t,x)=W(t)dW(t)+\frac12dt</script><p>求积分</p><script type="math/tex; mode=display">\frac12 W(T)^2=\int_0^TW(t)dW(t)+\frac12\int_0^Tdt=\int_0^TW(t)dW(t)+\frac12T</script><blockquote><p>又或者利用特性</p></blockquote><script type="math/tex; mode=display">E[\int_{T_0}^TW_tdW_t]=0</script><script type="math/tex; mode=display">VAR=E[(\int_{T_0}^TW_tdW_t)^2]=E[\int_{T_0}^TW_t^2dt]=\int_0^Ttdt=T^2/2</script><blockquote><p>相比于普通的积分 $\int_0^Tf(t)df(t) = \frac12f(T)^2$, 伊藤积分是取左值求积分的，如果采用取中值求积分（Stratonovich）</p></blockquote><p>$I_W[f]$ 具有如下性质：</p><ol><li>$\mathbb{E}\int_{T_0}^Tf_tdW_t=0$</li><li>$\mathbb{E}(\int_{T_0}^Tf_tdW_t)^2=\mathbb{E}\int_{T_0}^Tf_t^2dt$<ul><li>Ito Isometry</li></ul></li><li>$[I_W[f],I_W[f]]_T=\int_0^Tf^2(t)dt$<ul><li>$dI_W[f]dI_W[f]=f^2(t)dt$</li></ul></li></ol><h3 id="随机差分方程的等价的离散积分形式及其连续极限"><a href="#随机差分方程的等价的离散积分形式及其连续极限" class="headerlink" title="随机差分方程的等价的离散积分形式及其连续极限"></a>随机差分方程的等价的离散积分形式及其连续极限</h3><script type="math/tex; mode=display">\begin{align}X_{j+1}&\approx X_j+b_j\Delta t+\sigma_j\omega_{j+1}\\&= X_j+ \underbrace{b_j\Delta t}+\underbrace{\sigma_j\xi_{j+1}\sqrt{\Delta t}}\\&\qquad\quad\ 确定运动 \quad\ 随机运动\end{align}</script><blockquote><p>第一步省略了一个 $o(\Delta t)$</p></blockquote><h4 id="离散积分"><a href="#离散积分" class="headerlink" title="离散积分"></a>离散积分</h4><script type="math/tex; mode=display">X_n=X_0+\Delta t\sum_{j=0}^{n-1} b_j+\sum_{j=0}^{n-1} w_{j+1}\sigma_j</script><h4 id="连续积分"><a href="#连续积分" class="headerlink" title="连续积分"></a>连续积分</h4><script type="math/tex; mode=display">X(t)=X(0)+\int_0^t b(s)ds+\int_0^t\sigma(s)dW(s)</script><h4 id="Ito-公式"><a href="#Ito-公式" class="headerlink" title="Ito 公式"></a>Ito 公式</h4><p>做 Taylor 二阶展开, 将超过 $o(\Delta t) $的部分省略, 其中包含二阶以上导($X_{n+1}-X_n$ 是一个 $o(\sqrt{\Delta t})$ 的量)与一部分二阶导 ($\Delta t$ 超过一次的)</p><script type="math/tex; mode=display">\begin{align}f(X_{n+1})&=f(X_n)+f'(X_n)·(X_{n+1}-X_n)+\frac{f''(X_n)}{2}·(X_{n+1}-X_n)^2+o(\Delta t)^{3/2}\\&=f(X_n)+f'(X_n)·(b_n\Delta t+\sigma_n\xi_{n+1}\sqrt{\Delta t})+\frac{f''(X_n)}{2}·(b_n\Delta t+\sigma_n\xi_{n+1}\sqrt{\Delta t})^2\\&=f(X_n)+f'(X_n)·(b_n\Delta t+\sigma_n\xi_{n+1}\sqrt{\Delta t})+\frac{f''(X_n)}{2}·\sigma_n^2\xi_{n+1}^2\Delta t\\\end{align}</script><p>$\xi_{n+1}^2$ 在 almost surely (a.s.) 的意义下等于 1, 整理上式得到</p><script type="math/tex; mode=display">f(X_{n+1})-f(X_n)=f'(X_n)\sigma_n\xi_{n+1}\sqrt{\Delta t}+(f'(X_n)·b_n+\frac{f''(X_n)·\sigma_n^2}{2})\Delta t</script><p>也可以写成离散积分的形式</p><script type="math/tex; mode=display">f(X_n)=X_0+\sum_{j=0}^{n-1}f'(X_j)\sigma_jw_{j+1}+\sum_{j=0}^{n-1}(f'(X_j)·b_j+\frac{f''(X_j)·\sigma_j^2}{2})\Delta t</script><p>对应于连续的形式</p><script type="math/tex; mode=display">f(X(t))=X(0)+\int_0^tf'(X(s))\sigma(s)dw(s)+\int_0^t(f'(X(s))·b(s)+\frac{f''(X(s))·\sigma(s)^2}{2})ds</script><p>上述公式被称为<strong>Ito公式</strong>，简记为</p><script type="math/tex; mode=display">df(X(t))=f'(X(s))\sigma(s)dw(s)+(f'(X(s))·b(s)+\frac{f''(X(s))·\sigma(s)^2}{2})ds</script><h4 id="随机差分方程"><a href="#随机差分方程" class="headerlink" title="随机差分方程"></a>随机差分方程</h4><script type="math/tex; mode=display">X_{j+1}-X_j=s(X_j,t)w_{j+1}+m(X_j,t)\Delta t</script><h4 id="随机微分方程"><a href="#随机微分方程" class="headerlink" title="随机微分方程"></a>随机微分方程</h4><script type="math/tex; mode=display">dX(t)=\sigma(X(t),t)dW(t)+m(X(t),t)dt</script><h4 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h4><p><strong>（Vasicek Model）Interest rate stochastic differential equation</strong></p><script type="math/tex; mode=display">dR(t)=(\alpha-\beta R(t))dt+\sigma dW(t)</script><p>有一个 mean reversion 的特点，均值为 $\frac\alpha\beta$</p><script type="math/tex; mode=display">f(t,x)=e^{\beta t}x,\ f_t=x\beta e^{\beta t},\ f_x=e^{\beta t},\ f_{xx}=0</script><script type="math/tex; mode=display">\begin{align}d(e^{\beta t}R(t))=df(t,R(t))&=x\beta e^{\beta t}dt+e^{\beta t}dR(t)\\&=R(t)\beta e^{\beta t}dt+e^{\beta t}((\alpha-\beta R(t))dt+\sigma dW(t))\\&=e^{\beta t}\alpha dt+e^{\beta t}\sigma dW(t)\end{align}</script><script type="math/tex; mode=display">\begin{align}e^{\beta T}R(T)&=R(0)+\int_0^Te^{\beta t}\alpha dt+\int_0^Te^{\beta t}\sigma dW(t)\\R(T)&=e^{-\beta T}R(0)+e^{-\beta T}\frac\alpha\beta[e^{\beta t}|_0^T]+\int_0^Te^{-\beta(T-t)}\sigma dW(t)\\&=e^{-\beta T}R(0)+e^{-\beta T}\frac\alpha\beta(e^{\beta T}-1)+\int_0^Te^{-\beta(T-t)}\sigma dW(t)\\&=e^{-\beta T}R(0)+\frac\alpha\beta(1-e^{-\beta T})+\int_0^Te^{-\beta(T-t)}\sigma dW(t)\\\end{align}</script><p><strong>特性</strong></p><script type="math/tex; mode=display">\mathbb E[R(t)]=e^{-\beta t}R(0)+\frac\alpha\beta(1-e^{-\beta t})</script><p>If $t\to\infty$, then $\mathbb E[R(t)]\to \frac\alpha\beta$</p><hr><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><p><a href="https://www.zhihu.com/people/wei-zhi-3-47">埃格先生</a></p></li><li><p><a href="https://www.bilibili.com/video/BV1NC4y1a7XY">Ito积分练习题(Part 2)</a></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Ito Integral</tag>
      
      <tag>Stochastic Process</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】Fourier Transform</title>
    <link href="/2021/05/30/Fourier_Transform/"/>
    <url>/2021/05/30/Fourier_Transform/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于B站 up 童哲校长 的视频<a href="https://www.bilibili.com/video/BV1zW411Z7Cz?spm_id_from=333.999.0.0">《傅里叶变换，拉普拉斯变换与小波变换》</a>的笔记</p></blockquote><span id="more"></span><h1 id="复数基本复习"><a href="#复数基本复习" class="headerlink" title="复数基本复习"></a>复数基本复习</h1><p><img src="/2021/05/30/Fourier_Transform/pic1-1.jpg" alt></p><script type="math/tex; mode=display">Z=x+iy,\ i^2=-1</script><script type="math/tex; mode=display">f(Z)=u(x,y)+iv(x,y),\ x,y,u,v\in\mathbb{R}</script><h4 id="在图中虚部的解释"><a href="#在图中虚部的解释" class="headerlink" title="在图中虚部的解释"></a>在图中虚部的解释</h4><ol><li><p>当一个实数乘 $i$，相当于把它逆时针旋转了90°</p></li><li><p>如果存在两个单位向量 $Z_1,Z_2$，并且它们的夹角呈90°，那么 $\frac{Z_1}{Z_2}=e^{i\frac{\pi}{2}}=i$</p></li></ol><h4 id="复数的极坐标表示"><a href="#复数的极坐标表示" class="headerlink" title="复数的极坐标表示"></a>复数的极坐标表示</h4><script type="math/tex; mode=display">Z=x+iy=re^{i\theta}=r(Cos\theta+iSin\theta)</script><blockquote><p>$e^{i\pi}=-1$ Euler Formula (欧拉公式)</p></blockquote><h4 id="共轭"><a href="#共轭" class="headerlink" title="共轭"></a>共轭</h4><script type="math/tex; mode=display">\bar{Z}=x-iy=re^{-i\theta}</script><script type="math/tex; mode=display">Z+\bar{Z}=2cos\theta</script><script type="math/tex; mode=display">Z-\bar{Z}=2isin\theta</script><h3 id="特性1"><a href="#特性1" class="headerlink" title="特性1"></a>特性1</h3><p>若 $f’(Z)$ 存在，$u,v$ 存在牵连关系，延 $x$轴 $y$轴接近的表达式相同</p><p>延 $x$轴：$Z-Z_0=\Delta x$</p><script type="math/tex; mode=display">\lim_{z-z_0}\frac{\Delta f(Z)}{\Delta Z}=\lim\frac{\Delta u+i\Delta v}{\Delta x}</script><p>延 $y$轴：$Z-Z_0=i\Delta y$</p><script type="math/tex; mode=display">\lim_{z-z_0}\frac{\Delta f(Z)}{\Delta Z}=\lim\frac{\Delta u+i\Delta v}{i\Delta y}</script><p>So we have <strong>Cauchy-Riemann Equations</strong> (柯西-黎曼方程)</p><script type="math/tex; mode=display">\frac{\partial u}{\partial x}=\frac{\partial v}{\partial y},\ \frac{\partial v}{\partial x}=-\frac{\partial u}{\partial y}</script><blockquote><p>所有初等函数都满足此条件</p></blockquote><h3 id="特性2"><a href="#特性2" class="headerlink" title="特性2"></a>特性2</h3><p>当 $f(Z)$ 满足 C-R (柯西-黎曼)关系，只要知道边界的表达式，就能确定内部任意一个点的函数值</p><h4 id="Step-1"><a href="#Step-1" class="headerlink" title="Step 1"></a>Step 1</h4><p>当复变函数存在闭合的边界 $L$</p><script type="math/tex; mode=display">\oint_{L}f(Z)dZ=0</script><p><strong>证明</strong></p><p>对于 复变函数</p><script type="math/tex; mode=display">\begin{align}\oint_{L}f(Z)dZ&=\oint_{L}(u+iv)(dx+idy)\\&=\oint_{L}(udx-vdy)+i\oint_{L}(vdx+udy)\end{align}</script><p>Recall Green formula (格林公式)</p><script type="math/tex; mode=display">\oint_{L}(Pdx+Qdy)=\iint_L(\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y})dxdy</script><script type="math/tex; mode=display">\begin{align}\oint_{L}f(Z)dZ&=\oint_{L}(udx-vdy)+i\oint_{L}(vdx+udy)\\&=\iint_L(-\frac{\partial v}{\partial x}-\frac{\partial u}{\partial y})dxdy+i\iint_L(\frac{\partial u}{\partial x}-\frac{\partial v}{\partial y})dxdy\end{align}</script><p>According to Cauchy-Riemann Equations</p><script type="math/tex; mode=display">\oint_{L}f(Z)dZ=0+0=0</script><h4 id="Step-2"><a href="#Step-2" class="headerlink" title="Step 2"></a>Step 2</h4><p>求 $Z_0$ 点上的函数值</p><script type="math/tex; mode=display">f(Z_0)=\frac{1}{2\pi i}\oint_{L}\frac{f(Z)}{Z-Z_0}dZ</script><p><strong>证明</strong></p><p>以 $Z_0$ 为圆心，取一个 $l$ 为边界，$\delta$为半径的圆.  此时我们有</p><script type="math/tex; mode=display">\oint_{L}f(Z)dZ=\oint_{l}f(Z)dZ=0</script><p>or</p><script type="math/tex; mode=display">\oint_{L-l}f(Z)dZ=0</script><p><img src="/2021/05/30/Fourier_Transform/pic1-2.jpg" alt></p><p>对边界求积时的 $dZ$ 相当于在边界上走一步</p><script type="math/tex; mode=display">dZ=\delta(-Sin\theta d\theta+iCos\theta d\theta)</script><script type="math/tex; mode=display">Z-Z_0=\delta(Cos\theta+iSin\theta)</script><script type="math/tex; mode=display">\frac{dZ}{Z-Z_0}=id\theta</script><p>$\theta\in[0,2\pi]$</p><script type="math/tex; mode=display">\oint_{L} id\theta =2\pi i</script><p>当 $\delta \to 0$, $Z\to Z_0$</p><script type="math/tex; mode=display">\frac{f(Z_0)}{2\pi i}\oint_{L}\frac{dZ}{Z-Z_0}=\frac{f(Z_0)}{2\pi i}2\pi i=f(Z_0)</script><h1 id="卷积-Convolution"><a href="#卷积-Convolution" class="headerlink" title="卷积 Convolution"></a>卷积 Convolution</h1><script type="math/tex; mode=display">\int_{-\infty}^\infty f(t)g(x-t)dt=f*g</script><p>t：哑指标，$t+(x-t)=x$</p><h4 id="常见性质"><a href="#常见性质" class="headerlink" title="常见性质"></a>常见性质</h4><ol><li>线性</li><li>交互律<ul><li>$f\star g=g\star f$</li></ul></li><li>结合律<ul><li>$(f\star g)\star k=f\star (g\star k)$</li></ul></li></ol><h4 id="运用"><a href="#运用" class="headerlink" title="运用"></a>运用</h4><p>有 $u(x,y)=f(x)·g(y)$, 期望求关于 $s=x+y$ 的概率密度, 就是 $f*g$</p><h1 id="傅里叶展开"><a href="#傅里叶展开" class="headerlink" title="傅里叶展开"></a>傅里叶展开</h1><p>傅里叶级数：表示$2\pi$为周期</p><script type="math/tex; mode=display">f(x)=\frac{1}{2}a_0+\sum_{n=1}^\infty a_nCosnx+\sum_{n=1}^\infty b_nSinnx</script><p>以 $\{\mathbb{I},Sinnx,Cosnx\}$ 为基向量</p><p>其中</p><script type="math/tex; mode=display">\frac{1}{2\pi}\int_0^{2\pi}SinnxSinmx\ dx=\begin{cases}0&m\ne n\\\frac{1}{2}&m=n\ne 0\\0&m=n=0\end{cases}</script><script type="math/tex; mode=display">\frac{1}{2\pi}\int_0^{2\pi}CosnxCosmx\ dx=\begin{cases}0&m\ne n\\\frac{1}{2}&m=n\ne 0\\1&m=n=0\end{cases}</script><script type="math/tex; mode=display">\int_0^{2\pi}SinnxCosmx\ dx=0</script><p>可证得正交性被满足</p><script type="math/tex; mode=display">\int_0^{2\pi}f(x)Cosnx\ dx=\int_0^{2\pi}a_nCosnxCosnx\ dx=\pi a_n</script><script type="math/tex; mode=display">a_n=\frac{1}{\pi}\int_0^{2\pi}f(x)Cosnx\ dx</script><p>同理</p><script type="math/tex; mode=display">b_n=\frac{1}{\pi}\int_0^{2\pi}f(x)Sinnx\ dx</script><p>and</p><script type="math/tex; mode=display">a_0=\frac{1}{\pi}\int_0^{2\pi}f(x)\ dx=2</script><p>使得常值为 1</p><h3 id="【Example-1】"><a href="#【Example-1】" class="headerlink" title="【Example 1】"></a>【Example 1】</h3><p><img src="/2021/05/30/Fourier_Transform/pic1-3.jpg" alt></p><script type="math/tex; mode=display">a_0=\frac{1}{\pi}\int_0^\pi f(x)dx=1</script><blockquote><p>$a_0$ 通常是均值</p></blockquote><script type="math/tex; mode=display">\begin{align}a_n&=\frac{1}{\pi}\int_0^\pi f(x)Cosnx\ dx\\&=\frac{1}{\pi}\int_0^\pi Cosnx\ dx\\&=\frac{1}{n\pi}\int_0^\pi Cosnx\ dnx\\&=\frac{1}{n\pi}\int_0^\pi dSinnx\\&=\frac{1}{n\pi} Sinnx|_0^\pi=0-0\end{align}</script><script type="math/tex; mode=display">\begin{align}b_n&=\frac{1}{\pi}\int_0^\pi f(x)Sinnx\ dx\\&=\frac{1}{\pi}\int_0^\pi Sinnx\ dx\\&=\frac{1}{n\pi}\int_0^\pi Sinnx\ dnx\\&=\frac{1}{n\pi}\int_0^\pi -\ dCosnx\\&=-\frac{1}{n\pi} Cosnx|_0^\pi\\&=\begin{cases}\frac{2}{n\pi}& n=2k+1\\0&n=2k\end{cases}\end{align}</script><script type="math/tex; mode=display">f(x)=\frac{1}{2}+\frac{2}{\pi}(Sinx+\frac{Sin3x}{3}+\frac{Sin5x}{5}+...)</script><p>当 $Sinnx$ 项加的越多 $n\to\infty$, 越趋近目标图像. 但当不够多时，振动会比较剧烈，且存在吉布斯现象/音爆 (可用小波变换解决)</p><p>如果将原目标往左移 $\frac{\pi}{2}$ , $x\to x+\frac{\pi}{2}$</p><blockquote><p>$Sinx$ 向左移 $\frac{\pi}{2}$ 得到 $Cosx$, $Cosx$ 向左移 $\frac{\pi}{2}$ 得到 $-Sinx$</p><p>$Sinx$ 向右移 $\frac{\pi}{2}$ 得到 $-Cosx$, $Cosx$ 向右移 $\frac{\pi}{2}$ 得到 $Sinx$</p></blockquote><script type="math/tex; mode=display">\begin{align}f(x+\frac{1}{2}\pi)&=\frac{1}{2}+\frac{2}{\pi}(Sin(x+\frac{1}{2}\pi)+\frac{Sin(3x+\frac{3}{2}\pi)}{3}+\frac{Sin(5x+\frac{5}{2}\pi)}{5}+...)\\&=\frac{1}{2}+\frac{2}{\pi}(Cosx-\frac{Cos3x}{3}+\frac{Cos5x}{5}-...)\end{align}</script><p>令 $x=0$</p><script type="math/tex; mode=display">1=\frac{1}{2}+\frac{2}{\pi}(1-\frac{1}{3}+\frac{1}{5}-...)</script><p>得出一个重要的恒等式</p><script type="math/tex; mode=display">\frac{\pi}{4}=1-\frac{1}{3}+\frac{1}{5}-...</script><h3 id="【Example-2】"><a href="#【Example-2】" class="headerlink" title="【Example 2】"></a>【Example 2】</h3><p><img src="/2021/05/30/Fourier_Transform/pic1-4.jpg" alt></p><script type="math/tex; mode=display">a_0=\frac{1}{\pi}\frac{x^2}{2}|_0^\pi=\frac{\pi}{2}</script><blockquote><p>$\int udv=uv-\int vdu$</p></blockquote><script type="math/tex; mode=display">\begin{align}a_n&=\frac{1}{n\pi}\int_0^\pi x\ dSinnx\\&=\frac{1}{n\pi}[0-\int_0^\pi Sinnx\ dx]\\&=\frac{1}{n^2\pi}Cosnx|_0^\pi\\&=\begin{cases}-\frac{2}{n^2\pi}&n=2k+1\\0&n=2k\end{cases}\end{align}</script><script type="math/tex; mode=display">\begin{align}b_n&=\frac{1}{n\pi}\int_0^\pi -x\ dCosnx\\&=\frac{1}{n\pi}[\int_0^\pi Cosnx\ dx+\pi]\\&=\frac{1}{n^2\pi}Sinnx|_0^\pi-\frac{Cosn\pi}{n}\\&=\frac{(-1)^{n-1}}{n}\end{align}</script><script type="math/tex; mode=display">f(x)=\frac{\pi}{4}-\frac{2}{\pi}(Cosx+\frac{Cos3x}{3^2}+\frac{Cos5x}{5^2}+...)+(Sinx-\frac{Sin2x}{2}+\frac{Sin3x}{3}-...)</script><p>令 $x=0$</p><script type="math/tex; mode=display">0=\frac{\pi}{4}-\frac{2}{\pi}(1+\frac{1}{3^2}+\frac{1}{5^2}+...)</script><p>得出一个重要的恒等式</p><script type="math/tex; mode=display">\frac{\pi^2}{8}=1+\frac{1}{3^2}+\frac{1}{5^2}+...</script><h2 id="扩充到复数域"><a href="#扩充到复数域" class="headerlink" title="扩充到复数域"></a>扩充到复数域</h2><p>以复数与共轭替换原表达式</p><script type="math/tex; mode=display">\begin{align}f(x)&=\frac{a_0}{2}+\sum_{n=1}^\infty a_nCosnx+\sum_{n=1}^\infty b_nSinnx\\&=\frac{a_0}{2}+\sum_{n=1}^\infty a_n(\frac{e^{inx}+e^{-inx}}{2})+\sum_{n=1}^\infty b_n(\frac{e^{inx}-e^{-inx}}{2i})\\&\Rightarrow c_n\sum_{n=-\infty}^\infty e^{inx}\end{align}</script><p>此时</p><p>当 $n&gt;0$</p><script type="math/tex; mode=display">c_n=\frac{a_n}{2}-\frac{ib_n}{2}</script><p>当 $n&lt;0$</p><script type="math/tex; mode=display">c_{-n}=\frac{a_{-n}}{2}+\frac{ib_{-n}}{2}</script><p>当 $n=0$</p><script type="math/tex; mode=display">f(x)=\frac{a_0}{2}+振动=c_0+振动</script><p>以 $e^{inx}$ 为基向量</p><script type="math/tex; mode=display">\begin{align}&\int_0^{2\pi}e^{inx}·e^{-imx}dx\\=&\int_0^{2\pi}e^{i(n-m)x}dx\\=&\int_0^{2\pi}Cos(n-m)x+iSin(n-m)x\ dx\\=&\begin{cases}2\pi&m=n\\0&m\ne n\end{cases}\end{align}</script><p>可证得正交性被满足</p><script type="math/tex; mode=display">c_n=\frac{1}{2\pi}\int_0^{2\pi}f(x)·e^{-inx}dx</script><h3 id="帕塞瓦尔定理"><a href="#帕塞瓦尔定理" class="headerlink" title="帕塞瓦尔定理"></a>帕塞瓦尔定理</h3><script type="math/tex; mode=display">E(f^2(x))=\frac{1}{2\pi}\int_0^{2\pi}f^2(x)dx=(\frac{a_0}{2})^2+\sum_{n=1}^\infty(\frac{1}{2}a_n^2+\frac{1}{2}b_n^2)</script><script type="math/tex; mode=display">E(f^2(x))=\frac{1}{2\pi}\int_0^{2\pi}|f(x)|^2dx=\sum_{n=1}^\infty|c_n|^2,\ \frac{a_0}{2}=c_0</script><p>where $|f(x)|^2=f(x)\bar{f}(x)$</p><h1 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="傅里叶变换"></a>傅里叶变换</h1><p>将原先以 $(-\pi,\pi)$ 为一周期，改写为以 $(-L,L)$ 为一周期</p><script type="math/tex; mode=display">Cosnx \Leftrightarrow Cosn(\frac{2\pi x}{2L})=Cos\frac{n\pi x}{L}</script><script type="math/tex; mode=display">Sinnx \Leftrightarrow Sin\frac{n\pi x}{L}</script><script type="math/tex; mode=display">e^{inx}\Leftrightarrow e^{\frac{in\pi x}{L}}</script><script type="math/tex; mode=display">a_n=\frac{1}{\pi}\int_{-\pi}^\pi f(x)Cosnx\ dx\Leftrightarrow \frac{1}{L}\int_{-L}^L f(x)Cos\frac{n\pi x}{L}\ dx</script><script type="math/tex; mode=display">c_n\Leftrightarrow\frac{1}{L}\int_{-L}^Lf(x)·e^{-\frac{in\pi x}{L}}dx</script><p>普通 $2L$ 周期的展开</p><script type="math/tex; mode=display">f(x)=\sum_{n=-\infty}^\infty c_n e^{\frac{in\pi}{L}x}</script><p>定义：$\frac{n\pi}{L}=\alpha_n$, $\Delta \alpha=\alpha_{n+1}-\alpha_n=\frac{\pi}{L}$</p><script type="math/tex; mode=display">f(x)=\sum_{n=-\infty}^\infty c_n e^{i\alpha_nx}</script><script type="math/tex; mode=display">c_n=\frac{1}{2L}\int_{-L}^Lf(x)e^{-i\alpha_nx}dx=\frac{\Delta\alpha}{2\pi}\int_{-L}^Lf(x)e^{-i\alpha_nx}dx</script><p>把 $c_n$ 代入 $f(x)$</p><script type="math/tex; mode=display">\begin{align}f(x)&=\sum_{n=-\infty}^\infty \frac{\Delta\alpha}{2\pi} \int_{-L}^Lf(u)e^{-i\alpha_nu}du\ e^{i\alpha_nx}\\&=\frac{1}{2\pi}\sum_{n=-\infty}^\infty \int_{-L}^Lf(u)e^{i\alpha_n(x-u)}du\ \Delta\alpha\\\end{align}</script><p>令 $L\to\infty$, 有 $\Delta\alpha\to 0$</p><script type="math/tex; mode=display">f(x)=\frac{1}{2\pi}\int_{-\infty}^\infty\int_{-\infty}^\infty f(u)e^{i\alpha_n(x-u)}du\ d\alpha\\</script><p>可以将上式拆成两份</p><script type="math/tex; mode=display">f(x)=\frac{1}{2\pi}\int_{-\infty}^\infty g(\alpha)e^{i\alpha_nx}d\alpha\\</script><script type="math/tex; mode=display">g(\alpha)=\int_{-\infty}^\infty f(u)e^{-i\alpha_nu}du</script><h3 id="双重可逆定义"><a href="#双重可逆定义" class="headerlink" title="双重可逆定义"></a>双重可逆定义</h3><script type="math/tex; mode=display">f(x) \leftrightarrow g(\alpha)</script><p>总结得</p><script type="math/tex; mode=display">F.T\begin{cases}g(\alpha)=\int_{-\infty}^\infty f(x)e^{-i\alpha_nx}dx\\f(x)=\frac{1}{2\pi}\int_{-\infty}^\infty g(\alpha)e^{i\alpha_nx}d\alpha\\\end{cases}</script><p>有时候表达式不同，但积分前的数相乘必须等于$\frac{1}{2\pi}$</p><script type="math/tex; mode=display">\begin{align}f'(x)&\leftrightarrow\int_{-\infty}^\infty f'(x)e^{-i\alpha_nx}dx\\&=f(x)e^{-i\alpha_nx}|_{-\infty}^\infty-\int_{-\infty}^\infty (-i\alpha_n)f(x)e^{-i\alpha_nx}dx\\&=0+i\alpha_ng(\alpha)\end{align}</script><p>因此可推导</p><script type="math/tex; mode=display">f''(x)\leftrightarrow(i\alpha)^2g(\alpha),\ f'''(x)\leftrightarrow(i\alpha)^3g(\alpha)</script><p>此方法可以用来 $求导\leftrightarrow乘积$</p><script type="math/tex; mode=display">(3f'''(x)+2f''(x)+f(x))\rightarrow多项式</script><script type="math/tex; mode=display">f(x)\leftarrow g(\alpha)</script><p>如果采用</p><script type="math/tex; mode=display">\int_{-\infty}^\infty f(x)e^{-\alpha x}dx</script><p>则是拉普拉斯变换</p><h3 id="傅里叶变换的正式表达"><a href="#傅里叶变换的正式表达" class="headerlink" title="傅里叶变换的正式表达"></a>傅里叶变换的正式表达</h3><script type="math/tex; mode=display">\mathscr{F}(f(x))(\alpha)=g(\alpha)</script><script type="math/tex; mode=display">\mathscr{F}(g(\alpha))(x)=f(x)</script><h3 id="帕塞瓦尔定理-1"><a href="#帕塞瓦尔定理-1" class="headerlink" title="帕塞瓦尔定理"></a>帕塞瓦尔定理</h3><p>函数的模（在一定区间内的积分）= 所有系数的平方和的叠加； 能量没有损失</p><script type="math/tex; mode=display">\int_{-\infty}^\infty|g(\alpha)|^2d\alpha=2\pi\int_{-\infty}^\infty|f(x)|^2dx</script><p>证明</p><script type="math/tex; mode=display">\begin{align}\int_{-\infty}^\infty|g(\alpha)|^2d\alpha&=\int_{-\infty}^\infty g(\alpha)\bar{g}(\alpha)d\alpha\\&=\int_{-\infty}^\infty g(\alpha)(\int_{-\infty}^\infty\bar{f}(x)e^{idx}dx)d\alpha\\&=\int_{-\infty}^\infty \bar{f}(x)(\int_{-\infty}^\infty g(\alpha)e^{idx}d\alpha)dx\\&=2\pi\int_{-\infty}^\infty \bar{f}(x)f(x)dx\end{align}</script><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><p><strong>线性性</strong></p><p>有 F.T : $f\to g$, $t\to s$</p><script type="math/tex; mode=display">\mathscr{F}(\alpha f+\beta t)=\alpha g+\beta s</script><p><strong>求导特性</strong></p><script type="math/tex; mode=display">f^{(n)}(x)\leftrightarrow(i\alpha)^ng(\alpha)</script><script type="math/tex; mode=display">(-ix)^nf(x)\leftrightarrow g^{(n)}(\alpha)</script><p><strong>卷积特性</strong></p><p>有 F.T : $f\to g$, $t\to s$</p><script type="math/tex; mode=display">f*t\leftrightarrow g*s</script><h2 id="不确定性关系-Uncertainty-Principle"><a href="#不确定性关系-Uncertainty-Principle" class="headerlink" title="不确定性关系 Uncertainty Principle"></a>不确定性关系 Uncertainty Principle</h2><script type="math/tex; mode=display">\Delta X\Delta P\ge\frac{\hbar}{2}</script><blockquote><p>$G(引力), \hbar (普朗克常量 量子), c (时定)$</p></blockquote><h3 id="求正态分布分F-T"><a href="#求正态分布分F-T" class="headerlink" title="求正态分布分F.T"></a>求正态分布分F.T</h3><script type="math/tex; mode=display">f(x)=\frac{1}{\sqrt{4\pi a}}e^{-\frac{x^2}{4a}}</script><script type="math/tex; mode=display">\mathscr{F}(f(x))=e^{-\alpha u^2}</script><blockquote><p>用到解析函数在解析区域内围道积分=0</p></blockquote><script type="math/tex; mode=display">\begin{align}g(u)&=\int_{-\infty}^\infty f(x)e^{-iux}dx\\&=\frac{1}{\sqrt{4\pi a}}\int_{-\infty}^\infty e^{-\frac{x^2}{4a}}e^{-iux}dx\\&=\frac{1}{\sqrt{4\pi a}}e^{-au^2}\int_{-\infty}^\infty e^{-(\frac{x^2}{4a}+iux+a(iu)^2)}dx\\&=\frac{1}{\sqrt{4\pi a}}e^{-au^2}\int_{-\infty}^\infty e^{-(\frac{x}{2\sqrt{a}}+\sqrt{a}iu)^2}dx\\\end{align}</script><h4 id="Recall"><a href="#Recall" class="headerlink" title="Recall"></a>Recall</h4><script type="math/tex; mode=display">\int_{-\infty}^\infty e^{-x^2}dx=I=\sqrt{\pi}</script><p>证明</p><script type="math/tex; mode=display">\begin{align}I^2&=\int_{-\infty}^\infty e^{-x^2}dx\int_{-\infty}^\infty e^{-y^2}dy\\&=\int\int_{-\infty}^\infty e^{-(x^2+y^2)}dx\ dy\\&=\int_0^{2\pi}\int_{-\infty}^\infty e^{-r^2}rdr\ d\theta\\&=\pi\int_{-\infty}^\infty e^{-r^2}dr^2\\&=\pi\end{align}</script><blockquote><p>$\int\int_Df(x,y)dxdy=\int\int_Df(\rho Cos\theta,\rho Sin\theta)\rho d\rho d\theta$</p></blockquote><script type="math/tex; mode=display">\oint_{I-II}e^{-z^2}dZ=0</script><script type="math/tex; mode=display">II:\int_{-\infty}^\infty e^{-(\frac{x}{2\sqrt{a}}+\sqrt{a}iu)^2}dx=I:\int_{-\infty}^\infty e^{-(\frac{x}{2\sqrt{a}})^2}dx=2\sqrt{a}\int_{-\infty}^\infty e^{-x'^2}dx'=2\sqrt{a\pi}</script><blockquote><p>从另一种角度解释了正态分布的形成</p></blockquote><p>所以</p><script type="math/tex; mode=display">\begin{align}g(u)&=\frac{1}{\sqrt{4\pi a}}e^{-au^2}·2\sqrt{a\pi}\\&=e^{-au^2}\end{align}</script><p>引入定理</p><script type="math/tex; mode=display">\psi(x)=\frac{1}{\sqrt{4\pi a}}e^{-\frac{x^2}{4a}}</script><script type="math/tex; mode=display">P(k)=e^{-ak^2}</script><p>with $4a=2\sigma_x^2$, $\frac{1}{a}=2\sigma_k^2$; $\sigma_x\sigma_k=const.$ 位置越确定，动量越不确定，反之亦然. 两者只有一种能优化到一种程度.</p><h2 id="解热传导公式"><a href="#解热传导公式" class="headerlink" title="解热传导公式"></a>解热传导公式</h2><blockquote><p>此步骤可以套入由BS-PDE推导的BS model</p></blockquote><p>初始热温分布 $f(x)$, 目标函数 $h(x,t)$ 在 t 时间 x 位置的温度.</p><h3 id="热传导方程"><a href="#热传导方程" class="headerlink" title="热传导方程"></a>热传导方程</h3><script type="math/tex; mode=display">\frac{\partial h(x,t)}{\partial t}=k\frac{\partial^2 h(x,t)}{\partial x^2}</script><p>在 t 时增加的温度，是两边温差的差乘以一个系数</p><p>选择 x 消去，用 F.T $x\to u$</p><script type="math/tex; mode=display">\begin{align}\mathscr{F}(\frac{\partial h}{\partial t})&=\mathscr{F}(k\frac{\partial^2 h}{\partial x^2})\\\frac{\partial}{\partial t}[\mathscr{F}(h)]&=k(iu)^2\mathscr{F}(h)\end{align}</script><p>因为有 $\frac{d}{dt}W=aW$, 判断 $\mathscr{F}(h)$ 为指数形式</p><script type="math/tex; mode=display">\mathscr{F}(h)=c(u)e^{-ku^2t}</script><p>由卷积特性，若 F.T : $f\to g$, $t\to s$, 有$f\star t\leftrightarrow g\star s$</p><p>因为存在初态 t=0 时，$h(x,0)=f(x)$</p><script type="math/tex; mode=display">\mathscr{F}(f(x))=c(u)e^{-ku^20}=c(u)</script><p>依照正态分布分F.T得出</p><script type="math/tex; mode=display">\mathscr{F}(\frac{1}{\sqrt{4\pi kt}}e^{-\frac{x^2}{4kt}})=e^{-ku^2t}</script><p>总结</p><script type="math/tex; mode=display">h(x,t)=\int_{-\infty}^\infty f(L)\frac{1}{\sqrt{4\pi kt}}e^{-\frac{(x-L)^2}{4kt}}dL</script><h2 id="核磁共振成像-MRI"><a href="#核磁共振成像-MRI" class="headerlink" title="核磁共振成像 MRI"></a>核磁共振成像 MRI</h2><p>密度分布 $\mu(x,y)$，原强度 $I_0$，穿透后的强度 $I=I_0e^{-\int_L \mu}$，现已知 $\int_L \mu$, $\theta$ 射入角度，$\rho$ 距圆心距离</p><h3 id="将变换扩展到二维"><a href="#将变换扩展到二维" class="headerlink" title="将变换扩展到二维"></a>将变换扩展到二维</h3><script type="math/tex; mode=display">F.T\begin{cases}g(k_x,k_y)=\int\int f(x,y)e^{-i(k_xx+k_yy)}dxdy\\f^{(n)}(x,y)\leftrightarrow(i(k_xx+k_yy))^ng(k_x,k_y)\\\end{cases}</script><p>固定 $\theta$，改变 $\rho$，并对 $\rho$ 进行 F.T</p><script type="math/tex; mode=display">\begin{align}\mathscr{F}(\int_L \mu(\rho,\theta))(r)&=\int(\int_L \mu(\rho,\theta))e^{-ir\rho}d\rho\\&=\int\int \mu(x,y)e^{-ir(xCos\theta+ySin\theta)}dxdy\\\end{align}</script><p>变量替换 $rCos\theta=k_x, rSin\theta=k_y$</p><script type="math/tex; mode=display">\begin{align}\mathscr{F}(\int_L \mu(\rho,\theta))(r)&=\int\int \mu(x,y)e^{-i(k_xx+k_yy)}dxdy\\\end{align}</script><p>得到 $\mathscr{F}(\mu(x,y))$ 后，I.F.T，得到 $\mu(x,y)$</p><h2 id="离散傅里叶变换"><a href="#离散傅里叶变换" class="headerlink" title="离散傅里叶变换"></a>离散傅里叶变换</h2><p>等效与矩阵算法，发展为快速傅里叶变换 F.F.T</p><p>定义 [x] 中括号为离散, 以下是 D.F.T, $2\pi$ 为一个周期</p><script type="math/tex; mode=display">\mathscr{F}(f[n])(m)\equiv\sum_{n=0}^{N-1}f[n]e^{-2\pi inm/N}</script><h4 id="矩阵形式"><a href="#矩阵形式" class="headerlink" title="矩阵形式"></a>矩阵形式</h4><script type="math/tex; mode=display">W_{nm}=e^{-\frac{2\pi i}{N}nm},\ m,n\in[0,N-1]</script><script type="math/tex; mode=display">\mathscr{F}(f[n])(m)= Wf[n]</script><p>定义 $e^{-\frac{2\pi i}{N}}=\omega$</p><script type="math/tex; mode=display">W=\begin{bmatrix}1&1&1&...&1\\1&\omega&\omega^2&...&\omega^m\\1&\omega^{2}&\omega^{4}&...&\omega^{2m}\\...&...&...&...&...\\1&\omega^{n}&\omega^{2n}&...&\omega^{mn}\\\end{bmatrix}</script><script type="math/tex; mode=display">W^{-1}=\frac{1}{N}\begin{bmatrix}1&1&1&...&1\\1&\omega^{-1}&\omega^{-2}&...&\omega^{-m}\\1&\omega^{-2}&\omega^{-4}&...&\omega^{-2m}\\...&...&...&...&...\\1&\omega^{-n}&\omega^{-2n}&...&\omega^{-mn}\\\end{bmatrix}</script><script type="math/tex; mode=display">WW^{-1}=I</script><h4 id="快速傅里叶变换"><a href="#快速傅里叶变换" class="headerlink" title="快速傅里叶变换"></a>快速傅里叶变换</h4><p>有 $e^{i\theta}=Cos\theta+iSin\theta$, 在 $e^{-\frac{2\pi i}{N}nm}$ 中，当 nm 能被 N 整除，则 $W_{mn}$ 等于 1</p><p>$W_{N\times N}$ 可以分成 $一个分块矩阵\times一个对角分块矩阵\times位移矩阵$</p><script type="math/tex; mode=display">W_{N\times N}=\begin{bmatrix}I&D\\I&-D\end{bmatrix}\begin{bmatrix}W_{\frac{N}{2}}&0\\0&W_{\frac{N}{2}}\end{bmatrix}\begin{bmatrix}n\leq\frac{N}{2},第n行2n+1列为1\\n\ge\frac{N}{2},第(n-\frac{N}{2})行2(n-\frac{N}{2})列为1\end{bmatrix}</script><p>D 是一个包含 $[1,\omega,\omega^2,…,\omega^{\frac{N}{2}-1}]$ 的对角矩阵</p><h2 id="Gabor变换-短时傅里叶变换"><a href="#Gabor变换-短时傅里叶变换" class="headerlink" title="Gabor变换/短时傅里叶变换"></a>Gabor变换/短时傅里叶变换</h2><p>为了研究一段时间，引入$g(t)$ 时窗因子，只在 0 点附近不为 0，其余快速消减</p><script type="math/tex; mode=display">G(f(t))(w,u)=\int_{-\infty}^\infty f(t)g(t-u)e^{-iwt}dt</script><h2 id="小波变换-Wavelet-Transform"><a href="#小波变换-Wavelet-Transform" class="headerlink" title="小波变换 Wavelet Transform"></a>小波变换 Wavelet Transform</h2><script type="math/tex; mode=display">W(f(t))(a,b)=\int_{-\infty}^\infty f(t)\psi_{a,b}(t)dt</script><script type="math/tex; mode=display">f(t)=\frac{1}{C}\int_0^\infty\int_{-\infty}^\infty a^{-2}W_f(a,b)\psi_{a,b}(t)db\ da</script><script type="math/tex; mode=display">C=\int_0^\infty\frac{|\mathscr{F}(\psi(t))(\omega)|^2}{\omega}d\omega</script><script type="math/tex; mode=display">\psi_{a,b}(t)=\frac{1}{\sqrt{a}}\psi(\frac{t-b}{a})</script><ul><li>$a&gt;0$ 放缩尺度因子</li><li>$-\infty&lt;b&lt;\infty$ 平移因子</li><li>$\psi(t)$ 基函数</li></ul><blockquote><p> 基函数/小波平均值必须为0</p></blockquote><h3 id="墨西哥草帽式"><a href="#墨西哥草帽式" class="headerlink" title="墨西哥草帽式"></a>墨西哥草帽式</h3><script type="math/tex; mode=display">\psi(t)=\frac{2}{B}\pi^{-\frac{1}{4}}(1-t^2)e^{-\frac{t^2}{2}}</script><h3 id="Morlet-小波"><a href="#Morlet-小波" class="headerlink" title="Morlet 小波"></a>Morlet 小波</h3><script type="math/tex; mode=display">\psi(t)=e^{-\frac{t^2}{2}}e^{i\omega_0t}</script><h2 id="拉普拉斯变换-Laplace-Transform"><a href="#拉普拉斯变换-Laplace-Transform" class="headerlink" title="拉普拉斯变换 Laplace Transform"></a>拉普拉斯变换 Laplace Transform</h2><script type="math/tex; mode=display">F.T\begin{cases}\mathscr{L}(f(t))(p)=F(p)=\int_0^\infty f(t)e^{-pt}dt\\f'(t)\leftrightarrow pF(p)-f(0)\\f''(t)\leftrightarrow p(pF(p)-f(0))-f'(0)\\\end{cases}</script><h1 id="傅里叶变换表"><a href="#傅里叶变换表" class="headerlink" title="傅里叶变换表"></a>傅里叶变换表</h1><p><img src="/2021/05/30/Fourier_Transform/pic1-5.jpg" alt></p><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://zhuanlan.zhihu.com/p/19763358">傅里叶分析之掐死教程（完整版）</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Complex Number</tag>
      
      <tag>Fourier Transform</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】Change of Measure</title>
    <link href="/2021/05/23/Change_of_Measure/"/>
    <url>/2021/05/23/Change_of_Measure/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于B站up Jerry Xu 的视频<a href="https://www.bilibili.com/video/BV1454y1D7to?spm_id_from=333.999.0.0">《概率测度变换》</a>系列的笔记</p></blockquote><span id="more"></span><h1 id="Section-1：Preliminary-of-Probability-Theory"><a href="#Section-1：Preliminary-of-Probability-Theory" class="headerlink" title="Section 1：Preliminary of Probability Theory"></a>Section 1：Preliminary of Probability Theory</h1><h3 id="1-Probability-Space"><a href="#1-Probability-Space" class="headerlink" title="1. Probability Space"></a>1. Probability Space</h3><script type="math/tex; mode=display">(\Omega,\mathcal{F},\mathbb{P})</script><ul><li><p>Sample Space (可能出现的结果)：$\Omega$</p><ul><li>$\Omega=\{\omega_1,\omega_2,…\}$</li><li>$\Omega =\omega_i, i\in I(index set)$，无限多不可数</li><li>Random Variable $X(\omega)$定义在$\Omega$上<ul><li>$X：\Omega \to \mathbb{R}^K$</li><li>$X^{-1}(B)=\{\omega\in\Omega:X(\omega)\in B\}\in \mathcal{F} for all$<ul><li>Borel sets：$B\in\mathscr{B}(\mathbb{R}^K)$</li></ul></li></ul></li></ul></li><li><p>$\sigma$-algebra (all measurable events)：$\mathcal{F}$</p><ul><li>$\varnothing \in \mathcal{F}$</li><li>$A \in \mathcal{F} \Rightarrow A^C \in \mathcal{F}$</li><li>$A_1,A_2,…\in\mathcal{F}\Rightarrow\cup_{n=1}^\infty A_n\in\mathcal{F}$</li><li>Events are subset of $\Omega$</li></ul></li><li><p>Probability measure (all events will be assigned a value)：$\mathbb{P}$</p><ul><li><p>$\mathbb{P}(\Omega)=1$</p></li><li><p>$If A_1,A_2,… are disjoint sets$</p><p>$\Rightarrow \mathbb{P}(\cup_{n=1}^\infty A_n)=\sum_{n=1}^\infty\mathbb{P}(A_n)$</p></li><li><p>$\mathbb{P}$能给$\mathcal{F}$中每一个事件都映射到闭区间0到1上，所以概率测度定义域是$\sigma$域</p><ul><li>$\mathbb{P}：\Omega \to [0,1]$</li></ul></li></ul></li></ul><h4 id="De-Morgan’s-law"><a href="#De-Morgan’s-law" class="headerlink" title="De Morgan’s law"></a>De Morgan’s law</h4><script type="math/tex; mode=display">(A\cap B)^C=A^C\cup B^C,\ (A\cup B)^C=A^C\cap B^C</script><h3 id="2-Other-Definition"><a href="#2-Other-Definition" class="headerlink" title="2. Other Definition"></a>2. Other Definition</h3><p><strong>期望</strong></p><ul><li>Countable Infinite</li></ul><script type="math/tex; mode=display">\mathbb{E}X=\sum_{k=1}^\infty X(\omega_k)\mathbb{P}(\omega_k)</script><ul><li>Uncountable Infinite</li></ul><script type="math/tex; mode=display">\begin{align}\mathbb{E}X&=\int_\Omega X(\omega)d\mathbb{P}(\omega) (Leb\ Integral)\\&=\int_{-\infty}^\infty x\underbrace{f(x)}dx=\int_{-\infty}^\infty xd\underbrace{F(x)}\\&\ \qquad\qquad  pdf\ \qquad\qquad\quad\quad cdf\end{align}</script><p><strong>Riemann积分(upper)&amp;Lebesgue积分(lower)</strong></p><p><img src="/2021/05/23/Change_of_Measure/pic1-1.png" alt></p><p><strong>Indicator function (示性函数)</strong></p><script type="math/tex; mode=display">\mathbb{I}_A(\omega)=\begin{cases}1&,\omega\in A\\0&,\omega\not\in A\end{cases}</script><script type="math/tex; mode=display">\mathbb{E}[\mathbb{I}_A(\omega)]=\mathbb{P}(\omega\in A)</script><p><strong>积分</strong></p><p>For $A\subset\Omega, A\in\mathcal{F}$</p><script type="math/tex; mode=display">\int_AX(\omega)d\mathbb{P}(\omega)=\int_\Omega\mathbb{I}_A(\omega)X(\omega)d\mathbb{P}(\omega)</script><p>For $A\subset\Omega, B\subset\Omega, A,B\in\mathcal{F}$</p><p>and $A \cap B = \varnothing$</p><script type="math/tex; mode=display">\begin{align}\int_{A\cup B}X(\omega)d\mathbb{P}(\omega)&=\int_\Omega\mathbb{I}_{A\cup B}(\omega)X(\omega)d\mathbb{P}(\omega)\\&=\int_\Omega\mathbb{I}_A(\omega)X(\omega)d\mathbb{P}(\omega)+\int_\Omega\mathbb{I}_B(\omega)X(\omega)d\mathbb{P}(\omega)\end{align}</script><div class="table-container"><table><thead><tr><th>($A \cap B = \varnothing$)</th><th>$\mathbb{I}_A$</th><th>$\mathbb{I}_B$</th><th>$\mathbb{I}_{A\cup B}$</th></tr></thead><tbody><tr><td>$A$</td><td>1</td><td>0</td><td>1</td></tr><tr><td>$B$</td><td>0</td><td>1</td><td>1</td></tr><tr><td>$A\cup B$</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div><h3 id="3-Change-of-Measure"><a href="#3-Change-of-Measure" class="headerlink" title="3. Change of Measure"></a>3. Change of Measure</h3><p><strong>测度</strong></p><ul><li><p>测度$\mathbb{P}$：真实世界测度</p></li><li><p>测度$\mathbb{Q}$：单个风险中性测度 (股票过程) 多个等价鞅测度 (债券过程)</p></li></ul><p><strong>Radon-Nikodym Derivative</strong></p><p>Let $Z\ge 0$, with</p><script type="math/tex; mode=display">\mathbb{E}^\mathbb{P}[Z(\omega)]=1</script><p>For $A\in \mathcal{F}$, define</p><script type="math/tex; mode=display">\mathbb{Q}(A)=\int_AZ(\omega)d\mathbb{P}(\omega)</script><script type="math/tex; mode=display">\mathbb{Q}(A)=\sum_{\omega\in A}\mathbb{Q}(\omega)=\sum_{\omega\in A}\mathbb{P}(\omega)Z(\omega)</script><p>Then $\mathbb{Q}$ is a prob measure.</p><p>Furtheremore, if $X\ge 0$, then</p><script type="math/tex; mode=display">\mathbb{E}^\mathbb{Q}[X]=\mathbb{E}^\mathbb{P}[XZ]</script><p>if $Z&gt; 0$, then</p><script type="math/tex; mode=display">\mathbb{E}^\mathbb{Q}[\frac{X}{Z}]=\mathbb{E}^\mathbb{P}[X]</script><h3 id="4-Example"><a href="#4-Example" class="headerlink" title="4. Example"></a>4. Example</h3><p><strong>Question</strong>：we have $X(\omega)=\omega\sim N^\mathbb{P}(0,1)$ . Set $Y(\omega)=X(\omega)+\theta (\theta&gt;0)$ . So it follow $N^\mathbb{P}(\theta,1)$ . Build a Probability measure $\mathbb{Q}$ and make $Y$ follow $N^\mathbb{Q}(0,1)$ . Find the Radon-Nikodym Derivative.</p><script type="math/tex; mode=display">Z(\omega)=\frac{d\mathbb{Q}(\omega)}{d\mathbb{P}(\omega)}</script><p>Recall that the PDF and CDF of Standard normal distribution：</p><p><strong>PDF</strong></p><script type="math/tex; mode=display">\phi(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}},\ x\in \mathbb{R}</script><p><strong>CDF</strong></p><script type="math/tex; mode=display">\Phi(x)=\int_{-\infty}^x\frac{1}{\sqrt{2\pi}}e^{-\frac{s^2}{2}}ds</script><p>Under $\mathbb{P}: X\sim N^\mathbb{P}(0,1)$, we have:</p><script type="math/tex; mode=display">\begin{align}\Delta\mathbb{P}(l)&=\mathbb{P}(l\leq\omega\leq l+\Delta l)\\&= \Phi(l+\Delta l)-\Phi(l)\end{align}</script><p>Under $\mathbb{Q}: Y\sim N^\mathbb{Q}(0,1)$, we have:</p><script type="math/tex; mode=display">\begin{align}\Delta\mathbb{Q}^*(l)&=\mathbb{Q}(l\leq Y(\omega)\leq l+\Delta l)\\&=\mathbb{Q}(l-\theta\leq\omega\leq l+\Delta l-\theta)\\&=\Phi(l+\Delta l)-\Phi(l)\end{align}</script><p>Set $l\to l+\theta$</p><script type="math/tex; mode=display">\begin{align}\Delta\mathbb{Q}(l)=\Delta\mathbb{Q}^*(l+\theta)&=\mathbb{Q}(l\leq\omega\leq l+\Delta l)\\&=\Phi(l+\Delta l+\theta)-\Phi(l+\theta)\end{align}</script><p>Solving the function</p><script type="math/tex; mode=display">\begin{align}Z(l)&=\frac{d\mathbb{Q}(l)}{d\mathbb{P}(l)}\\&=\lim_{\Delta l\to 0}\frac{\Delta\mathbb{Q}(l)}{\Delta\mathbb{P}(l)}\\&=\lim_{\Delta l\to 0}\frac{\Phi(l+\Delta l+\theta)-\Phi(l+\theta)}{\Phi(l+\Delta l)-\Phi(l)}\\& (\frac{0}{0})\ 洛必达法则\\&=\lim_{\Delta l\to 0}\frac{\phi(l+\Delta l+\theta)}{\phi(l+\Delta l)}\\&=\frac{\phi(l+\theta)}{\phi(l)}\end{align}</script><p>so</p><script type="math/tex; mode=display">\begin{align}Z(\omega)&=\frac{\phi(\omega+\theta)}{\phi(\omega)}\\&=\frac{\frac{1}{\sqrt{2\pi}}e^{-\frac{(\omega+\theta)^2}{2}}}{\frac{1}{\sqrt{2\pi}}e^{-\frac{\omega^2}{2}}}\\&=exp(-\frac{(\omega+\theta)^2}{2}+\frac{\omega^2}{2})\\&=exp(-\frac{\theta^2}{2}-X(\omega)\theta)\end{align}</script><p>在随机变量中 $Z(\omega)$ 为 exponential martingale (指数鞅)</p><script type="math/tex; mode=display">dW_t^\mathbb{P}=dW_t^\mathbb{Q}-\theta_tdt,\ \theta_t=\frac{\mu-r}{\sigma}</script><p>真实世界中</p><script type="math/tex; mode=display">\mathbb{P}:dS_t=\mu S_tdt+\sigma S_tdW_t^\mathbb{P}</script><p>风险中性世界中</p><script type="math/tex; mode=display">\begin{align}\mathbb{Q}:dS_t&=\mu S_tdt+\sigma S_t(dW_t^\mathbb{Q}-\theta_tdt)\\&=\mu S_tdt+\sigma S_tdW_t^\mathbb{Q}-S_t(\mu-r)dt\\&=r S_tdt+\sigma S_tdW_t^\mathbb{Q}\end{align}</script><h1 id="Section-2：Girsanov’s-Theorem"><a href="#Section-2：Girsanov’s-Theorem" class="headerlink" title="Section 2：Girsanov’s Theorem"></a>Section 2：Girsanov’s Theorem</h1><h3 id="1-Conditional-Expection"><a href="#1-Conditional-Expection" class="headerlink" title="1. Conditional Expection"></a>1. Conditional Expection</h3><p>$\mathscr{G}$ is a sub-$\sigma$-algebra of $\mathcal{F}$. $X$ is a nonnegative &amp; integrable r.v. The conditiond expextation of $X$ given $\mathscr{G}$, denoted $\mathbb{E}[X|\mathscr{G}]$, is any r.v. that satisfies：</p><ul><li>$\mathbb{E}[X|\mathscr{G}]$ is $\mathscr{G}$-measurable</li><li>$\int_A \mathbb{E}[X|\mathscr{G}]d\mathbb{P}(\omega)=\int_AX(\omega)d\mathbb{P}(\omega), for \forall A\in\mathscr{G}$ : Partical Averaging</li></ul><h4 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h4><ol><li><p><strong>Pull out property:</strong> If $X$ is a $\mathscr{G}$-measureable, then</p><script type="math/tex; mode=display">\mathbb{E}[XY|\mathscr{G}]=X\mathbb{E}[Y|\mathscr{G}]</script></li><li><p><strong>Tower property (or Iteration):</strong> If $\mathcal{H}$ is a sub-$\sigma$-algebra of $\mathscr{G}$</p><script type="math/tex; mode=display">\mathbb{E}[\mathbb{E}[X|\mathscr{G}]|\mathcal{H}]=\mathbb{E}[X|\mathcal{H}]</script></li></ol><h4 id="Radon-Nikodym-Derivative-Process"><a href="#Radon-Nikodym-Derivative-Process" class="headerlink" title="Radon-Nikodym Derivative Process"></a>Radon-Nikodym Derivative Process</h4><script type="math/tex; mode=display">Z(t)=\mathbb{E}[Z|\mathcal{F}(t)],\ 0\leq t\leq T</script><ol><li><p>$Z(t)$ is a martingale ($ 0\leq s\leq t\leq T$)</p><script type="math/tex; mode=display">\begin{align}\mathbb{E}[Z(t)|\mathcal{F}(s)]&=\mathbb{E}[Z(t)|\mathcal{F}(s)]\\&=\mathbb{E}[\mathbb{E}[Z|\mathcal{F}(t)]|\mathcal{F}(s)]\\&=\mathbb{E}[Z|\mathcal{F}(s)]\\&=Z(s)\end{align}</script></li><li><p>$Z(t)$ is Radon-Nikodym Derivative ($Y$ is $\mathcal{F}(t)$-measureable)</p><script type="math/tex; mode=display">\begin{align}\mathbb{E}^\mathbb{Q}[Y]&=\mathbb{E}^\mathbb{P}[YZ]\\&=\mathbb{E}^\mathbb{P}[\mathbb{E}^\mathbb{P}[YZ|\mathcal{F}(t)]]\\&=\mathbb{E}^\mathbb{P}[Y\mathbb{E}^\mathbb{P}[Z|\mathcal{F}(t)]]\\&=\mathbb{E}^\mathbb{P}[YZ(t)]\end{align}</script></li><li><p>$\mathbb{Q}^\mathbb{P}[Y|\mathcal{F}(s)]=\frac{1}{Z(s)}\mathbb{E}^\mathbb{P}[YZ(t)|\mathcal{F}(s)]$ (Right hand side is the conditiond expextation of $Y$)</p><ul><li>$\frac{1}{Z(s)}\mathbb{E}^\mathbb{P}[YZ(t)|\mathcal{F}(s)]$ is $\mathcal{F}(s)$-measureable</li><li>For any $A \in \mathcal{F}(s)$, we have $\int_AY(\omega)d\mathbb{Q}(\omega)=\int_A \frac{1}{Z(s)}\mathbb{E}^\mathbb{P}[YZ(t)|\mathcal{F}(s)]d\mathbb{Q}(\omega)$</li></ul><script type="math/tex; mode=display">\begin{align}RHS&=\int_\Omega \mathbb{I}_A(\omega)\frac{1}{Z(s)}\mathbb{E}^\mathbb{P}[YZ(t)|\mathcal{F}(s)]d\mathbb{Q}(\omega)\\&=\mathbb{E}^\mathbb{Q}[\mathbb{I}_A(\omega)\frac{1}{Z(s)}\mathbb{E}^\mathbb{P}[YZ(t)|\mathcal{F}(s)]]\\&=\mathbb{E}^\mathbb{P}[\mathbb{I}_A(\omega)\mathbb{E}^\mathbb{P}[YZ(t)|\mathcal{F}(s)]]\\&=\mathbb{E}^\mathbb{P}[\mathbb{E}^\mathbb{P}[\mathbb{I}_A(\omega)YZ(t)|\mathcal{F}(s)]]\\&=\mathbb{E}^\mathbb{P}[\mathbb{I}_A(\omega)YZ(t)]\\&=\mathbb{E}^\mathbb{Q}[\mathbb{I}_A(\omega)Y]\\&=\int_\Omega\mathbb{I}_A(\omega)Yd\mathbb{Q}(\omega)\\&=\int_A Yd\mathbb{Q}(\omega)=LHS\end{align}</script></li><li><p>levy’s theorem：Let $M(t)$, $t\ge 0$, be a martingale, relative to$\mathcal{F}(t)$, $t\ge 0$. Assume $M(0)=0$, $M(T)$ has contiunous paths and quadratic variation = t ( 二次变差 ) for all $t\ge 0$. $\Rightarrow M(t)$ is a Brownian Motion.</p><ul><li><p>当 $\{t_i^n\}_{i=0}^n$ 遍取 $[0,t]$ 的分割，其模 $\delta_n=max_{0\leq i\leq n-1}\{t_{i+1}^n-t_i^n\}\to 0$时，依概率收敛意义下的极限</p><script type="math/tex; mode=display">[B,B](t)=[B,B]([0,t])=\lim_{\delta_n\to0}\sum_{i=0}^{n-1}|B(t_{i+1}^n)-B(t_i^n)|^2</script></li><li><p>BM 只有 $dW(t)dW(t)=dt$ 会在一单位时间内积累一单位二次变差. $dtdt=dtdW(t)=0$</p></li></ul></li></ol><h3 id="2-Girsanov"><a href="#2-Girsanov" class="headerlink" title="2. Girsanov"></a>2. Girsanov</h3><p>Let $W(t)$ be a BM on $(\Omega,\mathcal{F},\mathbb{P})$ and let $\mathcal{F}(t)$ be a filtration. For this BM, let $\Theta(t)$ be an adopted process. Define</p><script type="math/tex; mode=display">Z(t)=exp(-\int_0^t\Theta(u)dW(u)-\frac{1}{2}\int_0^t\Theta^2(u)dv)</script><script type="math/tex; mode=display">\tilde{W}(t)=W(t)+\int_0^t\Theta(u)du</script><p>or</p><script type="math/tex; mode=display">Z(t)=exp(\int_0^t\Theta(u)dW(u)-\frac{1}{2}\int_0^t\Theta^2(u)dv)</script><script type="math/tex; mode=display">\tilde{W}(t)=W(t)-\int_0^t\Theta(u)du</script><p>Set $Z=Z(T)$. Then $\mathbb{E}Z=1$, $Z\ge 0$</p><p>Where $\mathbb{Q}$ given by</p><script type="math/tex; mode=display">\mathbb{Q}=\int_AZ(\omega)d\mathbb{P}(\omega),\ for\ \forall A\in \mathcal{F}</script><p>The process $\tilde{W}(t)$ is a BM</p><h4 id="Prove"><a href="#Prove" class="headerlink" title="Prove"></a>Prove</h4><ol><li><p>$\mathbb{E}Z=1$</p><p>Set </p><script type="math/tex; mode=display">X(t)=-\int_0^t\Theta(u)dW(u)-\frac{1}{2}\int_0^t\Theta^2(u)dv</script><script type="math/tex; mode=display">\begin{align}dZ(t)&=0+e^{X(t)}dX(t)+\frac{1}{2}e^{X(t)}dX(t)dX(t)\\&=Z(t)(-\Theta(t)dW(t)-\frac{1}{2}\Theta^2(t)dt)+\frac{1}{2}Z(t)\Theta^2(t)dt\\&=-\Theta(t)Z(t)dW(t)\end{align}</script><p>$\Rightarrow Z(t)$ is a $\mathbb{P}$-martingale</p><script type="math/tex; mode=display">Z(t)=Z(0)-\int_0^t\Theta(u)Z(u)dW(u),\ Z(0)=exp(0)=1</script><script type="math/tex; mode=display">\mathbb{E}Z=\mathbb{E}[Z(T)]=\mathbb{E}[Z(T)|\mathcal{F}(0)]=Z(0)=1</script></li><li><p>$\tilde{W}(t)Z(t)$ is a martingale</p><script type="math/tex; mode=display">\begin{align}d(\tilde{W}(t)Z(t))&=Z(t)d\tilde{W}(t)+\tilde{W}(t)dZ(t)+dZ(t)d\tilde{W}(t)\\&=Z(t)[dW(t)+\Theta(t)dt]+\tilde{W}(t)[-\Theta(t)Z(t)dW(t)]...\\&\quad ...+[-\Theta(t)Z(t)dW(t)][dW(t)+\Theta(t)dt]\\&=Z(t)\Theta(t)dt+Z(t)dW(t)-\tilde{W}(t)\Theta(t)Z(t)dW(t)-\Theta(t)Z(t)dt\\&=Z(t)(1-\tilde{W}(t)\Theta(t))dW(t)\end{align}</script><p>$\Rightarrow \tilde{W}(t)Z(t)$ is a $\mathbb{P}$-martingale</p></li><li><p>$\tilde{W}(t)$ is a martingale $\mathbb{E}^\mathbb{Q}[\tilde{W}(t)|\mathcal{F(s)}]=\tilde{W}(s)$</p><script type="math/tex; mode=display">\begin{align}LHS&=\frac{1}{Z(s)}\mathbb{E}^\mathbb{P}[\tilde{W}Z(t)|\mathcal{F}(s)]\\&=\frac{1}{Z(s)}\tilde{W}(s)Z(s)=\tilde{W}(s)\end{align}</script><p>$\Rightarrow \tilde{W}(t)$ is a $\mathbb{Q}$-martingale</p></li><li><p>$\tilde{W}(0)=W(0)+\int_0^0\Theta(s)ds=0$</p></li><li><p>The both parts of $\tilde{W}(t)$ has contiunous paths.</p></li><li><p>$d\tilde{W}(t)=dW(t)+\Theta(t)dt$, where $dtdt=0$ accumulated zero quadratic variation. </p><script type="math/tex; mode=display">[\tilde{W},\tilde{W}](t)=[W,W](t)=t</script></li><li><p>$[3-6]\Rightarrow \tilde{W}(t)$ is a BM </p></li></ol><hr><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://space.bilibili.com/275959084/video?tid=0&amp;page=2&amp;keyword=&amp;order=pubdate">Jerry Xu B站主页</a></li><li><a href="https://space.bilibili.com/275959084/video?tid=0&amp;page=2&amp;keyword=&amp;order=pubdate">从Riemann积分到Lebesgue积分</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Probability Theory</tag>
      
      <tag>Rado-Nicodym</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【课程】Modelling and Forecasting Financial Markets</title>
    <link href="/2021/05/18/Modelling_and_Forecasting_Financial_Markets/"/>
    <url>/2021/05/18/Modelling_and_Forecasting_Financial_Markets/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于格拉斯哥ECON5022的笔记；</p></blockquote><span id="more"></span><h1 id="General-information"><a href="#General-information" class="headerlink" title="General information"></a>General information</h1><p>The course offers an introduction to modelling and forecasting financial time series. The first part of the course will be mainly devoted to analysing univariate models for the conditional mean and the conditional variance (<strong>ARMA and GARCH models</strong>). These models will be used to produce forecasts. Additional topics, e.g. <strong>multiple time series analysis and nonlinear models</strong> may be discussed, if time allows. In the second part of the course will discuss forecasts evaluation, aimed to <strong>monitor and improve forecast performances</strong>. The course will be complemented by practical session using statistical or econometric software.</p><h1 id="Aims"><a href="#Aims" class="headerlink" title="Aims"></a>Aims</h1><p>The main aims of the course are to introduce the basic models widely used to analyse and forecast <strong>financial time series</strong>, and to evaluate the forecast produced using these models.</p><h1 id="ILOs"><a href="#ILOs" class="headerlink" title="ILOs"></a>ILOs</h1><p>By the end of this course, students will be able to:</p><ol><li><strong>Select and fit</strong> the appropriate model to analyse financial time series.</li><li><strong>Derive the main properties</strong> of the models used to analyse and forecast financial time series.</li><li><strong>Produce optimal forecasts</strong> for a given information set and forecast horizon.</li><li><strong>Evaluate</strong> critically the forecasts.</li><li><strong>Model and predict</strong> financial time series using statistical/econometric software.</li><li><strong>Work collaboratively</strong> in a group to produce a combined output, by liaising with other class members, allocating tasks and co-ordinating.</li></ol><h1 id="Unit-1：Time-Series-and-Their-Features"><a href="#Unit-1：Time-Series-and-Their-Features" class="headerlink" title="Unit 1：Time Series and Their Features"></a>Unit 1：Time Series and Their Features</h1><p><strong>Reading</strong>：</p><ul><li>Brooks, Chapter 2, Section 2.7 (Essential)</li><li>Brooks, Chapter 6, Sections 6.1-6.2 (Essential)</li></ul><p>Students are supposed to be familiar with the topics covered in the sections below:</p><ul><li>Brooks, Chapter 1, Sections 1.5-1.6.</li><li>Brooks, Chapter 2, Section 2.1-2.5.</li></ul><p><strong>Activities</strong>：</p><ul><li>Brooks, Chapter 1, Self-Study Questions 6, 10, 23.</li><li>Brooks, Chapter 2, Self-Study Questions 1-6, 9.</li></ul><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition:"></a>Definition:</h3><p>Most financial studies involves returns, instead of prices, of assets</p><ul><li>Return of an asset is a scale-free summary of an investment opportunity.</li><li>Return series are easier to handle than prices because of the more attractive statistical properties.</li></ul><h4 id="Time-Series-Data"><a href="#Time-Series-Data" class="headerlink" title="Time Series Data"></a>Time Series Data</h4><ol><li>The term <strong>time series</strong> is used to mean both the data $\{x_t\}$ and the process $\{X_t\}$ of which it is a realization.</li><li>$\{x_t\}$ and $\{X_t\}$ are the shorthand notations for $\{x_t , t \in T_0\}$ and $\{X_t , t \in T_0\}$ when it is not necessary to specify $\mathbb{T}_0$ where $\mathbb{T}_0$ is a discrete set..</li></ol><p><strong>Mean function</strong></p><script type="math/tex; mode=display">\mu(t)\equiv\mathbb{E}X_t</script><p><strong>covariance function</strong></p><script type="math/tex; mode=display">\gamma(t,s)\equiv\mathbb{Cov}(X_t,X_s)=\mathbb{E}[(X_t-\mu(t))(X_s-\mu(s))]</script><p><strong>Strict Stationarity</strong>：</p><p>The process is said to be strictly stationary if thejoint distribution of $(X_{t_1}, X_{t_2}, . . .X_{t_n})’$ and $(X_{t_1+h}, X_{t_2+h}, . . .X_{t_n+h})’$ are the same for all the positive integers $n$ and for all $t_1, t_2, . . . , t_n$</p><p><strong>Weak Stationarity</strong>：</p><ol><li>$\mathbb{E}|X_t|^2&lt;\infty$,</li><li>$\mu(t)=\mu   \forall t \in \mathbb{Z}$</li><li>$\gamma(t+h,t)=\gamma(h)  \forall t\in\mathbb{Z},h\in\mathbb{N}$</li></ol><p><strong>Autocovariance function (ACVF)</strong></p><script type="math/tex; mode=display">\gamma(h)\equiv\mathbb{Cov}(X_{t+h},X_h)</script><p><strong>Autocorrelation function (ACF)</strong> </p><script type="math/tex; mode=display">\rho(h)\equiv\frac{\gamma(h)}{\gamma(0)}=\mathbb{Corr}(X_{t+h},X_h)=\frac{\mathbb{Cov}(X_{t+h},X_h)}{\sqrt{\mathbb{Var}(X_{t})}\sqrt{\mathbb{Var}(X_{t+h})}}</script><p>A weakly stationary time series $\{X_t\}$ is <strong>not serially autocorrelated</strong> if $\rho(h) = 0$ for all $h &gt; 0$.</p><p>For a given sample $\{x_t\}$</p><script type="math/tex; mode=display">\rho(h)=\frac{\sum_{t=h+1}^T(x_t-\bar{x})(x_{t-h}-\bar{x})}{\sum_{t=h+1}^T(x_t-\bar{x})^2}</script><p>If $\{X_t\}$ is a sequence of independent and identically distributed (iid) random variables satisfying $\mathbb{E}|X_t|^2&lt;\infty$</p><script type="math/tex; mode=display">\hat{\rho}(h)\sim N(0,1/T)</script><p>The interval $[-\frac{1.96}{\sqrt{T}},\frac{1.96}{\sqrt{T}}]$ is the 95% non-rejection region for the null $\rho(h) = 0$. We can use the confidence interval to test individual ACFs.</p><p><strong>Box and Pierce (1970)</strong> proposed the statistic</p><script type="math/tex; mode=display">Q^*(m)\equiv T\sum_{h=1}^m\hat{\rho}^2(h)</script><p>as a test static for $H_0 : \rho(1) = · · · = \rho(m) = 0$ versus $H_1 : \rho(h) \not= 0$ for some $k \in \{1, . . . , m\}$. The null is rejected if $Q^∗ (m)$ lies in the upper tail of $\chi^2 (m)$.</p><p><strong>Ljung and Box (1978)</strong> modified the statistic to improve the small sample properties of the test</p><script type="math/tex; mode=display">Q^*(m)\equiv T(T+2)\sum_{h=1}^m\frac{\hat{\rho}^2(h)}{T-h}\sim \chi^2 (m)</script><h3 id="Self-Study-Questions："><a href="#Self-Study-Questions：" class="headerlink" title="Self-Study Questions："></a>Self-Study Questions：</h3><p>【<strong>CHP 2：Q5</strong>】<strong>Which is a more useful measure of central tendency for stock returns − the arithmetic mean or the geometric mean? Explain your answer.</strong></p><script type="math/tex; mode=display">Arithmetic\ Mean:\frac1N\sum_{i=1}^N r_i</script><script type="math/tex; mode=display">Geometric\ Mean:\prod_{i=1}^N (1+r_i)^{1/N}-1</script><p>The geometric return is always <strong>less than</strong> or equal to the arithmetic return, and so the geometric return is a downward-biased predictor of future performance. </p><p>If the objective is to summarise <strong>historical performance</strong>, <strong>the geometric mean</strong> is more appropriate, but if we want to <strong>forecast future returns</strong>, <strong>the arithmetic mean</strong> is the one to use.</p><p>【<strong>CHP 2：Q10</strong>】<strong>Real Return (Simple Return -Inflation)</strong></p><h1 id="Unit-2：Linear-Models-for-Stationary-Time-Series"><a href="#Unit-2：Linear-Models-for-Stationary-Time-Series" class="headerlink" title="Unit 2：Linear Models for Stationary Time Series"></a>Unit 2：Linear Models for Stationary Time Series</h1><p><strong>Reading</strong>：</p><ul><li>Brooks, Chapter 6, Sections 6.1-6.8 (Essential)</li><li>Diebold, Chapter 6, Sections 6.1-6.6 (Recommended)</li><li>Diebold, Chapter 7, Sections 7.1-7.2 (Recommended)</li></ul><p><strong>Activities</strong>：</p><ul><li>Brooks, Chapter 6, Self-Study Questions 1-9</li></ul><h3 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition:"></a>Definition:</h3><h4 id="White-noise"><a href="#White-noise" class="headerlink" title="White noise"></a>White noise</h4><ul><li>mean 0 and variance $\sigma^2$, $\epsilon_t\sim WN(0,\sigma^2)$</li><li>$\gamma(h)=\begin{cases}\sigma^2&amp;if h= 0\ 0&amp;if h\ne 0 \end{cases}$</li><li>If iid $\to$ a <em>strong</em> white noise</li></ul><h4 id="Moving-Average-Models-MA"><a href="#Moving-Average-Models-MA" class="headerlink" title="Moving Average Models (MA)"></a>Moving Average Models (MA)</h4><ul><li><p>$X_t = \epsilon_t+\theta_1\epsilon_{t-1}+\theta_2\epsilon_{t-2}…, \epsilon_t\sim WN(0,\sigma^2)$</p></li><li><p>$\gamma(h)=\begin{cases}\sigma^2(\theta_h+\sum_{j=1}^{q-h}\theta_{h+j}\theta_j)&amp;0\leq h\leq q\\0&amp;h&gt;q\end{cases}$</p></li><li>MA(q) Test by ACF</li></ul><p><strong>MA(1)</strong></p><ul><li>$X_t=\mu+\epsilon_t+\theta\epsilon_{t-1}$</li><li>For $Y_{t-k}=X_{t-k}-\mu=\epsilon_{t-k}+\theta\epsilon_{t-k-1}$</li></ul><p>By backward substitution</p><script type="math/tex; mode=display">\begin{align}Y_t&=\theta\epsilon_{t-1}+\epsilon_{t}\\&=\theta(Y_{t-1}+\theta\epsilon_{t-2})+\epsilon_{t}\\&=...\\&=\sum_{j=1}^{k-1}\theta^jY_{t-j}+\epsilon_t+\theta^k\epsilon_{t-k}\end{align}</script><ul><li>If $k\to\infty and |\theta_1|&lt;1$,  $Y_t=\sum_{j=1}^\infty\theta^jY_{t-j}+\epsilon_t$</li></ul><h4 id="Autoregressive-Models-AR"><a href="#Autoregressive-Models-AR" class="headerlink" title="Autoregressive Models (AR)"></a>Autoregressive Models (AR)</h4><ul><li>$X_t = \phi_0+\phi_1X_{t-1}+\phi_2X_{t-2}…+\epsilon_t, \epsilon_t\sim WN(0,\sigma^2)$</li><li>AR(p) Test by PACF</li></ul><p><strong>AR(1)</strong></p><script type="math/tex; mode=display">\begin{align}X_t &= \phi_0+\phi_1X_{t-1}+\epsilon_t\\&=\phi_0+\phi_1(\phi_0+\phi_1X_{t-2}+\epsilon_{t-1})+\epsilon_t\\&=...\\&=\underbrace{\phi_0\sum_{j=0}^{k-1}\phi_1^j}+\phi_1^kX_{t-k}+\sum_{j=0}^{k-1}\phi_1^j\epsilon_{t-j}\\\phi_0&\frac{1-\phi_1^k}{1-\phi_1}=\mu(1-\phi_1^k)\end{align}</script><blockquote><p>Summation for geometric sequence：$S_n=a_1+…+a_n=a_1\frac{1-q^n}{1-q}$</p></blockquote><p>we obtain</p><script type="math/tex; mode=display">(X_t-\mu)=\phi_1^k(X_{t-k}-\mu)+\sum_{j=0}^{k-1}\phi_1^j\epsilon_{t-j},\ \mu\equiv\frac{\phi_0}{1-\phi_1}</script><ul><li>If $k\to\infty and |\phi_1|&lt;1$,  $X_t=\mu+\sum_{j=0}^\infty\phi_1^j\epsilon_{t-j}$</li></ul><script type="math/tex; mode=display">\mathbb{E}(X_t)=\mu=\frac{\phi_0}{1-\phi_1}</script><script type="math/tex; mode=display">\mathbb{Var}(X_t)=\sigma^2\sum_{j=0}^\infty\phi_1^{2j}=\frac{\sigma^2}{1-\phi_1^2}</script><script type="math/tex; mode=display">\begin{align}\mathbb{Cov}(X_t,X_{t-h})&=\mathbb{E}[(X_t-\mu)(X_{t-h}-\mu)]\\&=\mathbb{E}[(\sum_{k=0}^{h-1}\phi_1^k\epsilon_{t-k}+\sum_{k=h}^\infty\phi_1^k\epsilon_{t-k})(\sum_{j=0}^\infty\phi_1^j\epsilon_{t-h-j})]\\&=\mathbb{E}[\phi_1^h(\sum_{k=0}^\infty\phi_1^k\epsilon_{t-h-k})(\sum_{j=0}^\infty\phi_1^j\epsilon_{t-h-j})]\\&=\phi_1^h\sigma^2\sum_{j=0}^\infty\phi_1^{2j}=\phi_1^h\mathbb{Var}(X_t)\end{align}</script><script type="math/tex; mode=display">\mathbb{Corr}(X_t,X_{t-h})=\phi_1^h</script><h4 id="Yule-Walker"><a href="#Yule-Walker" class="headerlink" title="Yule-Walker"></a>Yule-Walker</h4><p>For AR(p) we have</p><script type="math/tex; mode=display">\begin{bmatrix}Y_t\\Y_{t+1}\\...\\Y_{t+n}\end{bmatrix}=\begin{bmatrix}Y_{t-1}&Y_{t-2}&...&Y_{t-p}\\Y_{t}&Y_{t-1}&...&Y_{t+1-p}\\...&...&...&...\\Y_{t+n-1}&Y_{t+n-2}&...&Y_{t+n-p}\end{bmatrix}\begin{bmatrix}\phi_1\\ \phi_2\\...\\ \phi_p\end{bmatrix}+\begin{bmatrix}\epsilon_t\\ \epsilon_{t+1}\\...\\ \epsilon_{t+n}\end{bmatrix}</script><p>Times $Y_{t-1}$ at both side and taking $\mathbb{E}$, with $\mathbb{E}(Y_t)=0$</p><script type="math/tex; mode=display">\mathbb{E}(Y_tY_{t-1})=\gamma(1)=\sum_{j=1}^p\gamma_{j-1}\phi_j</script><p><strong>Linear projection</strong> of $X$ onto $\{1, z_1, . . . , z_n\}$</p><script type="math/tex; mode=display">\mathscr{P}[X|1, z_1,..., z_n]=\sum_{j=0}^na_jz_j,\ z_0=1</script><p>where $a_0, . . . , a_n$ satisfy</p><script type="math/tex; mode=display">\mathbb{E}[(X-\sum_{j=0}^na_jz_j)z_j]=0,\ i=0,1,...,n</script><blockquote><p>同等于OLS中$\sum_{i=1}^n\hat{u}_ix_i=0$, 此处是$z_j$对$X$的回归</p></blockquote><p><strong>Partial Autocorrelation Function (PACF)</strong></p><ul><li>$\alpha(0)\equiv 1$</li><li>$\alpha(1)\equiv\rho(1)=\mathbb{Corr}(X_2,X_1)$</li><li>$\alpha(2)=\mathbb{Corr}(e_2,e_1)=\frac{\rho(2)-\rho^2(1)}{1-\rho^2(1)}$</li><li>$\alpha(h)\equiv\mathbb{Corr}(e_{h+1},e_1), h&gt;1$<ul><li>$e_{h+1}=X_{h+1}-\mathscr{P}[X_{h+1}|1, X_2,…, X_h]$</li><li>$e_{1}=X_{1}-\mathscr{P}[X_1|1, X_2,…, X_h]$</li></ul></li><li>$\alpha(h)=\phi_{hh}$<ul><li>$\mathscr{P}[X_{h+1}|1, X_1,…, X_h]=\phi_{h0}+\phi_{h1}X_h+…+\phi_{hh}X_1$</li><li>$\alpha=\Gamma_p^{-1}\gamma(p)$</li></ul></li></ul><script type="math/tex; mode=display">\begin{bmatrix}\alpha(1)\\ \alpha(2)\\...\\ \alpha(p)\end{bmatrix}=\begin{bmatrix}\gamma(0)&\gamma(1)&...&\gamma(p-1)\\\gamma(1)&\gamma(2)&...&\gamma(p-2)\\...&...&...&...\\\gamma(p-1)&\gamma(p-2)&...&\gamma(0)\end{bmatrix}^{-1}\begin{bmatrix}\gamma(1)\\ \gamma(2)\\...\\ \gamma(p)\end{bmatrix}</script><p><strong>If ACF and PACF are both declining geometrically $\to$ ARMA(1,1)</strong></p><p><strong>Box and Jenkins (1976) suggest the following approach:</strong></p><ul><li>Identification</li><li>Estimation</li><li>Diagnostic Checking</li></ul><h4 id="Information-criteria"><a href="#Information-criteria" class="headerlink" title="Information criteria"></a>Information criteria</h4><p>The residuals satisfy the equation ARMA(p,q)</p><script type="math/tex; mode=display">e_t=X_t-\hat{\phi}_0-\hat{\phi}_1X_{t-1}-...-\hat{\phi}_pX_{t-p}-\hat{\theta}_1e_{t-1}-...-\hat{\theta}_qe_{t-q}</script><p>Let $k=p+q+1$.  The information criteria are often written as</p><ul><li>AIC = $ln(\hat{\sigma}^2)+2\frac{k}{T}$</li><li>SBIC =  $ln(\hat{\sigma}^2)+\frac{k}{T}ln(T)$​</li><li>HQIC = $ln(\hat{\sigma}^2)+\frac{2k}{T}ln(ln(T))$​​</li></ul><p>where $\hat{\sigma}^2=T^{-1}\sum_{t=1}^Te_t^2$</p><p>Select p,q to minimize the information criteria.</p><p><strong>lag operator</strong> $L$</p><ul><li><p>$L^kX_t=X_{t-k}$</p></li><li><p>The AR(p) process can be rewritten as</p><ul><li>$\Phi(L)X_t=\phi_0+\epsilon, \Phi(L)=1-\phi_1L-\phi_2L^2-…-\phi_pL^p$</li></ul></li><li>The solutions of the equation $\Phi(z)=0$ are called the roots of the polynomial.</li></ul><h4 id="Stationarity-of-an-AR-p-process"><a href="#Stationarity-of-an-AR-p-process" class="headerlink" title="Stationarity of an AR(p) process"></a><strong>Stationarity of an AR(p) process</strong></h4><p>If $\Phi(z)\ne 0$ for $|Z|\leq 1$, then $\{X_t\}$  is stationary and causal, and the following <strong>causal</strong> representation</p><script type="math/tex; mode=display">X_t=\mu+\sum_{j=0}^\infty\psi_j\epsilon_{t-j},\ \psi_0=1</script><p>where</p><ul><li>$\mu = \frac{\phi_0}{\Phi(1)}$</li><li>$\Psi(z)=1+\psi_1z+\psi_2z^2+…=\Phi^{-1}(z)=1/\Phi(z)$</li><li>For AR(1), $\psi_j=\phi^j$ by Taylor Expansion</li><li>For AR(2), $\psi_0=1,\psi_1=\phi_1,\psi_j=\phi_1\psi_{j-1}+\phi_2\psi_{j-2}$</li></ul><p><strong>Stationarity only need $|Z|\ne 1$, So we can find the stationary solution of AR(1) with $|\phi|&gt;1$</strong></p><script type="math/tex; mode=display">Y_t=\phi Y_{t-1}+\epsilon_t</script><p>Equation can be rewritten as</p><script type="math/tex; mode=display">\begin{align}(1-\phi L)Y_t&=\epsilon_t\\-(\phi L)^{-1}(1-\phi L)Y_t&=-(\phi L)^{-1}\epsilon_t\\(1-\phi^{-1} L^{-1})Y_t&=-(\phi L)^{-1}\epsilon_t\end{align}</script><p>we get</p><script type="math/tex; mode=display">\begin{align}Y_t&=-(1-\phi^{-1} L^{-1})^{-1}(\phi L)^{-1}\epsilon_t\\&=-[\sum_{j=0}^\infty\phi^{-j} L^{-j}](\phi L)^{-1}\epsilon_t\\&=-[\sum_{j=1}^\infty\phi^{-j} L^{-j}]\epsilon_t\\&=-\sum_{j=1}^\infty\phi^{-j}\epsilon_{t+j}\end{align}</script><h4 id="ARMA-models"><a href="#ARMA-models" class="headerlink" title="ARMA models"></a>ARMA models</h4><p><strong>Autocorrelation Function</strong></p><script type="math/tex; mode=display">\rho(h)=\begin{cases}\frac{(1-\phi_1\theta_1)(\phi_1-\theta_1)}{1+\theta_1^2-2\phi_1\theta_1}&h=1\\\rho_1\phi_1^{k-1}&h>1\end{cases}</script><p><strong>Causal Processes</strong></p><script type="math/tex; mode=display">Y_t=\sum_{j=0}^\infty\psi_j\epsilon_{t-j},\ \psi_0=1,\ \sum_{j=0}^\infty|\psi_j|<\infty</script><p><strong>Invertible Processes</strong></p><script type="math/tex; mode=display">\epsilon_t=\sum_{j=0}^\infty\pi_jY_{t-j},\ \pi_0=1,\ \sum_{j=0}^\infty|\pi_j|<\infty</script><p>We have</p><script type="math/tex; mode=display">\Phi(L)Y_t=\Theta(L)\epsilon_t</script><p>where</p><script type="math/tex; mode=display">\begin{align}\Phi(z)&=1-\phi_1z-\phi_2z^2-...-\phi_pz^p\\\Theta(z)&=1+\theta_1z+\theta_2z^2+...+\theta_qz^q\end{align}</script><ol><li><p>$\{Y_t\}$ is stationary and causal if and only if</p><p>$\Phi(z)\ne 0 for all |z|\leq1$</p><p>and the coefficients are determined by the relationship</p><p>$\Psi(z)=\sum_{j=0}^\infty\psi_jz^j=\frac{\Theta(z)}{\Phi(z)}$</p></li><li><p>$\{Y_t\}$ is invertible if and only if</p><p>$\Theta(z)\ne 0 for all |z|\leq1$</p><p>and the coefficients are determined by the relationship</p><p>$\Pi(z)=\sum_{j=0}^\infty\pi_jz^j=\frac{\Phi(z)}{\Theta(z)}$</p></li><li><p>The ARMA(p,q) models is often preferred for parsimony reasons:</p><p>$\frac{\Theta(z)}{\Phi(z)}=1+\sum_{j=1}^\infty\psi_j^{(p,q)}z^j$</p></li></ol><blockquote><p>$z=\frac{-b\pm\sqrt{b^2-4ac}}{2a}$</p></blockquote><p><strong>On the representation of ARMA processes</strong></p><p>We have $\Psi(z)=\frac{\Theta(z)}{\Phi(z)}$</p><p>Rewrite as $\Psi(z)\Phi(z)=\Theta(z)$ with $\phi_0=\theta_0=1$, i.e.</p><script type="math/tex; mode=display">\sum_{j=0}^\infty\psi_jz^j(1-\sum_{i=1}^p\phi_iz^i)=1+\sum_{k=1}^q\theta_kz^k</script><p>Evaluating at $z=0$, we find $\psi_0=1$</p><p>Taking first derivative</p><script type="math/tex; mode=display">\begin{align}&\sum_{j=1}^\infty j\psi_jz^{j-1}-\sum_{i=1}^pi\phi_iz^{i-1}\sum_{j=0}^\infty\psi_jz^j\\&-\sum_{i=1}^p\phi_iz^i\sum_{j=1}^\infty j\psi_jz^{j-1}=\sum_{k=1}^qk\theta_kz^{k-1}\end{align}</script><p>Evaluating at $z=0$, we find $\psi_1-\phi_1\psi_0=\theta_1$, so $\psi_1=\phi_1+\theta_1$</p><p>Taking first derivative again</p><script type="math/tex; mode=display">\begin{align}&\sum_{j=2}^\infty j(j-1)\psi_jz^{j-2}-\sum_{i=2}^pi(i-1)\phi_iz^{i-2}\sum_{j=0}^\infty\psi_jz^j\\&-2\sum_{i=1}^pi\phi_iz^{i-1}\sum_{j=1}^\infty j\psi_jz^{j-1}-\sum_{i=1}^p\phi_iz^i\sum_{j=2}^\infty j(j-1)\psi_jz^{j-2}\\&=\sum_{k=2}^qk(k-1)\theta_kz^{k-2}\end{align}</script><p>Evaluating at $z=0$, we find $2\psi_2-2\phi_2-2\phi_1\psi_1=2\theta_2$, so $\psi_2=\theta_2+\phi_2+\phi_1^2+\phi_1\theta_1$</p><p>Repeating the step above, we can find</p><script type="math/tex; mode=display">\psi_j=\theta_j+\sum_{0< k\leq j}\phi_k\psi_{j-k},\ 0\leq j< max(p,q+1)</script><script type="math/tex; mode=display">\psi_j=\sum_{0< k\leq p}\phi_k\psi_{j-k},\ j\ge max(p,q+1)</script><h3 id="Lab："><a href="#Lab：" class="headerlink" title="Lab："></a>Lab：</h3><p>ACF/PACF Confident interval $\pm 1.96/\sqrt{T}$</p><p>Persistent : How long the shock will die out. ( long when $\theta \to 1$)</p><h3 id="Self-Study-Questions：-1"><a href="#Self-Study-Questions：-1" class="headerlink" title="Self-Study Questions："></a>Self-Study Questions：</h3><p>【<strong>CHP 6：Q8</strong>】<strong>Comment on ‘Given that the objective of any econometric modelling exercise is to find the model that most closely ‘fits’ the data, then adding more lags to an ARMA model will almost invariably lead to a better fit. Therefore a large model is best because it will fit the data more closely.’</strong></p><p>In most financial series, there is a substantial amount of <strong>‘noise’</strong>. This can be interpreted as a number of random events that are unlikely to be repeated in any forecastable way. We want to fit a model to the data which will be able to <strong>‘generalise’</strong>. In other words, we want a model which fits to features of the data which will be replicated in future; we do not want to fit to sample-specific noise.</p><p>This is why we need the concept of <strong>‘parsimony’</strong> – fitting the smallest possible model to the data. Otherwise we may get a great fit to the data in the sample, but any use of the model for forecasts could yield terrible results. </p><p>Another important point is that the larger the number of estimated parameters (i.e., the more variables we have), then the smaller will be the number of <strong>degrees of freedom</strong>, and this will imply that coefficient standard errors will be larger than they would otherwise have been. This could lead to a <strong>loss of power in hypothesis tests</strong>, and variables that would otherwise have been significant are now insignificant.</p><p>【<strong>CHP 6：Q9</strong>】<strong>You obtain the following sample autocorrelations and partial autocorrelations for a sample of 100 observations from actual data:</strong></p><div class="table-container"><table><thead><tr><th>Lag</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th></tr></thead><tbody><tr><td>acf</td><td>0.420</td><td>0.104</td><td>0.032</td><td>−0.206</td><td>−0.138</td><td>0.042</td></tr><tr><td>pacf</td><td>0.632</td><td>0.381</td><td>0.268</td><td>0.199</td><td>0.205</td><td>0.101</td></tr></tbody></table></div><p>MA(1), the significant lag 4 acf is a typical wrinkle that one might expect with real data and should probably be ignored.</p><p><strong>Use the Ljung–Box Q* test to determine whether the first three autocorrelation coefficients taken together are jointly  significantly different from zero.</strong> </p><script type="math/tex; mode=display">Q^*=100\times 102\times[\frac{0.420^2}{100-1}+\frac{0.104^2}{100-2}+\frac{0.032^2}{100-3}]</script><h1 id="Unit-3：Forecasting-with-ARMA-models"><a href="#Unit-3：Forecasting-with-ARMA-models" class="headerlink" title="Unit 3：Forecasting with ARMA models"></a>Unit 3：Forecasting with ARMA models</h1><p><strong>Reading</strong>：</p><ul><li>Brooks, Chapter 6, Sections 6.10.1 - 6.10.8 (Essential)</li><li>Diebold, Chapter 6, Sections 6.7, 6.8, 7.3-7.5 (Essential)</li></ul><p><strong>Activities</strong>：</p><ul><li>Brooks, Chapter 6, Self-Study Questions 10(a)-(b); 11(a)-(c); 12(a)-(e).</li></ul><h3 id="Definition-2"><a href="#Definition-2" class="headerlink" title="Definition:"></a>Definition:</h3><ul><li>h : forecast horizon</li><li>Univariate information set : $\Omega_T \equiv\{X_t,t\leq T\}$</li><li>The definition of the forecast horizon implies that we are dealing with out of sample forecasts</li></ul><h4 id="Forecast-types"><a href="#Forecast-types" class="headerlink" title="Forecast types"></a>Forecast types</h4><ol><li>Point Forecast: A single number.</li><li>Interval Forecast: A range of values in which we expect the realized value of the series to fall with a given probability. The length of the interval depends on the uncertainty surrounding the point forecast.</li><li>Density Forecast: The conditional probability distribution of the series at a give forecast horizon.</li></ol><h4 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h4><ul><li>$\{X_t\}^T_{t=1}$ : Series</li><li>Point forecast : $f_{T,h}=\mathbb{E}(X_{T+h}|\Omega_T)$ </li><li>Forecast error : $e_{T,h}\equiv X_{T+h}-f_{T,h}$</li><li>Mean Squared Error (MSE) : $\mathbb{E}[e_{T,h}]^2$</li><li>$\mathbb{E}[X_{T+h}-\mathbb{E}(X_{T+h}|\Omega_T )]\leq \mathbb{E}[e_{T,h}]^2$</li><li>Loss function : $l(e_{T,h})$</li></ul><p>We will consider $Y_t=X_t-\mu, \mathbb{E}(Y_t)=0$</p><h4 id="Forecasting-based-on-lagged-epsilon-’s"><a href="#Forecasting-based-on-lagged-epsilon-’s" class="headerlink" title="Forecasting based on lagged $\epsilon$’s"></a>Forecasting based on lagged $\epsilon$’s</h4><p>Consider a stationary process $\{Y_t\}$ with Wold representation</p><script type="math/tex; mode=display">Y_t=\sum_{j=0}^\infty\psi_j\epsilon_{t-j},\ \epsilon_t\sim WN(0,\sigma^2)</script><p>with $\psi_0=1$ and $\sum_{j=0}^\infty \psi_j^2&lt;\infty$</p><script type="math/tex; mode=display">Y_{T+h}=\sum_{j=0}^\infty\psi_j\epsilon_{T+h-j}</script><p>Recall that for $f_{T,h}=\mathscr{P}[Y_{T+h}|\epsilon_j,j\leq T]=\sum_{j=0}^\infty\beta_j\epsilon_{T-j}$</p><script type="math/tex; mode=display">\begin{bmatrix}\mathbb{E}[(Y_{T+h}-f_{T,h})\epsilon_{T}]\\ \mathbb{E}[(Y_{T+h}-f_{T,h})\epsilon_{T-1}]\\...\end{bmatrix}=\begin{bmatrix}\mathbb{E}[(\psi_h-\beta_0)\epsilon_{T}^2]\\ \mathbb{E}[(\psi_{h+1}-\beta_1)\epsilon_{T-1}^2]\\...\end{bmatrix}=\begin{bmatrix}0\\0\\...\end{bmatrix}</script><p>So $\psi_h=\beta_0,\psi_{h+1}=\beta_1,….$</p><p>The optimal linear forecast takes the form</p><script type="math/tex; mode=display">f_{T,h}=\mathscr{P}[Y_{T+h}|\epsilon_j,j\leq T]=\sum_{j=0}^\infty\psi_{j+h}\epsilon_{T-j}</script><p>The forecast error takes the form</p><script type="math/tex; mode=display">\begin{align}e_{T,h} &= Y_{T+h}-\mathscr{P}[Y_{T+h}|\epsilon_j,j\leq T]\\&=\epsilon_{T+h}+\psi_1\epsilon_{T+h-1}+...+\psi_{h-1}\epsilon_{T+1}\\&=\sum_{j=0}^{h-1}\psi_j\epsilon_{T+h-j}\end{align}</script><p>with $\mathbb{E}(e_{T,h})=0$ and $\mathbb{Cov}(e_{T,h},\epsilon_j)=0 for j\leq T$</p><p>We also note that $e_{T,h}\sim MA(h-1)$ process, and</p><script type="math/tex; mode=display">\mathbb{Var}(e_{T,h})=\sigma^2(1+\psi^2_1+\psi^2_2+...+\psi^2_{h-1})</script><p>that is, the MSE (risk) approaches to $\mathbb{Var}(Y_t)$ when $h \to \infty$</p><p>$Y_t$ can be rewritten as ,$Y_t=\Psi(L)\epsilon_t$ with</p><script type="math/tex; mode=display">\Psi(L)=\sum_{j=0}^\infty\psi_jL^j</script><p>Divide $\Psi(L)$ by $L^h$</p><script type="math/tex; mode=display">\frac{\Psi(L)}{L^h}=L^{-h}+\psi_1L^{1-h}+\psi_2L^{2-h}+...+\psi_{h-1}L^{-1}+\psi_h+\psi_{h+1}L+...</script><p>The annihilation operator $[·]_+$ replace the negative powers of L with a zero,</p><script type="math/tex; mode=display">[\frac{\Psi(L)}{L^h}]_+\equiv \psi_h+\psi_{h+1}L+\psi_{h+2}L^2+...</script><p>Then, optimal linear forecast can be rewritten as</p><script type="math/tex; mode=display">\mathscr{P}[Y_{T+h}|\epsilon_j,j\leq T]=\sum_{j=0}^\infty\psi_{j+h}\epsilon_{T-j}=[\frac{\Psi(L)}{L^h}]_+\epsilon_T</script><h4 id="Forecasting-based-on-lagged-Y-t-’s"><a href="#Forecasting-based-on-lagged-Y-t-’s" class="headerlink" title="Forecasting based on lagged $Y_t$’s"></a>Forecasting based on lagged $Y_t$’s</h4><p>If $Y_t$ admits the $AR(\infty)$ representation</p><script type="math/tex; mode=display">\alpha(L)Y_t=\epsilon_t,\ \alpha(L)=\Psi^{-1}(L)</script><p>we can obtain the forecast of $Y_{T+h}$ as a function of $\Omega_T$</p><script type="math/tex; mode=display">\mathscr{P}[Y_{T+h}|Y_j,j\leq T]=\mathscr{P}[Y_{T+h}|\Omega_T]=[\frac{\Psi(L)}{L^h}]_+\alpha(L)Y_T</script><p>known as <strong>Wiener-Kolmogorov prediction formula</strong>.</p><h4 id="Forecasting-an-AR-1-process"><a href="#Forecasting-an-AR-1-process" class="headerlink" title="Forecasting an AR(1) process"></a>Forecasting an AR(1) process</h4><script type="math/tex; mode=display">Y_t=\phi_1Y_{t-1}+\epsilon_t,\ |\phi_1|<1</script><p>1-step-ahead forecast :</p><script type="math/tex; mode=display">f_{T,1}=\mathscr{P}[Y_{T+1}|\Omega_T]=\phi_1Y_T</script><p>2-step-ahead forecast:</p><script type="math/tex; mode=display">f_{T,2}=\mathscr{P}[Y_{T+2}|\Omega_T]=\mathscr{P}[\phi_1Y_{T+1}+\epsilon_{T+2}|\Omega_T]=\phi_1\mathscr{P}[Y_{T+1}|\Omega_T]=\phi_1^2Y_T</script><p>h-step-ahead forecast:</p><script type="math/tex; mode=display">f_{T,h}=\mathscr{P}[Y_{T+h}|\Omega_T]=\phi_1^hY_T</script><p>We refer to this approach as the <strong>chain rule of forecasting</strong></p><p>Noting that</p><script type="math/tex; mode=display">\Psi(L)=(1-\phi_1L)^{-1}=1+\phi_1L+\phi_1^2L^2+...</script><p>we have</p><script type="math/tex; mode=display">[\frac{\Psi(L)}{L^h}]_+=\phi_1^h+\phi_1^{h+1}L+\phi_1^{h+2}L^2+...=\frac{\phi_1^{h}}{1-\phi_1L}</script><p>Hence, using the Wiener-Kolmogorov prediction formula</p><script type="math/tex; mode=display">\mathscr{P}[Y_{T+h}|\Omega_T]=[\frac{\Psi(L)}{L^h}]_+(1-\phi_1L)Y_T=\phi_1^hY_T</script><script type="math/tex; mode=display">e_{T,h} = Y_{T+h}-\mathscr{P}[Y_{T+h}|\Omega_T]=\sum_{j=0}^{h-1}\psi_j\epsilon_{T+h-j},\ with\ \psi_j=\phi^j</script><h4 id="Forecasting-an-AR-2-process"><a href="#Forecasting-an-AR-2-process" class="headerlink" title="Forecasting an AR(2) process"></a>Forecasting an AR(2) process</h4><script type="math/tex; mode=display">Y_T=\phi_1Y_{T-1}+\phi_2T_{T-2}+\epsilon_T</script><p>By backward substitution we get</p><script type="math/tex; mode=display">Y_{T+2}=\epsilon_{T+2}+\phi_1\epsilon_{T+1}+(\phi_1^2+\phi_2)Y_t+\phi_1\phi_2Y_{T-1}</script><p>The Wiener-Kolmogorov prediction formula gives</p><script type="math/tex; mode=display">\mathscr{P}[Y_{T+2}|\Omega_T]=(\phi_1^2+\phi_2)Y_t+\phi_1\phi_2Y_{T-1}</script><p>The same result can be obtained using the chain rule</p><script type="math/tex; mode=display">\begin{align}&\mathscr{P}[Y_{T+2}|\Omega_T]\\&=\phi_1\mathscr{P}[Y_{T+1}|\Omega_T]+\phi_2\mathscr{P}[Y_{T}|\Omega_T]+\mathscr{P}[\epsilon_{T+2}|\Omega_T]\\&=\phi_1(\phi_1Y_T+\phi_2Y_{T-1})+\phi_2Y_T+0\\&=(\phi_1^2+\phi_2)Y_t+\phi_1\phi_2Y_{T-1}\end{align}</script><h4 id="Forecasting-an-MA-1-process"><a href="#Forecasting-an-MA-1-process" class="headerlink" title="Forecasting an MA(1) process"></a>Forecasting an MA(1) process</h4><script type="math/tex; mode=display">Y_T=(1+\theta L)\epsilon_T</script><p>Note that</p><script type="math/tex; mode=display">[\frac{(1+\theta L)}{L^h}]_+=\begin{cases}\theta&if\ h=1\\ 0&if\ h>1\end{cases}</script><p>Hence,</p><script type="math/tex; mode=display">\mathscr{P}[Y_{T+1}|\epsilon_T]=\theta\epsilon_T,\ \mathscr{P}[Y_{T+1}|\Omega_T] = \frac{\theta}{1+\theta L}Y_T</script><p>and view $\theta\epsilon_T$ as the outcome of the infifinite recursion</p><script type="math/tex; mode=display">\begin{align}\epsilon_T&=Y_T-\theta\epsilon_{T-1}=Y_T-\theta Y_{T-1}+\theta^2\epsilon_{T-2}=...\\&=(\sum_{j=0}^{m-1}\theta^jY_{T-j}+\theta^m\epsilon_{T-m})\end{align}</script><h4 id="Interval-and-Density-forecasts"><a href="#Interval-and-Density-forecasts" class="headerlink" title="Interval and Density forecasts"></a>Interval and Density forecasts</h4><p>Let $\{Y_t\}$</p><script type="math/tex; mode=display">\Phi(L)Y_t=\Theta(L)\epsilon_t,\ \epsilon_t\sim N(0,\sigma^2)</script><p>be a stationary and invertible Gaussian ARMA process. Then,</p><script type="math/tex; mode=display">Y_t=\Psi(L)\epsilon_t \sim N(0,\sigma^2\sum_{j=0}^\infty\psi_j^2)</script><p>By construction,</p><script type="math/tex; mode=display">Y_{T+h}=f_{T,h}+e_{T,h},\ with\ e_{T,h}=\sum_{j=0}^{h-1}\psi_j\epsilon_{T+h-j}</script><p>The 95% h-step-ahead interval forecast is</p><script type="math/tex; mode=display">f_{T,h}\pm 1.96\sqrt{\mathbb{Var}(e_{T,h})}</script><p>The h-step-ahead density forecast is $N(f_{T,h},\mathbb{Var}(e_{T,h}))$</p><h4 id="Making-the-forecasts-operational"><a href="#Making-the-forecasts-operational" class="headerlink" title="Making the forecasts operational"></a>Making the forecasts operational</h4><ul><li>For forecasting an <strong>AR(p) process</strong>, an optimal <strong>h−step-ahead forecast</strong> based on $\Omega_T$ make uses only of the p most recent values $\{Y_T , Y_{T −1}, . . . , Y_{T −p+1}\}$.</li><li>For an <strong>MA or ARMA process</strong> we would need to know $\Omega_T$<br>to use the <strong>Wiener-Kolmogorov prediction formula</strong>.</li></ul><p><strong>In MA(1) Process, if we assume $\theta$ is not observable</strong></p><p>We replace the optimal linear forecast $f_{T,1}=\theta\epsilon_T$ with $\hat{f}_{T,1}=\hat\theta\epsilon_T$</p><p>The forecast error will take the form</p><script type="math/tex; mode=display">\hat{e}_{T,1}\equiv Y_{T+1}-\hat{f}_{T,1}=e_{T,1}+(\theta-\hat\theta)\epsilon_T</script><p>$\mathbb{Var}(\hat{e}_{T,1})$ will also account for the variability of $\hat\theta$</p><p><strong>MSE</strong></p><script type="math/tex; mode=display">\frac1{T-(T_1-1)}\sum_{t=T_1}^T(y_{t+s}-f_{t,s})^2</script><p><strong>MAE</strong></p><script type="math/tex; mode=display">\frac1{T-(T_1-1)}\sum_{t=T_1}^T|y_{t+s}-f_{t,s}|</script><h3 id="Lab"><a href="#Lab" class="headerlink" title="Lab :"></a>Lab :</h3><script type="math/tex; mode=display">(1+\phi L)(1-\phi L)=1-\phi^2L^2</script><script type="math/tex; mode=display">(1+\phi L)(1-\phi L + \phi^2 L^2) = 1-\phi^3L^3</script><script type="math/tex; mode=display">(1+\phi L)(1-\phi L + \phi^2 L^2 - \phi^3 L^3) = 1-\phi^4L^4</script><script type="math/tex; mode=display">(1+\phi L)^{-1}=\sum_{j=0}^\infty(-\phi)^jL^j</script><p>or</p><script type="math/tex; mode=display">[1+L+L^2+...+L^{t-1}](1-L)=1-L^t</script><h3 id="Self-Study-Questions：-2"><a href="#Self-Study-Questions：-2" class="headerlink" title="Self-Study Questions："></a>Self-Study Questions：</h3><p>【<strong>CHP 6：Q12.a</strong>】Macroeconomic explanatory variables 对比 financial data 的劣势是，它通常是 on a quarterly or at best monthly basis. 频率低.</p><p>【<strong>CHP 6：Q12.c</strong>】如果一个模型 Pacf 联合显著不为 0，但是 Pacf 中并没有明显的截断，且 Acf 中存在明显的截断，那么可能这个现实数据并不属于 ARMA family，但我们依旧要尝试寻找最优模型.</p><h1 id="Unit-4：ARIMA-models-for-nonstationary-time-series"><a href="#Unit-4：ARIMA-models-for-nonstationary-time-series" class="headerlink" title="Unit 4：ARIMA models for nonstationary time series"></a>Unit 4：ARIMA models for nonstationary time series</h1><p><strong>Reading</strong>：</p><ul><li>Brooks, Chapter 8, Sub-sections 8.1.1 - 8.1.4 (Essential)</li><li>Brooks, Chapter 8, Sub-sections 8.1.5-8.1.7, Section 8.2(Further)</li></ul><p><strong>Activities</strong>：</p><ul><li>Brooks, Chapter 8, Self-Study Questions 1-3.</li></ul><h3 id="Definition-3"><a href="#Definition-3" class="headerlink" title="Definition:"></a>Definition:</h3><p>To deal with such <strong>nonstationarity</strong> we begin characterizing a time series as</p><script type="math/tex; mode=display">X_t=\mu_t+U_t</script><ul><li>$U_t$：a zero-mean stationary process</li><li>$\mu_t=\sum_{j=0}^m\beta_jt^m$：such trend is said to be <strong>deterministic</strong>.</li></ul><p>The deterministic trend can either be estimated or be removed by transformation</p><p>If $m=1, U_t=\epsilon_t, X_t=\beta_0+\beta_1t+\epsilon_t$</p><script type="math/tex; mode=display">\Delta X_t=\beta_1+\Delta\epsilon_t,\ \Delta\equiv(1-L)</script><p>The MA process $\Delta\epsilon_t$ is stationary but not invertible</p><p><strong>Stochastic Trends</strong></p><ul><li><p>Increasing trends alternates to decreasing trends</p></li><li><p>A process which is not stationary in mean could be modelled as an ARMA where $\Phi(z)=0$ for $|z| \leq 1$.</p></li><li>These processes are characterized by stochastic trends. More later (<strong>Beveridge-Nelson Decomposition</strong>)</li></ul><h4 id="Random-Walk"><a href="#Random-Walk" class="headerlink" title="Random Walk"></a>Random Walk</h4><script type="math/tex; mode=display">X_t=X_{t-1}+\epsilon_t</script><p>The representation</p><script type="math/tex; mode=display">X_t=X_0+\sum_{j=1}^t\epsilon_j</script><ul><li>$X_0\in\mathbb{R}$ denotes the initial value</li></ul><p>The “memory” of the process is non-decreasing</p><script type="math/tex; mode=display">\mathbb{Cov}(X_t,X_{t+h})=\sigma^2t,\ \mathbb{Corr}(X_t,X_{t+h})=\frac{t}{\sqrt{t}\sqrt{t+h}}</script><ul><li>For $t$ large compared to $h$, $\mathbb{Corr}(X_t , X_t+h)\simeq 1$.</li></ul><p>The 1-step ahead forecast of model (1) is</p><script type="math/tex; mode=display">f_{T,1}=\mathbb{E}(X_T+\epsilon_{T+1}|X_T,...,X_0)=X_T</script><ul><li>Similarly, $f_{T,2}=X_T$</li></ul><p>The h−step ahead forecast error is</p><script type="math/tex; mode=display">e_{T,h}=X_{T+h}-f_{T,h}=\epsilon_{T+h}+\epsilon_{T+h-1}+...+\epsilon_{T+1}</script><ul><li>so that $\mathbb{Var}[e_{T,h}]=h\sigma^2$,  which diverges to $\infty$ when $h\to\infty$.</li></ul><h4 id="Random-Walk-with-Drift"><a href="#Random-Walk-with-Drift" class="headerlink" title="Random Walk with Drift"></a>Random Walk with Drift</h4><p>If $X_t$ denotes the log price of a stock, the random walk hypothesis entails that</p><script type="math/tex; mode=display">\Delta X_t=X_t-X_{t-1}=\epsilon_t,\ \Delta\equiv(1-L)</script><p>If $\Delta X_t=\mu+\epsilon_t$, then</p><script type="math/tex; mode=display">X_t=\mu t+X_0+\sum_{j=1}^t\epsilon_j</script><ul><li>$\{X_t\}$ is said to be <strong>random walk with drift</strong></li></ul><h4 id="Unit-root-processes"><a href="#Unit-root-processes" class="headerlink" title="Unit root processes"></a>Unit root processes</h4><p>The random walk can be represented as</p><script type="math/tex; mode=display">\Delta X_t=\epsilon_t</script><ul><li>Because $\Delta=(1-L)$, the root of the characteristic equation is one</li></ul><p>Consider the more general example</p><script type="math/tex; mode=display">X_t=0.75X_{t-1}+0.25X_{t-2}+\epsilon_t+0.4_{t-1}</script><p>The lag polynomial can be factorized as</p><script type="math/tex; mode=display">(1-0.75L-0.25L^2)=(1+0.25L)(1-L)</script><p>The process $\{\Delta X_t\}$ satisfying</p><script type="math/tex; mode=display">\Delta X_t=-0.25\Delta X_{t-1}+\epsilon_t+0.4_{t-1}</script><h4 id="Integrated-processes"><a href="#Integrated-processes" class="headerlink" title="Integrated processes"></a>Integrated processes</h4><p>A time series $\{X_t\}$is said to be integrated of order $d$, written $X_t\sim I(d)$, if $\Delta^dX_t$ is $I(0)$ </p><ul><li>$\{X_t\}\sim I(d)$ is sometimes said <strong>difference stationary</strong></li></ul><h4 id="Stochastic-processes-integrated-of-order-0"><a href="#Stochastic-processes-integrated-of-order-0" class="headerlink" title="Stochastic processes integrated of order 0"></a>Stochastic processes integrated of order 0</h4><p>A time series satisfying $X_t-\mathbb{E}(X_t)=\sum_{j=0}^\infty\psi_j\epsilon_{t-j}$ is said to be integrated of order zero, if</p><script type="math/tex; mode=display">\sum_{j=0}^\infty|\psi_j|z^j<\infty,\ for|z|\leq 1\ and\ \Psi(1)=\sum_{j=0}^\infty\psi_j\ne 0</script><p>Let $|\theta|&lt;1$</p><ul><li>If $X_t=X_{t-1}+\epsilon_t-\theta\epsilon_{t-1}$, then $\Delta X_t=(1-\theta L)\epsilon_t$ and</li></ul><script type="math/tex; mode=display">\Psi(Z)=(1-\theta z)\ne 0,\ for |z|\leq 1</script><p>Hence, $\Delta X_t$ is an $I(0)$ process</p><ul><li>If $X_t=\epsilon_t-\theta\epsilon_{t-1}$, then $\Delta X_t=(1-L)(1-\theta L)\epsilon_t$ and</li></ul><script type="math/tex; mode=display">\Psi(Z)=(1-z)(1-\theta z)= 0,\ for |z|\leq 1</script><p>Hence, $\Delta X_t$ is not an $I(0)$ process</p><h4 id="ARIMA-p-d-q-process"><a href="#ARIMA-p-d-q-process" class="headerlink" title="ARIMA(p,d,q) process"></a>ARIMA(p,d,q) process</h4><p>A time series $\{X_t\}$ is called an ARIMA process of order (p,d,q), written $\{X_t\}\sim ARIMA(b,d,q)$, if</p><script type="math/tex; mode=display">\Phi(L)(\Delta^dX_t-\mu)=\Theta(L)\epsilon_t</script><p>is a stationary and invertible ARMA(p,q) process.</p><h4 id="The-Beveridge-Nelson-Decomposition"><a href="#The-Beveridge-Nelson-Decomposition" class="headerlink" title="The Beveridge-Nelson Decomposition"></a>The Beveridge-Nelson Decomposition</h4><p>Let $X_T$ be an ARIMA(p,1,q) and $\Psi(L)\equiv\Phi^{-1}(L)\Theta(L)$. Then,</p><script type="math/tex; mode=display">X_t=\mu t+\Psi(1)\sum_{j=1}^t\epsilon_j+\Psi^*(L)\epsilon_t+k_0</script><p>where</p><ul><li>$\mu t$ is the deterministic (linear) trend</li><li>$\Psi(1)\sum_{j=1}^t\epsilon_j$ is the stochastic trend</li><li>$\Psi^\star(L)=\sum_{j=0}^\infty\psi_j^\star L^j$, $\psi_j^*=-\sum_{k=j+1}^\infty\psi_k$</li><li>$k_0$ denotes the initial condition</li></ul><script type="math/tex; mode=display">X_t=\mu t+\epsilon_t+(1+\psi_1)\epsilon_{t-1}+(1+\psi_1+\psi_2)\epsilon_{t-2}+....+k_0</script><script type="math/tex; mode=display">X_{t-1}=\mu(t-1)+\epsilon_{t-1}+(1+\psi_1)\epsilon_{t-2}+(1+\psi_1+\psi_2)\epsilon_{t-3}+....+k_0</script><script type="math/tex; mode=display">X_t-X_{t-1}=\mu+\epsilon_t+\psi_1\epsilon_{t-1}+\psi_2\epsilon_{t-2}+....</script><h4 id="Characteristics-of-I-0-processes"><a href="#Characteristics-of-I-0-processes" class="headerlink" title="Characteristics of I(0) processes"></a>Characteristics of I(0) processes</h4><ul><li>$\mathbb{Var}(X_t)$ is finite and does not depended on <em>t</em>.</li><li>The innovation $\epsilon_t$ has a temporary effect on $X_t$.</li><li>The expected length of time between crossing of $\mu$ is finite, so that $X_t$ fluctuates around its mean $\mu$.</li><li>The autocorrelation $\rho(h)$ decreases in magnitude for large enough $h$, so their sum is finite.</li></ul><h4 id="Characteristics-of-I-1-processes"><a href="#Characteristics-of-I-1-processes" class="headerlink" title="Characteristics of I(1) processes"></a>Characteristics of I(1) processes</h4><ul><li>$\mathbb{Var}(X_t)$ goes to infinite as $t$ goes to infinity.</li><li>The innovation $\epsilon_t$ has a permanent effect on $X_t$.</li><li>The process is not mean-reverting.</li><li>The autocorrelation $\rho(h)\to 1$ for all $h$ as $t\to\infty$.</li></ul><h4 id="Unit-roots-testing"><a href="#Unit-roots-testing" class="headerlink" title="Unit roots testing"></a>Unit roots testing</h4><p><strong>Dickey Fuller Test</strong></p><p>Main idea: test of $\phi=1$ in the regression model</p><script type="math/tex; mode=display">X_t=\phi X_{t-1}+\epsilon_t</script><p>against the one-sided alternative $\phi&lt;1$.</p><p>If we rewrite the regression model as</p><script type="math/tex; mode=display">\Delta X_t=\lambda X_{t-1}+\epsilon_t</script><p>and assume that $|\phi|\leq1$ ($|\phi|&gt;1$ ruled out),</p><script type="math/tex; mode=display">\lambda=0\ if\ \phi=1,\ -2<\lambda<0\ otherwise</script><p>We can test the familiar hypothesis</p><script type="math/tex; mode=display">H_0:\lambda=0\ vs\ H_1:\lambda<0</script><p>The standard t-test for statistically significance based on</p><script type="math/tex; mode=display">t_\lambda=\frac{\hat\lambda}{\sqrt{\hat{\mathbb{Var}}(\hat\lambda)}},\ \hat\lambda=\frac{\sum_{t=2}^n\Delta X_tX_{t-1}}{\sum_{t=1}^nX_t^2}</script><p><strong>The Augmented Dickey Fuller (ADF) Test</strong></p><p>The tests above are only valid if $\{\epsilon_t\}\sim WN(0,\sigma^2)$ An “overly parsimonious” specifification will result in autocorrelated errors.</p><p>If $Y_t$ satisfies $(1-\sum_{j=1}^p\phi_jL^p)X_t=\epsilon_t$, the following <strong>always</strong> holds:</p><script type="math/tex; mode=display">\Delta X_t=\lambda X_{t-1}+\sum_{j=1}^{p-1}\phi_j^*\Delta X_{t-j}+\epsilon_t</script><p>where $\lambda=1-\phi_1-…-\phi_p, \phi_j^*=-\sum_{i=j+1}^p\phi_i$</p><ul><li>P should large enough to ensure $\epsilon_t$ is White noise</li></ul><p><strong>Example</strong></p><p>If we have</p><script type="math/tex; mode=display">X_t=\phi_1X_{t-1}+\phi_2X_{t-2}+\phi_3X_{t-3}+\epsilon</script><p>This series is I(1) if $(1-\phi_1-\phi_2-\phi_3)=0$</p><p>We construct the function</p><script type="math/tex; mode=display">\begin{align}X_t-X_{t-1}&=(\phi_1-1)X_{t-1}+\phi_2X_{t-2}+\phi_3X_{t-3}+\epsilon_t\\&=(\phi_1+\phi_2-1)X_{t-1}+\phi_2(X_{t-2}-X_{t-1})+\phi_3X_{t-3}+\epsilon_t\\&=(\phi_1+\phi_2+\phi_3-1)X_{t-1}+\phi_2(X_{t-2}-X_{t-1})-\phi_3X_{t-1}+\phi_3X_{t-3}+\epsilon_t\\&=(\phi_1+\phi_2+\phi_3-1)X_{t-1}+\phi_2(X_{t-2}-X_{t-1})+\phi_3(X_{t-2}-X_{t-1})+\phi_3(X_{t-3}-X_{t-2})+\epsilon_t\\&=(\phi_1+\phi_2+\phi_3-1)X_{t-1}+(\phi_2+\phi_3)(X_{t-2}-X_{t-1})+\phi_3(X_{t-3}-X_{t-2})+\epsilon_t\end{align}</script><p><strong>Problems with Unit Root tests</strong></p><ul><li>Reject $I(1)$ null too often when is true, if $\Delta Y_t$ is an ARMA(p,q) with large and negative MA component.</li><li>Low power against $I(0)$ alternatives that are close to being $I(1)$ .</li><li>Fail to reject $I(1)$ when $Y_t$ is $I(0)$ around a trend function with a break.</li></ul><h3 id="Self-Study-Questions：-3"><a href="#Self-Study-Questions：-3" class="headerlink" title="Self-Study Questions："></a>Self-Study Questions：</h3><p>【<strong>CHP 8：Q1.b</strong>】<strong>Why is it in general important to test for non-stationarity in time series data before attempting to build an empirical model?</strong></p><p>If two series are non-stationary, we may experience the problem of <strong>‘spurious’ regression</strong>. This occurs when we regress one non-stationary variable on a completely unrelated non-stationary variable, but yield a reasonably high value of R2, apparently indicating that the model fits well.</p><p>Most importantly therefore, we are not able to perform any <strong>hypothesis tests</strong> in models which inappropriately use non-stationary data since the test statistics will no longer follow the distributions which we assumed they would (e.g.,  t or F), so any inferences we make are likely to be invalid.</p><h1 id="Unit-5：Conditional-Heteroskedasticity"><a href="#Unit-5：Conditional-Heteroskedasticity" class="headerlink" title="Unit 5：Conditional Heteroskedasticity"></a>Unit 5：Conditional Heteroskedasticity</h1><p><strong>Reading</strong>：</p><ul><li>Brooks, Chapter 9, Sections 9.1-9.8, 9.10-9.14 (Essential)</li><li>Diebold, Chapter 8 (Recommended)</li><li>Robert Engle (2001), <a href="http://www.cmat.edu.uy/~mordecki/hk/engle.pdf">GARCH 101: The Use of ARCH/GARCH Models in Applied Econometrics</a> (Further)</li></ul><p><strong>Activities</strong>：</p><ul><li>Brooks, Chapter 9, Self-Study Questions, Question 1 (except (f)), Question 3(a) and Question 5</li></ul><h3 id="Definition-4"><a href="#Definition-4" class="headerlink" title="Definition:"></a>Definition:</h3><blockquote><p>Jarque-Bera统计量，是用来检验一组样本是否能够认为来自正态总体的一种方法</p></blockquote><h4 id="Volatility-models"><a href="#Volatility-models" class="headerlink" title="Volatility models"></a>Volatility models</h4><script type="math/tex; mode=display">\mathbb{Var}(r_t|\Omega_{t-1})\equiv \sigma_t^2\ne const</script><p>Let $\mathbb{E}(r_t|\Omega_{t-1})\equiv \mu_t$ and define $\epsilon_t\equiv r_t-\mu_t$</p><script type="math/tex; mode=display">r_t=\mu_t+\epsilon_t,\ \epsilon_t=\sigma_t\eta_t</script><p>where $\sigma_t$ is deterministic function of $\Omega_{t-1}$, $\sigma_t&gt;0$, {$\eta_t$} <strong>is i.i.d.(0,1)</strong>, $\sigma_t\in\Omega_{t-1}, \eta_t\perp \Omega_{t-1}$</p><script type="math/tex; mode=display">\mathbb{E}(\epsilon_t|\Omega_{t-1})=\mathbb{E}(\sigma_t\eta_t|\Omega_{t-1})=\sigma_t\mathbb{E}(\eta_t|\Omega_{t-1})=\sigma_t\times 0</script><script type="math/tex; mode=display">\mathbb{Var}(\epsilon_t|\Omega_{t-1})=\mathbb{E}(\epsilon_t^2|\Omega_{t-1})=\mathbb{E}(\sigma_t^2\eta_t^2|\Omega_{t-1})=\sigma_t^2\mathbb{E}(\eta_t^2|\Omega_{t-1})=\sigma_t^2\times 1</script><p>So with $\eta_t\sim N(0,1)$, $\epsilon_t|\Omega_{t-1}\sim N(0,\sigma_t^2)$</p><blockquote><p>此时$\epsilon_t$随时间变换，$\sigma_s^2$越大，正态分布越扁</p></blockquote><p><strong>Thickness of the tails is measured by the kurtosis</strong></p><blockquote><p>峰度反映了峰部的尖度</p></blockquote><script type="math/tex; mode=display">\begin{align}\mathcal{K}_\epsilon &\equiv \frac{\mathbb{E}[\epsilon_t-\mathbb{E}(\epsilon_t)]^4}{[\mathbb{Var}(\epsilon_t)]^2}=\frac{\mathbb{E}[\mathbb{E}(\epsilon_t^4|\Omega_{t-1})]}{\mathbb{E}[\mathbb{E}(\epsilon_t^2|\Omega_{t-1})]^2}\\&=\frac{\mathbb{E}[\mathbb{E}(\sigma_t^4\eta_t^4|\Omega_{t-1})]}{\mathbb{E}[\mathbb{E}(\sigma_t^2\eta_t^2|\Omega_{t-1})]^2}=\frac{\mathbb{E}[\sigma_t^4\mathbb{E}(\eta_t^4|\Omega_{t-1})]}{\mathbb{E}[\sigma_t^2\mathbb{E}(\eta_t^2|\Omega_{t-1})]^2}\\&=\frac{\mathbb{E}[\sigma_t^4\mathbb{E}(\eta_t^4)]}{\mathbb{E}[\sigma_t^2\mathbb{E}(\eta_t^2)]^2}=\frac{\mathbb{E}[\sigma_t^4]}{\mathbb{E}[\sigma_t^2]^2}\mathcal{K}_\eta=(1+\frac{\mathbb{Var}(\sigma_t^2)}{\mathbb{E}[\sigma_t^2]^2})\mathcal{K}_\eta\end{align}</script><p>If $\sigma_t^2=\sigma^2$, then $\mathcal{K}_\epsilon=\mathcal{K}_\eta$</p><blockquote><p>正态分布峰度为3, 如果残差图峰度过高，就表示存在异方差</p></blockquote><p>Fat-tails can be modelled by a <strong>leptokurtic</strong>（尖峰厚尾） distribution of {$\eta_t$} and/or variability of {$\sigma_t^2$}</p><h4 id="The-ARCH-p-models"><a href="#The-ARCH-p-models" class="headerlink" title="The ARCH(p) models"></a>The ARCH(p) models</h4><script type="math/tex; mode=display">\sigma_t^2=\omega+\sum_{i=1}^p\alpha_i\epsilon_{t-i}^2,\ \omega>0,\ \alpha_i\ge0\ \forall i</script><ul><li>$\mathbb{E}(\epsilon_t|\Omega_{t-1})=\sigma_t\mathbb{E}(\eta_t|\Omega_{t-1})=0$, implying that, for $s\ne t$</li></ul><script type="math/tex; mode=display">\mathbb{E}(\epsilon_t)=0,\ \mathbb{Cov}(\epsilon_t,\epsilon_s)=\mathbb{E}(\epsilon_t\epsilon_s)=0</script><ul><li>$\epsilon_t,\epsilon_s$ are uncorrelated, but NOT independent!</li><li>$\mathbb{Var}(\epsilon_t|\Omega_{t-1})=\sigma_t^2\mathbb{E}(\eta_t^2|\Omega_{t-1})=\sigma_t^2$</li></ul><h4 id="Volatility-Clustering-波动聚类"><a href="#Volatility-Clustering-波动聚类" class="headerlink" title="Volatility Clustering (波动聚类)"></a>Volatility Clustering (波动聚类)</h4><ul><li>Large past squared shocks $\epsilon_{t-i}^2(i&gt;0)$imply a large conditional variance $\sigma_t^2$ for $\epsilon_t$</li><li>The magnitude of the noise is a function of its past value</li><li>$\mathbb{Var}(\sigma_t^2)\ne 0$, then implies that $\mathcal{K}_\epsilon&gt;\mathcal{K}_\eta$ (Excess Kurtosis)</li></ul><h4 id="ARCH-1"><a href="#ARCH-1" class="headerlink" title="ARCH(1)"></a>ARCH(1)</h4><script type="math/tex; mode=display">\sigma_t^2=\omega+\alpha\epsilon_{t-1}^2=\omega+(\alpha\eta_{t-1}^2)\sigma_{t-1}^2</script><script type="math/tex; mode=display">\epsilon_t^2=\omega+\alpha\epsilon_{t-1}^2+v_t,\ v_t=\epsilon_t^2-\sigma_t^2</script><p>With $\omega,\alpha&gt;0$</p><script type="math/tex; mode=display">\mathbb{E}(v_t|\Omega_{t-1})=\mathbb{E}[\sigma_t^2\mathbb{E}(\eta_t^2-1|\Omega_{t-1})]=0</script><blockquote><p>$v_t=\epsilon_t^2-\sigma_t^2=\sigma_t^2(\eta_t^2-1)$</p></blockquote><p>for $\alpha&lt;1$</p><script type="math/tex; mode=display">\mathbb{Var}(\epsilon_t)=\mathbb{E}(\epsilon_t^2)=\frac{\omega}{1-\alpha}+\mathbb{E}[\sum_{j=0}^\infty\alpha^jv_{t-j}]=\frac{\omega}{1-\alpha}</script><p>If $\alpha&lt;1$, then $\epsilon_t$ is weakly stationary.</p><script type="math/tex; mode=display">\mathbb{Var}(v_t)=\mathbb{E}[\sigma_t^4\mathbb{E}[(\eta_t^2-1)^2|\Omega_{t-1}]]</script><h4 id="The-GARCH-p-q-models"><a href="#The-GARCH-p-q-models" class="headerlink" title="The GARCH(p,q) models"></a>The GARCH(p,q) models</h4><script type="math/tex; mode=display">\sigma_t^2=\omega+\sum_{i=1}^p\alpha_i\epsilon_{t-i}^2+\sum_{j=1}^q\beta_j\sigma_{t-j}^2,\ \omega>0,\ \alpha_i\ge0,\ \beta_i\ge0\ \forall i</script><p>Let</p><script type="math/tex; mode=display">A(z)=\sum_{i=1}^p\alpha_iz^i,\ \ B(z)=1-\sum_{j=1}^q\beta_jz^j</script><p>Then</p><script type="math/tex; mode=display">B(L)\sigma_t^2=\omega+A(L)\epsilon_t^2</script><p>and</p><script type="math/tex; mode=display">\sigma_t^2=\phi_0+\sum_{i=1}^\infty\phi_i\epsilon_{t-i}^2,\ \phi_0=\frac{\omega}{B(1)},\ \sum_{i=1}^\infty\phi_iz^i=\frac{A(z)}{B(z)}</script><p><strong>ARMA representation of GARCH</strong></p><p>The original equation can be rewritten as</p><script type="math/tex; mode=display">\epsilon_t^2=\omega+\sum_{i=1}^{max(p,q)}(\alpha_i+\beta_i)\epsilon_{t-i}^2+v_t-\sum_{j=1}^q\beta_jv_{t-j}</script><ul><li>using the convention $\alpha_i=0 (\beta_i=0)$ if $i&gt;p(i&gt;q)$</li></ul><blockquote><p>把 $\sigma_t$ 的部分替换成了 $v_t$</p></blockquote><p>Bollerslev (1986), Theorem 1, shows that if</p><script type="math/tex; mode=display">\sum_{i=1}^p\alpha_i+\sum_{j=1}^q\beta_j<1</script><p>then $\epsilon_t$ is weakly stationary, and {$\epsilon_t^2$} $\sim$ ARMA(max(p,q),q)</p><p><strong>GARCH(1,1)</strong> </p><script type="math/tex; mode=display">\begin{align}\sigma_t^2&=\omega+\alpha\epsilon_{t-1}^2+\beta \sigma_{t-1}^2\\\epsilon_t^2&=\omega+\alpha\epsilon_{t-1}^2+\beta \sigma_{t-1}^2+v_t\\&=\omega+(\alpha+\beta)\epsilon_{t-1}^2-\beta(\epsilon_{t-1}^2-\sigma_{t-1}^2)+v_t\\&=\omega+(\alpha+\beta)\epsilon_{t-1}^2-\beta v_{t-1}^2+v_t\end{align}</script><script type="math/tex; mode=display">\mathbb{E}(\epsilon_t^2)=\frac{\omega}{1-\alpha-\beta}=\sigma^2</script><p>and the autocorrelation function of $\epsilon_t^2$ is</p><script type="math/tex; mode=display">\rho(h)=\begin{cases}\frac{\alpha(1-\beta(\alpha+\beta))}{1-(\alpha+\beta)^2+\alpha^2}=\alpha+\frac{\alpha^2\beta}{1-2\alpha\beta-\beta^2}&for\ h=1\\\rho(1)(\alpha+\beta)^{h-1}&for\ h>1\end{cases}</script><p>GARCH models are often estimated using the maximum likelihood estimator based on the Gaussian Likelihood (GMLE)</p><ul><li>If $\eta_t\sim NID(0,1)$, then $\epsilon_t|\Omega_{t-1}\sim N(0,\sigma_t^2)$</li></ul><p><strong>Specification strategy for GARCH models</strong></p><p>“Specific-to-general” approach</p><ol><li><p>Specify an adequate model for the $\mu_t=\mathbb{E}(r_t,\Omega_{t-1})$.</p></li><li><p>Test for the presence of conditional heteroskedasticity;</p></li><li><p>Select p,q and estimate GARCH models (use IC);</p></li><li><p>Evaluate the model by misspecifification tests, e.g. $\epsilon_t/\hat\sigma_t$should behave like a i.i.d. sequence.</p></li><li><p>Estimate a more suitable GARCH model (if necessary);</p></li></ol><h4 id="Extensions-of-the-GARCH-models"><a href="#Extensions-of-the-GARCH-models" class="headerlink" title="Extensions of the GARCH models"></a>Extensions of the GARCH models</h4><p>Drawbacks of GARCH(p,q) Models:</p><ul><li><p>Non-negativity constraints may be violated.</p></li><li><p>Symmetric response to past shocks.</p></li></ul><h4 id="The-leverage-effect"><a href="#The-leverage-effect" class="headerlink" title="The leverage effect"></a>The leverage effect</h4><blockquote><p>价格大幅度下降后往往会有同样幅度价格上升的倾向</p></blockquote><ul><li>Negative shocks appear to contribute more to stock market volatility than do positive shocks. (stylized fact )</li><li>A negative shock to the market value of equity increases the debt/equity ratio (other things the same), increasing leverage.</li><li>The asymmetric response of the volatility to past shocks is known as <strong>leverage effect</strong>.</li></ul><h4 id="The-EGARCH-Exponential-GARCH-Models"><a href="#The-EGARCH-Exponential-GARCH-Models" class="headerlink" title="The EGARCH (Exponential GARCH) Models"></a>The EGARCH (Exponential GARCH) Models</h4><script type="math/tex; mode=display">ln(\sigma_t^2)=\omega+\sum_{i=1}^p\alpha_ig(\eta_{t-i})+\sum_{j=1}^q\beta_jln\sigma_{t-j}^2</script><p>where</p><script type="math/tex; mode=display">g(\eta_{t-i})=\theta\eta_{t-i}+\zeta(|\eta_{t-i}|-\mathbb{E}|\eta_{t-i}|)</script><blockquote><p>$\mathbb E|\eta|=\sqrt{2/\pi}$</p></blockquote><ul><li>$\sigma_t^2$ will be positive (without imposing non-negativeness restrictions on the parameters)</li><li>The asymmetry property is taken into account through $\theta$.</li><li>The leverage effect will imply that $\theta&lt;0$.</li><li>Innovation of large modulus should increase the volatility, entailing that we expect</li></ul><script type="math/tex; mode=display">-\zeta<\theta<\zeta,\ \alpha_i\ge0,\ \beta_j\ge0</script><p><strong>An Example</strong></p><script type="math/tex; mode=display">ln\sigma_t^2=\omega+\theta\eta_{t-1}</script><ul><li><p>If $\eta_{t-1}&lt;0(i.e.\epsilon_{t-1}&lt;0)$, the variable $ln(\sigma_t^2)$ will be larger than its mean $\omega$.</p></li><li><p>If $\eta_{t-1}&gt;0(i.e.\epsilon_{t-1}&gt;0)$, the variable $ln(\sigma_t^2)$ will be smaller than its mean $\omega$.</p></li></ul><p>Thus, we obtain the typical asymmetry property of financial time series.</p><h4 id="The-Threshold-GARCH-TGARCH-model"><a href="#The-Threshold-GARCH-TGARCH-model" class="headerlink" title="The Threshold GARCH (TGARCH) model"></a>The Threshold GARCH (TGARCH) model</h4><script type="math/tex; mode=display">\sigma_t^2=\omega+\alpha\epsilon^2_{t-1}+\gamma\epsilon^2_{t-1}1_{\{\epsilon_{t-1<0}\}}+\beta\sigma^2_{t-1}</script><h4 id="The-GJR-GARCH-Glosten-Jaganathan-and-Runkle-models"><a href="#The-GJR-GARCH-Glosten-Jaganathan-and-Runkle-models" class="headerlink" title="The GJR-GARCH (Glosten, Jaganathan and Runkle) models"></a>The GJR-GARCH (Glosten, Jaganathan and Runkle) models</h4><script type="math/tex; mode=display">\sigma_t^2=\omega+\sum_{i=1}^p\alpha_i\epsilon_{t-i}^2+\sum_{i=1}^p\gamma_i\epsilon_{t-1}^21_{\epsilon_{t-1}<0}+\sum_{j=1}^q\beta_j\sigma_{t-j}^2</script><ul><li><p>The asymmetry is accounted for through the $\gamma_i$</p></li><li><p>$\omega&gt;0,(\alpha_i+\gamma_i)\ge0,\beta_j\ge0$  are sufficient for $\sigma_t^2&gt;0$</p></li></ul><h4 id="News-Impact-Curves-NIC"><a href="#News-Impact-Curves-NIC" class="headerlink" title="News Impact Curves (NIC)"></a>News Impact Curves (NIC)</h4><ul><li>The news impact curve plots $\sigma_t^2$ against $\epsilon_{t-1}$, setting $\sigma_{t-h}^2=\sigma^2$, for $h&gt;0$</li></ul><h4 id="Forecasting"><a href="#Forecasting" class="headerlink" title="Forecasting"></a>Forecasting</h4><p>Consider the AR(1)-GARCH(1,1) model</p><script type="math/tex; mode=display">X_t=\phi X_{t-1}+\epsilon_t</script><script type="math/tex; mode=display">\epsilon_t=\sigma_t\eta_t</script><script type="math/tex; mode=display">\sigma_t^2=\omega+\alpha\epsilon_{t-1}^2+\beta\sigma_{t-1}^2</script><p>with $\omega&gt;0,\alpha,\beta\ge0,\alpha+\beta&lt;1,|\phi|&lt;1$</p><p>Recall that $f_{T,h}=\phi^hX_T$</p><script type="math/tex; mode=display">e_{T+h}=\sum_{j=1}^h\phi^{h-j}\epsilon_{T+j}</script><p>and</p><script type="math/tex; mode=display">\begin{align}\mathbb{Var}(e_{T+h}|\Omega_T)&=\mathbb{E}[(\sum_{j=1}^h\phi^{h-j}\epsilon_{T+j})^2|\Omega_T]\\&=\sum_{j=1}^h\phi^{2(h-j)}\mathbb{E}[\epsilon_{T+j}^2|\Omega_T]\\&=\sum_{j=1}^h\phi^{2(h-j)}\mathbb{E}[\mathbb{E}(\epsilon_{T+j}^2|\Omega_{T+j-1})|\Omega_T]\\&=\sum_{j=1}^h\phi^{2(h-j)}\mathbb{E}[\sigma_{T+j}^2|\Omega_T]\end{align}</script><p>The 1-step-ahead forecast  of $\sigma_{T+1}^2$ </p><script type="math/tex; mode=display">\begin{align}f_{T,1}^{\sigma^2}&=\mathbb{E}[\sigma_{T+1}^2|\Omega_T]\\&=\mathbb{E}[\omega+\alpha\epsilon_T^2+\beta\sigma_T^2|\Omega_T]\\&=\omega+\alpha\epsilon_T^2+\beta\sigma_T^2\\&=\sigma_{T+1}^2\end{align}</script><ul><li><p>GARCH model are <strong>deterministic</strong> volatility models.</p></li><li><p>If the parameters are known, $\sigma_{T+1}^2$ is a deterministic function of $\Omega_T$ .</p></li></ul><p>The 2-step-ahead forecast</p><script type="math/tex; mode=display">\begin{align}f_{T,2}^{\sigma^2}&=\mathbb{E}[\sigma_{T+2}^2|\Omega_T]\\&=\mathbb{E}[\omega+\alpha\epsilon_{T+1}^2+\beta\sigma_{T+1}^2|\Omega_T]\\&=\omega+\alpha\mathbb{E}[\epsilon_{T+1}^2|\Omega_T]+\beta\sigma_{T+1}^2\\&=\omega+(\alpha+\beta)\sigma_{T+1}^2\end{align}</script><p>because</p><script type="math/tex; mode=display">\mathbb{E}[\epsilon_{T+1}^2|\Omega_T]=\mathbb{E}[\sigma_{T+1}^2\eta_{T+1}^2|\Omega_T]=\sigma_{T+1}^2\mathbb{E(\eta_{T+1}^2)}=\sigma_{T+1}^2</script><p>In general, the h-step-ahead forecast</p><script type="math/tex; mode=display">\begin{align}f_{T,h}^{\sigma^2}&=\mathbb{E}[\omega+\alpha\epsilon_{T+h-1}^2+\beta\sigma_{T+h-1}^2|\Omega_T]\\&=\omega+\alpha\mathbb{E}[\epsilon_{T+h-1}^2|\Omega_T]+\beta f_{T,h-1}^{\sigma^2}\\&=\omega+(\alpha+\beta)f_{T,h-1}^{\sigma^2}\end{align}</script><p>By recursive substitutions it follows that</p><script type="math/tex; mode=display">f_{T,h}^{\sigma^2}=\omega\sum_{j=0}^{h-2}(\alpha+\beta)^j+(\alpha+\beta)^{h-1}\sigma_{T+1}^2</script><ul><li>If $(\alpha+\beta)&lt;1$, $lim_{h\to\infty}f_{T,h}^{\sigma^2}=\sigma^2$, where</li></ul><script type="math/tex; mode=display">\sigma^2\equiv\lim_{h\to\infty}\omega\sum_{j=0}^{h-1}(\alpha+\beta)^j=\frac{\omega}{1-\alpha-\beta}</script><ul><li>If $(\alpha+\beta)=1$ (IGARCH)</li></ul><script type="math/tex; mode=display">f_{T,h}^{\sigma^2}=\omega(h-1)+\sigma_{t+1}^2</script><h4 id="Heteroskedasticity-and-interval-forecasts"><a href="#Heteroskedasticity-and-interval-forecasts" class="headerlink" title="Heteroskedasticity and interval forecasts"></a>Heteroskedasticity and interval forecasts</h4><p>The $100 \times (1 - \alpha)\%$ interval forecast for $X_{T+h}$ takes the form</p><script type="math/tex; mode=display">Pr(L_{T,h}\leq X_{T+h}\leq U_{T,h}|\Omega_T)=1-\alpha</script><p>It is usual to construct interval forecasts that are symmetric around the conditional mean of $X_{T+h}$</p><script type="math/tex; mode=display">f_{T,h}\pm z_{1-\alpha/2}\sqrt{\mathbb{Var}[e_{T,h}|\Omega_T]}</script><h3 id="Self-Study-Questions：-4"><a href="#Self-Study-Questions：-4" class="headerlink" title="Self-Study Questions："></a>Self-Study Questions：</h3><p>【<strong>CHP 9：Q1.d</strong>】<strong>Describe two extensions to the original GARCH model. What additional characteristics of financial data might they be able to capture?</strong></p><p>EGARCH, GJR or GARCH-M. The first two of these are designed to capture leverage effects. These are asymmetries in the response of volatility to positive or negative returns. The EGARCH model also has the added benefit that the model is expressed in terms of the log of ht, so that even if the parameters are negative, the conditional variance will always be positive. GARCH-M model allows the lagged value of the conditional variance to affect the return.</p><h1 id="Unit-6：Multivariate-Time-Series"><a href="#Unit-6：Multivariate-Time-Series" class="headerlink" title="Unit 6：Multivariate Time Series"></a>Unit 6：Multivariate Time Series</h1><p><strong>Reading</strong>：</p><ul><li>Brooks, Chapter 1, Section 1.7 (Essential - Week 6)</li><li>Brooks, Chapter 7, Sections 7.10 - 7.16 (Essential - Week 7)</li><li>Diebold, Chapter 16 (Recommended)</li></ul><p><strong>Activities</strong>：</p><ul><li>Brooks, Chapter 1, Self-Study Questions 21, 22.</li></ul><h3 id="Definition-5"><a href="#Definition-5" class="headerlink" title="Definition:"></a>Definition:</h3><p>We consider n possibly related time series $X_{1t}. . . , X_{nt}$, and<br>define the $n$−vector</p><script type="math/tex; mode=display">X_t\equiv[X_{1t},. . . , X_{nt}]'=\begin{bmatrix}X_{1t}\\. . . \\X_{nt}\end{bmatrix}</script><h4 id="Weak-Stationarity"><a href="#Weak-Stationarity" class="headerlink" title="Weak Stationarity"></a>Weak Stationarity</h4><ul><li>$\mathbb E(X_t)\equiv \mu &lt; \infty$ for all $t$</li><li>$\mathbb E(X_t-\mu)(X_t-\mu)’\equiv\Gamma(0)&lt;\infty$ for all $t$</li><li>$\mathbb E(X_t-\mu)(X_{t-h}-\mu)’\equiv\Gamma(h)$ for all $t$</li></ul><p><strong>The expectation of a vector</strong></p><script type="math/tex; mode=display">\mu = \mathbb E(X_t)=\begin{bmatrix}\mathbb E(X_{1t})\\. . . \\\mathbb E(X_{nt})\end{bmatrix}=\begin{bmatrix}\mathbb \mu_1\\. . . \\\mu_n\end{bmatrix}</script><p><strong>The variance-Covariance matrix</strong></p><p>When $h=0$</p><script type="math/tex; mode=display">\gamma_{ij}(0)=\mathbb E(X_{it}-\mu_i)(X_{jt}-\mu_j)=\mathbb{Cov}(X_{it},X_{jt})</script><script type="math/tex; mode=display">\Gamma(0)=\begin{bmatrix}\mathbb{Var}(X_{1t})&\mathbb{Cov}(X_{1t},X_{2t})&...&\mathbb{Cov}(X_{1t},X_{nt})\\\mathbb{Cov}(X_{2t},X_{1t})&\mathbb{Var}(X_{2t})&...&\mathbb{Cov}(X_{2t},X_{nt})\\...&...&...&...&\\\mathbb{Cov}(X_{nt},X_{1t})&\mathbb{Cov}(X_{nt},X_{2t})&...&\mathbb{Var}(X_{nt})\end{bmatrix}</script><p>When $h\ne0$</p><script type="math/tex; mode=display">\gamma_{ij}(h)=\mathbb E(X_{it}-\mu_i)(X_{j,t-h}-\mu_j)=\mathbb{Cov}(X_{it},X_{j,t-h})</script><script type="math/tex; mode=display">\gamma_{ji}(-h)=\mathbb E(X_{jt}-\mu_j)(X_{i,t+h}-\mu_i)=\mathbb{Cov}(X_{jt},X_{i,t-h})</script><script type="math/tex; mode=display">\Gamma(h)=\Gamma'(-h)</script><script type="math/tex; mode=display">\Gamma(0)=\begin{bmatrix}\mathbb{Cov}(X_{1t},X_{1,t-h})&\mathbb{Cov}(X_{1t},X_{2,t-h})&...&\mathbb{Cov}(X_{1t},X_{n,t-h})\\\mathbb{Cov}(X_{2t},X_{1,t-h})&\mathbb{Cov}(X_{2t},X_{2,t-h})&...&\mathbb{Cov}(X_{2t},X_{n,t-h})\\...&...&...&...&\\\mathbb{Cov}(X_{nt},X_{1,t-h})&\mathbb{Cov}(X_{nt},X_{2,t-h})&...&\mathbb{Cov}(X_{nt},X_{n,t-h})\end{bmatrix}</script><p><strong>Diagonal matrix</strong></p><script type="math/tex; mode=display">D=\begin{bmatrix}sd(X_{1t})&0&...&0\\0&sd(X_{2t})&...&0\\...&...&...&...&\\0&0&...&sd(X_{nt})\end{bmatrix}</script><p><strong>Correlation Matrix</strong></p><script type="math/tex; mode=display">\rho(h)\equiv D^{-1}\Gamma(h)D^{-1},\ with\ \rho_{ij}(h)=\frac{\mathbb{Cov}(X_{it},X_{j,t-h})}{sd(X_{it})sd(X_{jt})}</script><h4 id="The-multivariate-white-noise"><a href="#The-multivariate-white-noise" class="headerlink" title="The multivariate white noise"></a>The multivariate white noise</h4><p>Let $\epsilon_t\equiv[\epsilon_{1t},…,\epsilon_{nt}]’$</p><ul><li>$\mathbb E(\epsilon_t)=0$</li><li>$\Gamma(h)=\mathbb E(\epsilon_t\epsilon_{t-h})=\begin{cases}\Sigma&amp;for h=0\\0&amp;for h\ne 0\end{cases}$</li></ul><p>For individual shocks</p><ul><li>$\mathbb E(\epsilon_{it})=0$</li><li>$\mathbb E(\epsilon_{it}^2)=\sigma_i^2$</li><li>$\mathbb E(\epsilon_{it}\epsilon_{i,t-h})=0$</li></ul><p>We do allow for <strong>contemporaneous correlation</strong></p><ul><li>$\mathbb E(\epsilon_{it}\epsilon_{jt})=\sigma_{ij}$</li><li>$\mathbb E(\epsilon_{it}\epsilon_{j,t-h})=0$</li></ul><h4 id="Vector-Autoregressive-Processes-VAR"><a href="#Vector-Autoregressive-Processes-VAR" class="headerlink" title="Vector Autoregressive Processes (VAR)"></a>Vector Autoregressive Processes (VAR)</h4><p>Let $Y_t\equiv X_t-\mu$. A VAR(p) process satisfifies the equation</p><script type="math/tex; mode=display">Y_t=\Phi_1 Y_{t-1}+...+\Phi_p Y_{t-p}+\epsilon_t</script><script type="math/tex; mode=display">\Phi(L)Y_t=\epsilon_t</script><script type="math/tex; mode=display">\Phi(L)=I_n-\Phi_1L-...-\Phi_pL^P</script><p>and $I_n$ denotes the n−dimensional identity matrix.</p><p>【<strong>Example</strong>】</p><p>For $n = 2, p = 2$</p><script type="math/tex; mode=display">\begin{align}y_{1t}&=\phi_{11}^{(1)}y_{1,t-1}+\phi_{12}^{(1)}y_{2,t-1}+\phi_{11}^{(2)}y_{1,t-2}+\phi_{12}^{(2)}y_{2,t-2}+\epsilon_{1t}\\y_{2t}&=\phi_{21}^{(1)}y_{1,t-1}+\phi_{22}^{(1)}y_{2,t-1}+\phi_{21}^{(2)}y_{1,t-2}+\phi_{22}^{(2)}y_{2,t-2}+\epsilon_{2t}\end{align}</script><p><strong>Stationarity of a VAR</strong></p><p>Consider the VAR(1) process</p><script type="math/tex; mode=display">Y_t=\Phi_1Y_{t-1}+\epsilon_t</script><p>By recursively substituting</p><script type="math/tex; mode=display">Y_t=\Phi_1^tY_0+\sum_{j=0}^{t-1}\Phi_1^j\epsilon_{t-j}</script><p>when $max_{j=1,…,n}|\lambda_j(\Phi_1)|&lt;1$, $\Phi_1^t\to 0$ as $t\to\infty$</p><script type="math/tex; mode=display">(I_n-\Phi_1L)Y_t=\epsilon_t</script><p>The previous condition can be restated as</p><script type="math/tex; mode=display">det[\Phi_1-\lambda I_n]=0\ for\ |\lambda|<1</script><p> is equivalent to</p><script type="math/tex; mode=display">det[\Phi(z)]=det[I_n-\Phi_1z]\ne 0\ for\ |z|>1</script><p>If the above conditions are satisfified</p><script type="math/tex; mode=display">Y_t=\sum_{j=0}^\infty\Phi_1^j\epsilon_{t-j}</script><p>A VAR(p) process <strong>is stationary if</strong></p><script type="math/tex; mode=display">det(I_n-\Phi_1z-...-\Phi_pz^p)\ne 0\ for\ |z|\leq1</script><p><strong>Remarks</strong></p><p>The VAR(p) processes belong to the class of VARMA(p,q) processes</p><script type="math/tex; mode=display">\Phi(L)Y_t=\Theta(L)\epsilon_t</script><p>where</p><script type="math/tex; mode=display">\Theta(L)\equiv I_n-\Theta_1L-...-\Theta_qL^q</script><p>VARMA(p,q) processes are difficult to estimate when $q &gt; 0$. VAR models are usually used in empirical applications.</p><h4 id="Applying-VAR-models"><a href="#Applying-VAR-models" class="headerlink" title="Applying VAR models"></a><strong>Applying VAR models</strong></h4><p>Supposed that the appropriate order p for the VAR model is found, that is, a VAR(p-1) is <strong>misspecified</strong> and VAR(p+1) <strong>contains too many redundant parameters</strong>, and the parameters are estimated.</p><p>The resultant empirical model can be used for various purposes.</p><ol><li>Out-of-sample forecasting.</li><li>Granger causality analysis.</li><li>Structural analysis (impulse response function and error variance decomposition).</li></ol><p><strong>Forecasting</strong></p><p>Consider the VAR(1) model. The h−step forecast at time T is given by</p><script type="math/tex; mode=display">f_{T,h}=\Phi_1^hY_T</script><p>The forecast error covariance matrix equals</p><script type="math/tex; mode=display">\mathbb E(e_{T,h}e_{T,h}')=\Sigma+\Phi_1\Sigma\Phi_1'+...+\Phi_1^{(h-1)}\Sigma\Phi_1^{(h-1)'}</script><p>【Example】</p><script type="math/tex; mode=display">Y_{T+2}=\phi_1Y_{T+1}+\epsilon_{T+2}=\phi_1^2Y_T+\epsilon_{T+2}+\phi\epsilon_{T+1}</script><script type="math/tex; mode=display">\begin{align}Var(e_{T,2})&=\mathbb E(e_{T,2}e_{T,2}')=\mathbb E(\epsilon_{T+2}+\phi\epsilon_{T+1})(\epsilon_{T+2}+\phi\epsilon_{T+1})'\\&=\mathbb E(\epsilon_{T+2}\epsilon_{T+2}')+\mathbb E(\phi\epsilon_{T+1}\phi'\epsilon_{T+1}')\\&=\Sigma+\Phi\Sigma\Phi'\end{align}</script><p><strong>Granger Causality</strong></p><p>An important statistical notion of causality that’s intimately related to forecasting is based on two key principles</p><ul><li><p>Cause should occur before effect.</p></li><li><p>A causal series should contain information useful for forecasting that in not available in other series.</p></li></ul><p>We can say that $X$ Granger-cause $Y$ , $“X \Rightarrow Y ”$ if</p><script type="math/tex; mode=display">\mathbb E(Y_t|Y_{t-1},X_{t-1},Y_{t-2},X_{t-2},...)\ne \mathbb E(Y_t|Y_{t-1},Y_{t-2},...)</script><p>It $Z_t=[X_t,Y_t]’$ can be represented as a bivariate VAR</p><script type="math/tex; mode=display">\begin{bmatrix}\phi_{11}(L)&\phi_{12}(L)\\\phi_{21}(L)&\phi_{22}(L)\end{bmatrix}\begin{bmatrix}Y_t\\X_t\end{bmatrix}=\begin{bmatrix}\epsilon_{1t}\\ \epsilon_{2t}\end{bmatrix}</script><p>then $X\not\Rightarrow Y$ if $\phi_{12}(L)\equiv 1+\sum_{j=1}^p\phi_{12,j}L^j=0$</p><p>The the equation for $Y_t$</p><script type="math/tex; mode=display">Y_t=\sum_{j=1}^p\phi_{11,j}Y_{t-j}+\sum_{j=1}^p\phi_{12,j}X_{t-j}+\epsilon_{1t}</script><p>then, the hypothesis $X\not\Rightarrow Y$ is equivalent to</p><script type="math/tex; mode=display">H_0:\phi_{12,1}=\phi_{12,2}=...=\phi_{12,p}</script><p>If the VAR is stationary an F−test can be used.</p><p><strong>Impulse Response Functions</strong>（脉冲响应函数）</p><p>To understand what are the dynamic effects of the error process $\epsilon_t$ on $Y_{t+h}$, one can calculate the so-called impulse-response function.</p><script type="math/tex; mode=display">Y_t=\Phi_1Y_{t-1}+\epsilon_t,\ \epsilon_t\sim WN(0,\Sigma)</script><p>with $\Sigma=diag[\sigma_1^2,…,\sigma_n^2]$</p><p>Suppose there is an interest in the effect of shocks corresponding to the first variable.</p><p>One can then calculate</p><script type="math/tex; mode=display">V_0\equiv e_1=[1,0,0,...,0]'</script><p>and</p><script type="math/tex; mode=display">V_k\equiv\Phi_1^ke_1,\ k=1,...,h</script><p>The n elements of the $V_k$ vector series, $k = 0, 1, 2, . . . , h$ are called the <strong>impulse-response functions</strong></p><p>The i-th impulse-response function is the trajectory $\{v_{ik},k=0,1,…,h\}$</p><p>If we consider a VAR(p) stationary process</p><script type="math/tex; mode=display">Y_t=\Phi(L)^{-1}\epsilon_t=\sum_{k=0}^\infty\Psi_k\epsilon_{t-k}</script><p>The impulse-response function is defined as</p><script type="math/tex; mode=display">v(i,j,k)\equiv\frac{\partial Y_{it}}{\partial\epsilon_{j,t-k}}=\psi_{ij}^{(k)},\ k=0,1,2,...,h</script><blockquote><p>k 时间上 j 对 i 的影响</p></blockquote><p>$v(i,j,k)$ represent the response of $Y_{it}$ to a unitary shock in $Y_{j,t-k}$ (produced by a unitary shock in $\epsilon_{j,t-k}$.)</p><p>$\Sigma$ is <strong>not required</strong> to be diagonal, so the component of  $\epsilon_t$ may be <strong>contemporaneously correlated</strong>.</p><p>If the correlations are high, there is <strong>no way</strong> of separating the response of $Y_{it}$ to a shock on $\epsilon_{j,t−k}$ from its response to other shocks that are correlated to $\epsilon_{j,t−k}$.</p><p>If we defifine the <strong>square invertible matrix</strong> $S$ such that</p><script type="math/tex; mode=display">\epsilon_t\equiv S\xi_t\ with\ \mathbb E(\xi_t\xi_t')\equiv I_n</script><p>then, setting $\tilde\Psi_j\equiv\Psi_jS,\xi_t=S^{-1}\epsilon_t$</p><script type="math/tex; mode=display">Y_t=\sum_{j=0}^\infty\Psi_k\epsilon_{t-k}=\sum_{j=0}^\infty(\Psi_kS)S^{-1}\epsilon_{t-k}=\sum_{j=0}^\infty\tilde\Psi_k\xi_{t-k}</script><blockquote><p>让原本相关性强的残差变成白噪</p></blockquote><p>We can define the <strong>structural impulse-response function</strong> as</p><script type="math/tex; mode=display">\tilde v(i,j,k)\equiv\frac{\partial T_{it}}{\partial\xi_{j,t-k}}=\tilde\psi_{ij}^{(k)},\ k=0,1,2,...,h</script><ul><li>Note that if $\epsilon_t=S\xi_t$, then $\Sigma=SS’$</li></ul><p>$S$ is often defined as a lower triangular matrix (<strong>Choleski decomposition</strong>)</p><script type="math/tex; mode=display">\begin{bmatrix}\epsilon_{1t}\\\epsilon_{2t}\\...\\\epsilon_{nt}\end{bmatrix}=\begin{bmatrix}s_{11}&0&...&0\\s_{21}&s_{22}&...&0\\...&...&...&...\\s_{n1}&s_{n2}&...&s_{nn}\\\end{bmatrix}\begin{bmatrix}\xi_{1t}\\\xi_{2t}\\...\\\xi_{nt}\end{bmatrix}=\begin{bmatrix}s_{11}\xi_{1t}\\s_{21}\xi_{1t}+s_{22}\xi_{2t}\\...\\s_{n1}\xi_{1t}+...+s_{nn}\xi_{nt}\end{bmatrix}</script><p>The fact that $S$ is triangular implies that $\epsilon_{1t}$ is a function of the first structural shocks $\xi_{1t}, \epsilon_{2t}$ is a function of the structural shocks $\xi_{1t}$ and $\xi_{2t}$ and so on.</p><p>【<strong>Example</strong>】</p><p>Let $Y_t=\Phi Y_{t-1}+\epsilon_t,\epsilon_t\sim(0,\Sigma)$, with</p><script type="math/tex; mode=display">\Phi=\begin{bmatrix}0.4&0.5\\-0.2&1.1\end{bmatrix}\qquad\Sigma=\begin{bmatrix}1&0.6\\0.6&1\end{bmatrix}</script><p>Hence,</p><script type="math/tex; mode=display">\Phi^2=\begin{bmatrix}0.06&0.75\\-0.3&1.11\end{bmatrix}\qquad\Phi^3=\begin{bmatrix}-0.126&0.855\\-0.342&1.071\end{bmatrix}</script><p>and so on.</p><p>Note that $\Sigma=SS’$, with</p><script type="math/tex; mode=display">S=\begin{bmatrix}1&0\\0.6&0.8\end{bmatrix}</script><p>which is equivalent to $\tilde\Psi_0$. Moreover</p><script type="math/tex; mode=display">\tilde\Psi_1=\Phi S=\begin{bmatrix}0.7&0.4\\0.46&0.88\end{bmatrix}\qquad\tilde\Psi_2=\Phi^2S=\begin{bmatrix}0.51&0.6\\0.366&0.888\end{bmatrix}</script><p>and so on.</p><p>In practice $ \Sigma$ is estimate by</p><script type="math/tex; mode=display">\hat\Sigma=\frac1T\sum_{t=1}^T\hat\epsilon_t\hat\epsilon_t'</script><p>and the Cholesky decomposition is computed on $ \hat\Sigma$, that is</p><script type="math/tex; mode=display">\hat\Sigma=\hat S\hat S'</script><p><strong>Forecast error variance decomposition</strong></p><p>The <strong>orthogonalized error variance decomposition</strong> is defined as</p><script type="math/tex; mode=display">\psi(i,j,h)\equiv\frac{\sum_{k=0}^{h-1}\tilde v^2(i,j,k)}{\sum_{j=1}^n\sum_{k=0}^{h-1}\tilde v^2(i,j,k)}</script><p>Expressed as percentage, one can thus examine the relative importance of the error variance $Y_j$ for forecasting $Y_i$ h-step ahead.</p><h4 id="Nonstationary-VAR"><a href="#Nonstationary-VAR" class="headerlink" title="Nonstationary VAR"></a>Nonstationary VAR</h4><p>Consider the n−variate VAR</p><script type="math/tex; mode=display">\Phi(L)Y_t=\epsilon_t,\ \Phi(L)=I_n-\Phi_1L-...-\Phi_pL^p</script><p>The VAR process is stationary if</p><script type="math/tex; mode=display">det[\Phi(z)]\ne 0,\ for |z|<1</script><p>Recall that</p><script type="math/tex; mode=display">\Phi(L)=I_n(1-L)+\Pi L+\sum_{j=1}^{p-1}\Phi_j^*L^j(1-L)</script><p>where $\Phi_j^*=\sum_{k=j+1}^p\Phi_k$ and $\Pi\equiv\Phi(1)$</p><blockquote><p>Beveridge-Nelson Decomposition 取 I(1)</p><p>Augmented Dickey Fuller (ADF)  Test</p></blockquote><ul><li><p>If $\Pi$ is a matrix of zeros</p><script type="math/tex; mode=display">\Delta Y_t=\sum_{j=1}^{p-1}\Phi^*_j\Delta Y_{t-j}+\epsilon_t</script></li><li><p>If $\Pi\ne 0$ and $det(\Pi)\ne0$ the process is stationary.</p></li><li><p>If $\Pi\ne 0$ but $det(\Pi)=0$,  that is <strong>Π</strong> has reduced rank, then $Y_t$ is a <strong>cointegrated process</strong>.</p><blockquote><p>协整检验的目的是决定一组非平稳序列的线性组合是否具有稳定的均衡关系</p></blockquote></li><li><p>If $rank(\Pi)=r&lt;n$, then</p><script type="math/tex; mode=display">\Pi =\alpha\beta'</script><p>where $\alpha$ and $\beta$ are $(n \times r)$ full column rank matrices.</p><p>Hence, the VAR admits the representation</p><script type="math/tex; mode=display">\Delta Y_t=\alpha\beta'Y_t+\sum_{j=1}^{p-1}\Phi_j^*\Delta Y_{t-j}+\epsilon_t</script><p>where $\beta’Y_t$ needs to be stationary!</p></li></ul><h1 id="Unit-7：Cointegration"><a href="#Unit-7：Cointegration" class="headerlink" title="Unit 7：Cointegration"></a>Unit 7：Cointegration</h1><p><strong>Reading</strong>：</p><ul><li>Brooks, Chapter 8, Sections 8.3 - 8.11 (Essential)</li><li>Appendix C (Essential)</li></ul><p><strong>Activities</strong>：</p><ul><li>Brooks Chapter 8, Self-Study Questions 5,6,7</li></ul><h3 id="Definition-6"><a href="#Definition-6" class="headerlink" title="Definition:"></a>Definition:</h3><h4 id="Cointegration"><a href="#Cointegration" class="headerlink" title="Cointegration"></a>Cointegration</h4><p>An n-variate time series {$X_t$} is called a cointegrated system of order ($d,b$), written {$X_t$} $\sim CI(d, b)$, if all the components are I($d$) and there exists a $n \times r(r &lt; n)$ matrix $\beta \ne 0$ such that $\beta ‘X_t \sim I(d − b)$, with $d \ge b &gt; 0$. The vectors $\beta_k, k = 1, . . . , r$ are called the cointegrating vectors.</p><p>Examples of possible Cointegrating Relationships in finance:</p><ul><li>Spot and futures prices, spot and forward prices.</li><li>Bid and ask prices.</li><li>Ratio of relative prices and an exchange rate (law of one price) </li><li>Equity prices and dividends</li></ul><blockquote><p> Market forces arising from no arbitrage conditions should ensure an equilibrium relationship</p></blockquote><h4 id="The-Engle-Granger-Method（协整检验）"><a href="#The-Engle-Granger-Method（协整检验）" class="headerlink" title="The Engle-Granger Method（协整检验）"></a>The Engle-Granger Method（协整检验）</h4><p><a href="https://www.pianshen.com/article/6716218462/">Link</a></p><script type="math/tex; mode=display">X_{1t}=\mu+\gamma'X_{2t}+U_t</script><ul><li>If the null is not rejected, $\beta=[1,-\gamma’]$ is not a cointegrating vector. (ADF Test)</li></ul><h4 id="Stock-prices-and-Dividends"><a href="#Stock-prices-and-Dividends" class="headerlink" title="Stock prices and Dividends"></a>Stock prices and Dividends</h4><p>The dividend-price ratio $\Lambda_t$ is usually measured as</p><script type="math/tex; mode=display">\Lambda_t=\frac{D_t}{S_t}</script><ul><li><p>$D_t$: the sum of dividends paid on the stock/index over the previous year</p></li><li><p>$S_t$:  the current price of the stock/ current level of the index</p></li></ul><p>Hence,</p><script type="math/tex; mode=display">\lambda_t=ln(D_t)-ln(S_t)=d_t-s_t</script><p>Assume $\lambda_t=\lambda+u_t$, with $u_t\sim I(0)$</p><script type="math/tex; mode=display">d_t=s_t+\lambda+u_t</script><p>Let</p><script type="math/tex; mode=display">\Delta s_t=\mu+v_t,\ v_t\sim I(0)</script><p>which can be rewritten as</p><script type="math/tex; mode=display">s_t=\mu+s_{t-1}+v_t,\ v_t\sim I(0)</script><p>and we have</p><script type="math/tex; mode=display">\Delta d_t=\mu-(d_{t-1}-s_{t-1}-\lambda)+\epsilon_t,\ \epsilon_t=u_t+v_t</script><p>This model can be generalized to</p><script type="math/tex; mode=display">\Delta d_t=\mu+\alpha(d_{t-1}-s_{t-1}-\lambda)+\epsilon_t</script><ul><li><p>known as an <strong>Error Correction Model</strong> (ECM)</p></li><li><p>In an ECM, the change in a variable depends on the deviations from some equilibrium relation</p></li></ul><p>Let $x_t=(s_t,d_t)’$ and assume that</p><script type="math/tex; mode=display">\mathbb E(\epsilon_t|x_{t-1})=0\ and\ \mathbb E(v_t|x_{t-1})=0</script><p>Then, </p><script type="math/tex; mode=display">\mathbb E(\Delta s_t|x_{t-1})=\mu\ and\ \mathbb E(\Delta d_t|x_{t-1})=\mu+\alpha(d_{t-1}-s_{t-1}-\lambda)</script><p>Consider 3 situations:</p><ol><li><p>$d_{t-1}-s_{t-1}-\lambda=0$ (equilibrium)</p><script type="math/tex; mode=display">\mathbb E(\Delta d_t|x_{t-1})=\mathbb E(\Delta s_t|x_{t-1})=\mu</script><p>where $\mu$ represent the growth rates of stock prices (and dividends) in the long-run.</p></li><li><p>$d_{t-1}-s_{t-1}-\lambda&gt;0$ (positive disequilibrium error)</p><script type="math/tex; mode=display">\mathbb E(\Delta d_t|x_{t-1})=\mu+\alpha(d_{t-1}-s_{t-1}-\lambda)<\mu</script><p>If $\alpha&lt;0$, the model predicts that $d_t$ will grow more slowly than its long-run rate to restore the dividend-yield to its long-run mean.</p></li><li><p>$d_{t-1}-s_{t-1}-\lambda&lt;0$ (negative disequilibrium error)</p><script type="math/tex; mode=display">\mathbb E(\Delta d_t|x_{t-1})=\mu+\alpha(d_{t-1}-s_{t-1}-\lambda)>\mu</script><p>If $\alpha&lt;0$, the model predicts that $d_t$ will grow faster thani ts long-run rate to restore the dividend-yield to its long-run mean.</p></li></ol><h4 id="VARs-with-Integrated-Variables"><a href="#VARs-with-Integrated-Variables" class="headerlink" title="VARs with Integrated Variables"></a>VARs with Integrated Variables</h4><p>we have</p><script type="math/tex; mode=display">X_t=\sum_{j=1}^p\Phi_jX_{t-j}+\epsilon_t</script><p>can be re-written as</p><script type="math/tex; mode=display">\Delta X_t=\Pi X_{t-1}+\sum_{j=1}^{p-1}\Phi_j^*\Delta X_{t-j}+\epsilon_t</script><ul><li><p>$\Phi_j^*=-\sum_{k=j+1}^p\Phi_k$ and $\Pi \equiv -\Phi(1)$</p></li><li><p>$\Pi$ is know as the long-run matrix</p></li><li><p>The representation is the multivariate counterpart of the ADF regression</p></li><li><p>If $det(\Pi) = 0$ then the $VAR(p)$ is said to have at least a unit root</p></li><li><p>If $det(\Pi) = 0$, then $rank(\Pi) = r &lt; n$.</p></li><li><p>If $r = 0$, then $\Pi = 0$ (n unit roots), and $\Delta X_t$ is a $VAR(p − 1)$.</p></li><li><p>If $0&lt; r &lt; n$, then</p><script type="math/tex; mode=display">\Pi =\alpha\beta'</script></li><li><p>$\alpha$ and $\beta$ are $(n \times r)$ matrices.</p></li><li><p>$\beta$ is know as cointegrating vectors</p></li><li><p>The system will contain only $(n − r)$ unit roots</p></li><li><p>we obtain the <strong>Vector Error Correction Model</strong> (VECM)</p><script type="math/tex; mode=display">\Delta Y_t=\alpha\beta'Y_t+\sum_{j=1}^{p-1}\Phi_j^*\Delta Y_{t-j}+\epsilon_t</script></li></ul><p>Let $A$ a $(r \times r)$ non-singular matrix. Then,</p><script type="math/tex; mode=display">\Pi = \alpha\beta'=(\alpha A)(A^{-1}\beta')</script><p>Let</p><script type="math/tex; mode=display">\beta = \begin{bmatrix}\beta_1(r\times r)\\ \beta_2 (n\times r)\end{bmatrix}</script><p>and assume that $\beta_1$ is invertible. To identify the matrices, the following normalization is often imposed</p><script type="math/tex; mode=display">\beta = \begin{bmatrix}I_r\\ \beta_2\beta_1^{-1}\end{bmatrix}</script><h4 id="Testing-for-Cointegrating"><a href="#Testing-for-Cointegrating" class="headerlink" title="Testing for Cointegrating"></a>Testing for Cointegrating</h4><p>Johansen (1988) proposed to estimated the model using the MLE, assuming the Gausssianity of {$\epsilon_t$}</p><p>MLE estimation is based upon a known value of the cointegrating rank r (<strong>usually unknown</strong>).</p><p>The <strong>maximum eigenvalue statistic</strong>, $λ_{max}$ has been proposed to the the hypothesis</p><script type="math/tex; mode=display">H_0:rank(\Pi)=r_0\ versus\ H_1:rank(\Pi)=r_0+1</script><p>The statistic $λ_{max}$ is constructed as follow:</p><ul><li><p>A positive semi-definite matrix $\Xi$ having the same rank of<br>$\Pi$ is defined. Let $\lambda_k\equiv\lambda_k(\Xi)$, $k = 1, . . . , n$. By definition</p><script type="math/tex; mode=display">1>\lambda_1\ge\lambda_2\ge...\ge\lambda_r>0,\ \lambda_{r+1}=...=\lambda_n=0</script></li><li><p>Obtain a consistent estimate $\hat{\Xi}$. Then $\lambda_k(\hat{\Xi})$ are consistent estimates of $\lambda_k, k = 1,…, n$</p></li><li><p>Test the null hypothesis $H_0 : −T ln(1 − \lambda_{r_0+1}) = 0$, for $r_0 = 0, …, n − 1$ until we fail to reject</p></li><li><p>Let $r^∗_0$ the value of $r_0$ for which the null hypothesis cannot<br>be rejected for the first time. Then, $\hat r = r^∗_0$</p></li></ul><p>The <strong>trace statistic</strong> $λ_{trace}$ has been proposed to the the hypothesis</p><script type="math/tex; mode=display">H_0:rank(\Pi)=r_0\ versus\ H_1:r_0<rank(\Pi)\leq n</script><p>The statistic $λ_{trace}$ is constructed as</p><ul><li><script type="math/tex; mode=display">\lambda_{trace}(r_0)=-T\sum_{k=r_0+1}^nln(1-\lambda_k),\ r_0=0,1,...,n-1</script></li><li><p>Test the sequence of null hypotheses $H_0 : λ_{trace}(r_0) = 0$, from $r_0 = 0$ to $r_0 = n − 1$ until we fail to reject</p></li></ul><blockquote><p>$r_0$ 按顺序依次取</p></blockquote><h4 id="Forecasting-Causality-and-IRFs"><a href="#Forecasting-Causality-and-IRFs" class="headerlink" title="Forecasting, Causality and IRFs"></a>Forecasting, Causality and IRFs</h4><p><strong>Causality Testing in VECMs</strong></p><p>Assume $n = 2$ and $X_t = (Y_t , Z_t)’$. The VECM taks the form</p><script type="math/tex; mode=display">\Delta Y_t=\sum_{j=1}^{p-1}\phi_{11,j}^*\Delta Y_{t-j}+\sum_{j=1}^{p-1}\phi_{12,j}^*\Delta Z_{t-j}+\alpha_1(\beta_1Y_{t-1}+\beta_2Z_{t-1})+\epsilon_{1t}</script><script type="math/tex; mode=display">\Delta Z_t=\sum_{j=1}^{p-1}\phi_{21,j}^*\Delta Y_{t-j}+\sum_{j=1}^{p-1}\phi_{22,j}^*\Delta Z_{t-j}+\alpha_2(\beta_1Y_{t-1}+\beta_2Z_{t-1})+\epsilon_{2t}</script><p>where</p><script type="math/tex; mode=display">\Phi_j^*=\begin{bmatrix}\phi_{11,j}^*&\phi_{12,j}^*\\\phi_{21,j}^*&\phi_{22,j}^*\end{bmatrix},\alpha=\begin{bmatrix}\alpha_1\\ \alpha_2\end{bmatrix},\beta=\begin{bmatrix}\beta_1\\ \beta_2\end{bmatrix}</script><p>The hypothesis that $Z$ does not Granger-cause $Y$ may be formalized as</p><script type="math/tex; mode=display">H_0:\phi_{12,1}^*=\phi_{12,2}^*=...=\phi_{12,p-1}^*,\ \alpha_1=0</script><p>Testing the hypothesis is not straightforward.</p><p>Alternative approaches (as the lag-augmented VAR) have been proposed.</p><p><strong>Forecasting Integrated and Cointegrated systems</strong></p><ul><li><p>Forecasting can be discussed in the framework of the levels VAR representation.</p></li><li><p>A VECM may be rewritten in VAR form, or forecasting can be obtained directly from the VECM.</p><p>If a variable enters the system in differenced form only, it is, of course still possible to generated forecasts of the levels. See Brooks, Rew and Ritson (2001), Section 4.</p></li></ul><p><strong>Impulse Response Analysis</strong></p><p>In principle, impulse response analysis in cointegrated systems can be conducted in the same way as for stationary systems.</p><h3 id="Self-Study-Questions：-5"><a href="#Self-Study-Questions：-5" class="headerlink" title="Self-Study Questions："></a>Self-Study Questions：</h3><p>【<strong>CHP 8：Q6.a</strong>】<strong>Suppose that a researcher has a set of three variables, she wishes to test for the existence of cointegrating relationships using the Johansen procedure. What is the implication of finding that the rank of the appropriate matrix takes on a value of 0,1,2,3</strong></p><p>If the rank of the  matrix is zero, this implies that there is no cointegration or no common stochastic trends between the series. The rank of  is one or two would imply that there were one or two linearly independent cointegrating vectors or combinations of the series that would be stationary, respectively. A finding that the rank of  is 3 would imply that the matrix is of full rank. The implication of a rank of 3 would be that the original series were stationary, and provided that unit root tests had been conducted on each series, this would have effectively been ruled out.</p><h1 id="Unit-8：Forecasts-Evaluation-Part-I"><a href="#Unit-8：Forecasts-Evaluation-Part-I" class="headerlink" title="Unit 8：Forecasts Evaluation (Part I)"></a>Unit 8：Forecasts Evaluation (Part I)</h1><p><strong>Reading</strong>：</p><ul><li>Brooks, Chapter 6, Section 6.10 (Essential)</li><li>Diebold, Chapter 10 (Essential, Subsections 10.2.2 and 10.2.4 excluded )</li></ul><p><strong>Activities</strong>：</p><ul><li>Brooks Chapter 6, Self-Study Questions 11(d), 12(f).</li><li>Diebold, Section 10.4, Exercises, Problems and Complements 1-3. The solutions can be found <a href="https://www.sas.upenn.edu/~fdiebold/Teaching221/Fcst4Solns.pdf">here</a> (See Chapter 12, Exercises 1.2.6).</li></ul><h3 id="Definition-7"><a href="#Definition-7" class="headerlink" title="Definition:"></a>Definition:</h3><p><strong>Rolling vs Recursive Samples</strong></p><ul><li>Rolling （M1-M12；M2-M1；M3-M2；…）</li><li>Recursive（M1-M12；M1-M1；M1-M2；…）</li></ul><h4 id="Testing-Properties-of-Optimal-Forecasts"><a href="#Testing-Properties-of-Optimal-Forecasts" class="headerlink" title="Testing Properties of Optimal Forecasts"></a>Testing Properties of Optimal Forecasts</h4><ol><li><p>Have a zero mean (unbiasedness). </p></li><li><p>1-step-ahead optimal forecast errors are white noise.</p></li><li><p>h-step-ahead optimal forecast errors are at most MA (h <em>−</em> 1).</p></li><li><p>The h-step-ahead optimal forecast error variance is non-decreasing in h.</p></li></ol><p><strong>Hypothesis 1</strong></p><script type="math/tex; mode=display">H_0:\mathbb E[e_{t,h}]=0,\ vs\ H_1:\mathbb E[e_{t,h}]\ne0</script><ul><li><p>Regress $e_{t,h}$ on a constant and use the reported t−statistic:</p><script type="math/tex; mode=display">t=\frac{\bar{e}_{t,h}}{s.e.(\bar{e}_{t,h})}</script></li><li><p>Multi-step-ahead forecast errors will be serially correlated because the forecast periods overlap.</p></li><li>Fitting a MA(h − 1) is a good initial guess to model autocorrelation in the regression error.</li><li>Robust standard errors can be used (e.g. Newey-West estimator).</li></ul><p><strong>Hypothesis 2</strong></p><p>1-step-ahead optimal forecast errors are white noise.</p><ul><li>Regress the $e_{t,1}$ on a constant test the null hypothesis that the residuals are white noises</li></ul><p><strong>Hypothesis 3</strong></p><p>The h-step ahead optimal forecast errors are at most MA (h <em>−</em> 1).</p><ul><li><p>Examine the statistical signifificance of sample ACF(k), k &gt; (h <em>−</em> 1) using Bartlett’s standard errors.</p></li><li><p>Regress $e_{t,h}$ on a constant, allowing for MA(q) disturbances, with q &gt; (h − 1) and test.</p><script type="math/tex; mode=display">\theta_h=\theta_{h+1}=...=\theta_q=0</script></li></ul><p><strong>Hypothesis 4</strong></p><p>The h-step ahead optimal forecast error variance is non-decreasing in h. </p><p><strong>Is {$e_{t,h}$} orthogonal to available information?</strong></p><p>Mincer and Zarnowitz (1969) proposed to test partial optimality with respect to $f_{t+h,t}$ using the regressions</p><script type="math/tex; mode=display">e_{t,h}=\beta_0+\beta_1 f_{t,h}+U_t</script><p>or, equivalently</p><script type="math/tex; mode=display">Y_{t,h}=\alpha_0+\alpha_1 f_{t,h}+U_t</script><p>If the forecast is optimal with respect to the information set used to construct it, then we’d expect</p><script type="math/tex; mode=display">(\beta_0,\beta_1)'=(0,0)'\ or\ (\alpha_0,\alpha_1)'=(0,1)'</script><p>Ramsey (1969)’s test account for various sort of nonlinearity</p><script type="math/tex; mode=display">e_{t,h}=\sum_{j=0}^k\beta_jf_{t,h}^j+U_t</script><p>If the forecast is optimal with respect to the information set used to construct it, then we’d expect</p><script type="math/tex; mode=display">\beta_0=\beta_1=...=\beta_k=0</script><p>In general $\Omega_t$ doesn’t include all information available at the time the forecast was made. We will deal with forecasts that will be at most partially optimal.</p><h4 id="Relative-standards-for-point-forecasts"><a href="#Relative-standards-for-point-forecasts" class="headerlink" title="Relative standards for point forecasts"></a>Relative standards for point forecasts</h4><p><strong>Accuracy ranking via expected loss</strong></p><ul><li>Forecast accuracy is measured with respect to a loss function, $\mathscr L(e_{t,h})$, and the forecast horizon h</li></ul><p><strong>Forecast error</strong></p><p>Accuracy measure are defined on the forecast errors</p><script type="math/tex; mode=display">e_{t,h}=Y_{t+h}-f_{t,h}</script><p>or the percent forecast error</p><script type="math/tex; mode=display">p_{t,h}=\frac{Y_{t+h}-f_{t,h}}{Y_{t+h}}</script><p><strong>Mean error</strong></p><script type="math/tex; mode=display"> (population)\quad ME(h)=\mathbb E(e_{t,h})</script><script type="math/tex; mode=display">(sample)\quad \hat{ME}(h)=\frac1{N-h+1}\sum_{t=0}^{N-h} e_{t,h}</script><ul><li>The ME measures the bias</li><li>If ME&gt; 0, then on average we are “under-forecasting” (“over-forecasting”  if ME &lt; 0)</li><li>Other things the same, we prefer a forecast whose error have small bias.</li></ul><p><strong>Error Variance</strong></p><script type="math/tex; mode=display">(population)\quad EV(h)=\mathbb E(e_{t,h}-ME)^2</script><script type="math/tex; mode=display">(sample)\quad \hat{EV}(h)=\frac1{N-h+1}\sum_{t=0}^{N-h} (e_{t,h}-\hat{ME})^2</script><ul><li>EV measures the dispersion of the forecast error. </li><li>Other things the same, we prefer a forecast whose error have small variance.</li><li>Although ME and EV are components of accuracy, neither provides an overall accuracy measure.</li></ul><p><strong>Mean Square Error</strong></p><p>The most common overall accuracy measures is the <strong>mean squared error</strong></p><script type="math/tex; mode=display">MSE(h)=\mathbb E[e_{t,h}^2]</script><p>In sample we write</p><script type="math/tex; mode=display">\hat{MSE}(h)=\frac1{N-h+1}\sum_{t=0}^{N-h} e_{t,h}^2</script><p><strong>Mean Square Error Decomposition</strong></p><script type="math/tex; mode=display">MSE=\mathbb{Var}(e_{t,h})+[\mathbb E(e_{t,h})]^2=EV+ME^2</script><p>Bias-Variance trade-off: a small bias increase is acceptable in exchange for a massive variance reduction.</p><p><strong>Root Mean Square Error</strong></p><p>Often the square roots of MSE is used to preserve units.</p><script type="math/tex; mode=display">RMSE(h)=\sqrt{MSE(h)}</script><p>Suppose that the forecast errors are measured in dollars, then the MSE is measured in dollars squared.</p><p>Taking the square root brings the unit back to dollars.</p><p><strong>Mean Absolute Error</strong></p><p>Somehow less popular, but nevertheless common measures are the mean absolute error</p><script type="math/tex; mode=display">MAE(h)=\mathbb E|e_{t,h}|</script><script type="math/tex; mode=display">\hat{MAE}(h)=\frac1{N-h+1}\sum_{t=0}^{N-h} |e_{t,h}|</script><blockquote><p>Quadratic 的 loss function 会放更多 weight 在大的值</p></blockquote><h4 id="Statistical-comparison-of-forecast-accuracy"><a href="#Statistical-comparison-of-forecast-accuracy" class="headerlink" title="Statistical comparison of forecast accuracy"></a>Statistical comparison of forecast accuracy</h4><ul><li><p>Suppose that two different forecasts of the same object are available, say $f_{t,h}^{(1)}$ and $f_{t,h}^{(2)}$.</p></li><li><p>Suppose that $\hat{MSE}^{(1)}(h) &lt; \hat{MSE}^{(2)}(h)$</p></li><li><p>One is tempted to conclude that $f_{t,h}^{(1)}$ “wins” under the<br>quadratic loss function （$\mathscr L$）.</p></li><li><p>The Diebold-Mariano test answers that question.</p></li><li><p>In hypothesis testing terms, we might want to test the null of equal predictive accuracy</p><script type="math/tex; mode=display">\mathbb E[\mathscr L(e_{t,h})^{(1)}]=\mathbb E[\mathscr L(e_{t,h})^{(2)}]</script><p>against the alternative that one forecast is better, i.e.</p><script type="math/tex; mode=display">\mathbb E(d_{12,t})=\mathbb E[\mathscr L(e_{t,h})^{(1)}-\mathscr L(e_{t,h})^{(2)}]=0</script><p>against $\mathbb E(d_{12,t})\ne 0$, where $d_{12,t}=e_{t,h})^{(1)}-\mathscr L(e_{t,h})^{(2)}$</p></li></ul><p><strong>The Diebold-Mariano Test</strong></p><ul><li><p>Diebold and Mariano assume that $d_{12,t}$ is covariance stationary, i.e., for every t</p><script type="math/tex; mode=display">\mathbb E(d_{12,t})=\mu_d,\ \mathbb Cov(d_{12,t},d_{12,t-k})=\gamma_d(k),\ \mathbb Var(d_{12,t})=\sigma_{12}^2<\infty</script><p>and short memory, i.e.  $\sum_{k=-\infty}^\infty|\gamma_d(k)|&lt;\infty$</p></li><li><p>Under $H_0:\mathbb E(d_{12,t})=0$</p><script type="math/tex; mode=display">DM_{12}\equiv\frac{\bar d_{12}}{\hat\sigma_{\bar d_{12}}}\sim^aN(0,1)</script><p>where $\bar d_{12} = (N − h + 1)^{−1}\sum^{N−h}_{t=0} d_{12,t}$ has an estimated standard deviation equal to $\hat\sigma_{\bar d_{12}}$</p></li></ul><p><strong>Benchmark Comparisons: the predictive</strong> $R^2$</p><p>To assess the forecasts, one might compare a forecast to a “naive” competitor .</p><p>The Predictive $R^2$</p><script type="math/tex; mode=display">R^2=1-\frac{\sum_{t=0}^{N-1}e_{t,1}^2}{\sum_{t=0}^{N-1}(Y_{t-1}-\bar Y)^2}</script><p>considers $\bar Y$ as a benchmark for $f_{t,1}$.</p><ul><li>The (estimate of) 1-step-ahead out-of-sample forecast error variance is compared to an estimate of unconditional variance.</li><li>The predictive $R^2$ should be close to 1 if the forecast is by far more accurate than $\bar Y$ .</li><li>The h-step-ahead version of the predictive $R^2$ is defined replacing $e_{t,1}$ with $e_{t,h}$.</li></ul><p><strong>Benchmark Comparison: Theils’s U-Statistic</strong></p><p>The Theil U-Statistic is similar to a predictive $R^2$ , but the benchmark changes from $\bar Y$ , to a “no change” forecast</p><script type="math/tex; mode=display">U=1-\frac{\sum_{t=0}^{N-1}e_{t,1}^2}{\sum_{t=0}^{N-1}(Y_{t+1}-Y_t)^2}</script><p>Many economic variables may in fact be nearly random walk.</p><p>In this case the forecaster will have great difficult beating the random walk (RW), for which $f_{t,1} = Y_{t}$.</p><blockquote><p>此方法不能运用于 GARCH，因为 Y 部分</p></blockquote><h4 id="Evaluating-direction-of-change-forecasts"><a href="#Evaluating-direction-of-change-forecasts" class="headerlink" title="Evaluating direction-of-change-forecasts"></a>Evaluating direction-of-change-forecasts</h4><ul><li>In terms of profitability of a trading strategy, a forecast can be assessed in terms of the ability to predict direction changes irrespective of their magnitude.</li><li>The accuracy of the forecast is measured in terms of % correct sign prediction.</li><li>We can also test the null hypothesis of no predictive power.</li></ul><p>Introduce the indicator variables</p><script type="math/tex; mode=display">Z_t^y=\begin{cases}1&if\ Y_{t+1}>0\\0&otherwise\end{cases},\quad Z_t^f=\begin{cases}1&if\ f_{t+1}>0\\0&otherwise\end{cases}</script><p>Let $P_y = Pr(Y_{t+1} &gt; 0)$ and $P_f = Pr(f_{t,1} &gt; 0)$. Define</p><script type="math/tex; mode=display">W_t=\begin{cases}1&if\ (Y_{t+1}\times f_{t,1})>0\\0&otherwise\end{cases}</script><p>Denote by $\hat P$ the proportion of times that the sign of $Y_{t+1}$ is predicted correctly, i.e.</p><script type="math/tex; mode=display">\hat P=\frac1N\sum_{t=1}^NW_t=\bar W</script><ul><li><p>The assessment is based on a test for the null that $Z_t^y$ and $Z_t^f$ are independent (no predictive power).</p></li><li><p>Under the null, $N\hat P$ has a binomial distribution with mean $NP_∗$, where</p><script type="math/tex; mode=display">P_*=P_yP_f+(1-P_y)(1-P_f)</script><p>and</p><script type="math/tex; mode=display">\hat P_*=\hat P_y\hat P_f+(1-\hat P_y)(1-\hat P_f)</script><p>with</p><script type="math/tex; mode=display">\hat P_y=N^{-1}\sum_{t=1}^NZ_t^y,\quad \hat P_f=N^{-1}\sum_{t=1}^NZ_t^f</script></li><li><p>A nonparametric test of predictive performance of $f_{t,1}$​ can be based on</p><script type="math/tex; mode=display">S_n=\frac{\hat P-\hat P_*}{\hat{\mathbb Var}(\hat P)-\hat{\mathbb Var}(\hat P_*)}\sim^aN(0,1)</script><blockquote><p>如果是 iid $P(xy)=P(x)P(y)$, 即 $\hat P-\hat P_*=0$</p></blockquote><p>where</p><script type="math/tex; mode=display">\hat{\mathbb Var}(\hat P)=N^{-1}\hat P_*(1-\hat P_*)</script><p>and</p><script type="math/tex; mode=display">\begin{align}\hat{\mathbb Var}(\hat P_*)&=N^{-1}(2\hat P_y-1)^2\hat P_f(1-\hat P_f)+N^{-1}(2\hat P_f-1)^2\hat P_y(1-\hat P_y)...\\&...+4N^{-2}\hat P_y\hat P_f(1-\hat P_y)(1-\hat P_f)\end{align}</script></li></ul><h1 id="Unit-8：Forecasts-Evaluation-Part-II"><a href="#Unit-8：Forecasts-Evaluation-Part-II" class="headerlink" title="Unit 8：Forecasts Evaluation (Part II)"></a>Unit 8：Forecasts Evaluation (Part II)</h1><p><strong>Activities</strong>：</p><ul><li>Brooks Chapter 6, Self-Study Questions 11(d), 12(f).</li><li>Diebold, Section 10.4, Exercises, Problems and Complements 1-3. The solutions can be found <a href="https://www.sas.upenn.edu/~fdiebold/Teaching221/Fcst4Solns.pdf">here</a> (See Chapter 12, Exercises 1.2.6).</li></ul><h3 id="Definition-8"><a href="#Definition-8" class="headerlink" title="Definition:"></a>Definition:</h3><h4 id="Evaluating-Volatility-Forecasts"><a href="#Evaluating-Volatility-Forecasts" class="headerlink" title="Evaluating Volatility Forecasts"></a>Evaluating Volatility Forecasts</h4><p>We can compute the forecasts $f_{t,1}^{\sigma^2}$ but we don’t observe $\sigma_{t+1}^2$</p><p>If $\epsilon_t=\sigma_t\eta_t$, $\eta_t\sim iid(0,1)$, a popular proxy is $\epsilon_{t+1}^2$, because $\mathbb E(\epsilon_{t+1}^2|\Omega_t)=\sigma_{t+1}^2$​.</p><blockquote><p>$\sigma_{t+1}^2$ 依附于 $\Omega_t$</p></blockquote><p>Assume we have generated the series of 1-step-ahead-point forecasts $\{f_{T+j,1}^{\sigma^2}\}_{j=1}^N$</p><p>To simplify the notation we write</p><script type="math/tex; mode=display">\{f_{T+j,1}^{\sigma^2}\}_{j=1}^N=\{f_{t,1}^{\sigma^2}\}_{t=1}^N=\{f_{1,1}^{\sigma^2},...,f_{N,1}^{\sigma^2}\}</script><p>For example, the MSE is computed as</p><script type="math/tex; mode=display">MSE=\frac1N\sum_{t=1}^N(\epsilon_{t+1}^2-f_{t,1}^{\sigma^2})^2</script><p>$\epsilon_t^2$ is an unbiased proxy of $\sigma_t^2$</p><p>Alternative volatility proxies have been proposed (see Section 9.18 Brooks).</p><p>If  $\epsilon_t=\sigma_t\eta_t$, $\eta_t\sim NID(0,1)$, then</p><script type="math/tex; mode=display">\frac{\epsilon_t^2}{\sigma_t^2}=\eta_t^2\sim \chi^2(1),\quad Pr(\eta_t^2\leq0.455)=\frac12</script><ul><li>i.e. $\epsilon_t^2&lt;1/2\sigma_t^2$​ more than fifty percent of the time.</li></ul><blockquote><p>not a good proxy</p></blockquote><p>Even if one is willing to accept a proxy that is up to 50% different from $\sigma_t^2$ , $\epsilon_t^2$ would fulfil this condition only 25% of the time</p><script type="math/tex; mode=display">Pr(\epsilon_t^2\in[\frac12\sigma_t^2,\frac32\sigma_t^2])=Pr(\eta_t^2\in[\frac12,\frac32])=0.2588</script><blockquote><p>25%的可能 $\epsilon^2$ 与 $\sigma^2$ 差 50% 的比</p></blockquote><h4 id="Transforming-Volatility-Forecasts-into-Probability-Forecasts"><a href="#Transforming-Volatility-Forecasts-into-Probability-Forecasts" class="headerlink" title="Transforming Volatility Forecasts into Probability Forecasts"></a>Transforming Volatility Forecasts into Probability Forecasts</h4><p>Lopez (2001) proposed an alternative forecast evaluation framework.</p><p>If $\epsilon_t=\sigma_t\eta_t$, $\eta_t\sim D(0,1)$, and $\sigma_t^2$ is a predictable function of $\Omega_{t-1}$, then</p><script type="math/tex; mode=display">\epsilon_t|\Omega_{t-1}\sim D(0,\sigma_t^2)</script><p>volatility forecasts can be readily transformed into probability forecasts.</p><p>Out-of-sample $P_{t|t-1}$ for $t = 1, . . . , N$ is the one-step-ahead probability forecast conditional on $\Omega_{t-1}$</p><p><strong>Probability Forecasts</strong></p><p>Let $Y_t=\mu_t+\epsilon_t$</p><p>Suppose for example that a Central Bank is interested in forecasting whether the exchange rate ($Y_t$) will remain within a target zone</p><p>In such a case, the event of interest is</p><script type="math/tex; mode=display">Y_t\in[L_t,U_t]</script><p>where $L_t$ and $U_t$ are fixed by the Central Bank (forecast user).</p><p>Assuming that D is continuous and $\mu_t$ and $\sigma_t$ are known</p><script type="math/tex; mode=display">\begin{align}Pr(L_t\leq Y_t\leq U_t)&=Pr(L_t-\mu_t\leq \epsilon_t\leq U_t-\mu_t)\\&=Pr(\frac{L_t-\mu_t}{\sigma_t}< \eta_t< \frac{U_t-\mu_t}{\sigma_t})\\&=Pr(l_t< \eta_t< u_t)=\int_{l_t}^{u_t}f(\eta_t)d\eta_t\end{align}</script><ul><li>Out aim is to forecast $Pr (L_t \leq Y_t \leq U_t)$ at time $t − 1$.</li></ul><p>Then, the one-step-ahead probability forecast $P_t$ is computed as</p><script type="math/tex; mode=display">\begin{align}P_{t|t-1}&=Pr(\frac{L_t-\mu_{t|t-1}}{\sigma_{t|t-1}}< \eta_t< \frac{U_t-\mu_{t|t-1}}{\sigma_{t|t-1}})\\&=Pr(l_{t|t-1}< \eta_t< u_{t|t-1})=\int_{l_{t|t-1}}^{u_{t|t-1}}f(\eta_t)d\eta_t\end{align}</script><p><strong>Remark</strong></p><ul><li><p>To avoid cumbersome notation, we will use $X_{t|t-1}$ to denote the one-step-ahead forecast of a variable $X_t$ , conditional on $\Omega_{t-1}$.</p></li><li><p>As an example of probability forecast evaluation, we will consider the Brier score.</p></li><li>The Brier score is a rough analogue of the MSE for probability forecasts.</li></ul><p>Accuracy measures for probability forecasts are commonly called <strong>scores</strong>.</p><p>The most common is the <strong>Brier quadratic probability score</strong></p><script type="math/tex; mode=display">QPS=\frac1N\sum_{t=1}^N2(P_{t|t-1}-R_t)^2</script><ul><li>where $R_t$ takes value one if the event occurs and zero otherwise.</li></ul><p>$QPS\in [0, 2]$ and smaller values indicate more accurate forecasts.</p><h4 id="Evaluating-Interval-Forecasts"><a href="#Evaluating-Interval-Forecasts" class="headerlink" title="Evaluating Interval Forecasts"></a>Evaluating Interval Forecasts</h4><p>The Lopez approach to volatility forecast evaluation is based on time-varying probabilities assigned to fixed intervals.</p><p>Alternatively, one may fix the probabilities and vary the widths of the intervals, as in the traditional confidence intervals construction.</p><p>The objective is to construct a sequence of out-of-sample interval forecasts $\{[L_{t|t-1}(\alpha),U_{t|t-1}(\alpha)]\}_{t=1}^N$.</p><p>The sequence of ex-ante forecast interval for time t made at time $t − 1$ have coverage probability $(1 − \alpha)$.</p><p>We are going to consider the approach proposed by<br>Christoffensen (1998)</p><p><strong>Defifinition 1 (Indicator variable)</strong></p><p>The indicator variable It for a given interval forecast $[L_{t|t-1}(\alpha),U_{t|t-1}(\alpha)]$ is defined as</p><script type="math/tex; mode=display">I_t\begin{cases}1,&if\ Y_t\in[L_{t|t-1}(\alpha),U_{t|t-1}(\alpha)]\\0,&if\ Y_t\not\in[L_{t|t-1}(\alpha),U_{t|t-1}(\alpha)]\end{cases}</script><ul><li>$I_t$ is a function of $Y_t$, so $I_t$ is a random variable</li></ul><p><strong>Defifinition 2 (Testing Criteria)</strong></p><p>We say that the sequence of interval forecasts</p><script type="math/tex; mode=display">\{[L_{t|t-1}(\alpha),U_{t|t-1}(\alpha)]\}_{t=1}^N</script><p>is efficient with respect to information set $\Omega_{t-1}$, if</p><script type="math/tex; mode=display">\mathbb E(I_t|\Omega_{t-1})=1-\alpha,\quad \forall\ t</script><p>If $\Omega_{t−1} = \{I_{t−1}, I_{t−2}, . . . , I_1\}$, it can be shown that</p><script type="math/tex; mode=display">\mathbb E(I_t| \Omega_{t−1}) =\mathbb E(I_t|I_{t−1}, I_{t−2}, . . . , I_1) = 1 − \alpha</script><p>is equivalent to</p><script type="math/tex; mode=display">\{I_t\}\sim^{iid}Bern(1-\alpha)</script><p><strong>Defifinition 3 (Conditional coverage)</strong></p><p>We say that a sequence of interval forecasts</p><script type="math/tex; mode=display">\{[L_{t|t-1}(\alpha),U_{t|t-1}(\alpha)]\}_{t=1}^N</script><p>has correct conditional coverage if</p><script type="math/tex; mode=display">I_t\sim^{iid}Bern(1-\alpha),\quad \forall\ t</script><p>Standard evaluation methods for interval forecasts compare the nominal coverage</p><script type="math/tex; mode=display">N^{-1}\sum_{t=1}^NI_t</script><p>to the true coverage</p><script type="math/tex; mode=display">\mathbb E(I_t)=1-\alpha</script><p>The interval forecast might be correct on average, but the conditional coverage might be characterized by clustered outliers.</p><h4 id="LR-test-of-unconditional-coverage"><a href="#LR-test-of-unconditional-coverage" class="headerlink" title="LR test of unconditional coverage"></a>LR test of unconditional coverage</h4><p>Consider the indicator sequence $\{I_t\}^N_{t=1}$ constructed from a given interval forecast.</p><p>To test the unconditional coverage, the hypothesis</p><script type="math/tex; mode=display">H_0:\mathbb E(I_t)=1-\alpha,\quad vs\quad H_1:\mathbb E(I_t)=\pi\ne 1-\alpha</script><p>should be tested, given independence</p><p>Let $n_j$ be the number of observations for which $I_t = j$, $j = 0, 1$. By construction $n_0 + n_1 = N$.<br>The likelihood under the null hypothesis is</p><script type="math/tex; mode=display">L(p_\alpha;I_1,I_2,...,I_N)=p_\alpha^{n_1}(1-p_\alpha)^{n_0}</script><p>with $p_\alpha=1-\alpha$, and under the alternative</p><script type="math/tex; mode=display">L(\pi;I_1,I_2,...,I_N)=\pi^{n_1}(1-\pi)^{n_0}</script><p>Testing for unconditional coverage can be formulated as a likelihood ratio test,</p><script type="math/tex; mode=display">LR_{uc}=-2ln[\frac{L(p_\alpha;I_1,...,I_N)}{L(\hat\pi;I_1,...,I_N)}]\sim^\alpha\chi^2(1)</script><p>where $\hat\pi = n_1/(n_0 + n_1)$ is the MLE of $\pi$</p><ul><li>The test has no power against the alternative that zeros and ones come clustered in a time-dependent fashion.</li><li><p>Testing for correct unconditional coverage is insufficient when dynamics are present in the higher-order moment.</p></li><li><p>Interval should be narrow in tranquil times and wide in volatile times, so that occurrences of observations outside the interval forecast would be spread out over the sample and not come in clusters.</p></li><li><p>An interval that fails to account for higher-order dynamics may be correct on average, but in any given period it will have incorrect conditional coverage characterized by clustered outliers.</p></li></ul><p>The two tests presented in the next</p><h4 id="LR-test-of-independence"><a href="#LR-test-of-independence" class="headerlink" title="LR test of independence"></a>LR test of independence</h4><p>Recall that a sequence of interval forecasts has correct condition coverage if $\{I_t\} \sim^{iid} Bern(p_\alpha)$.</p><p>The “independence part” will be tested against an explicit first-order Markov alternative.</p><p>Consider a binary first-order Markov chain $\{I_t\}$, with transition probability matrix</p><script type="math/tex; mode=display">\Pi=\begin{bmatrix}\pi_{00}&\pi_{01}\\\pi_{10}&\pi_{11}\end{bmatrix}=\begin{bmatrix}1-\pi_{01}&\pi_{01}\\1-\pi_{11}&\pi_{11}\end{bmatrix}</script><p>where $\pi_{ij}=Pr(I_t=j|I_{t-1}=i)$</p><p>The likelihood function for this process is</p><script type="math/tex; mode=display">L(\Pi;I_1,I_2,...,I_N)=(1-\pi_{01})^{n_{00}}\pi_{01}^{n_{01}}(1-\pi_{11})^{n_{10}}\pi_{11}^{n_{11}}</script><p>where $n_{ij}$ is the number of observations with value $i$ followed by $j$.</p><p>The MLE(Maximum Likelihood Estimate) of $\Pi$ is</p><script type="math/tex; mode=display">\hat\Pi=\begin{bmatrix}\frac{\pi_{00}}{n_{00}+n_{01}}&\frac{\pi_{01}}{n_{00}+n_{01}}\\\frac{\pi_{10}}{n_{10}+n_{11}}&\frac{\pi_{11}}{n_{10}+n_{11}}\end{bmatrix}</script><p>Under the null of independence, $\Pi$ simplifies to</p><script type="math/tex; mode=display">\Pi_{ind}=\begin{bmatrix}1-\pi_{ind}&\pi_{ind}\\1-\pi_{ind}&\pi_{ind}\end{bmatrix}</script><p>The likelihood function under the null became</p><script type="math/tex; mode=display">L(\Pi_{ind};I_1,I_2,...,I_N)=(1-\pi_{ind})^{n_{00}+n_{10}}\pi_{ind}^{n_{01}+n_{11}}</script><p>The MLE of $\pi$ is</p><script type="math/tex; mode=display">\hat\pi_{ind}=\frac{n_{01}+n_{11}}{n_{00}+n_{11}+n_{10}+n_{01}}=\frac{n_1}{n_0+n_1}</script><p>The LR test of independence is</p><script type="math/tex; mode=display">LR_{ind}=-2ln[\frac{L(\hat\Pi_{ind};I_1,...,I_N)}{L(\hat\Pi;I_1,...,I_N)}]\sim^\alpha\chi^2(1)</script><p>Next we will test jointly for independence and correct probability parameter $\pi_{ind}=p_\alpha$.</p><p>Combining the two test we get a complete test for correct conditional coverage (cc).</p><p><strong>The Joint Test of Coverage and Independence</strong></p><p>The main idea is to test the null of unconditional coverage against the alternative of the independence test.</p><p>Christoffersen (1998) defifine the test for correct</p><script type="math/tex; mode=display">LR_{cc}=-2ln[\frac{L(p_\alpha;I_1,...,I_N)}{L(\hat\Pi;I_1,...,I_N)}]\sim^\alpha\chi^2(2)</script><p>If the likelihood is computed conditional to the first observation (as we did), then</p><script type="math/tex; mode=display">LR_{cc}=LR_{uc}+LR_{ind}</script><h4 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h4><p>Christoffersen (1998) evaluate the forecast methodology suggested by J.P. Morgan’s (1995) RiskMetrics using Exchange rates data for different countries.</p><p>He considers the model</p><script type="math/tex; mode=display">Y_{t+1}|\Omega_t\sim D(0,\sigma_{t+1}^2)</script><p>The RiskMetrics interval forecasts is tested against two peers.</p><p>The interval forecast suggested by J.P Morgan is</p><script type="math/tex; mode=display">[L_{t|t-1}(\alpha),U_{t|t-1}(\alpha)]=[\Phi^{-1}(\frac\alpha2)\hat\sigma_{t+1|t},\Phi^{-1}(1-\frac\alpha2)\hat\sigma_{t+1|t}]</script><p>where</p><script type="math/tex; mode=display">\hat\sigma_{t+1|t}^2=\sigma_{t+1}^2=\lambda\sigma_t^2+(1-\lambda)Y_t^2</script><p>Here $\lambda$ is fixed at 0.94</p><p>The distribution $D(·)$ is Gaussian, and its c.d.f. is denoted by $\Phi(·)$.<br>Let $c_\alpha = \Phi^{−1} (\alpha)$, then $c_\alpha$ satisfies $P(Y_{t+1}/\sigma_{t+1}\leq c_\alpha)=\alpha$</p><p>The first peer is constructed from an estimated GARCH(1,1) model with a Student’s t−innovation.</p><p>If the Student’s t−distribution has 4 degrees of freedom with c.d.f. $\tau$ , for $\alpha = 95%$ we have $\tau^{-1} (\alpha/2) = −2.776$ and $\tau^{−1}(1 − \alpha/2) = 2.776$.</p><script type="math/tex; mode=display">[L_{t|t-1}(\alpha),U_{t|t-1}(\alpha)]=[-2.776\hat\sigma_{t+1|t},2.776\hat\sigma_{t+1|t}]</script><p>To compute the interval, the unknown parameters in $\hat\sigma_{t+1|t}^2$ need to be replaced by estimates.</p><p>The second peer is a simple static forecast, constructed assuming that $D(·)$ is Gaussian.</p><p>Let $F(·)$ the unconditional, time-invariant c.d.f. of $Y_{t+1}$</p><script type="math/tex; mode=display">[L(\alpha),U(\alpha)]=[F^{-1}(\frac\alpha2),F^{-1}(1-\frac\alpha2)]</script><p>Comparing interval forecasting of daily exchange rates.</p><ul><li>Tests for UC, IND, CC across coverage rates and exchange rates.</li><li>Nominal coverage rate.</li><li>Average width of the interval prediction.</li><li>See Christoffersen (1996) Section 5 for further details</li></ul>]]></content>
    
    
    <categories>
      
      <category>Econometrics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Time Series</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【课程】Economic Fundamentals and Financial Markets</title>
    <link href="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/"/>
    <url>/2021/05/17/Economic_Fundamentals_and_Financial_Markets/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于格拉斯哥ECON5005的笔记；</p></blockquote><span id="more"></span><h1 id="General-information"><a href="#General-information" class="headerlink" title="General information"></a>General information</h1><p>The aim of this course is to outline how macroeconomics fundamentals influence asset returns and asset prices.</p><h1 id="Aims"><a href="#Aims" class="headerlink" title="Aims"></a>Aims</h1><p>The main aim of this course is to outline how <strong>macroeconomics fundamentals</strong> influence <strong>asset returns and asset prices</strong>.</p><h1 id="ILOs"><a href="#ILOs" class="headerlink" title="ILOs"></a>ILOs</h1><p>By the end of this course, students will be able to:</p><ol><li>Identify the role the <strong>financial sector</strong> plays in the economy at large, both in terms of <strong>resource allocation</strong> under uncertainty, <strong>trading of risk</strong>, and <strong>capital accumulation</strong>;</li><li>Understand the determination of interest rates (using <strong>IS-LM and OLG</strong>);</li><li>Identify the fundamental prices of basic financial assets, such as shares of stock, using state-of-the art techniques such as <strong>q-theory</strong>, <strong>real asset theory</strong> and <strong>monopolistic economic profit theory</strong>;</li><li>Understand stock market price indices based on the market fundamentals <strong>implied</strong> by the previously mentioned theories.</li></ol><h1 id="Topic-1-–-Macroeconomics-and-Financial-Markets-The-Gold-Standard"><a href="#Topic-1-–-Macroeconomics-and-Financial-Markets-The-Gold-Standard" class="headerlink" title="Topic 1 – Macroeconomics and Financial Markets: The Gold Standard"></a>Topic 1 – Macroeconomics and Financial Markets: The Gold Standard</h1><h2 id="Unit-1-1：Money-Paper-Money-and-the-Gold-Standard"><a href="#Unit-1-1：Money-Paper-Money-and-the-Gold-Standard" class="headerlink" title="Unit 1.1：Money, Paper Money and the Gold Standard"></a>Unit 1.1：Money, Paper Money and the Gold Standard</h2><h4 id="What-is-money"><a href="#What-is-money" class="headerlink" title="What is money?"></a>What is money?</h4><ul><li>It is a means of payment</li><li>It is a unit of account</li><li>It is a store of value</li></ul><h4 id="Commodity-and-Fiat-Money"><a href="#Commodity-and-Fiat-Money" class="headerlink" title="Commodity and Fiat Money"></a>Commodity and Fiat Money</h4><ul><li>Commodity money are things with intrinsic value (gold, silver).</li><li>Today’s paper money is called fiat money, because its value comes from government decree, or fiat.</li></ul><h2 id="Unit-1-2：Some-History-on-the-Gold-Standard"><a href="#Unit-1-2：Some-History-on-the-Gold-Standard" class="headerlink" title="Unit 1.2：Some History on the Gold Standard"></a>Unit 1.2：Some History on the Gold Standard</h2><h5 id="A-Brief-History-of-Paper-Money-The-Role-of-Central-Banking-Link"><a href="#A-Brief-History-of-Paper-Money-The-Role-of-Central-Banking-Link" class="headerlink" title="A Brief History of Paper Money: The Role of Central Banking Link"></a>A Brief History of Paper Money: The Role of Central Banking <a href="https://www.youtube.com/watch?v=LrB9bS2VOLE">Link</a></h5><h5 id="A-Brief-History-of-Paper-Money-The-Role-of-the-Gold-Standard-Link"><a href="#A-Brief-History-of-Paper-Money-The-Role-of-the-Gold-Standard-Link" class="headerlink" title="A Brief History of Paper Money: The Role of the Gold Standard Link"></a>A Brief History of Paper Money: The Role of the Gold Standard <a href="https://www.youtube.com/watch?v=GNo7MDN5-0g">Link</a></h5><h2 id="Unit-1-3：Practical-Implications-of-a-Gold-Standard-Today"><a href="#Unit-1-3：Practical-Implications-of-a-Gold-Standard-Today" class="headerlink" title="Unit 1.3：Practical Implications of a Gold Standard Today"></a>Unit 1.3：Practical Implications of a Gold Standard Today</h2><h5 id="Dollar-gold-exchange-rate"><a href="#Dollar-gold-exchange-rate" class="headerlink" title="Dollar-gold exchange rate"></a>Dollar-gold exchange rate</h5><ul><li>55.12 dollar = 1 gram of gold</li><li>$1 dollar=\frac{1 gram of gold}{55.12}=0.0181 grams of gold$</li></ul><h5 id="What-would-happen-if-the-US-tries-to-revert-to-this-gold-standard"><a href="#What-would-happen-if-the-US-tries-to-revert-to-this-gold-standard" class="headerlink" title="What would happen if the US tries to revert to this gold standard?"></a>What would happen if the US tries to revert to this gold standard?</h5><ul><li>Buffer stock problem</li></ul><p>After simulated daily net inflows of cash and gold at the Fed during a year and cumulative net inflow of gold, we observe a <strong>positive net inflow of cash</strong> (negative net inflow of gold).</p><h5 id="Is-this-sustainable"><a href="#Is-this-sustainable" class="headerlink" title="Is this sustainable?"></a>Is this sustainable?</h5><ul><li><p>Suppose the <strong>inflow of dollars increase sharply</strong>, while the inflow of gold stops.</p><ul><li>Inflows of currency still lead to outflows of gold</li><li>The Fed will <strong>run out of gold</strong> to exchange for dollars at the beginning of the year.</li></ul></li><li><p>Of course, the exchange rate between the dollar and gold could not remain the same.</p><ul><li>The dollar will have to be <strong>devalued</strong> (less gold disbursed per dollar)</li></ul></li></ul><h2 id="Unit-1-4：Speculative-Attacks"><a href="#Unit-1-4：Speculative-Attacks" class="headerlink" title="Unit 1.4：Speculative Attacks"></a>Unit 1.4：Speculative Attacks</h2><h5 id="Self-fulfilling-Speculative-Attacks"><a href="#Self-fulfilling-Speculative-Attacks" class="headerlink" title="Self-fulfilling Speculative Attacks"></a>Self-fulfilling Speculative Attacks</h5><p>Even if the central bank is maintaining macroeconomic stability, a speculative attack could still happen.</p><ul><li>The <strong>doubts</strong> the investors/speculators have regarding the commitment of the monetary authority to the fixed exchange rate make the costs of defending the fixed exchange rate excessively high.</li></ul><h4 id="The-Obstfeld-1996-model"><a href="#The-Obstfeld-1996-model" class="headerlink" title="The Obstfeld (1996) model"></a>The Obstfeld (1996) model</h4><blockquote><p>Models of currency crises with self-fulfilling features</p></blockquote><p>It illustrates how the <strong>coordination problem of currency-market traders</strong> changes, when changes in macroeconomic fundamentals modify the degree of discomfort a government will suffer because of an attack.</p><p>We will adapt this model to study the mechanics of a speculative attack on a currency that is pegged to gold.</p><ul><li>The model is based in a <strong>one-shot cooperative game between the two private traders</strong>.</li><li>Each trader has 6 units of domestic currency and transactions costs are equal to 1.</li><li>The size of the committed reserve stock defines the payoffs that the 2 traders potentially can have.</li></ul><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic1-1.jpg" alt></p><h1 id="Topic-2-–-Financial-Markets-and-the-Role-of-the-Financial-System"><a href="#Topic-2-–-Financial-Markets-and-the-Role-of-the-Financial-System" class="headerlink" title="Topic 2 – Financial Markets and the Role of the Financial System"></a>Topic 2 – Financial Markets and the Role of the Financial System</h1><p><strong>Supplementary Reading</strong></p><p>Mankiw, N.G., Macroeconomics (2007, 2010, 2013, 2015, 2018), Ch. 3 &amp; 6.</p><h2 id="Unit-2-1：The-Role-of-the-Financial-System-in-the-Economy"><a href="#Unit-2-1：The-Role-of-the-Financial-System-in-the-Economy" class="headerlink" title="Unit 2.1：The Role of the Financial System in the Economy"></a>Unit 2.1：The Role of the Financial System in the Economy</h2><h4 id="The-Economy-as-a-Circular-Flow"><a href="#The-Economy-as-a-Circular-Flow" class="headerlink" title="The Economy as a Circular Flow"></a>The Economy as a Circular Flow</h4><p>Y(GDP) = C(Consumption) + I(Investment)</p><p><strong>GDP</strong> measures both:</p><ul><li><strong>Total income</strong> of the economy</li><li><strong>Total expenditure</strong> on the economy’s output of goods and services</li></ul><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic2-1.jpg" alt></p><ul><li><strong>Real flow</strong> (Blue) &amp; <strong>Monetary flow</strong> (Green)</li><li>Total Income = Total Expenditure</li><li>Implicitly in this simple description of the economy we have <strong>financial markets</strong>:<ul><li>Channelling savings from surplus units (who want a return) to deficit units (who have an investment opportunity)</li></ul></li></ul><h4 id="Adding-financial-markets-explicitly-and-the-government"><a href="#Adding-financial-markets-explicitly-and-the-government" class="headerlink" title="Adding financial markets explicitly and the government"></a>Adding financial markets explicitly and the government</h4><p>Y(GDP) = C(Consumption) + I(Income) + G(Government spending)</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic2-2.jpg" alt></p><h4 id="Adding-the-Rest-of-the-World"><a href="#Adding-the-Rest-of-the-World" class="headerlink" title="Adding the Rest of the World"></a>Adding the Rest of the World</h4><p>Y(GDP) = C(Consumption) + I(Income) + G(Government spending) + NX(Net Exports)</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic2-3.jpg" alt></p><h4 id="Funds-Flowing-through-the-Financial-System"><a href="#Funds-Flowing-through-the-Financial-System" class="headerlink" title="Funds Flowing through the Financial System"></a>Funds Flowing through the Financial System</h4><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic2-4.jpg" alt></p><p>The financial system channels funds from lenders to borrowers through intermediaries.</p><ul><li>In indirect finance, a financial institution takes the resources from the lender and then provides them to the borrower in the form of a loan (or the equivalent). </li><li>With direct finance an agent can invest in a firm directly (buying stock).</li></ul><p><strong>What other roles of Financial System</strong></p><ul><li>Channel Saving to investor</li><li>Redistribute Risks</li><li>Information related roles</li><li>Design related reasons</li></ul><h2 id="Unit-2-2：The-Government-and-Financial-Markets"><a href="#Unit-2-2：The-Government-and-Financial-Markets" class="headerlink" title="Unit 2.2：The Government and Financial Markets"></a>Unit 2.2：The Government and Financial Markets</h2><p><strong>Why do goverments invest?</strong></p><ul><li>Redistribute the consumption of the stream of income (timing of consumption). Government does not want to maximize profits (at least not always) but rather they want to maximize the wefare of everyone in the economy (This means investment in education, infrastructure, health system etc).</li></ul><h4 id="The-Government-Spending-Multiplier"><a href="#The-Government-Spending-Multiplier" class="headerlink" title="The Government Spending Multiplier"></a>The Government Spending Multiplier</h4><p><strong>Equilibrium</strong> in the Market for Goods and Services is represented by:</p><script type="math/tex; mode=display">Y = C (Y,t) + I (Y,r) + G + X - M (Y,e)</script><ul><li>$t$ : taxes</li><li>$r$ : interest rate</li><li>$X$ : export</li><li>$M$ : import</li><li>$e$ : exchange rate</li></ul><p>Take $I$, $X$ and $M$  to be exogenous for now. Then the government purchases multiplier is:</p><script type="math/tex; mode=display">\frac{dY}{dG}=\frac{1}{1-\frac{\partial C}{\partial Y}}</script><p>Which is greater than 1 if  $\partial C/\partial Y \in (0,1)$</p><p>Government spending is worthwhile if <strong>the increase in output is more than the increased interest cost</strong>.</p><p>Government expenditure would yield higher returns by <strong>increasing aggregate output in the future</strong>, which could make the cost of borrowing worthwhile.</p><ul><li>Health</li><li>Education (Human Capital)</li><li>Infrastructure</li><li>R&amp;D</li></ul><h4 id="A-little-model-of-government-and-debt"><a href="#A-little-model-of-government-and-debt" class="headerlink" title="A little model of government and debt"></a>A little model of government and debt</h4><p>Assume that the governments is running a balanced budget and that at t = 0, the government <strong>runs a one-off deficit</strong> by issuing one-period bonds:</p><script type="math/tex; mode=display">B_0=D>0</script><p>Let the governments run a balanced budget from t =1 forever, that is: </p><script type="math/tex; mode=display">T_t=G_t\ for\ all\ t=1,2,...</script><ul><li>Keeping Books Balance : Tax revenue = government expenditure</li></ul><p>Suppose that:</p><ul><li>The growth of taxes and expenditures is a constant, $g$.<ul><li>Think of $g$ as the rate of growth of the economy.</li></ul></li><li>Also, that the interest rate on government debt is a constant, $r$.</li></ul><p>If the government continues to run a balanced budget, the debt keeps accumulating:</p><script type="math/tex; mode=display">B_t=(1+r)^tD</script><p>Similarly, tax revenues (and expenditures) grow</p><script type="math/tex; mode=display">T_t=(1+g)^tT_0</script><h4 id="Sustainability-of-debt"><a href="#Sustainability-of-debt" class="headerlink" title="Sustainability of debt"></a>Sustainability of debt</h4><p>One way to think about the sustainability of the debt is the <strong>debt/revenue ratio</strong> (upper case gamma):</p><script type="math/tex; mode=display">\Gamma_t=\frac{B_t}{T_t}=(\frac{1+r}{1+g})^t\frac{D}{T_0}</script><p>We will define the growth rate of the debt/revenue ratio (lower case gamma) as:</p><script type="math/tex; mode=display">\gamma_t=\frac{\Gamma_t}{\Gamma_{t-1}}-1=\frac{1+r_t}{1+g}-1=\frac{r_t-g}{1+g}</script><p>So, if $g &gt; 0$</p><ul><li>If $r_t&gt;g$,$\gamma_t&gt;0$ - debt burden outpaces growth</li><li>If $r_t&lt;g$,$\gamma_t&lt;0$ - revenues grow faster than debt pile </li></ul><p>For a fixed growth rate of the economy (g), the sustainability of debt depends on the interest rate (rt).</p><ul><li><p>The interest rate is determined in Financial Markets.</p></li><li><p>Moreover, the size of the debt/revenue ratio may influence the interest rate.</p><ul><li>If $r_t&gt;g$, $\Gamma$ keeps growing for a long time, $r_t$ may go up, making the acceleration worse</li></ul></li></ul><h2 id="Unit-2-3：Classifying-Financial-Markets"><a href="#Unit-2-3：Classifying-Financial-Markets" class="headerlink" title="Unit 2.3：Classifying Financial Markets"></a>Unit 2.3：Classifying Financial Markets</h2><p>In terms of the <strong>broad type of financial instrument that is traded</strong> we can divide financial markets in the following categories:</p><ol><li>Deposit-Loan market</li><li>Money market</li><li>Securities (bond and equity) markets</li><li>Derivatives market</li><li>Foreign exchange market</li></ol><h4 id="1-Deposit-Loan-Market"><a href="#1-Deposit-Loan-Market" class="headerlink" title="(1) Deposit-Loan Market"></a>(1) Deposit-Loan Market</h4><p>Implicitly this market assumes a framework described by the following forces: </p><ul><li>A <strong>demand for loanable funds</strong> by those with a spending deficit.</li><li>A <strong>supply of loanable funds</strong> by those who wish to obtain some return on surplus funds (made available through different instruments).</li></ul><p>Where there is an imbalance between demand and supply, prices adjust to reestablish the equilibrium. Prices in this context are interest rates.</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic2-5.jpg" alt></p><ul><li><strong>Demand for loanable funds</strong> is planned investment, I(r), which is negatively related to the real interest rate r.</li><li><strong>Supply of loanable funds</strong> is national savings, S(Y) which we assume are not affected by r, but which increases with Y since $S = Y - C - T$ (assuming G = T ) or $S = ( Y - T - C ) + ( T - G ) =$ private savings + government savings</li></ul><p>Then if $S = I(r)$, the schedule also gives us all points at which the goods market is in equilibrium:</p><script type="math/tex; mode=display">S = Y - C - T = I(r) \Rightarrow Y = C + I(r) + G</script><p>The IS curve gives combinations of r and Y such at <strong>Investment (I) = Savings (S)</strong>. Hence its name, IS curve.</p><h4 id="2-Money-Market"><a href="#2-Money-Market" class="headerlink" title="(2) Money Market"></a>(2) Money Market</h4><p>The Money Market is for <strong>short term funds</strong>.</p><ul><li><p>This market clears (short term) surpluses and deficits among financial institutions.</p></li><li><p>In the traditional money market, banks are linked <strong>indirectly through the Central  Bank’s automated clearing house (ACM)</strong>.</p><ul><li>At the end of the day, all these transactions are cleared in the automated clearinghouse in the central bank.</li><li>And the corresponding balances are transferred between banks.</li></ul></li><li><p><strong>Inter-bank money</strong> market connect banks <strong>directly</strong>. </p><ul><li>lending money to other banks</li></ul></li><li><p>Central Bank <strong>transmits interest rate signals</strong> through the money market.</p></li></ul><h4 id="3-Security-Bond-and-Equity-Markets"><a href="#3-Security-Bond-and-Equity-Markets" class="headerlink" title="(3) Security (Bond and Equity) Markets"></a>(3) Security (Bond and Equity) Markets</h4><ul><li><strong>Primary markets for bonds and equity</strong> enable long term funding.<ul><li>Companies issue equity and (corporate) bonds to finance their projects and expansions.</li><li>The government issues (government) bonds to finance its budget deficit.</li></ul></li><li><strong>Secondary markets for equity and bonds</strong>.<ul><li>Provide liquidity.</li><li>Allow the values of shares and bonds to adjust according to demand and supply.</li></ul></li></ul><h4 id="4-Derivatives-Market"><a href="#4-Derivatives-Market" class="headerlink" title="(4) Derivatives Market"></a>(4) Derivatives Market</h4><p>A derivative is a financial instrument whose value depends on (is derived from) the value of some other financial instrument, known as the <strong>underlying asset</strong>.</p><ul><li>Derivatives help us to <strong>hedge (or speculate)</strong> against price movements in underlying assets.</li><li>There are many examples, including:<ul><li><strong>Forwards</strong> – private agreement to exchange at future date and price.</li><li><strong>Futures</strong> – standardized forward contracts traded in organized exchanges.</li><li><strong>Options</strong> – give the owner the right to buy (or sell) a financial instrument in the future at some specified price.</li><li><strong>Swaps</strong> – contracts that allow traders to transfer risk by exchanging financial instruments or cash flows in the future. </li></ul></li></ul><h4 id="5-Foreign-Exchange-Forex-Market"><a href="#5-Foreign-Exchange-Forex-Market" class="headerlink" title="(5) Foreign Exchange (Forex) Market"></a>(5) Foreign Exchange (Forex) Market</h4><p><strong>Foreign currencies are exchanged</strong> when goods and services are <strong>exported/imported</strong> and when capital flows across borders.</p><ul><li>The Forex market also allows foreign currency trading.<ul><li>Profits from arbitrage opportunities and speculation around future currency values.</li></ul></li><li>In the Forex market, the price of a currency is expressed in terms of another currency (<strong>exchange rates</strong>).<ul><li>Forex markets are driven by the demand and supply of foreign currencies.</li></ul></li><li>If exchange rates are <strong>floating</strong>, the price is determined by market forces<ul><li>Some <strong>currencies are pegged (tied) to another</strong>. Or governments may intervene to affect market exchange rates.</li></ul></li></ul><h2 id="Unit-2-4：The-Loanable-Funds-Model-for-a-Small-Open-Economy"><a href="#Unit-2-4：The-Loanable-Funds-Model-for-a-Small-Open-Economy" class="headerlink" title="Unit 2.4：The Loanable Funds Model for a Small Open Economy"></a>Unit 2.4：The Loanable Funds Model for a Small Open Economy</h2><h4 id="The-exchange-rate-and-fundamentals"><a href="#The-exchange-rate-and-fundamentals" class="headerlink" title="The exchange rate and fundamentals"></a>The exchange rate and fundamentals</h4><script type="math/tex; mode=display">Y = C + I + G + NX</script><ul><li>$NX = X -M$</li><li>$S = Y - C - G$</li></ul><p>so we have</p><ul><li>$S - I = NX$<ul><li>If $S - I &gt; 0$ then $NX &gt; 0$, we have a trade surplus</li><li>China, Germany are big savers, and have big trade surpluses.</li></ul></li></ul><p><strong>Assumption</strong>: Small open economy with perfect capital mobility.</p><ul><li>His implies that the domestic interest rate, r end up aligned to the world interest rate, r<em> (r = r</em>). </li><li>Under perfect capital mobility, any discrepancy between the domestic and the world interest rate triggers capital movements restoring the parity.</li></ul><h4 id="Revisiting-the-demand-for-loanable-funds-small-open-economy"><a href="#Revisiting-the-demand-for-loanable-funds-small-open-economy" class="headerlink" title="Revisiting the demand for loanable funds (small open economy)"></a>Revisiting the demand for loanable funds (small open economy)</h4><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic2-6.jpg" alt></p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic2-7.jpg" alt></p><h4 id="The-Nominal-Exchange-Rate"><a href="#The-Nominal-Exchange-Rate" class="headerlink" title="The Nominal Exchange Rate"></a>The Nominal Exchange Rate</h4><p>e =  nominal exchange rate, the relative price of <strong>domestic currency in terms of foreign currency</strong> (以外币为单位)</p><h4 id="The-Real-Exchange-Rate"><a href="#The-Real-Exchange-Rate" class="headerlink" title="The Real Exchange Rate"></a>The Real Exchange Rate</h4><p>$\epsilon$ = real exchange rate, the relative price of <strong>domestic goods in terms of foreign goods</strong> (e.g., German cars per British car)</p><script type="math/tex; mode=display">\epsilon = \frac{e\times P}{P^*}</script><ul><li>P : Domestic level of prices</li><li>P* : Level of prices in abroad</li></ul><p><strong>In the real world</strong>: We can think of $\epsilon$  as the relative price of a basket of domestic goods in terms of a basket of foreign goods.<br><strong>In our macro model</strong>: There’s just one good, “output.” So $\epsilon$  is the relative price of one country’s output in terms of the other country’s output</p><h4 id="How-epsilon-is-determined-If-uparrow-epsilon"><a href="#How-epsilon-is-determined-If-uparrow-epsilon" class="headerlink" title="How $\epsilon$ is determined (If $\uparrow \epsilon$ )"></a>How $\epsilon$ is determined (If $\uparrow \epsilon$ )</h4><ul><li>$\Rightarrow$ domestic goods become more expensive relative to foreign goods</li><li>$\Rightarrow \downarrow X,\uparrow M$</li><li>$\Rightarrow \downarrow NX$</li></ul><h4 id="Effects-of-Fiscal-Policy-in-the-Home-Country"><a href="#Effects-of-Fiscal-Policy-in-the-Home-Country" class="headerlink" title="Effects of Fiscal Policy in the Home Country"></a>Effects of Fiscal Policy in the Home Country</h4><p>$\downarrow S=Y-C-\uparrow G$</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic2-8.jpg" alt></p><h4 id="Effects-of-Fiscal-Policy-Abroad"><a href="#Effects-of-Fiscal-Policy-Abroad" class="headerlink" title="Effects of Fiscal Policy Abroad"></a>Effects of Fiscal Policy Abroad</h4><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic2-9.jpg" alt></p><h1 id="Topic-3-–-Interest-Rate-Determination-The-IS-LM-model"><a href="#Topic-3-–-Interest-Rate-Determination-The-IS-LM-model" class="headerlink" title="Topic 3 – Interest Rate Determination: The IS-LM model"></a>Topic 3 – Interest Rate Determination: The IS-LM model</h1><p><strong>Supplementary Reading</strong></p><p>Mankiw, N.G., Macroeconomics (2007, 2010, 2013, 2015, 2018), Ch. 11, 12 &amp; 14</p><h2 id="Unit-3-1：The-Short-Run-The-IS-and-LM-curves-and-the-model-equilibrium"><a href="#Unit-3-1：The-Short-Run-The-IS-and-LM-curves-and-the-model-equilibrium" class="headerlink" title="Unit 3.1：The Short Run: The IS and LM curves and the model equilibrium"></a>Unit 3.1：The Short Run: The IS and LM curves and the model equilibrium</h2><blockquote><p>在此部分 M 不代表进口，代表 money supply</p></blockquote><h3 id="The-IS-curve"><a href="#The-IS-curve" class="headerlink" title="The IS curve"></a>The IS curve</h3><p>(a) The loanable funds model with (b) The IS curve</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-1.jpg" alt></p><p>$ \downarrow S=\downarrow Y-C-G$ and $\uparrow r$</p><h3 id="The-LM-curve"><a href="#The-LM-curve" class="headerlink" title="The LM curve"></a>The LM curve</h3><p><strong>The Market for Money and the Theory of Liquidity Preference</strong></p><blockquote><p>A simple theory in which the interest rate is determined by money supply and money demand.  —- John Maynard Keynes</p></blockquote><p>The <strong>supply</strong> of real money balances is fixed:</p><script type="math/tex; mode=display">(\frac{M}{P})^s=\frac{\bar{M}}{\bar{P}}</script><p>where</p><ul><li>The price level $P=\bar{P}$ is fixed in the short run</li><li>The money supply $M=\bar{M}$ is an exogenous policy variable</li></ul><p>The <strong>demand</strong> of real money balances is a function of the real interest rate and income:</p><script type="math/tex; mode=display">(\frac{M}{P})^d=L(r,Y)</script><p>where we assume that</p><ul><li>$\frac{\partial L}{\partial r}&lt;0$ - higher rates mean less money demand<ul><li>Interest rate is opportunity cost of holding liquid assets (e.g., cash).</li></ul></li><li>$\frac{\partial L}{\partial Y}&gt;0$ - higher income means more money demand</li></ul><p><strong>Money Market Equilibrium</strong></p><p>Money market equilibrium, $(\frac{M}{P})^d=(\frac{M}{P})^s$</p><script type="math/tex; mode=display">L(r,Y)=\frac{\bar{M}}{\bar{P}}</script><p>For a given Y, the euqilibrium interest rate is that which equates supply and demand:</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-2.jpg" alt></p><p>The <strong>LM  curve</strong> is a graph of all combinations of r  and Y  that equate the supply and demand for real money balances.</p><p>The equation for the LM  curve is:</p><script type="math/tex; mode=display">(\frac{M}{P})^s=\frac{\bar{M}}{\bar{P}}=L(r,Y)</script><p><strong>Deriving the LM  curve</strong></p><p>(a) The market for real money balances (b) The LM curve</p><p>Since the supply of real money balances is fixed, there is now excess demand in the money market. </p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-3.jpg" alt></p><blockquote><p>r,Y 成反比，为了保持 L 不变，Y 增加 r 增加，线增高</p></blockquote><p>What happens if Money Supply M is reduced?</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-4.jpg" alt></p><h3 id="The-hidden-market-in-the-IS-LM-model"><a href="#The-hidden-market-in-the-IS-LM-model" class="headerlink" title="The hidden market in the IS-LM model"></a>The hidden market in the IS-LM model</h3><ul><li><p>The IS represents equilibrium in the <strong>goods market</strong>（$Y\uparrow,r \downarrow$） and the LM equilibrium in the <strong>money market</strong>（$Y\uparrow,r \uparrow$）.</p></li><li><p>But there is a third market in the model – the <strong>market for bonds</strong>.</p><ul><li>Walras’ Law says that if we have N markets, and N–1 are in equilibrium, then the Nth market must also be in equilibrium.</li></ul></li><li><p>The reduction in M comes about through OMOs (open market operations)</p><ul><li>The central bank sells government bonds on the open market.</li><li>The buyers of the bonds pay with cash, reducing the money supply.</li><li>Effectively <strong>the government is increasing the supply of bonds in the market</strong> (reducing the money supply $(\frac{M}{P})^s$). This <strong>reduces the price</strong> and <strong>increases the yield of bonds</strong> ($r \uparrow$).</li></ul></li></ul><p><strong>Bond Prices and Yield</strong></p><script type="math/tex; mode=display">Bond\ Price=\frac{100}{1+r}</script><script type="math/tex; mode=display">Yield\ i =r+E[Inflation]</script><p>where $\bar{P}\to E[Inflation]=0$</p><p><strong>What determines the slope of the LM?</strong></p><ul><li>The slope of the LM curve is determined by how sensitive is the demand for money to changes in the real interest rate.<ul><li>The more sensitive is L(r, Y) to changes in r, the flatter is the LM curve.</li><li>The less sensitive is L(r, Y) to changes in r, the steeper is the LM curve.</li></ul></li></ul><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-5.jpg" alt></p><p><strong>The short-run equilibrium</strong></p><script type="math/tex; mode=display">S(Y) = Y - C - G = I(r)</script><script type="math/tex; mode=display">\frac{\bar{M}}{\bar{P}}=L(r,Y)</script><p>The <strong>short-run equilibrium</strong> is the combination of <strong>r  and Y</strong> that simultaneously satisfies the equilibrium conditions in the <strong>goods and money markets</strong>. </p><h2 id="Unit-3-2：Fiscal-and-Monetary-Policy-in-the-Short-Run"><a href="#Unit-3-2：Fiscal-and-Monetary-Policy-in-the-Short-Run" class="headerlink" title="Unit 3.2：Fiscal and Monetary Policy in the Short Run"></a>Unit 3.2：Fiscal and Monetary Policy in the Short Run</h2><ul><li>We can use the IS-LM model to analyse the effects of<ul><li>Fiscal policy, G, T</li><li>Monetary policy, M</li></ul></li><li>We can also think about the short run and long run effects.<ul><li>Short run: prices are fixed </li><li>Long run: prices can change</li></ul></li></ul><h4 id="Expansionary-monetary-policy-–-increase-in-M"><a href="#Expansionary-monetary-policy-–-increase-in-M" class="headerlink" title="Expansionary monetary policy – increase in M"></a>Expansionary monetary policy – increase in M</h4><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-6.jpg" alt></p><ul><li>LM shifts down $\to$ reduces r at original Y</li><li>Once r fall, investment increases by I(r)</li><li>Investment increases causes Y to go up</li><li>Higher Y causes higher S(Y)</li></ul><p><strong>Effectiveness of monetary policy</strong></p><ol><li>Slope of the LM<ul><li>The less sensitive $M^d$ is to r, the steeper is LM</li></ul></li><li>Slope of the IS<ul><li>The more sensitive I is to r, the flatter the IS curve</li></ul></li><li>Zero lower bound<ul><li>There needs to be room for r to drop. If is already close to zero, it cannot fall further to stimulate the required increase in I</li></ul></li></ol><p><strong>Other factors</strong></p><ul><li>The example is in closed economy. If we open the monetary policy, exchange rate are start to interrupt. </li></ul><h4 id="Expansionary-fiscal-policy"><a href="#Expansionary-fiscal-policy" class="headerlink" title="Expansionary fiscal policy"></a>Expansionary fiscal policy</h4><h5 id="–-increase-in-G-or-decrease-in-T"><a href="#–-increase-in-G-or-decrease-in-T" class="headerlink" title="– increase in G, or decrease in T"></a>– increase in G, or decrease in T</h5><p>Recall spending multiplier</p><script type="math/tex; mode=display">\frac{dY}{dG}=\frac{1}{1-\frac{\partial C}{\partial Y}}</script><p>IS curve shifts to right by an amount greater than $\Delta G$ if $\frac{\partial C}{\partial Y}\in (0,1)$</p><ul><li>For a given r, higher Y increase money demend</li><li>given $\bar{M}$ and $\bar{P}$, this means a higher interest rate</li><li>Higher interest rate reduce I, depressing Y<ul><li>Crowding out (刺激消费)</li></ul></li></ul><p><strong>Effectiveness of fiscal policy</strong></p><ol><li><p>Marginal propensity to consume determines spending multiplier (higher MPC means larger shift to IS)</p></li><li><p>Slope of IS</p><ul><li><p>Sensitivity of investment to r determines</p></li><li><p>Determines extent of direct crowding out</p></li></ul></li><li><p>Slope of LM</p><ul><li>Sensitivity of money demand to r</li><li>A higher r for equilibrium in money market crowds out more investment</li></ul></li></ol><p><strong>Other factors</strong></p><ul><li>How easy is it to increase government spending? Cost of borrowing? Resistance to taxes?</li></ul><h2 id="Unit-3-3：Using-the-IS-LM-Model-to-Inform-Policy-in-the-Short-Run"><a href="#Unit-3-3：Using-the-IS-LM-Model-to-Inform-Policy-in-the-Short-Run" class="headerlink" title="Unit 3.3：Using the IS-LM Model to Inform Policy in the Short Run"></a>Unit 3.3：Using the IS-LM Model to Inform Policy in the Short Run</h2><h4 id="Effect-of-Shocks-on-the-Economy"><a href="#Effect-of-Shocks-on-the-Economy" class="headerlink" title="Effect of Shocks on the Economy"></a>Effect of Shocks on the Economy</h4><p><strong>LM</strong>：shocks to $M^d$</p><ul><li>A wave of credit card fraud increases demand for cash</li><li>Financial innovation, or online shopping reduces demand for cash</li><li>Confidence in the banking industry shifts</li></ul><p><strong>IS</strong>：shocks to I, C</p><ul><li>Asset price boom that increase consumption</li><li>Increase in business confidence that increase investment</li><li>Inproved consumer confidence</li></ul><h4 id="Policy-Objectives"><a href="#Policy-Objectives" class="headerlink" title="Policy Objectives"></a>Policy Objectives</h4><ul><li>Targeting an interest rate but keep output constant</li><li>Respond to an economic downturn without increasing spending</li><li>Decrease money supply without changing output</li></ul><p><strong>Targeting r</strong></p><p>Using monetary policy to reduce interest rate to a target level $\bar{r}$</p><ul><li>CB needs to sufficiently increase $\bar{M}$</li><li>Result also in Y increasing </li></ul><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-7.jpg" alt></p><p><strong>Response to a demand shock</strong></p><ul><li>Fiscal response to an asset shock that causes Y to fall</li></ul><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-8.jpg" alt></p><p><strong>Sometimes fiscal policy may be constrained</strong></p><p>Policy makers may not want to use fiscal policy （increase taxes） because of the repercussion on budget deficit</p><ul><li>Expansionary monetary policy restores Y but causes r to fall even further</li></ul><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-9.jpg" alt></p><h2 id="Unit-3-4：The-Long-Run-The-AD-and-AS-curves-and-the-model-equilibrium"><a href="#Unit-3-4：The-Long-Run-The-AD-and-AS-curves-and-the-model-equilibrium" class="headerlink" title="Unit 3.4：The Long Run: The AD and AS curves and the model equilibrium"></a>Unit 3.4：The Long Run: The AD and AS curves and the model equilibrium</h2><h3 id="Aggregate-Demand-AD"><a href="#Aggregate-Demand-AD" class="headerlink" title="Aggregate Demand (AD)"></a>Aggregate Demand (AD)</h3><script type="math/tex; mode=display">L(r,Y)=\frac{\bar{M}}{P}</script><ul><li>Increase in P causes a fall in real money balances</li></ul><p><strong>Deriving the AD curve</strong></p><ul><li>$\uparrow P\Rightarrow\downarrow(M/P)\Rightarrow LM shifts left\Rightarrow\uparrow r\Rightarrow\downarrow I\Rightarrow\downarrow Y$</li></ul><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-10.jpg" alt></p><h3 id="Aggregate-Supply-AS"><a href="#Aggregate-Supply-AS" class="headerlink" title="Aggregate Supply (AS)"></a>Aggregate Supply (AS)</h3><p>The short-run Aggregate Supply (SRAS) curve</p><ul><li>P is either fixed or moves slowly</li><li>Output can fluctuate around its full employment level ($\bar{Y}$)</li></ul><p>The long-run Aggregate Supply (LRAS) curve</p><ul><li>Captures the long run Aggregate Supply where the price level P varies to achieve full employment level $\bar{Y}$</li></ul><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-11.jpg" alt></p><h4 id="Expansionary-fiscal-policy-in-the-short-and-long-run"><a href="#Expansionary-fiscal-policy-in-the-short-and-long-run" class="headerlink" title="Expansionary fiscal policy in the short and long run"></a>Expansionary fiscal policy in the short and long run</h4><h5 id="–-increase-in-G"><a href="#–-increase-in-G" class="headerlink" title="– increase in G"></a>– increase in G</h5><p>Starting from $\bar{Y}$. Short run</p><ul><li>IS shifts to right</li><li>AD shifts to right</li><li>P is fixed, so output increases to $Y&gt;\bar{Y}$</li></ul><p>Over time</p><ul><li>Because $Y’&gt;\bar{Y}$, prices go up</li><li>SRAS shifts up</li><li>Movement along AD by real money balances declining (LM shifts left)</li></ul><p>Long run outcome</p><ul><li>Output returns to $\bar{Y}$</li><li>Prices now higher</li><li>Interest rates higher (all of increase in G reduces I)</li></ul><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-12.jpg" alt></p><h4 id="Expansionary-monetary-policy-in-the-short-and-long-run"><a href="#Expansionary-monetary-policy-in-the-short-and-long-run" class="headerlink" title="Expansionary monetary policy in the short and long run"></a>Expansionary monetary policy in the short and long run</h4><h5 id="–-increase-in-M"><a href="#–-increase-in-M" class="headerlink" title="– increase in M"></a>– increase in M</h5><p>Short run</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-13.jpg" alt></p><p>$Y_2&gt;\bar{Y}\Rightarrow\uparrow P$</p><p>Long run</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-14.jpg" alt></p><h2 id="Topic-2-3-总结"><a href="#Topic-2-3-总结" class="headerlink" title="Topic 2-3 总结"></a>Topic 2-3 总结</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><ul><li>Y : GDP</li><li>C ( Y , t ) : Consumption</li><li>I ( Y , r ) : Investment</li><li>G : Government purchases</li><li>NX : Net Exports</li><li>X : Export</li><li>M ( Y , e ) : Import</li><li>$\bar{M}$ : Money supply</li><li>P : Price</li><li>S ( Y ) : Saving/ Supply of loanable Funds</li><li>L ( Y , r ) : Demand of real money</li><li>T/t : Taxes</li><li>r : Interest rate</li><li>e : Exchange rate</li><li>$\epsilon$ : Real Exchange rate</li></ul><script type="math/tex; mode=display">Y=C+I+G+NX</script><script type="math/tex; mode=display">NX=X-M</script><script type="math/tex; mode=display">S=(Y-T-C)+(T-G)=Y-C-G</script><script type="math/tex; mode=display">S-I=NX</script><script type="math/tex; mode=display">\epsilon = \frac{e\times p}{p^*}</script><script type="math/tex; mode=display">\frac{\bar{M}}{\bar{P}}=(\frac{M}{P})^s=(\frac{M}{P})^d=L(Y,r)</script><script type="math/tex; mode=display">AD: \frac{\bar{M}}{P}=L(Y,r),\ 此处P是变动的</script><ul><li><p>Expansionary Fiscal Policy : $T\downarrow G\uparrow$</p></li><li><p>Expansionary monetary Policy : $M\uparrow$</p></li><li><p>Demand Shock $\to$ Price boom $\to$ $C\uparrow$</p></li></ul><div class="table-container"><table><thead><tr><th><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-15.jpg" alt></th><th><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-16.jpg" alt></th></tr></thead><tbody><tr><td></td><td><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-19.jpg" alt></td></tr><tr><td><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-17.jpg" alt></td><td><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-18.jpg" alt></td></tr><tr><td></td><td><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic3-19.jpg" alt></td></tr></tbody></table></div><p>(1)$Y\uparrow$，S右移;</p><p>(1)S左移，$r\uparrow$;</p><p>(2)$r\uparrow$，IS中$Y\downarrow$;</p><p>(1)S中非Y变换会导致它偏移;</p><p>(3)$Y\uparrow$，L(Y,r) 右移;</p><p>(3)L(Y,r)右移，$r\uparrow$;</p><p>(4)$r\uparrow$，LM中$Y\uparrow$;</p><p>(3/4)$\frac{\bar{M}}{\bar{P}}$左移，$r\uparrow$，此时考虑L(Y,r)不变，即Y不变，LM左移;</p><p>(5)$Y\uparrow$, 短时AD右移，过度SRAS上移，长时$Y$恢复$P\uparrow r\uparrow\uparrow$；</p><h1 id="Topic-4-–-Money-and-Interest-Rates-in-an-OLG-model"><a href="#Topic-4-–-Money-and-Interest-Rates-in-an-OLG-model" class="headerlink" title="Topic 4 – Money and Interest Rates in an OLG model"></a>Topic 4 – Money and Interest Rates in an OLG model</h1><p><strong>Supplementary Reading</strong></p><p>For a standard exposition of the OLG model see:</p><ul><li>Romer, D., Advanced Macroeconomics, Ch. 2 (2006, 2011 or 2017).</li></ul><p>More advanced, but closer to our discussion: </p><ul><li>Blanchard and Fischer (1989) Lectures in Macroeconomic, MIT Press, Sections 4.1 and 5.2.</li></ul><blockquote><p>相似的有 <a href="https://www.bilibili.com/video/BV18b411b7pu">耶鲁大学：金融理论</a> 讲了费雪的不耐定理和用养老保险金为例子讲了世代交叠模型</p></blockquote><h2 id="Unit-4-1：The-Economy-as-an-Overlapping-Generations-of-Agents"><a href="#Unit-4-1：The-Economy-as-an-Overlapping-Generations-of-Agents" class="headerlink" title="Unit 4.1：The Economy as an Overlapping Generations of Agents"></a>Unit 4.1：The Economy as an Overlapping Generations of Agents</h2><p>In the last couple of weeks we have looked at models that were based on macroeconomic variables.</p><p>This week we look at interest rates here as a result of preferences and interesting generational dynamics.</p><h3 id="A-Simple-OLG-Model"><a href="#A-Simple-OLG-Model" class="headerlink" title="A Simple OLG Model"></a>A Simple OLG Model</h3><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic4-1.jpg" alt></p><p>We assume there is a single commodity which is <strong>perishable</strong>. (Can not be conserve)</p><p>An OLG set-up thus brings useful features</p><ul><li>Life-cycle dynamics, interfenerational features</li><li>Savings and investment</li><li>A role for fiat money</li></ul><h4 id="Endowments-and-Consumption"><a href="#Endowments-and-Consumption" class="headerlink" title="Endowments and Consumption"></a>Endowments and Consumption</h4><p>Each generation born at t will receive an endowment $\omega_y$ when young and $\omega_o$ when old</p><ul><li>There is no other form of producing the consumption good</li><li>The endowment cannot be stored or transferred</li></ul><div class="table-container"><table><thead><tr><th>Agents born in generation t</th><th>Endowment (Wealth)</th><th>Consumption</th></tr></thead><tbody><tr><td>Young</td><td>$\omega_y$</td><td>$c_y$</td></tr><tr><td>Old</td><td>$\omega_o$</td><td>$c_o$</td></tr></tbody></table></div><p>The simplest type of equilibrium:</p><script type="math/tex; mode=display">c_y=\omega_y,\ c_o=\omega_o</script><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic4-2.jpg" alt></p><h4 id="If-agents-would-be-able-to-save"><a href="#If-agents-would-be-able-to-save" class="headerlink" title="If agents would be able to save"></a>If agents would be able to save</h4><ul><li>Savings opportunity exist at 5% interest rate.</li><li>Agents would like to ‘smooth’ their consumption.</li></ul><p>If the endowments are the following</p><script type="math/tex; mode=display">\omega_y=80,\ \omega_o=20</script><p>And assuming agents save 1/4 of their endowment when young</p><script type="math/tex; mode=display">c_y=80-\frac{1}{4}80=60,\ c_o=20+\frac{1}{4}80(1+0.05)=41</script><h2 id="Unit-4-2：Preferences-Interest-Rates-and-Optimization"><a href="#Unit-4-2：Preferences-Interest-Rates-and-Optimization" class="headerlink" title="Unit 4.2：Preferences, Interest Rates and Optimization"></a>Unit 4.2：Preferences, Interest Rates and Optimization</h2><p>Agents <strong>maximize their lifetime utility</strong> subject to their lifetime budget constraint</p><ul><li>Lifetime utility</li></ul><script type="math/tex; mode=display">U=U(c_y,c_o)</script><ul><li>Lifetime budget constraint</li></ul><script type="math/tex; mode=display">c_y+\frac{c_o}{1+r}=\omega_y+\frac{\omega_o}{1+r}=\Omega</script><p>(Present Value of Consumption = Present Value of Wealth)</p><h4 id="Indifference-Curves-无差异曲线"><a href="#Indifference-Curves-无差异曲线" class="headerlink" title="Indifference Curves (无差异曲线)"></a>Indifference Curves (无差异曲线)</h4><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic4-3.jpg" alt></p><p>Shape and position of indifference curves indicate <strong>consumer preferences</strong></p><p>Movements onto <strong>higher indifference curves</strong> indicate <strong>higher utility</strong></p><blockquote><p>同一条线上 Utility 相同，越高越好</p></blockquote><p>If an agent decide to save <strong>all</strong> his/her endowment when young</p><script type="math/tex; mode=display">\frac{c_o}{1+r}=\Omega\Rightarrow c_o=(1+r)\Omega</script><p>Or he/she borrow his/her endowment when old and consume all when young</p><script type="math/tex; mode=display">c_y=\Omega</script><h4 id="The-Lifetime-Budget-Constraint"><a href="#The-Lifetime-Budget-Constraint" class="headerlink" title="The Lifetime Budget Constraint"></a>The Lifetime Budget Constraint</h4><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic4-4.jpg" alt></p><h4 id="Optimal-consumption-borrower"><a href="#Optimal-consumption-borrower" class="headerlink" title="Optimal consumption: borrower"></a>Optimal consumption: borrower</h4><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic4-5.jpg" alt></p><blockquote><p>低收益的学生可以通过贷款让C达到更高的U</p></blockquote><h4 id="Optimal-consumption-saver"><a href="#Optimal-consumption-saver" class="headerlink" title="Optimal consumption: saver"></a>Optimal consumption: saver</h4><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic4-6.jpg" alt></p><blockquote><p>高收益的教授可以通过存款让C达到更高的U</p></blockquote><h4 id="The-Consumer’s-Optimization-Problem"><a href="#The-Consumer’s-Optimization-Problem" class="headerlink" title="The Consumer’s Optimization Problem"></a>The Consumer’s Optimization Problem</h4><p>Maximise lifetime utility subject to the lifetime budget constraint:</p><script type="math/tex; mode=display">\max_{c_y,c_o} U=ln(c_y)+ln(c_o)</script><script type="math/tex; mode=display">s.t.\ c_y+\frac{c_o}{1+r}=\omega_y+\frac{\omega_o}{1+r}</script><p>Notice that we can also write this problem as:</p><script type="math/tex; mode=display">\max_{c_y,c_o} U=ln(c_y)+ln(c_o)</script><script type="math/tex; mode=display">\begin{align}s.t.\ &\omega_y-s=c_y \quad \qquad ,(1st\ period\ budget\ constraint)\\&\omega_o+(1+r)s=c_o ,(2nd\ period\ budget\ constraint)\end{align}</script><blockquote><p>用这个式子直接代入用 s 消掉 c，然后对 s 直接求导也是可以的</p></blockquote><p>In this setting, $\omega_y,\omega_o$​ and $r$​ are all exogenous</p><p>Solving for $c_o$ in the lifetime budget constraint we have:</p><script type="math/tex; mode=display">\omega_o+(1+r)(\omega_y-c_y)=c_o</script><p>and then substitute for $C_o$ in the utility function</p><script type="math/tex; mode=display">\max_{c_y,c_o} U=ln(c_y)+ln(\omega_o+(1+r)(\omega_y-c_y))</script><p>After some maths, </p><script type="math/tex; mode=display">\begin{align}\frac{dU}{dc_y}&=\frac{1}{c_y}+\frac{1}{\omega_o+(1+r)(\omega_y-c_y)}(-(1+r))=0\\&\Rightarrow \frac{1}{c_y}=\frac{1+r}{\omega_o+(1+r)(\omega_y-c_y)}\\(1&+r)c_y=\omega_o+(1+r)(\omega_y-c_y)\\&\qquad c_y=\frac{\omega_o}{1+r}+\omega_y-c_y\\&\qquad c_y=\frac{1}{2}(\frac{\omega_o}{1+r}+\omega_y)\\\end{align}</script><p>optimal consumption when young is</p><script type="math/tex; mode=display">c_y=\frac{1}{2}(\frac{\omega_o}{1+r}+\omega_y)</script><p>and since $s=\omega_y-c_y$, we can see that $r\uparrow$ means $s\uparrow$</p><h2 id="Unit-4-3：Interest-Rate-Determination"><a href="#Unit-4-3：Interest-Rate-Determination" class="headerlink" title="Unit 4.3：Interest Rate Determination"></a>Unit 4.3：Interest Rate Determination</h2><script type="math/tex; mode=display">u=(1+r)s</script><p>This is the <strong>marginal rate of transformation</strong> (MRT)</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic4-7.jpg" alt></p><h4 id="The-offer-curve-based-on-preferences"><a href="#The-offer-curve-based-on-preferences" class="headerlink" title="The offer curve (based on preferences)"></a>The offer curve (based on preferences)</h4><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic4-8.jpg" alt></p><blockquote><p>考虑了价值</p></blockquote><p><strong>Features of a regular offer curve</strong></p><ul><li>Crosses origin</li><li>Upward sloping</li></ul><p><strong>This is a combination of two effect</strong></p><ul><li>Substitution effect<ul><li>When r increases, $c_o$​​ become ‘cheaper’ (rather than consum when young - oppotunity cost)（以后的东西更加便宜）</li></ul></li><li>Income effect<ul><li>When r increases, saving will earn more so the agent can save less and increase both $c_y$ and $c_o$ (总资产增加)</li></ul></li></ul><p><strong>Combination</strong></p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic4-9.jpg" alt></p><ul><li>In a regular offer curve, the substitution effect dominates the income effect, so saving increase in interest rate</li><li>If the income effect dominates at some level of interest, we can have a backward sloping offer curve</li></ul><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic4-10.jpg" alt></p><h4 id="The-steady-state"><a href="#The-steady-state" class="headerlink" title="The steady state"></a>The steady state</h4><p>A steady state equilibrium is one that is stable over time. All agents face the same problem, so perhaps they always consume and save the same amounts.</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic4-11.jpg" alt></p><p>For each of these steady state allocations require a <strong>0% interest rate</strong> for each generation to behave the same</p><p>The <strong>optimal point</strong> at intersection point</p><h2 id="Unit-4-4：Adding-Money-to-the-Model"><a href="#Unit-4-4：Adding-Money-to-the-Model" class="headerlink" title="Unit 4.4：Adding Money to the Model"></a>Unit 4.4：Adding Money to the Model</h2><p>Solving the issue of the saving-payoff transfer by introducing ‘bits’ of paper</p><ul><li>Intrinsically worthless bits of paper</li><li>It is liquid and tradeable</li><li>They can exchange it and it can imply a price of goods<ul><li><strong>Price of goods is supply of money divided by quantity of goods traded</strong></li></ul></li></ul><p>A feature of the OLG model with money is that it can have many equilibria. We can also find the non-steady state equilibria (optimal but prices changing).</p><p>Consider point <strong>B</strong> on the offer curve</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic4-12.jpg" alt></p><ul><li>$s=8.3, u=7.9$</li><li>$p_{t=0}=1/8.3=0.1205$</li><li>$p_{t=1}=1/7.9=0.1261$</li></ul><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic4-13.jpg" alt></p><p>What is happing to price over time</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic4-14.jpg" alt></p><p>If $r&lt;0$</p><ul><li>$s\downarrow, u\downarrow, p\uparrow$</li><li>r通常为正</li></ul><h1 id="Topic-5-–-Determinants-of-Firm-Value-Part-I-：Present-Value-Competition-and-Monopoly"><a href="#Topic-5-–-Determinants-of-Firm-Value-Part-I-：Present-Value-Competition-and-Monopoly" class="headerlink" title="Topic 5 – Determinants of Firm Value (Part I)：Present Value, Competition and Monopoly"></a>Topic 5 – Determinants of Firm Value (Part I)：Present Value, Competition and Monopoly</h1><p><strong>Supplementary Reading</strong></p><p>For the corporate finance aspects of the lecture see:</p><ul><li>Hillier, D., Ross, S., Westerfield, R., Jaffe, J., Jordan, B. (2020) Corporate Finance, 4th Edition, McGraw Hill, Ch. 5.</li></ul><p>For the economics aspects of the lecture see: </p><ul><li>Mankiw, N.G., Taylor, M.P (2020) Economics, 5th Edition, CENGAGE, Ch. 10-11.</li></ul><h2 id="Unit-5-1：Bond-Valuation"><a href="#Unit-5-1：Bond-Valuation" class="headerlink" title="Unit 5.1：Bond Valuation"></a>Unit 5.1：Bond Valuation</h2><p>Securities issued by <strong>corporations</strong> can be roughly classified as <strong>equity securities (stocks)</strong> and <strong>debt securities (bonds)</strong>.</p><p>From a financial point of view the <strong>main differences</strong> between equity and debt are the following:</p><ol><li><p><strong>Debt is not an ownership interest in the firm</strong>. In contrast, if you buy equity (by definition) you are getting a portion of the company.</p></li><li><p>The corporation’s <strong>payment of interest on debt</strong> is considered a cost of doing business, and is <strong>fully tax-deductible</strong>. Dividends paid to shareholders are not deductible.</p><blockquote><p>就相当于，debt是对于外部的欠款，需要计入账中。Shareholders相当于自己人，内部分红</p></blockquote></li><li><p><strong>Unpaid debt is a liability of the firm</strong>. If it is not paid, creditors can legally claim the assets of the firm. This possibility does not arise when equity is issued.</p><blockquote><p>bonds 的收益是固定的，而 stocks 因为贬值而没有分红是正常的</p></blockquote></li></ol><h4 id="What-is-a-Bond"><a href="#What-is-a-Bond" class="headerlink" title="What is a Bond?"></a>What is a Bond?</h4><p>A bond is a <strong>fixed-income security</strong> that is issued in connection with a borrowing (or debt) arrangement. </p><p>Some important <strong>terms</strong>:</p><ul><li><p>Coupon Payments ( C ): flow of interest payments (bond payoffs).</p></li><li><p>Face value (or par value) ( 100 ): Principal amount of the bond at maturity.</p></li><li><p>Coupon rate: Percentage of the face value that is paid as coupon payment.</p></li><li><p>Maturity ( T ) : The specified date on which the principal amount of a bond is paid.</p></li><li><p>Yield to maturity (YTM) ( r ) : The rate required in the market on a bond. It is expressed in annual terms.</p><blockquote><p>通常是名义利率</p><p>实际=名义-通货膨胀</p></blockquote></li></ul><h4 id="Bond-Value-Formula"><a href="#Bond-Value-Formula" class="headerlink" title="Bond Value Formula"></a>Bond Value Formula</h4><script type="math/tex; mode=display">Bond\ Value=C\times[\frac{1-\frac{1}{(1+r)^t}}{r}]+\frac{Face\ Value}{(1+r)^t}</script><ul><li>$\uparrow r\Rightarrow \downarrow Value$</li></ul><h2 id="Unit-5-2：The-Not-So-Easy-Task-of-Finding-the-Value-of-a-Stock"><a href="#Unit-5-2：The-Not-So-Easy-Task-of-Finding-the-Value-of-a-Stock" class="headerlink" title="Unit 5.2：The Not-So-Easy Task of Finding the Value of a Stock"></a>Unit 5.2：The Not-So-Easy Task of Finding the Value of a Stock</h2><h4 id="What-is-a-Stock"><a href="#What-is-a-Stock" class="headerlink" title="What is a Stock?"></a>What is a Stock?</h4><p>A stock is a <strong>share in the ownership of a corporation</strong>.  It represents a claim on the company’s assets and earnings. There are two types: <strong>ordinary equity</strong> and <strong>preference shares</strong>.</p><ul><li>Ordinary Equity (普通股)<ul><li>Equity without priority for dividends, or in a bankruptcy</li></ul></li><li>Preference Shares (优先股)<ul><li>Equity with dividend priority over ordinary stocks, normally with a fixed dividend rate, normally without voting rights.</li></ul></li></ul><h4 id="The-Cash-Flow-Model"><a href="#The-Cash-Flow-Model" class="headerlink" title="The Cash Flow Model"></a>The Cash Flow Model</h4><p>We need to calculate to present value of the future cash flows of a stock to find its price.</p><p>Unfortunately, this is <strong>not straightforward</strong> for the following reasons:</p><ul><li>We do not know the <strong>future cash flows</strong> of a stock.<ul><li>In bond valuation we know the coupon payments and face value.</li></ul></li><li>In theory, a stock <strong>can last forever</strong>, we do not know the life of the investment<ul><li>In bond valuation, time to maturity is given.</li></ul></li><li>It is not easy to observe the <strong>required rate of return in the market</strong>.<ul><li>In bond valuation, the YTM can be calculated using bond market prices.</li></ul></li></ul><h4 id="Cash-Flow-Valuation-t-periods-holding-stock"><a href="#Cash-Flow-Valuation-t-periods-holding-stock" class="headerlink" title="Cash Flow Valuation t-periods-holding stock"></a>Cash Flow Valuation t-periods-holding stock</h4><script type="math/tex; mode=display">p_0=\frac{D_1}{1+r}+\frac{D_2}{(1+r)^2}+...+\frac{D_t+P_t}{(1+r)^t}</script><ul><li>The <strong>difficulty</strong> is knowing the price of the stock in the end period, which is normally not possible.</li></ul><h4 id="The-Dividend-Discount-Model"><a href="#The-Dividend-Discount-Model" class="headerlink" title="The Dividend Discount Model"></a>The Dividend Discount Model</h4><p>We can extend the cash flow approach for an <strong>infinite stream of dividends</strong> and no future final sale price.</p><script type="math/tex; mode=display">p_0=\frac{D_1}{1+r}+\frac{D_2}{(1+r)^2}+...</script><h2 id="Unit-5-3：Special-Cases-of-the-Dividend-Discount-Model"><a href="#Unit-5-3：Special-Cases-of-the-Dividend-Discount-Model" class="headerlink" title="Unit 5.3：Special Cases of the  Dividend Discount Model"></a>Unit 5.3：Special Cases of the  Dividend Discount Model</h2><h4 id="Dividends-with-Zero-Growth"><a href="#Dividends-with-Zero-Growth" class="headerlink" title="Dividends with Zero-Growth"></a>Dividends with Zero-Growth</h4><script type="math/tex; mode=display">p_0=\frac{D}{1+r}+\frac{D}{(1+r)^2}+...</script><p>We have already seen this case when we studied ordinary perpetuities</p><script type="math/tex; mode=display">P_0=\frac{D}{r}</script><h4 id="Dividends-with-Constant-Growth-g"><a href="#Dividends-with-Constant-Growth-g" class="headerlink" title="Dividends with Constant-Growth (g)"></a>Dividends with Constant-Growth (g)</h4><script type="math/tex; mode=display">\begin{align}p_0&=\frac{D_1}{1+r}+\frac{D_2}{(1+r)^2}+\frac{D_3}{(1+r)^3}+...\\&=\frac{D_0(1+g)}{1+r}+\frac{D_0(1+g)^2}{(1+r)^2}+\frac{D_0(1+g)^3}{(1+r)^3}+...\end{align}</script><p>We have also seen this case when we studied growing perpetuities</p><script type="math/tex; mode=display">P_0=\frac{D_0(1+g)}{r-g}=\frac{D_1}{r-g}</script><h4 id="Dividends-with-Non-Constant-Growth"><a href="#Dividends-with-Non-Constant-Growth" class="headerlink" title="Dividends with Non-Constant Growth"></a>Dividends with Non-Constant Growth</h4><script type="math/tex; mode=display">p_0=\frac{D_1}{1+r}+\frac{D_2}{(1+r)^2}+\frac{P_3}{(1+r)^3}</script><h4 id="Where-does-“g”-come-from"><a href="#Where-does-“g”-come-from" class="headerlink" title="Where does “g” come from?"></a>Where does “g” come from?</h4><script type="math/tex; mode=display">\begin{align}\begin{matrix}Earnings\\next\ year\end{matrix}=\begin{matrix}Earnings\\this\ year\end{matrix}+&\underbrace{\begin{matrix}Retained\\earnings\\this\ year\end{matrix}\times\begin{matrix}Return\ on\\retained\\earnings\end{matrix}}\\&\ \ Increase\ in\ earnings\end{align}</script><p>Dividing by Earnings this year both sides</p><script type="math/tex; mode=display">\begin{align}\frac{Earnings\ next\ year}{Earnings\ this\ year}&=\frac{Earnings\ this\ year}{Earnings\ this\ year}+\frac{Retained\ earnings\ this\ year}{Earnings\ this\ year}\times\begin{matrix}Return\ on\\retained\ earnings\end{matrix}\\1+g&=1+Retention\ ratio\times\begin{matrix}Return\ on\ retained\ earnings\end{matrix}\\g&=Retention\ ratio\times\begin{matrix}Return\ on\\retained\ earnings\end{matrix}\end{align}</script><h4 id="Where-does-“r”-come-from"><a href="#Where-does-“r”-come-from" class="headerlink" title="Where does “r” come from?"></a>Where does “r” come from?</h4><script type="math/tex; mode=display">r=\frac{D_1}{P_0}+g</script><script type="math/tex; mode=display">Dividend\ Yield+Capital\ Gains=Total\ Return</script><ul><li><p>Dividend Yield</p><ul><li>Expected cash dividend divided by its current price</li></ul></li><li><p>Capital Gains</p><ul><li>Expected Stock price Appreciation</li></ul></li></ul><h4 id="Dividends-vs-Capital-Gains"><a href="#Dividends-vs-Capital-Gains" class="headerlink" title="Dividends vs. Capital Gains"></a>Dividends vs. Capital Gains</h4><p>The value of an equity is £100. The company earns £100 extra in cash. What is the investor’s portfolio at t =1? </p><div class="table-container"><table><thead><tr><th>100% Dividends</th><th>0% Dividends</th><th>50% Dividends</th></tr></thead><tbody><tr><td>$P_1$ = £100</td><td>$P_1$ = £200</td><td>$P_1$ = £150</td></tr><tr><td>g = 0</td><td>g = 1</td><td>g = 1/2</td></tr><tr><td>$D_1$ = £100</td><td>$D_1$ = £0</td><td>$D_1$ = £50</td></tr><tr><td>Total = £200</td><td>Total = £200</td><td>Total = £200</td></tr><tr><td>Dividend Yield = 1</td><td>Dividend Yield = 0</td><td>Dividend Yield = 1/2</td></tr></tbody></table></div><p>r = (£200 - £100)/£100 = 1 = Dividend Yield + g</p><h2 id="Unit-5-4：The-Value-of-the-Firm"><a href="#Unit-5-4：The-Value-of-the-Firm" class="headerlink" title="Unit 5.4：The Value of the Firm"></a>Unit 5.4：The Value of the Firm</h2><h4 id="Growth-Opportunities"><a href="#Growth-Opportunities" class="headerlink" title="Growth Opportunities"></a>Growth Opportunities</h4><h5 id="Cash-Cows-vs-Growing-Companie"><a href="#Cash-Cows-vs-Growing-Companie" class="headerlink" title="Cash Cows vs. Growing Companie"></a>Cash Cows vs. Growing Companie</h5><p><strong>Earnings per share</strong> (EPS) can be split into <strong>dividends</strong> (DPS) and <strong>retained earnings</strong></p><script type="math/tex; mode=display">EPS = \frac{Earnings}{Number\ of\ Shares}</script><ul><li><p>100% Dividends</p><ul><li>EPS = DPS</li><li>Share price = EPS/r = DPS/r</li><li>Value of the firm without any additional reinvestment</li></ul></li><li><p>0% Dividends</p><ul><li>All EPS is reinvested in firm</li><li>Dividends = £0</li><li>Share price = EPS/r + NPVGO</li><li>NPVGO = Net Present Value of growing opportunities</li></ul></li></ul><h4 id="The-Price–Earnings-P-E-Ratio"><a href="#The-Price–Earnings-P-E-Ratio" class="headerlink" title="The Price–Earnings (P/E) Ratio"></a>The Price–Earnings (P/E) Ratio</h4><script type="math/tex; mode=display">Price\ per\ share = \frac{EPS}{r} + NPVGO</script><p>Dividing by EPS both sides</p><script type="math/tex; mode=display">\frac{Price\ per\ share}{EPS} =\frac{P}{E}= \frac{1}{r} + \frac{NPVGO}{EPS}</script><p>The P/E ratio is based on the idea that the <strong>absolute value</strong> of a stock is not as important as its <strong>relative value</strong>.</p><p>The P/E ratio measures <strong>how much investors are willing to pay per unit of current earnings</strong>.</p><p>Companies with high growth opportunities will have higher P/E ratios.</p><ul><li>Be careful though, we are not only looking at the stock price here, but also at earnings per share. A high P/E may also result from low earning per share (denominator effect).</li></ul><h2 id="Unit-5-5：Market-Structures-and-Earnings"><a href="#Unit-5-5：Market-Structures-and-Earnings" class="headerlink" title="Unit 5.5：Market Structures and Earnings"></a>Unit 5.5：Market Structures and Earnings</h2><h4 id="Market-structures-are-classified-by-level-of-competition"><a href="#Market-structures-are-classified-by-level-of-competition" class="headerlink" title="Market structures are classified by level of competition"></a>Market structures are classified by level of competition</h4><ul><li><p>The degree of competition is determined by the following factors:</p><ul><li>Number of firms </li><li>Freedom of entry to the industry</li><li>Nature of the product</li><li>Nature of the demand curve</li></ul></li><li><p>The four market structures are:</p><ul><li>Perfect competition</li><li>Monopolistic competition</li><li>Oligopoly</li><li>duopoly</li><li>Monopoly</li></ul></li></ul><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic5-1.jpg" alt></p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic5-2.jpg" alt></p><h4 id="Monopoly-Power"><a href="#Monopoly-Power" class="headerlink" title="Monopoly Power"></a>Monopoly Power</h4><p>A firm can exert <strong>monopoly power by charging a price above marginal cost</strong>.</p><ul><li>Monopoly power can be exerted even if the firm does not control the whole market.</li></ul><p>Governments attempt to <strong>control or curb monopoly power</strong>.</p><p>Monopoly power allows companies to have <strong>excess profits</strong>.</p><h4 id="The-Fundamental-Cause-of-Monopoly-Barriers-to-Entry"><a href="#The-Fundamental-Cause-of-Monopoly-Barriers-to-Entry" class="headerlink" title="The Fundamental Cause of Monopoly: Barriers to Entry"></a>The Fundamental Cause of Monopoly: Barriers to Entry</h4><ul><li>Ownership of key resources<ul><li>When a single firm is the owner of a key resource. </li></ul></li><li>Government-created monopolies<ul><li>Patent and copyright laws create monopoly power but are crucial for innovation.</li></ul></li><li>Economies of scale<ul><li>Natural monopolies take advantage of economies of scale. </li><li>Arise when a single firm can supply a good or service to the entire market at a lower cost than two or more firms could. </li></ul></li><li>Horizontal integration <ul><li>Acquisition, merger or takeover, leading to the industry being more  concentrated.</li></ul></li></ul><h1 id="Topic-6-–-Determinants-of-Firm-Value-Part-II-：Monopolistic-Competition"><a href="#Topic-6-–-Determinants-of-Firm-Value-Part-II-：Monopolistic-Competition" class="headerlink" title="Topic 6 – Determinants of Firm Value (Part II)：Monopolistic Competition"></a>Topic 6 – Determinants of Firm Value (Part II)：Monopolistic Competition</h1><p><strong>Supplementary Reading</strong></p><p>The seminal paper on the area is:</p><ul><li>Dixit and Stiglitz (1977) Monopolistic Competition and Optimum Product Diversity, American Economic Review, 67(3), 297-308. Available here:<ul><li><a href="https://www.aeaweb.org/aer/top20/67.3.297-308.pdf">https://www.aeaweb.org/aer/top20/67.3.297-308.pdf</a> </li></ul></li></ul><p>For a “lighter” version see: </p><ul><li>Dinger (2009) The basics of “Dixit-Stiglitz lite”, teaching notes. Available here:<ul><li><a href="http://www.columbia.edu/~jid2106/td/dixitstiglitzbasics.pdf">http://www.columbia.edu/~jid2106/td/dixitstiglitzbasics.pdf</a> </li></ul></li></ul><h2 id="Unit-6-1：What-is-Monopolistic-Competition"><a href="#Unit-6-1：What-is-Monopolistic-Competition" class="headerlink" title="Unit 6.1：What is Monopolistic Competition?"></a>Unit 6.1：What is Monopolistic Competition?</h2><p><strong>Monopolistic competition</strong>: A market structure in which many firms sell products that are similar but not identical.</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic6-1.jpg" alt></p><ul><li>MC：Marginal Cost</li><li>MR：Marginal Revenue</li><li>ATC：Average Total Cost</li><li>Profit = ( Price - ATC ) * Quantity</li></ul><blockquote><p>MC 通过 ATC 最低点</p><p>MR 在垄断企业通常比 Demand 小</p></blockquote><p>Only the perfectly competitive firm produces at the efficient scale.</p><p>Price equals marginal cost under perfect competition, but price is above marginal cost under monopolistic competition so exerting market power.</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic6-2.jpg" alt></p><h2 id="Unit-6-2：Structure-of-the-Dixit-Stiglitz-Model"><a href="#Unit-6-2：Structure-of-the-Dixit-Stiglitz-Model" class="headerlink" title="Unit 6.2：Structure of the Dixit-Stiglitz Model"></a>Unit 6.2：Structure of the Dixit-Stiglitz Model</h2><blockquote><p>目的是平衡多样性带来的垄断利益，和大规模生产带来的低平均花销</p></blockquote><h4 id="Firms"><a href="#Firms" class="headerlink" title="Firms"></a>Firms</h4><p>There are two types good firms</p><ol><li>Intermediate good firms<ul><li>Monopoly producers of unique, differentiated products</li><li>Hire labour and capital as inputs</li><li>Free entry to being a producer of a different variety</li><li>Individual producer has some market power</li></ul></li><li>Final good firms<ul><li>Use intermefiate goods to produce a final consumption good</li><li>For the final goods producers, the intermediate inputs are imperfect substitutes</li><li>Final good is sold in a perfectly competitive market - individual producers have no market power</li></ul></li></ol><h2 id="Unit-6-3：Intermediate-Goods-Producers"><a href="#Unit-6-3：Intermediate-Goods-Producers" class="headerlink" title="Unit 6.3：Intermediate Goods Producers"></a>Unit 6.3：Intermediate Goods Producers</h2><p>There are $N$ firms producing different outputs $q_n$ using capital $k$ and labour $l$,</p><script type="math/tex; mode=display">q_n=\theta_nk_n^\gamma l_n^{1-\gamma}</script><ul><li>$\theta_n&gt;0$ is the individual firm’s productivity</li><li>$\gamma$ is the share spent on capital, which we assume is common to all firms</li></ul><h4 id="Profit-Maximization"><a href="#Profit-Maximization" class="headerlink" title="Profit Maximization"></a>Profit Maximization</h4><p>Each of the $N$ monopolists maximise their own profits by choosing</p><ul><li>How much to produce, $q_n$</li><li>What price to charge, $p_n$<ul><li>choice of $q_n$ affects the price $p_n$</li></ul></li><li>How much labour and capital to use in production</li></ul><h4 id="Unit-Cost-Function-for-Each-Firm"><a href="#Unit-Cost-Function-for-Each-Firm" class="headerlink" title="Unit Cost Function for Each Firm"></a>Unit Cost Function for Each Firm</h4><p>In order to minimizes its cost of production, taking $w$ and $r$ as given</p><script type="math/tex; mode=display">C(l_n,k_n)=wl_n+rk_n</script><ul><li>$w$：wage</li><li>$r$：rate</li></ul><p>We can writed down capital as a function of labour and output</p><script type="math/tex; mode=display">k_n=(\frac{q_n}{\theta_n})^{\frac1\gamma}(l_n)^{\frac{\gamma-1}\gamma}</script><p>So we have costs as</p><script type="math/tex; mode=display">C(q_n,l_n)=wl_n+r(\frac{q_n}{\theta_n})^{\frac1\gamma}(l_n)^{\frac{\gamma-1}\gamma}</script><p>For a given level of output, the cost-minimizing amount of labour is found by</p><script type="math/tex; mode=display">\frac{\partial C}{\partial l_n}=\omega+r(\frac{q_n}{\theta_n})^\frac1\gamma(\frac{\gamma-1}{\gamma})(l_n)^{\frac{-1}\gamma}=0</script><p>The optimal choice of labour as a function of input prices ($r,w$), output level ($q$) and technological parameters ($\theta$):</p><script type="math/tex; mode=display">l_n^*=[\frac rw\frac{1-\gamma}\gamma]^\gamma(\frac{q_n}{\theta_n})</script><ul><li>Higher $r$ (or lower $w$) means that more labour is used</li><li>More output means more labour required</li><li>For a given level of output, more productive firms need less labour</li></ul><p>Substituting $l_n^*$ into equation, we obtain optimal choice of capital,</p><script type="math/tex; mode=display">k_n^*=[\frac wr\frac\gamma{1-\gamma}]^{1-\gamma}(\frac{q_n}{\theta_n})</script><ul><li>Higher $w$ (or lower $r$) means that more capital is used</li><li>More output means more capital required</li><li>For a given level of output, more productive firms need less capital</li></ul><p>Put these into cost function, we have cost as a function of output level.</p><script type="math/tex; mode=display">C_n(q_n)=w[\frac rw\frac{1-\gamma}\gamma]^\gamma(\frac{q_n}{\theta_n})+r[\frac wr\frac\gamma{1-\gamma}]^{1-\gamma}(\frac{q_n}{\theta_n})</script><p>which becomes</p><script type="math/tex; mode=display">C_n(q_n)=(\frac{q_n}{\theta_n})[\frac{r^\gamma w^{1-\gamma}}{\gamma^\gamma(1-\gamma)^{1-\gamma}}]</script><p>The ‘unit cost’, the cost of producing one unit of output, for firm $n$​ is thus,</p><script type="math/tex; mode=display">C_n(1)\equiv C_n^1=\frac{1}{\theta_n}[\frac{r^\gamma w^{1-\gamma}}{\gamma^\gamma(1-\gamma)^{1-\gamma}}]</script><blockquote><p>一单位最小花销</p><p>推导过程其实有点问题，因为不能保证 labour 的最优就是 capital 的最优，导致最终公式的边际值是稳定的，只能猜测这里采用了理想化的方法</p></blockquote><h2 id="Unit-6-4：Final-Goods-Producers"><a href="#Unit-6-4：Final-Goods-Producers" class="headerlink" title="Unit 6.4：Final Goods Producers"></a>Unit 6.4：Final Goods Producers</h2><h4 id="Production-Function"><a href="#Production-Function" class="headerlink" title="Production Function"></a>Production Function</h4><p>Final goods $Y$ are produced in perfectly competitive markets by firms that use the following production function,</p><script type="math/tex; mode=display">Y=[\frac1{N^{1-\rho}}((q_1)^\rho+(q_2)^\rho+...+(q_N)^\rho)]^{\frac1\rho}</script><p>This is what is called a <strong>CES (constant elasticity of substitution) production function</strong></p><p>$\sigma=\frac1{1-\rho}$ is the elasticity of substitution between the different $q_n$</p><ul><li>With $\rho\to 0$​, this is a Cobb-Douglas (unit elasticity) - 1</li><li>For $\rho\to 1$​, the $q_n$​ are perfect substitutes (linear) - q 之和</li><li>For $\rho\to -\infty$​, the $q_n$​​ are perfect complements (Leontief) - 趋向 0</li></ul><blockquote><p>substitutes 替代</p><p>complements 互补，存在消费依存</p><p>总产出（需求） Y 不变，如果 $\rho$​​​ 大，多为替代品，需要的 q 就少，商家间的竞争就大</p></blockquote><p>We focus on $\rho\in(0,1)$​, where $q_n$​ are substitutes (but not perfectly so) </p><h4 id="Profit-Maximization-and-the-Demand-for-Intermediate-Goods"><a href="#Profit-Maximization-and-the-Demand-for-Intermediate-Goods" class="headerlink" title="Profit Maximization and the Demand for Intermediate Goods"></a>Profit Maximization and the Demand for Intermediate Goods</h4><p><strong>Final good producers</strong> maximise their profits, given prices of intermediate goods and price of final output $P$,</p><script type="math/tex; mode=display">\max_{\{q_n\}}\Pi=PY-\sum_{n=1}^Np_nq_n</script><script type="math/tex; mode=display">\frac{\partial \Pi}{\partial q_n}=\frac P\rho[·]^{\frac1\rho-1}\frac\rho{N^{1-\rho}}q_n^{\rho-1}-p_n=0</script><script type="math/tex; mode=display">\begin{align}q_n^{\rho-1}&=\frac{p_n}P\frac1{N}^{\rho-1}[·]^{\frac{\rho-1}\rho}\\q_n&=(\frac P{p_n})^{\frac1{1-\rho}}\frac1{N}[·]^{\frac1\rho}\end{align}</script><h4 id="Marshallian-demand-for-each-good"><a href="#Marshallian-demand-for-each-good" class="headerlink" title="Marshallian demand for each good"></a>Marshallian demand for each good</h4><script type="math/tex; mode=display">q_n^*(p_n)=\frac1N(\frac P{p_n})^{\frac1{1-\rho}}Y</script><ul><li>Downward sloping in $p_n$</li><li>But less downward sloping in $p_n$, the less substitutable the goods are (lower $\rho$)</li><li>Lower as $N$ increases, higher as $Y$ increases</li></ul><blockquote><p>市场由每家生产价格决定每家最优生产产量</p></blockquote><h2 id="Unit-6-5：Optimization-Market-Shares-and-Profits-of-Intermediate-Goods-Producers"><a href="#Unit-6-5：Optimization-Market-Shares-and-Profits-of-Intermediate-Goods-Producers" class="headerlink" title="Unit 6.5：Optimization, Market Shares, and Profits of Intermediate Goods Producers"></a>Unit 6.5：Optimization, Market Shares, and Profits of Intermediate Goods Producers</h2><h3 id="Intermediate-goods-firm-optimization"><a href="#Intermediate-goods-firm-optimization" class="headerlink" title="Intermediate goods firm optimization"></a>Intermediate goods firm optimization</h3><p><strong>Intermediate good firms</strong> maximise their own profits by choosing prices, $p_n$, taking $P,Y$ and $N$ as given, and taking into account the effect on the demand for their good, $q_n^*(p_n)$</p><script type="math/tex; mode=display">\pi_n=p_nq_n^*(p_n)-q_n^*(p_n)C_n^1</script><p>Optimal price satisfies,</p><script type="math/tex; mode=display">p_n^*=C_n^1-\frac{q_n^*}{\frac{\partial q_n^*}{\partial p_n}}</script><p>After some algebra (find $\frac{\partial q_n^*}{\partial p_n}$​ first), we have the following:</p><script type="math/tex; mode=display">\frac{\partial q_n^*}{\partial p_n}=\frac{1}{N}P^{\frac1{1-\rho}} p_n^{\frac{2-\rho}{\rho-1}}Y(\frac1{\rho-1})</script><script type="math/tex; mode=display">\frac{q_n^*}{\frac{\partial q_n^*}{\partial p_n}}=(\rho-1)p_n</script><script type="math/tex; mode=display">p_n^*=\frac1 \rho C_n^1</script><blockquote><p>每家由单位花销决定最优单位生产价格</p><p>现在可以由单位(最低)花销-&gt;单位价格-&gt; Y &amp; P &amp; q</p></blockquote><p>Note:</p><ul><li>With $\rho\in (0,1)$​ this implies some <strong>markup</strong> in the price over unit cost (额外收益)</li><li>The lower is $\rho$, the less substitutable the goods, the higher the markups</li></ul><p>Recall that $C_n^1=\frac{1}{\theta_n}[\frac{r^\gamma w^{1-\gamma}}{\gamma^\gamma(1-\gamma)^{1-\gamma}}]$</p><ul><li>So price is decreasing (and sell more) in firm technology $\theta_n \uparrow$ more productive </li></ul><h3 id="Aggregates"><a href="#Aggregates" class="headerlink" title="Aggregates"></a>Aggregates</h3><p>The final good can also be written in aggregate as a function of all the inputs (because of constant returns):</p><script type="math/tex; mode=display">Y=\bar\theta\bar K^\gamma\bar L^{1-\gamma}</script><p>where $\bar K=\sum_{n=1}^N k_n$ and $\bar L=\sum_{n=1}^N l_n$ and where $\bar\theta$ is economy-wide average productivity</p><p>We can also write down the aggregate price level as,</p><script type="math/tex; mode=display">P=\frac1\rho \frac{\bar C}{\bar \theta}w\quad where\quad \bar C=(\frac rw)^\gamma[\frac1{\gamma^\gamma(1-\gamma)^{1-\gamma}}]</script><blockquote><p>P 是所有 p 的平均值</p></blockquote><p>Note that we have the price of an intermediate good as,</p><script type="math/tex; mode=display">p_n=\frac1\rho\frac{\bar C}{\theta_n}w</script><p>Both the aggregate price level and individual intermediate firm prices have similar structure</p><ul><li>But the intermediate good firm price can deviate from the aggregate price level （换个 productivity 可以达到从总体到特定生产商价格的转换）</li></ul><p>A direct result is to look at market shares of intermediate good firms</p><h3 id="Market-share-ms-of-firm-n"><a href="#Market-share-ms-of-firm-n" class="headerlink" title="Market share (ms) of firm n"></a>Market share (ms) of firm n</h3><script type="math/tex; mode=display">ms_n=\frac{p_nq_n}{PY}=\frac1N(\frac{\theta_n}{\bar\theta})^{\frac\rho{1-\rho}}=\frac1N(\frac{\theta_n}{\bar\theta})^{\sigma-1}</script><ul><li>$\sigma=\frac1{1-\rho}$ so $\sigma-1=\frac\rho{1-\rho}$</li></ul><p>Observations:</p><ul><li>A firm with average productivity ($\theta_n=\bar\theta$) has market share $ms_n=1/N$</li><li>More productive firms have higher market share (since $\sigma&gt;1$)</li><li>Greater productivety leads to higer market share if goods are more substitutable ($\sigma$ higher)</li><li>A more monopolistic market ($\downarrow \sigma$​​) <strong>protects</strong> less productive firms from some competition （保护新生企业，如下图 0.5）</li></ul><blockquote><p>$\frac{\theta_n}{\bar\theta}$: relative productivety of firm</p></blockquote><h4 id="Example"><a href="#Example" class="headerlink" title="Example:"></a>Example:</h4><p><strong>Market share if N = 5</strong></p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic6-3.jpg" alt></p><h3 id="Profit-of-firm-n"><a href="#Profit-of-firm-n" class="headerlink" title="Profit of firm n"></a>Profit of firm n</h3><p>Profit shares behave the same as market shares</p><script type="math/tex; mode=display">PY=\sum_{n=1}^Np_nq_n</script><p>Let aggregate profit be,</p><script type="math/tex; mode=display">\bar\Pi=\sum_{n=1}^N\pi_n=\frac1\sigma PY</script><p>And firm n profit is aggregate times the market share,</p><script type="math/tex; mode=display">\pi_n = ms_n·\bar\Pi =\frac1\sigma\frac{PY}{N}(\frac{\theta_n}{\bar\theta})^{\sigma-1}</script><p>What determines individual firm earnings?</p><ul><li>Macroeconomics: the size of nominal aggregate output (PY-GDP)</li><li>Aggregate market structure: the more competitive ($\sigma$ higher), the less aggregate profit; the more firms, the less share of aggregate profit (N)</li><li>Firm specifics: the more competitive ($\sigma$ higher), the more firms benefit from being productive relative to average ($\theta$)</li></ul><h4 id="Example-1"><a href="#Example-1" class="headerlink" title="Example:"></a>Example:</h4><p><strong>Firm profits if N = 5 and PY = 1</strong></p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic6-4.jpg" alt></p><blockquote><p>当 $\rho&lt;0, \sigma&lt;1$​​​ 时，需要等待低生产的生产同步，导致高生产收益低</p></blockquote><h2 id="Unit-6-4：Earnings-and-Firm-Valuation"><a href="#Unit-6-4：Earnings-and-Firm-Valuation" class="headerlink" title="Unit 6.4：Earnings and Firm Valuation"></a>Unit 6.4：Earnings and Firm Valuation</h2><h3 id="Earnings-of-firm-n"><a href="#Earnings-of-firm-n" class="headerlink" title="Earnings of firm n"></a>Earnings of firm n</h3><p>Now we have a better idea of what determines earnings, we can return to valuations based on that</p><p>Now we have an income syream:</p><script type="math/tex; mode=display">\pi_n(t) =\frac1\sigma\frac{P(t)Y(t)}{N(t)}(\frac{\theta_n(t)}{\bar\theta(t)})^{\sigma-1}\quad for\ t=1,2,...</script><p>Can we calculate PV based on this?</p><h3 id="Firm-Valuation"><a href="#Firm-Valuation" class="headerlink" title="Firm Valuation"></a>Firm Valuation</h3><p>Consider discount factor $\beta=\frac1{1+r}\in(0,1)$, then</p><script type="math/tex; mode=display">V_n(t)=\sum_{\tau=0}^\infty\beta^\tau\frac1\sigma E_t[\frac{P(t+\tau)Y(t+\tau)}{N(t+\tau)}(\frac{\theta_n(t+\tau)}{\bar\theta(t+\tau)})^{\sigma-1}]</script><p>where $E_t[·]$ are expectations formed at time t</p><p>Suppose that macroeconomic and market factors are forecasted accurately, then uncertainty rests on expectations of firm productivity,</p><script type="math/tex; mode=display">V_n(t)=\sum_{\tau=0}^\infty\beta^\tau\frac1\sigma \frac{P(t+\tau)Y(t+\tau)}{N(t+\tau)}E_t[(\frac{\theta_n(t+\tau)}{\bar\theta(t+\tau)})^{\sigma-1}]</script><p>Recall also that $Y(t)=\bar\theta\bar K(t)^\gamma\bar L(t)^{1-\gamma}$</p><ul><li>Business cycle: Positive shock to business cycle (higher $Y(t+\gamma)$ for some $\tau$) means higher firm valuation</li><li>Uncertainty: Future productivity relative to market</li><li>Future market structure: Entrants to market in future lower today’s present valuation<ul><li>We would not normally think of $\sigma$ as a time-varying parameter</li></ul></li><li>More monopolistic market reduces the potential future gains to being more productive</li></ul><h3 id="The-Long-Run"><a href="#The-Long-Run" class="headerlink" title="The Long Run"></a>The Long Run</h3><p>Excess profits attract new entrants</p><ul><li>$N(t)$ going up over time in the future</li><li>With everything else the same, that lowers profits in future</li><li>That means firm valuation is lower today</li></ul><p>There are still markups, since prices are not a function of N</p><script type="math/tex; mode=display">p_n=\frac1\rho\frac1{\theta_n}[\frac{r^\gamma w^{1-\gamma}}{\gamma^\gamma(1-\gamma)^{1-\gamma}}]</script><p>From an efficiency perspective</p><ul><li>Prices are higher and output is lower <strong>than</strong> under <strong>perfect competition</strong> （$\rho\to 1$）</li><li>If prices were made to be lower, more consumption could increase</li></ul><p>Indicidual firm productivity still matters to valuations</p><p><strong>But as N goes up, so firm profits decline,</strong></p><script type="math/tex; mode=display">\pi_n=\frac1\sigma\frac{PY}N(\frac{\theta_n}{\bar\theta})^{\sigma-1}</script><p>Both the monopolistic competitor and the perfect competitor make zero excess profit in the long-run</p><h3 id="Innovation-and-Marketing"><a href="#Innovation-and-Marketing" class="headerlink" title="Innovation and Marketing"></a>Innovation and Marketing</h3><p><strong>Innovation</strong></p><ul><li>Firms can allocate profits to innovation, improving $\theta_n$</li></ul><p><strong>Marketing and ‘non-price’ competition</strong> -attempts to shift demand curve and make it more inelastic</p><ul><li>The perception of innovation</li><li>The appearance of difference between products<ul><li>Reliability, style, safety, taste $\to$ products</li></ul></li></ul><p><strong>Competition</strong></p><ul><li>The structure of markets can fundamentally change with new technologies</li><li>Disruption</li><li>Creative destruction (‘Schumpeterian’ growth)</li></ul><h3 id="Omissions-and-Extensions"><a href="#Omissions-and-Extensions" class="headerlink" title="Omissions and Extensions"></a>Omissions and Extensions</h3><ol><li><strong>Firms only rented capital</strong><ul><li>If they own capital, stream of profits would relate to changes in value of capital</li></ul></li><li><strong>Labour market</strong><ul><li>We assumed a competitive labour market</li><li>If workers are specialized, or if workers are unionized, then there is a monopsony issue</li></ul></li><li><strong>Government borrowing may compete with firms</strong><ul><li>We have seen previously how price of credit needed for expansion may be affected by crowding out</li><li>Financial market distress also</li></ul></li><li><strong>Other costs</strong><ul><li>Fixed costs of operating, costst of innovation, regulatory restrictions,ets.</li></ul></li><li><strong>International</strong><ul><li>Trade, finance, foregin competition/ subsidies</li><li>Networks and cartels</li></ul></li></ol><h2 id="Topic-6-总结"><a href="#Topic-6-总结" class="headerlink" title="Topic 6 总结"></a>Topic 6 总结</h2><h3 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h3><script type="math/tex; mode=display">q_n=\theta_nk_n^\gamma l_n^{1-\gamma}</script><ul><li>Outputs: $q$</li><li>Technological parameters/ Productivity: $\theta$​</li><li>Capital: $k$</li><li>labour: $l$</li><li>The share spent on capital: $\gamma$​</li><li>The share spent on labour: $1-\gamma$</li><li>Price: $p$</li></ul><script type="math/tex; mode=display">\begin{align}C(l_n,k_n)&=wl_n+rk_n\\&消去\ k_n\\C(q_n,l_n)&=wl_n+r(\frac{q_n}{\theta_n})^{\frac1\gamma}(l_n)^{\frac{\gamma-1}\gamma}\\&C对l求导取0\\l_n^*&=[\frac rw\frac{1-\gamma}\gamma]^\gamma(\frac{q_n}{\theta_n})\\&同样操作对k\\k_n^*&=[\frac wr\frac\gamma{1-\gamma}]^{1-\gamma}(\frac{q_n}{\theta_n})\\&返回原式\\C_n^*(q_n)&=(\frac{q_n}{\theta_n})[\frac{r^\gamma w^{1-\gamma}}{\gamma^\gamma(1-\gamma)^{1-\gamma}}]\end{align}</script><ul><li>Cost of production: $C(l,k)$</li><li>$w$：wage</li><li>$r$：rate</li></ul><script type="math/tex; mode=display">Y=[\frac1{N^{1-\rho}}((q_1)^\rho+(q_2)^\rho+...+(q_N)^\rho)]^{\frac1\rho}</script><ul><li><p>Final goods: $Y$</p></li><li><p>Elasticity of substitution: $\sigma=\frac1{1-\rho}$</p></li></ul><script type="math/tex; mode=display">\begin{align}\max_{\{q_n\}}\Pi&=PY-\sum_{n=1}^Np_nq_n\\&\Pi对q求导取0\\q^*_n(p_n)&=\frac1{N}(\frac P{p_n})^{\frac1{1-\rho}}Y\end{align}</script><ul><li><p>Final good producers profits: $\Pi$</p></li><li><p>Price of final output: $P$</p></li></ul><script type="math/tex; mode=display">\begin{align}\max_{\{p_n\}}\pi_n&=p_nq_n^*(p_n)-q_n^*(p_n)C_n^1\\&\pi对p求导取0\\p_n^*&=\frac1 \rho C_n^1\end{align}</script><ul><li>Intermediate good firms profits: $\pi$</li></ul><script type="math/tex; mode=display">Y=\bar\theta\bar K^\gamma\bar L^{1-\gamma}</script><script type="math/tex; mode=display">P=\frac1\rho \frac{\bar C}{\bar \theta}w\quad where\quad \bar C=(\frac rw)^\gamma[\frac1{\gamma^\gamma(1-\gamma)^{1-\gamma}}]</script><script type="math/tex; mode=display">p_n=\frac1\rho\frac{\bar C}{\theta_n}w</script><script type="math/tex; mode=display">ms_n=\frac{p_nq_n}{PY}=\frac1N(\frac{\theta_n}{\bar\theta})^{\frac\rho{1-\rho}}=\frac1N(\frac{\theta_n}{\bar\theta})^{\sigma-1}</script><ul><li>Market share: $ms$​</li></ul><script type="math/tex; mode=display">\Pi=0</script><script type="math/tex; mode=display">\bar\Pi=\sum_{n=1}^N\pi_n=\frac1\sigma PY</script><script type="math/tex; mode=display">\pi_n = ms_n·\bar\Pi =\frac1\sigma\frac{PY}{N}(\frac{\theta_n}{\bar\theta})^{\sigma-1}</script><h1 id="Topic-7-–-Determinants-of-Firm-Value-Part-III-：Tobin’s-q-theory-of-investment"><a href="#Topic-7-–-Determinants-of-Firm-Value-Part-III-：Tobin’s-q-theory-of-investment" class="headerlink" title="Topic 7 – Determinants of Firm Value (Part III)：Tobin’s q theory of investment"></a>Topic 7 – Determinants of Firm Value (Part III)：Tobin’s q theory of investment</h1><p><strong>Supplementary Reading</strong></p><p>For further reading on the topic see:</p><ul><li>Talmain, G., Teaching Notes on Tobin’s q theory of investment. </li><li>Romer, D., Advanced Macroeconomics, Ch. 9 (2006, 2011 or 2017).</li><li>Blanchard, O., Rhee, C., &amp; Summers, L. (1993). The Stock Market, Profit, and Investment. The Quarterly Journal of Economics, 108(1), 115-136. doi:10.2307/2118497 </li></ul><h2 id="Unit-7-1：Tobin’s-q"><a href="#Unit-7-1：Tobin’s-q" class="headerlink" title="Unit 7.1：Tobin’s q"></a>Unit 7.1：Tobin’s q</h2><p>A firm is just a bundle of assets ($k_t$) that produces value ($v_t$)</p><script type="math/tex; mode=display">v_t=f(k_t)</script><p>Tobin’s q is a particular representation of this:</p><script type="math/tex; mode=display">q=\frac{market\ value\ of\ firm}{book\ value\ of\ firm}=\frac{v_t}{k_t}</script><ul><li>The market value is the <strong>market capitalization</strong> of the firm（stock price*number）</li><li>The book value is the <strong>replacement</strong> cost of the captial</li></ul><blockquote><p>q 单位 capital 产生的价值</p></blockquote><p>Net investment is the accumulation (or decumulation) of capital</p><p>What does the q tell us?</p><ul><li>If $q&gt;1$, the market assesses some value in the firm beyond the measured assets in the company</li><li>If $q&lt;1$, the market may be undervaluing the firm</li></ul><p>Investment:</p><ul><li>If $q&gt;1$, the firm can <strong>sell shares</strong> at a price higher than it costs to put more capital in the firm</li><li>If $q&lt;1$, the firm may do better to <strong>buy back</strong> some shares from the market, or let its capital depreciate</li></ul><p><strong>This interaction between investment and firm value is our focus</strong></p><p>Note a distinction:</p><ul><li>Tobin’s q is about the average value of a firm vs its book value</li><li>Investment decisions are made at the <strong>margin</strong>: A firm buys an extra unit of capital if that yields more value at the margin than the cost of the captial</li></ul><h4 id="Renting-vs-Owning-the-Capital"><a href="#Renting-vs-Owning-the-Capital" class="headerlink" title="Renting vs. Owning the Capital"></a>Renting vs. Owning the Capital</h4><p>We need to introduce a role for capital that generates insights about firm value</p><p>What we will do is take this in three steps:</p><ol><li>Leased（Rent）capital and firm value<ul><li>Firms make no profit, have no value</li></ul></li><li>Owned capital without adjustment costs<ul><li>Firm value is always just the capital stock; $q=1$ always</li></ul></li><li>Owned capital with adjustment costs<ul><li>Interesting dynamics of investment and value, where $q\gtrless1$ in transition to steady state</li></ul></li></ol><h2 id="Unit-7-2：Leased-Capital-and-Firm-Value"><a href="#Unit-7-2：Leased-Capital-and-Firm-Value" class="headerlink" title="Unit 7.2：Leased Capital and Firm Value"></a>Unit 7.2：Leased Capital and Firm Value</h2><h4 id="Firms-that-Lease-Capital"><a href="#Firms-that-Lease-Capital" class="headerlink" title="Firms that Lease Capital"></a>Firms that Lease Capital</h4><p>Suppose that capital is owned by leasing companies that rent it out to firms</p><p>Firms then hire capital and labour to produce according to</p><script type="math/tex; mode=display">y=f(k,l)</script><p>where $f$ is a regular production function with constant returns to scale</p><p>In a perfectly competitive environment, firms are price takers, choosing $k$ and $l$ to maximize profits, given prices for output, capital and labour,</p><script type="math/tex; mode=display">\max_{k,l}\pi=py-(rk+wl)</script><p>The first order conditions of this problem imply,</p><script type="math/tex; mode=display">p\frac{\partial f}{\partial l}=w\quad and \quad p\frac{\partial f}{\partial k}=r</script><h4 id="Euler’s-Homogeneous-Function-Theorem"><a href="#Euler’s-Homogeneous-Function-Theorem" class="headerlink" title="Euler’s Homogeneous Function Theorem"></a>Euler’s Homogeneous Function Theorem</h4><p>A function $g(x,y)$ that is homogeneous of degree $\lambda$ has the following property,</p><script type="math/tex; mode=display">xg_x'+yg_y'=\lambda g(x,y)</script><ul><li>This is called <strong>Euler’s Homogeneous Function Theorem</strong></li></ul><p>A function that has constant returns to scale is <strong>homogeneous of degree one</strong> （$\lambda=1$）, so we can write the following,</p><script type="math/tex; mode=display">f(k,l)=\frac{\partial f}{\partial k}k+\frac{\partial f}{\partial l}l</script><h4 id="Constant-Returns-to-Scale-and-Profits"><a href="#Constant-Returns-to-Scale-and-Profits" class="headerlink" title="Constant Returns to Scale and Profits"></a>Constant Returns to Scale and Profits</h4><p>Using this,we have the profits of a firm as,</p><script type="math/tex; mode=display">\pi=py-(rk+wl)=p(\frac{\partial f}{\partial k}k+\frac{\partial f}{\partial l}l)-(rk+wl)</script><p>Given the first order conditions $p\frac{\partial f}{\partial l}=w$ and $p\frac{\partial f}{\partial k}=r$ this means,</p><script type="math/tex; mode=display">\pi=0</script><p>We saw previously how departing frim the assumption of perfect competition generated insights to value</p><p>Today, we instead focus on the role of owned capital</p><h2 id="Unit-7-3：Firms-that-own-capital-without-adjustment-costs"><a href="#Unit-7-3：Firms-that-own-capital-without-adjustment-costs" class="headerlink" title="Unit 7.3：Firms that own capital, without adjustment costs"></a>Unit 7.3：Firms that own capital, without adjustment costs</h2><p>Now, suppose firms own capital (on behalf of their shareholders)</p><p>A firm wants to maximize the present discounted value of the future flow of dividends ($c_t$)</p><script type="math/tex; mode=display">V=\max_{c_t}\int_0^\infty u(c_t)e^{-\rho t}dt</script><ul><li>where $u(c_t)$ is the utility of the representative shareholder</li></ul><h4 id="Output-dividends-and-new-capital-investment"><a href="#Output-dividends-and-new-capital-investment" class="headerlink" title="Output, dividends and new capital investment"></a>Output, dividends and new capital investment</h4><p>Production arises out of capital holdings (let’s ignore labour for now)</p><script type="math/tex; mode=display">y_t=f(k_t)</script><p>Output is allocated to dividends (consumption of shareholder) or new capital investment, $i_t=y_t-c_t=rk_t-c_t$​​ (using Euler’s theorem again $f(k_t)=\frac{\partial f}{\partial k_t}k_t$​​)</p><p>So capital accumulation $\dot k_t=i_t$</p><script type="math/tex; mode=display">\dot k_t=r_tk_t-c_t</script><blockquote><p>The “dot” denotes the derivative with respect to time ($dk_t/dt$​) and is the continuous time version of $k_{t+1}-k_t$​</p></blockquote><p>Note:</p><ul><li>Implicit here is that capital is <strong>fungible</strong> - capital can costlessly be converted out of forsaken consumption (no adjustment cost)</li></ul><h4 id="Arbitrage-and-the-value-of-the-firm"><a href="#Arbitrage-and-the-value-of-the-firm" class="headerlink" title="Arbitrage and the value of the firm"></a>Arbitrage and the value of the firm</h4><p>An investor can</p><ul><li>Buy a publicly traded firm for its market capitalization $v_t$</li><li>Or it can buy new capital $k_t$ at the price of the consumption good</li></ul><p><strong>Arbitrage</strong> makes the two equal, hence,</p><script type="math/tex; mode=display">v_t=k_t</script><p>It is always $q=1$</p><p>If a firm has N common shares in the market, a single share in a firm is then just worth $p_t=\frac{v_t}N=\frac{k_t}N$</p><h4 id="Share-price-with-no-adjustment-costs"><a href="#Share-price-with-no-adjustment-costs" class="headerlink" title="Share price with no adjustment costs"></a>Share price with no adjustment costs</h4><p>According to this approach, the price of a share is simply,</p><script type="math/tex; mode=display">p_t=\frac{k_t}N</script><p>What we did before was to relax the assumption that firms are perfectly competitive</p><ul><li>Now we relax the fungibility assumption</li></ul><h2 id="Unit-7-4：Firms-that-own-capital-with-adjustment-costs"><a href="#Unit-7-4：Firms-that-own-capital-with-adjustment-costs" class="headerlink" title="Unit 7.4：Firms that own capital, with adjustment costs"></a>Unit 7.4：Firms that own capital, with adjustment costs</h2><h4 id="Set-up"><a href="#Set-up" class="headerlink" title="Set-up"></a>Set-up</h4><p>We have a <strong>simplified framework</strong>:</p><ul><li>All firms have the same technology</li><li>Produce identical goods</li><li>Produce using only capital $k_t$</li></ul><p>So this model is not so useful in telling use about the valuation of <strong>individual firms</strong></p><ul><li>For that, see monopolistic competition</li></ul><p>What we have here is how both <strong>interest rate</strong> and a nontrivial <strong>aggregate valuation</strong> of equity can be understood together</p><ul><li>So something akin (类似) to a stock market index and how it interacts with interest rates over the business cycle</li></ul><h4 id="Production"><a href="#Production" class="headerlink" title="Production"></a>Production</h4><p>A representative firm’s production function,</p><script type="math/tex; mode=display">y_t=f(k_t)</script><p>Where we have the regular assumptions,</p><script type="math/tex; mode=display">f'(k_t)>0\quad f''(k_t)<0</script><p>As such, we have a <strong>rate of return</strong> on capital, $ror_t=f’(k_t)$,</p><p>where</p><script type="math/tex; mode=display">ror'(k_t)<0\quad and\quad ror''(k_t)>0</script><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-1.jpg" alt></p><h4 id="Income-destinations-and-the-single-shareholder-in-the-model"><a href="#Income-destinations-and-the-single-shareholder-in-the-model" class="headerlink" title="Income destinations and the single shareholder in the model"></a>Income destinations and the single shareholder in the model</h4><p>Output at time $t$ can be used in two ways:</p><ol><li>Dividends: to pay $c_t$ to shareholders</li><li>Retained earnings: to invest $i_t$, which leads to:<ul><li>Increased capital stock at $t+1,t+2,…$</li><li>Higher production and so, potentially higher $c_{t+1},c_{t+1},…$</li></ul></li></ol><p>We assume all the shareholders share the same preferences</p><p>So, without loss of generality we assume there is a single shareholder</p><h4 id="Dynamics-of-Capital-and-Debt"><a href="#Dynamics-of-Capital-and-Debt" class="headerlink" title="Dynamics of Capital and Debt"></a>Dynamics of Capital and Debt</h4><p>The firm starts at $t=0$​ with an initial stock of captial, $k_0$​ and an initial level of debt $b_0$​</p><p>Out job is to keep track of how these two variables change over time</p><ol><li>Capital accumulation</li><li>Debt accumulation</li></ol><blockquote><p>为了使模型更加灵活，引入 debt</p></blockquote><h4 id="Capital-Accumulation"><a href="#Capital-Accumulation" class="headerlink" title="Capital Accumulation"></a>Capital Accumulation</h4><p>Investment adds to the stock of capital for next period, and we assume (for simplicity) that capital does not depreciate:</p><script type="math/tex; mode=display">k_{t+1}=k_t+i_t</script><p>Now we want to consider that switching output into capital is <strong>not costless</strong></p><h4 id="Cost-of-Installing-Capital"><a href="#Cost-of-Installing-Capital" class="headerlink" title="Cost of Installing Capital"></a>Cost of Installing Capital</h4><p>For an increase in capital of $i_t$, the firm pays,</p><ol><li><p>The simple cost of the investment $i_t$</p></li><li><p>Plus cost to install each unit of investment</p><script type="math/tex; mode=display">unit\ installation\ cost=T(\frac{i_t}{k_t})</script><ul><li>where $T$ here is a function of $\frac{i_t}{k_t}$</li><li>We assume $T(0)=0$, $T’&gt;0$ and $T’’&gt;0$</li></ul></li></ol><p>Total cost of capital increase is then,</p><script type="math/tex; mode=display">i_t[1+T(\frac{i_t}{k_t})]</script><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-2.jpg" alt></p><p>Note that the firm can also disinvest capital and transform is back into consumption by setting $i_t&lt;0$</p><h4 id="Debt-Accumulation"><a href="#Debt-Accumulation" class="headerlink" title="Debt Accumulation"></a>Debt Accumulation</h4><p>In each period $t$, the firm decides how to allocate to investment $i_t$ and dividends $c_t$</p><ul><li>It can finance investment or dividends using retained earnings or debt</li><li>Firm faces interest rate $r_t$</li></ul><p>Out of output $y_t$, firm can spend on:</p><ul><li>Dividends $c_t$</li><li>Investment $i_t[1+T(\frac{i_t}{k_t})]$</li><li>Debt interest $r_tb_t$</li></ul><p>The level of debt accumulates by the difference between <strong>expenditure</strong> and <strong>income</strong>:</p><script type="math/tex; mode=display">b_{t+1}-b_t=c_t+i_t[1+T(\frac{i_t}{k_t})]+r_tb_t-f(k_t)</script><h4 id="Firm-Decision-Making"><a href="#Firm-Decision-Making" class="headerlink" title="Firm Decision Making"></a>Firm Decision Making</h4><p>The firm can</p><ul><li>distribute more dividends by reducing investment, lowering capital formation and future income</li><li>distribute fewer dividends to increase capital formation and future income</li><li>borrow or lend at the current rate of interest $r_t$ to do more or less of the previous</li></ul><p>Hence, <strong>many paths</strong> for capital accumulation and for dividends are possible</p><p>The firm starts with some initial level of capital $k_0$ and debt $b_0$ </p><p>At time $t=0$ it produces</p><script type="math/tex; mode=display">y_0=f(k_0)</script><p>It uses these earnings to</p><ul><li>Invest in new capital $i_0$</li><li>Pay a cost of installation $i_0·T(\frac{i_t}{k_t})$</li><li>Pay interest on debt $r_0b_0$</li><li>Pay a dividend, $c_0$</li></ul><p>The firm’s surplus (or deficit) at the end of period $t=0$ is then,</p><script type="math/tex; mode=display">surplus_0=y_0-(c_0+i_0[1+T(\frac{i_0}{k_0})]+r_0b_0)</script><p>In the next period, debt will $\downarrow$​ by $surplus_0 (+)$​</p><script type="math/tex; mode=display">b_1=b_0-surplus_0</script><p>Capital will $\uparrow$ by $i_0$ so $k_1=k_0+i_0$ and production will be,</p><script type="math/tex; mode=display">y_1=f(k_1)</script><p>Out of which it invests, pays on debt, pays dividend, etc.,</p><h4 id="Examples-of-Accumulation-Paths"><a href="#Examples-of-Accumulation-Paths" class="headerlink" title="Examples of Accumulation Paths"></a>Examples of Accumulation Paths</h4><p>Consider some simple (potentially non-optimal) strategies chosen by the firm:</p><ol><li>Invest if the rate of return on capital is larger than the current interest rate</li><li>Pay dividends to stabilise interest payment : earnings ratio at some level<ul><li>I.e., sets some fixed target for $de_t=\frac{r_tb_t}{y_t}=\frac{interest charges}{earnings}$</li></ul></li></ol><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-3.jpg" alt></p><p>For $de=0.3$: Investment grows capital, increases output, stabilising dividend over time.</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-4.jpg" alt></p><p>For $de=0$: Invest less to avoid debt; accumulate more slowly but increased output is all going to investment and dividend. </p><h4 id="Which-of-these-strategies-is-better"><a href="#Which-of-these-strategies-is-better" class="headerlink" title="Which of these strategies is better?"></a>Which of these strategies is better?</h4><p>An intertemporal trade-off:</p><ul><li>In the first case, $de=0.3$, there is a high initial dividend, but lower later</li><li>Where the rule is $de=0$, there is a low initial dividend, but higher later</li></ul><p>Which of these is better? Or is there a further alternative that is superior?</p><p>We need an objective function for the firm</p><h2 id="Unit-7-5：The-Shareholder’s-Optimisation-Problem"><a href="#Unit-7-5：The-Shareholder’s-Optimisation-Problem" class="headerlink" title="Unit 7.5：The Shareholder’s Optimisation Problem"></a>Unit 7.5：The Shareholder’s Optimisation Problem</h2><p>Assume that a shareholder’s instantaneous <strong>utility</strong> is</p><script type="math/tex; mode=display">u(c_t)=ln(c_t)</script><p>and that the shareholder discounts future utility at rate $\rho$, then the time $t=0$ present discounted value of future dividends is,</p><script type="math/tex; mode=display">U_0=\sum_{t=0}^\infty\frac{u(c_t)}{(1+\rho)^t}</script><p>The firm’s objective is to maximise this subject to paths for capital and debt</p><p>That is, the firm chooses the dividend stream $\{c_t\}_{t=0}^\infty$ to solve:</p><script type="math/tex; mode=display">\max_{\{c_t\}_{t=0}^\infty}U_0</script><p>subject to</p><script type="math/tex; mode=display">k_{t+1}=k_t+i_t</script><script type="math/tex; mode=display">b_{t+1}-b_t=c_t+i_t[1+T(\frac{i_t}{k_t})]+r_tb_t-f(k_t)</script><h4 id="Optimal-Paths"><a href="#Optimal-Paths" class="headerlink" title="Optimal Paths"></a>Optimal Paths</h4><p>What we need to find is the optimal path for dividends and debt</p><p>We <strong>simplify</strong> matters slightly by supposing that $r_t=\bar r$​ is constant</p><p>The optimality condition, looks like a regular Euler equation:</p><script type="math/tex; mode=display">u'(c_t)=\frac{1+\bar r}{1+\rho}u'(c_{t+1})</script><blockquote><p>省略了过程</p></blockquote><p>and since $u(c_t)=ln(c_t)$​ this is simply,</p><script type="math/tex; mode=display">c_{t+1}=\frac{1+\bar r}{1+\rho}c_t</script><p>Iterating forwards,</p><script type="math/tex; mode=display">c_t=(\frac{1+\bar r}{1+\rho})^tc_0</script><ul><li>Dividend grows over time if <strong>shareholders are patient</strong> ($\bar r&gt;\rho$​)</li><li>Falls over time if $\bar r&lt;\rho$</li></ul><p>We set $\bar r=\rho$ for simplicity</p><ul><li>That means that dividends are constant $c_t=c_0$ along the optimal path</li><li>(Though note we do not know what $c_0$ is yet) $k_0\to c_0,q_0$</li></ul><h4 id="The-q"><a href="#The-q" class="headerlink" title="The q"></a>The q</h4><p>Recall that, for the firm, there are two types of capital:</p><ul><li>That which is <strong>already</strong> installed in the firm</li><li>That which <strong>can</strong> be installed with unit cost $T(\frac{i_t}{k_t})$​</li></ul><p>An agent can buy capital to be installed, but it cannot directly buy capital already installed</p><ul><li>What would be the <strong>price of an installed unit of capital</strong> if such thing was available? — Tobin’s q</li></ul><p>Tobin’s q is the value of the capital inthe firm, relative to the value of the capital outside the firm</p><script type="math/tex; mode=display">q_t=\frac{v_t}{k_t}</script><p>In other words, $q_t$​ is what is called the <strong>shadow price</strong> of installed capital</p><p>Recall</p><ul><li>If $q&gt;1$, then the firm is worth more than the book value of its capital $\to$ investment $i_t&gt;0$</li><li>If $q&lt;1$, the firm is worth less than the book value of its capital $\to$ investment $i_t&lt;0$</li></ul><h4 id="Equilibrium-stock-prices"><a href="#Equilibrium-stock-prices" class="headerlink" title="Equilibrium stock prices"></a>Equilibrium stock prices</h4><p>We can obtain expressions for $q_t$​ in terms of ($\frac{i_t}{k_t}$​)</p><blockquote><p>省略了过程</p></blockquote><p>If the frim is investing, $i_t&gt;0$ and,</p><script type="math/tex; mode=display">q_t=1+T(\frac{i_t}{k_t})+\frac{i_t}{k_t}T'(\frac{i_t}{k_t})</script><p>If the firm is disinvesting, $i_t&lt;0$ and,</p><script type="math/tex; mode=display">q_t=1-T(\frac{i_t}{k_t})-\frac{i_t}{k_t}T'(\frac{i_t}{k_t})</script><p>Note:</p><ul><li>If $T(\frac{i_t}{k_t})=0 \forall i_t$, then $q_t=1$ always</li><li>These are equilibrium relationships between stock price $q_t$ and investment $i_t$</li></ul><h4 id="Equilibrium-investment-and-capital-dynamics"><a href="#Equilibrium-investment-and-capital-dynamics" class="headerlink" title="Equilibrium investment and capital dynamics"></a>Equilibrium investment and capital dynamics</h4><p>The expressions for $q_t$ implicitly give us a function for investmet as a function of $q$</p><p>To see this, let, $x=\frac{i_t}{k_t}$ and specify unit installation cost as:</p><script type="math/tex; mode=display">T(x)=ax^2</script><p>Then we have, for $x&gt;0$</p><script type="math/tex; mode=display">q=1+T(x)+xT'(x)\Rightarrow x=\sqrt{\frac{q-1}{3a}}</script><p>Similarly, for $x&lt;0$</p><script type="math/tex; mode=display">x=-\sqrt{\frac{1-q}{3a}}</script><p>We write this as a single function,</p><script type="math/tex; mode=display">\frac{i_t}{k_t}=\phi(q_t)</script><p>where</p><script type="math/tex; mode=display">\phi(q)=\begin{cases}\sqrt{\frac{q-1}{3a}}&when\ q>1\\-\sqrt{\frac{1-q}{3a}}&when\ q<1\end{cases}</script><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-5.jpg" alt></p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-6.jpg" alt></p><h4 id="Dynamics-of-Capital-Accumulation"><a href="#Dynamics-of-Capital-Accumulation" class="headerlink" title="Dynamics of Capital Accumulation"></a>Dynamics of Capital Accumulation</h4><p>We now have an expression for investment</p><script type="math/tex; mode=display">i_t=\phi(q_t)k_t</script><p>So, the dynamics of capital</p><script type="math/tex; mode=display">\Delta k_{t+1}=k_{t+1}-k_t=i_t=\phi(q_t)k_t</script><p>We can show</p><script type="math/tex; mode=display">f'(k_t)=r_tq_t-\Delta q_{t+1}</script><blockquote><p>省略了过程</p></blockquote><p>Interpretation</p><ul><li>The left hand side is the <strong>marginal product</strong> of capital in the firm</li><li>The right hand side is the <strong>opportunity cost</strong> holding capital<ul><li>I.e., in holding capital in the firm, you forsake the earned $r_tq_t$ but make the capital gain $\Delta q_{t+1}$</li></ul></li></ul><p>We can also write this as:</p><script type="math/tex; mode=display">\Delta q_{t+1}=r_tq_t-f'(k_t)</script><h4 id="Putting-it-all-together"><a href="#Putting-it-all-together" class="headerlink" title="Putting it all together"></a>Putting it all together</h4><p>We have two dynamic equations:</p><script type="math/tex; mode=display">\Delta k_{t+1}=\phi(q_t)k_t</script><script type="math/tex; mode=display">\Delta q_{t+1}=r_tq_t-f'(k_t)</script><p>With initial $k_0,q_0$</p><ul><li>We could calculate $i_0=\phi(q_0)k_0$​</li><li>Then calculate $k_1=k_0+i_0$ and $q_1=q_0+r_tq_0-f’(k_0)$</li><li>With $k_1,q_1$ we can then similarly calculate $k_2,q_2,$ and so on</li></ul><p>We have an initial as given, but we have no clue about $q_0$</p><h2 id="Unit-7-6：The-Steady-State-Transition-Dynamics-and-Phase-Diagrams"><a href="#Unit-7-6：The-Steady-State-Transition-Dynamics-and-Phase-Diagrams" class="headerlink" title="Unit 7.6：The Steady State, Transition Dynamics and Phase Diagrams"></a>Unit 7.6：The Steady State, Transition Dynamics and Phase Diagrams</h2><p>We have two dynamic equations:</p><script type="math/tex; mode=display">\Delta k_{t+1}=\phi(q_t)k_t</script><script type="math/tex; mode=display">\Delta q_{t+1}=r_tq_t-f'(k_t)</script><p>We represent these dynamic equations diagrammatically</p><p>First, note the steady state definition as some $k^<em>,q^</em>$ such that</p><script type="math/tex; mode=display">\Delta k_t=0\quad \Delta q_t=0</script><h4 id="Exploring-the-dynamics-of-capital"><a href="#Exploring-the-dynamics-of-capital" class="headerlink" title="Exploring the dynamics of capital"></a>Exploring the dynamics of capital</h4><p>For capital,</p><script type="math/tex; mode=display">\Delta k_t=0=\phi(q^*)k^*\Rightarrow q=1</script><ul><li>And note, for $q&gt;1,\Delta k_t&gt;0$</li><li>For $q&lt;1,\Delta k_t&lt;0$</li></ul><p>We can draw this in $\{q,k\}$</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-7.jpg" alt></p><h4 id="Exploring-the-dynamics-of-stock-prices"><a href="#Exploring-the-dynamics-of-stock-prices" class="headerlink" title="Exploring the dynamics of stock prices"></a>Exploring the dynamics of stock prices</h4><p>For stock prices,</p><script type="math/tex; mode=display">\Delta q_t=0=r^*q^*-f'(k^*)\Rightarrow q^*=f'(k^*)/r^*</script><ul><li>And note, for $q&gt;\frac{f’(k_t)}{r_t}$, $\Delta q_t&gt;0$</li><li>Since $f’(k_t)$ is declining in $k_t$, it looks like this:</li></ul><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-8.jpg" alt></p><p><strong>Putting it all together</strong></p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-9.jpg" alt></p><h4 id="Saddle-Path"><a href="#Saddle-Path" class="headerlink" title="Saddle Path"></a>Saddle Path</h4><p>The Saddle Path is the path along which the dynamical system ends up at the steady state</p><p>Thus, for an initial $k_0$, there is an initial $q_0$ on that saddle path</p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-10.jpg" alt></p><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-11.jpg" alt></p><h4 id="Shocks-and-government-policies"><a href="#Shocks-and-government-policies" class="headerlink" title="Shocks and government policies"></a>Shocks and government policies</h4><p>We can use this framework to look at the impact of, e.g., macro shocks on stock prices</p><ul><li>There are lots of examples in <strong>Romer</strong></li></ul><p>Important note:</p><ul><li>We have a ‘jump’ variable, $q_t$</li><li>And a ‘predetermined’ variable, $k_t$</li></ul><p>Thus, in response to some shock, the $q$ jumps onto a new saddle path (if there is one), and the $k$​ does <strong>not immediately change</strong></p><h4 id="Permanent-increase-in-output"><a href="#Permanent-increase-in-output" class="headerlink" title="Permanent increase in output"></a>Permanent increase in output</h4><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-12.jpg" alt></p><h4 id="Temporary-increase-in-output"><a href="#Temporary-increase-in-output" class="headerlink" title="Temporary increase in output"></a>Temporary increase in output</h4><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-13.jpg" alt></p><h4 id="Permanent-fall-in-interest-rate"><a href="#Permanent-fall-in-interest-rate" class="headerlink" title="Permanent fall in interest rate"></a>Permanent fall in interest rate</h4><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-14.jpg" alt></p><p>$q\rightarrow \Delta k\rightarrow i\rightarrow q\rightarrow k$</p><h4 id="Investment-subsidy"><a href="#Investment-subsidy" class="headerlink" title="Investment subsidy"></a>Investment subsidy</h4><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-15.jpg" alt></p><ul><li>$\theta$ : tax credit</li></ul><h4 id="Temporary-tax-credit"><a href="#Temporary-tax-credit" class="headerlink" title="Temporary tax credit"></a>Temporary tax credit</h4><p><img src="/2021/05/17/Economic_Fundamentals_and_Financial_Markets/pic7-16.jpg" alt></p><h2 id="Topic-7-总结"><a href="#Topic-7-总结" class="headerlink" title="Topic 7 总结"></a>Topic 7 总结</h2><script type="math/tex; mode=display">q=\frac{market\ value\ of\ firm}{book\ value\ of\ firm}=\frac{v_t}{k_t}</script><ul><li>tobin’s q</li></ul><h4 id="Leased-Capital"><a href="#Leased-Capital" class="headerlink" title="Leased Capital"></a>Leased Capital</h4><script type="math/tex; mode=display">y=f(k,l)</script><ul><li>regular production function ：$f$​</li></ul><script type="math/tex; mode=display">\pi=py-(rk+wl)=p(\frac{\partial f}{\partial k}k+\frac{\partial f}{\partial l}l)-(rk+wl)</script><h4 id="own-capital-without-adjustment-costs"><a href="#own-capital-without-adjustment-costs" class="headerlink" title="own capital, without adjustment costs"></a>own capital, without adjustment costs</h4><script type="math/tex; mode=display">V=\max_{c_t}\int_0^\infty u(c_t)e^{-\rho t}dt</script><ul><li>utility of the representative shareholder ：$u(c_t)$</li></ul><script type="math/tex; mode=display">y_t=f(k_t)</script><script type="math/tex; mode=display">i_t=y_t-c_t=rk_t-c_t</script><ul><li>investment ：$i$</li><li>consumption of shareholder ：$c$</li></ul><script type="math/tex; mode=display">k_{t+1}-k_t=\dot k_t=i_t=r_tk_t-c_t</script><script type="math/tex; mode=display">p_t=\frac{k_t}N\ (with\ q=1)</script><ul><li>price of a share ：$p$</li></ul><h4 id="own-capital-with-adjustment-costs"><a href="#own-capital-with-adjustment-costs" class="headerlink" title="own capital, with adjustment costs"></a>own capital, with adjustment costs</h4><script type="math/tex; mode=display">y_t=f(k_t)</script><script type="math/tex; mode=display">ror_t=f'(k_t)>0\quad f''(k_t)<0\quad f'''(k_t)>0</script><script type="math/tex; mode=display">k_{t+1}=k_t+i_t</script><script type="math/tex; mode=display">T(\frac{i_t}{k_t})</script><script type="math/tex; mode=display">T(0)=0\quad T'>0\quad T''>0</script><ul><li><p>unit installation cost ：$T$</p></li><li><p>total cost of capital increase ：$i_t[1+T(\frac{i_t}{k_t})]$</p></li></ul><script type="math/tex; mode=display">b_{t+1}-b_t=c_t+i_t[1+T(\frac{i_t}{k_t})]+r_tb_t-f(k_t)</script><ul><li>debt ： $b_0$</li></ul><script type="math/tex; mode=display">surplus_t=y_t-(c_t+i_t[1+T(\frac{i_t}{k_t})]+r_tb_t)</script><script type="math/tex; mode=display">b_1=b_0-surplus_0</script><script type="math/tex; mode=display">de_t=\frac{r_tb_t}{y_t}=\frac{interest\ charges}{earnings}</script><script type="math/tex; mode=display">u(c_t)=ln(c_t)</script><ul><li>shareholder’s instantaneous utility</li></ul><script type="math/tex; mode=display">U_0=\sum_{t=0}^\infty\frac{u(c_t)}{(1+\rho)^t}</script><ul><li>discounts utility rate ：$\rho$</li></ul><script type="math/tex; mode=display">set\ r_t=\bar r</script><script type="math/tex; mode=display">c_t=(\frac{1+\bar r}{1+\rho})^tc_0</script><ul><li><strong>shadow price</strong> of installed capital ：$q$</li></ul><p>If $i_t&gt;0$​</p><script type="math/tex; mode=display">q_t=1+T(\frac{i_t}{k_t})+\frac{i_t}{k_t}T'(\frac{i_t}{k_t})</script><p>If $i_t&lt;0$​</p><script type="math/tex; mode=display">q_t=1-T(\frac{i_t}{k_t})-\frac{i_t}{k_t}T'(\frac{i_t}{k_t})</script><script type="math/tex; mode=display">\phi(q)=\frac{i_t}{k_t}=\begin{cases}\sqrt{\frac{q-1}{3a}}&when\ q>1\\-\sqrt{\frac{1-q}{3a}}&when\ q<1\end{cases}</script><script type="math/tex; mode=display">i_0=\phi(q_0)k_0</script><script type="math/tex; mode=display">\Delta k_{t+1}=\phi(q_t)k_t</script><script type="math/tex; mode=display">f'(k_t)=r_tq_t-\Delta q_{t+1}</script><script type="math/tex; mode=display">\Delta k_t=0=\phi(q^*)k^*\Rightarrow q=1</script><script type="math/tex; mode=display">\Delta q_t=0=r^*q^*-f'(k^*)\Rightarrow q^*=f'(k^*)/r^*</script>]]></content>
    
    
    <categories>
      
      <category>Economics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Macroeconomics</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【课程】Applied Computational Finance</title>
    <link href="/2021/05/12/Applied_Computational_Finance/"/>
    <url>/2021/05/12/Applied_Computational_Finance/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于格拉斯哥ECON5065的笔记；</p></blockquote><span id="more"></span><h1 id="General-information"><a href="#General-information" class="headerlink" title="General information"></a>General information</h1><p>Many problems in economics, finance and financial engineering do not possess a closed-form solution which could be computed easily. Typically, these problems are solved by using <strong>numerical algorithms and simulation methods</strong>. This course covers the study and implementation of such techniques. These include <strong>Monte Carlo simulation</strong> for <strong>pricing complex derivatives</strong>; <strong>finite difference methods</strong> to solve <strong>partial differential equations</strong> for option pricing; <strong>effective methods</strong> to compute <strong>hedging strategies</strong>; <strong>numerical dynamic programming</strong> for <strong>optimal portfolios</strong>, <strong>resource management and economic growth</strong>. Advanced understanding of these techniques and their implementation on computer using software packages and programming languages is the focus of this course.</p><h1 id="Aims"><a href="#Aims" class="headerlink" title="Aims"></a>Aims</h1><p>The main aims of this course are to introduce students to core techniques in computational finance, such as <strong>simulation of asset prices</strong>, pricing options using <strong>stochastic models</strong>, <strong>Monte Carlo methods</strong> as applied to complex derivatives, solving <strong>Black-Scholes</strong> type equations <strong>numerically</strong>, solving <strong>dynamic optimization</strong> problems <strong>numerically</strong>, and how to implement these techniques using modelling software packages and programming languages.</p><h1 id="ILOs"><a href="#ILOs" class="headerlink" title="ILOs"></a>ILOs</h1><p>By the end of this course, students will be able to:</p><ol><li>Calculate the price and hedging portfolios of complex derivatives using <strong>Monte Carlo simulations</strong>; </li><li>Calculate the price of American and other exotic options by implementing <strong>numerical methods</strong> to solve the related partial differential equations; </li><li>Implement <strong>dynamic programming algorithms</strong> to solve problems in portfolio optimisation, resource management and monetary policy; </li><li>Demonstrate advanced skills in modelling software package <strong>MATLAB</strong>.</li></ol><h1 id="Unit-1：Black-Scholes-Model"><a href="#Unit-1：Black-Scholes-Model" class="headerlink" title="Unit 1：Black-Scholes Model"></a>Unit 1：Black-Scholes Model</h1><h2 id="Unit-1-1：P-amp-L-Approach-to-Black-Scholes-Equation"><a href="#Unit-1-1：P-amp-L-Approach-to-Black-Scholes-Equation" class="headerlink" title="Unit 1.1：P&amp;L Approach to Black-Scholes Equation"></a>Unit 1.1：P&amp;L Approach to Black-Scholes Equation</h2><ul><li><strong>P&amp;L</strong>：profit and loss </li><li><strong>T</strong>：maturity</li><li><strong>S</strong>：underlying asset price</li><li>$F(S_T)$：payoff function</li><li>$P(t, S)$：pricing function </li></ul><p>Consider the <strong>P&amp;L</strong> due to trading between time $t$ and $t + \delta t$</p><script type="math/tex; mode=display">P\&L=-[P(t+\delta t,S+\delta S)-P(t,S)]+rP(t,S)\delta t+\Delta\delta S-(r-q)\Delta S\delta t</script><script type="math/tex; mode=display">P(t+\delta t,S+\delta S)-P(t,S) \approx \frac{dP}{dt}\delta t+\frac{dP}{dS}\delta S +\frac{1}{2}\frac{d^2P}{dS^2}(\delta S)^2</script><ul><li><p>$\delta S$：change in the stock price, $\delta S$ independent of $\delta t$</p></li><li><p>$\Delta = \frac{dP}{dS}$</p></li></ul><script type="math/tex; mode=display">\begin{align}P\&L&=-[\frac{dP}{dt}\delta t+\frac{dP}{dS}\delta S +\frac{1}{2}\frac{d^2P}{dS^2}(\delta S)^2]+rP\delta t+\frac{dP}{dS}\delta S-(r-q)\frac{dP}{dS} S\delta t\\&=-\underbrace{(\frac{dP}{dt}-rP+(r-q)\frac{dP}{dS} S)}\delta t -\underbrace{\frac{1}{2}S^2\frac{d^2P}{dS^2}(\frac{\delta S}{S})^2}\\&\qquad \qquad deterministic\ part \quad \quad \quad random\ exposure\end{align}</script><ul><li>theta：$\frac{dP}{dt}$</li><li><p>corrected theta：$\frac{dP}{dt}-rP+(r-q)S\frac{dP}{dS}$</p></li><li><p>gamma：$\frac{d^2P}{dS^2}$</p></li><li>Dollar gamma：$S^2\frac{d^2P}{dS^2}$</li></ul><script type="math/tex; mode=display">P\&L=-A(t,S)\delta t -B(t,S)(\frac{\delta S}{S})^2</script><p>Any model is unusable if $A(t, S)$ and $B(t, S)$ have the same sign. The model is usable only if $A(t, S)$ and $B(t, S)$ have different signs.</p><p>No money is made if</p><script type="math/tex; mode=display">\frac{\delta S}{S}=\pm \sqrt{-\frac{A(t, S)}{B(t, S)}}\delta t</script><p>On average we have </p><script type="math/tex; mode=display">\langle(\frac{\delta S}{S})^2\rangle=\hat{\sigma}^2\delta t</script><p>where $\hat{\sigma}$ is the historical volatility of $S$ based on returns $\delta S/S$</p><p>For risk-management, our model should satisfy the condition</p><script type="math/tex; mode=display">A(t, S) = -\hat{\sigma}^2B(t, S)</script><p>Thus,</p><script type="math/tex; mode=display">\frac{dP_{\sigma^2}}{dt}-rP_{\sigma^2}+(r-q)\frac{dP_{\sigma^2}}{dS} S= -\frac{\hat{\sigma}^2}{2}S^2\frac{d^2P_{\sigma^2}}{dS^2}</script><p>where $P_{\sigma^2}$ accounts for dependence on the volatility level $\hat{\sigma}$</p><p>We then get,</p><script type="math/tex; mode=display">P\&L=-\frac{S^2}{2}\frac{d^2P_{\sigma}^2}{dS^2}((\frac{\delta S}{S})^2-\hat{\sigma}^2\delta t)</script><p>For vanilla options in the market, $\hat{\sigma}$ is the <strong>implied volatility</strong> such that $P_{\sigma^2}$ is equal to the market price.</p><h2 id="Unit-1-2：Stochastic-Differential-Equations"><a href="#Unit-1-2：Stochastic-Differential-Equations" class="headerlink" title="Unit 1.2：Stochastic Differential Equations"></a>Unit 1.2：Stochastic Differential Equations</h2><p>Recall a <strong>differential equation</strong></p><script type="math/tex; mode=display">\dot{X}(t)=\frac{dX(t)}{dt}=g(t,X(t))</script><p>This can be written alternatively as</p><script type="math/tex; mode=display">dX(t)=g(t,X(t))dt</script><p>or approximately as an <strong>difference equation</strong> with small time interval (increment) $\Delta t$</p><script type="math/tex; mode=display">\Delta X(t)=X(t+\Delta t)-X(t)=g(t,X(t))\Delta t</script><p>with  the increments of <strong>Brownian motion</strong> $\Delta W = W(t+\Delta t)-W(t), \Delta W \sim N(0,\Delta t)$</p><script type="math/tex; mode=display">\begin{matrix}\Delta X(t)=\underbrace{g(t,X(t))\Delta t}+\underbrace{\sigma(t,X(t))\Delta W}\\\qquad\qquad\quad drift\ part \quad \quad diffusion\ part\end{matrix}</script><p><strong>stochastic differential equation</strong></p><script type="math/tex; mode=display">dX(t)=g(t,X(t))d t+\sigma(t,X(t))d W</script><h2 id="Unit-1-3：Ito-Formula"><a href="#Unit-1-3：Ito-Formula" class="headerlink" title="Unit 1.3：Ito Formula"></a>Unit 1.3：Ito Formula</h2><blockquote><p>Ito Formula 相当于 Taylor 展开的一种特殊形式，因为它是针对随机过程的，因此在二次导的展开项中直接略过了所有与 dt 相乘的项， 只留下 $F_{XX}$</p><p>与 dt 相乘的项都趋近 0 的原因是，对于 dtdt/dtdW，其中一个部分是作用于 $||\pi||\to 0$ 时，把累加部分相连的. $\sum f(x) (t_{i+1}-t_i)\to \int f(x) dt$. 剩下的那一部分由于 $||\pi||$ 极限趋近于 0，即两个 t 之间相隔极近，会使整个式子趋近 0. 比如 dtdt 为 $(dt)^2$, dtdW 为 $(dt)^{1.5}$, 去掉一个 dt 仍然有保留的幂，则整个式子取 0.</p></blockquote><p>We are interested in the dynamics of an expression such as $f(t)=F(t,X(t))$ with $F:[0,\infty]\times \mathbb{R}\to \mathbb{R}$ .</p><ul><li>$F$：option pricing function</li><li>$X(t)$：underlying share price</li><li>$(dW)^2 = dt$</li><li>up to order 1 in $dt$：$(dt)^2=0$， $(dW)(dt)=dt\sqrt{dt}=0$</li><li>$(dX)^2=\sigma(t,X(t))^2dt$</li></ul><p>Then, the stochastic process $f$  has the following dynamics</p><script type="math/tex; mode=display">\begin{align}df&=F_tdt+F_XdX+\frac{1}{2}F_{XX}(dX)^2\\&=F_tdt+F_Xg(t,X(t))dt+F_X\sigma(t,X(t)) dW+\frac{1}{2}F_{XX}\sigma(t,X(t))^2dt\\&=(F_t+F_Xg(t,X(t))+\frac{1}{2}F_{XX}\sigma(t,X(t))^2)dt+F_X\sigma(t,X(t)) dW\end{align}</script><p>Suppose that the asset price $S$ solves the following stochastic differential equation</p><script type="math/tex; mode=display">\frac{dS(t)}{S(t)}=\mu dt+\sigma dW(t) \sim N(\mu,\sigma^2 dt)</script><p>At $t = T$, we have</p><script type="math/tex; mode=display">S(T)=S(t)exp((\mu-\frac{1}{2}\sigma^2)(T-t)+\sigma(W(T)-W(t)))</script><h4 id="Delta-Hedging"><a href="#Delta-Hedging" class="headerlink" title="Delta Hedging"></a>Delta Hedging</h4><p>Black, Scholes, Merton approach : construct a riskless portfolio, which consists of selling the option and buying the asset</p><script type="math/tex; mode=display">\begin{align}-dP+\Delta dS&=-(P_tdt+P_SdS+\frac{1}{2}P_{SS}(dS)^2)+\Delta dS\\&=-(P_t+\frac{1}{2}S^2\sigma^2P_{SS})dt+(-P_S+\Delta)dS\end{align}</script><p>where</p><script type="math/tex; mode=display">\begin{align}(dS)^2&=(S(t)(\mu dt+\sigma dW(t)))^2\\&=S(t)^2(\mu^2(dt)^2+2\mu\sigma dtdW(t)+\sigma^2(dW(t))^2)\\&=S(t)^2(0+0+\sigma^2dt)\end{align}</script><p>Substitution of $dS$ gives</p><script type="math/tex; mode=display">-dP+\Delta dS=-(P_t+\frac{1}{2}S^2\sigma^2P_{SS}+(P_S-\Delta)S\mu)dt+(-P_S+\Delta)S\sigma dW</script><p>riskless $\Rightarrow \Delta = P_S$</p><p>Substitution gives</p><script type="math/tex; mode=display">-dP+\Delta dS=-(P_t+\frac{1}{2}S^2\sigma^2P_{SS})dt</script><p>Recall that</p><script type="math/tex; mode=display">-dP+\Delta dS=(-P+\Delta S)rdt</script><p>Combining the above results, leads to the Black-Scholes equation</p><script type="math/tex; mode=display">-Pr+P_SSr+P_t+\frac{1}{2}S^2\sigma^2P_{SS}=0</script><p>with boundary condition</p><script type="math/tex; mode=display">P(T,S(T))=F(S(T))</script><p>Under the Black-Scholes-Merton (BSM) model, European call option price is given as</p><script type="math/tex; mode=display">\begin{align}C(t,S,T,K)&=S\Phi(d_1)-Ke^{-r(T-t)}\Phi(d_2)\\d_1&=\frac{ln(\frac{S}{Ke^{-r(T-t)}})+\frac{1}{2}\sigma^2(T-t)}{\sigma\sqrt{T-t}}\\d_2&=\frac{ln(\frac{S}{Ke^{-r(T-t)}})-\frac{1}{2}\sigma^2(T-t)}{\sigma\sqrt{T-t}}\\&=d_1-\sigma\sqrt{T-t}\end{align}</script><p>European put option price is given as</p><script type="math/tex; mode=display">P(t,S,T,K)=Ke^{-r(T-t)}\Phi(-d_2)-S\Phi(-d_1)</script><p>Black-Scholes PDE can be transformed to Black-Scholes Pricing Formula through <strong>solving the heat equation</strong></p><h2 id="Unit-1-4：Greeks"><a href="#Unit-1-4：Greeks" class="headerlink" title="Unit 1.4：Greeks"></a>Unit 1.4：Greeks</h2><p>Certain partial derivatives of option prices are widely used for hedging purposes and have been assigned Greek names and symbols : </p><div class="table-container"><table><thead><tr><th>Delta</th><th>Gamma</th><th>Rho</th><th>Theta</th><th>Vega</th></tr></thead><tbody><tr><td>$\Delta$</td><td>$\Gamma$</td><td>$\rho$</td><td>$\Theta$</td><td>$vega$</td></tr><tr><td>$\frac{\partial C}{\partial S}$</td><td>$\frac{\partial^2 C}{\partial S^2}$</td><td>$\frac{\partial C}{\partial r}$</td><td>$\frac{\partial C}{\partial t}$</td><td>$\frac{\partial C}{\partial \sigma}$</td></tr></tbody></table></div><p><a href="https://achlier.github.io/2021/04/25/Mathematical_Finance/#Greeks">Read more about those functions</a></p><p>Recall that</p><script type="math/tex; mode=display">\begin{align}C(t,S,T,K)&=S\Phi(d_1)-Ke^{-r(T-t)}\Phi(d_2)\\\underbrace{Ke^{-r(T-t)}\Phi(d_2)}&=S\underbrace{\Phi(d_1)}-C(t,S,T,K)\\money\ market &\quad shares\ in\ asset\end{align}</script><h2 id="Unit-1-5：Implied-Volatility"><a href="#Unit-1-5：Implied-Volatility" class="headerlink" title="Unit 1.5：Implied Volatility"></a>Unit 1.5：Implied Volatility</h2><p>Suppose that the market price of a European call option with expiry $T$ and strike $K$ at time $t$ is observed to be $C^{mkt}(t)$</p><p>In our model</p><script type="math/tex; mode=display">C(t,T,\sigma,K)=C^{mkt}(t)</script><p>Now consider <strong>vega</strong> of the option given by</p><script type="math/tex; mode=display">\frac{\partial}{\partial\sigma}C(t,T,\sigma,K)=S_t\sqrt{T-t}\Phi'(d_1)</script><ul><li>It can be shown, that there exists a solution whenever $C^{mkt}(t)$ is contained in the open interval  $((S_t-Ke^{-r(T-t)})^+,S_t)$</li><li>The positivity of vega tells us that the function $C(t,T, σ,K) – C^{obs}(t)$ is strictly increasing as a function of $\sigma$</li></ul><p>The solution of the equation,  $\sigma^{impl}$ , is called implied volatility</p><p>We can therefore compute its zeros numerically by applying the <strong>Newton method</strong> (it always works if the function is convex)</p><script type="math/tex; mode=display">\sigma_{k+1} = \sigma_k - \frac{C(t,T, \sigma_k,K)-C^{obs}(t)}{\frac{\partial}{\partial \sigma}C(t,T, \sigma_k,K)}</script><p>Plot the Implied Volatility - Moneyness ( $\frac{ln(K/F)}{\sigma\sqrt{T}}$ ) and we could have volatility smile</p><blockquote><p>然而实际上 BS model 服从的是 normal distribution ，并且只包函基本的参数。因此对于 BS model 来说 moneyness （in，at，out of money）是不影响 volatility的，即画出的 moneyness-volatility 是一条直线。</p><p>对于真正的市场，存在 fat tail 现象，除此之外流动性，手续费，最低报价间隔，以及最小报价单位等变量未包含在 BS model 中，导致了它的不准确。此外，投资者参与期权交易的目的对隐含波动率也有影响。股票期权交易者中有很大一部分的交易目的是防止股票下跌，因此他们选择的策略多是 buy put 或者 covered call ，这样导致波动率曲线向右下侧倾斜；而外汇期权的交易者的交易目的并不偏向两种方向，因此隐含波动率曲线多是smile的形状。</p></blockquote><h1 id="Unit-2：Advanced-stochastic-models-and-their-calibration"><a href="#Unit-2：Advanced-stochastic-models-and-their-calibration" class="headerlink" title="Unit 2：Advanced stochastic models and their calibration"></a>Unit 2：Advanced stochastic models and their calibration</h1><h2 id="Unit-2-1：local-volatility"><a href="#Unit-2-1：local-volatility" class="headerlink" title="Unit 2.1：local volatility"></a>Unit 2.1：local volatility</h2><p>Local volatility is a class of market models which is an extension of the fixed volatility Black-Scholes-Merton model. In the model, instantaneous volatility is a function of t, S; $\sigma(t,S)$</p><p>Given the market observed European option prices, our aim is to find<br>the function $\sigma(t,S)$. It was shown by Bruno Dupire that</p><script type="math/tex; mode=display">\sigma(t,S)^2=2\frac{\frac{dC}{dt}+qC+(r-q)K\frac{dC}{dK}}{K^2\frac{d^2C}{dK^2}}| _ { K = S,T=t }</script><h2 id="Unit-2-2：Derivation-of-the-Dupire-Formula"><a href="#Unit-2-2：Derivation-of-the-Dupire-Formula" class="headerlink" title="Unit 2.2：Derivation of the Dupire Formula"></a>Unit 2.2：Derivation of the Dupire Formula</h2><p>Suppose that we have the following dynamics</p><script type="math/tex; mode=display">dS_t=(r-q)S_t dt+\sigma_tS_tdW_t</script><p>Next, recall that the price of a European call option is given as $C(T,K)=e^{-rT}\mathbb{E}[(S_T-K)^+]$</p><p>First, use Ito’s formula for $(S_T-K)^+$ over $[T,T + dT]$ :</p><script type="math/tex; mode=display">d(S_T-K)^+=\frac{\partial(S_T-K)^+}{\partial S_T}dS_T+\frac{1}{2}\frac{\partial^2(S_T-K)^+}{\partial S_T^2}(dS_T)^2</script><p>We then get</p><script type="math/tex; mode=display">d(S_T-K)^+=\frac{\partial(S_T-K)^+}{\partial S_T}((r-q)S_T dT+\sigma_TS_TdW_T)+\frac{1}{2}\frac{\partial^2(S_T-K)^+}{\partial S_T^2}\sigma^2_TS^2_TdT</script><p>Next, note that</p><script type="math/tex; mode=display">\frac{\partial(S_T-K)^+}{\partial S_T}=\theta(S_T-K)\ Heaviside\ function</script><script type="math/tex; mode=display">\frac{\partial^2(S_T-K)^+}{\partial S_T^2}=\delta(S_T-K)\ Dirac\ delta\ function</script><p>where <strong>Heaviside function</strong></p><script type="math/tex; mode=display">\theta(x)=\begin{cases}1&x>0\\0&x<0\end{cases}</script><p>and <strong>delta function</strong></p><script type="math/tex; mode=display">\delta(x)=\begin{cases}\infty&x=0\\0&x\ne0\end{cases},\ \int_{-\infty}^\infty \delta(x)dx=1</script><blockquote><p>$\int_{-\infty}^\infty\delta(x-y)f(x)dx=f(y)$</p></blockquote><p>Then,</p><script type="math/tex; mode=display">d(S_T-K)^+=\theta(S_T-K)((r-q)S_T dT+\sigma_TS_TdW_T)+\frac{1}{2}\delta(S_T-K)\sigma^2_TS^2_TdT</script><p>To use the above formula, let us consider “undiscounted” option prices $\mathscr{C}(T,K)=\mathbb{E}[(S_T-K)^+]$. Taking derivative w.r.t. K</p><script type="math/tex; mode=display">\begin{align}\frac{d\mathbb{E}[(S_T-K)^+]}{d K}&=-\mathbb{E}[\theta(S_T-K)]\\ \frac{d^2\mathbb{E}[(S_T-K)^+]}{d K^2}&=\mathbb{E}[\delta(S_T-K)]\end{align}</script><p>Note that $\mathbb{E}[\delta(S_T-K)]$ is the density of stock prices</p><blockquote><p>$\mathbb{E}[\delta(S_T-K)]=\int_{-\infty}^\infty\delta(S_T-K)f(S_T)dx=f(K)$</p></blockquote><p>From the identity</p><script type="math/tex; mode=display">\begin{align}\mathscr{C}(T,K)&=\mathbb{E}[(S_T-K)\theta(S_T-K)]\\&=\mathbb{E}[S_T\theta(S_T-K)]-K\mathbb{E}[\theta(S_T-K)]\end{align}</script><p>we get $\mathbb{E}[S_T\theta(S_T-K)]=\mathscr{C}+K\mathbb{E}[\theta(S_T-K)]=\mathscr{C}-K\frac{\partial\mathscr{C}}{\partial K}$</p><p>Next note that $\mathbb{E}[d(S_T-K)^+]=d\mathbb{E}[(S_T-K)^+]$</p><p>Then, by taking expectation in the Ito’s formula applied on $(S_T-K)^+$ with $\mathbb{E}[W_t]=0$</p><script type="math/tex; mode=display">\begin{align}\mathbb{E}[d(S_T-K)^+]&=\mathbb{E}[\theta(S_T-K)((r-q)S_T dT+0)]+\frac{1}{2}\mathbb{E}[\delta(S_T-K)\sigma^2_TS^2_TdT]\\d\mathscr{C}&=(r-q)\mathbb{E}[\theta(S_T-K)S_T]dT+\frac{1}{2}\mathbb{E}[\delta(S_T-K)\sigma^2_TS^2_T]dT\\\frac{d\mathscr{C}}{dT}dT&=(r-q)(\mathscr{C}-K\frac{\partial\mathscr{C}}{\partial K})dT+\frac{1}{2}\mathbb{E}[\delta(S_T-K)\sigma^2_TS^2_T]dT\end{align}</script><p>we evaluate the function at $S_t$ equal to $K$</p><script type="math/tex; mode=display">\frac{d\mathscr{C}}{dT}dT=(r-q)(\mathscr{C}-K\frac{\partial\mathscr{C}}{\partial K})dT+\frac{1}{2}K^2\mathbb{E}[\delta(S_T-K)\sigma^2_T]dT</script><p>Above yields</p><script type="math/tex; mode=display">\mathbb{E}[\delta(S_T-K)\sigma^2_T]=\frac{2}{K^2}(\frac{d\mathscr{C}}{dT}-(r-q)(\mathscr{C}-K\frac{\partial\mathscr{C}}{\partial K}))</script><script type="math/tex; mode=display">\frac{\mathbb{E}[\delta(S_T-K)\sigma^2_T]}{\mathbb{E}[\delta(S_T-K)]}=2\frac{\frac{d\mathscr{C}}{dT}-(r-q)(\mathscr{C}-K\frac{\partial\mathscr{C}}{\partial K})}{K^2\frac{d^2\mathscr{C}}{dK^2}}</script><p>Going back to the notation of $C = e^{–rT}\mathscr{C}$ , we obtain the Dupire’se quation</p><script type="math/tex; mode=display">\begin{align}\mathbb{E}[\sigma_T^2|S_T=K]&=\frac{\sigma(T,K)f(K)}{f(K)}=\frac{\mathbb{E}[\delta(S_T-K)\sigma^2_T]}{\mathbb{E}[\delta(S_T-K)]}\\&=2\frac{\frac{dC}{dT}+qC+(r-q)K\frac{\partial C}{\partial K}}{K^2\frac{d^2C}{dK^2}}\end{align}</script><p>Thus, we get the Dupire’s formula</p><script type="math/tex; mode=display">\sigma^2(t,S)=2\frac{\frac{dC}{dT}+qC+(r-q)K\frac{\partial C}{\partial K}}{K^2\frac{d^2C}{dK^2}}|_{K=S, T=t}</script><p>For a known volatility function $\sigma(t, S)$, we can use the Dupire’s formula to price all European call options on $S_0$</p><script type="math/tex; mode=display">\frac{dC}{dT}+(r-q)K\frac{\partial C}{\partial K}-\frac{1}{2}K^2\sigma^2(t=T,S=K)\frac{d^2C}{dK^2}=-qC</script><p>with initial condition $C(T=0,K)=(S_0-K)^+$</p><h2 id="Unit-2-3：Positivity-of-the-right-hand-side-of-the-Dupire-formula"><a href="#Unit-2-3：Positivity-of-the-right-hand-side-of-the-Dupire-formula" class="headerlink" title="Unit 2.3：Positivity of the right hand side of the Dupire formula"></a>Unit 2.3：Positivity of the right hand side of the Dupire formula</h2><p>Consider the second derivative in the <strong>denominator</strong></p><script type="math/tex; mode=display">\frac{d^2C}{dK^2}=\lim_{\epsilon\to 0}\frac{C(T,K-\epsilon)-2C(T,K)+C(T,K+\epsilon)}{\epsilon^2}</script><p>The right hand side can be thought of a <strong>Butterfly spread</strong></p><p>As $\epsilon \to 0$, the butterfly spread (more narrow and more much higher) converges to a Dirac-delta function which is either 0 or strictly positive and thus, it’s price must be positive, thus $\frac{d^2C}{dK^2}&gt;0$</p><p>The <strong>numerator</strong> in the Dupire’s formula can be re-written as</p><script type="math/tex; mode=display">e^{-qT}\frac{d}{dT}(e^{qT}C(T,Ke^{(r-q)T}))|_{K=S}</script><p>For the above to be positive, call option with a strike which is a fixed proportion $K$ of the forward $F_T=Se^{(r-q)T}$ must be an increasing function of $T$</p><p>For $T_1 \leq  T_2$</p><script type="math/tex; mode=display">e^{qT_1}C(T_1,KF_{T_1})\leq e^{qT_2}C(T_2,KF_{T_2})</script><p>In order to prove it, we suppose that the monotonicity condition is violated, that is </p><script type="math/tex; mode=display">e^{qT_1}C(T_1,KF_{T_1})> e^{qT_2}C(T_2,KF_{T_2})</script><p>Set up the following strategy:</p><ul><li><p>Buy one option of maturity $T_2$, strike $KF_{T_2}$ </p></li><li><p>Sell $e^{–q(T2–T1)}$ options of maturity $T_1$, strike $KF_{T1}$</p></li></ul><p>At inception, setting up the above strategy pays a premium ( &gt; 0 )</p><p>At $T_1$, take the following $\Delta$ position on S:</p><ul><li>If $S_{T_1}&lt;KF_{T1}$ : $\Delta =0$</li><li>If $S_{T_1}&gt;KF_{T1}$ : $\Delta =-1$</li></ul><p>At $T_2$ , the P&amp;L comprises of the following positions</p><ul><li>receipt of payoff from $T_2$ maturity option</li><li>payment of payoff from $T_1$ maturity option, capitalized up to $T_2$</li><li>P&amp;L generated by the delta position created at $T_1$ and liquidated at $T_2$</li></ul><p>For $S_{T_1}^*=\frac{F_{T_2}}{F_{T_1}}S_{T_1}$ , the P&amp;L is written as</p><script type="math/tex; mode=display">\begin{align}&T_2\ Option\ at\ T_2 \qquad\ \qquad T_1\ Option\ at\ T_2 \qquad\qquad\ \quad Delta\  portfolio\\&\overbrace{(S_{T_2}-KF_{T_2})^+}-\overbrace{e^{r(T_2-T_1)}e^{-q(T_2-T_1)}(S_{T_1}-KF_{T_1})^+}+\overbrace{\Delta(S_{T_2}-\frac{F_{T_2}}{F_{T_1}}S_{T_1})}\\&=(S_{T_2}-KF_{T_2})^+-[\frac{F_{T_2}}{F_{T_1}}(S_{T_1}-KF_{T_1})^++1_{S_{T_1}>KF_{T_1}}(S_{T_2}-\frac{F_{T_2}}{F_{T_1}}S_{T_1})]\\&=(S_{T_2}-KF_{T_2})^+-[(S_{T_1}^*-KF_{T_2})^++1_{S_{T_1}^*>KF_{T_2}}(S_{T_2}-S_{T_1}^*)]\end{align}</script><p>The last equation reads as</p><script type="math/tex; mode=display">f(S_{T_2})-[f(S_{T_1}^*)+(S_{T_2}-S_{T_1}^*)\frac{df}{dx}(S_{T_1}^*)]</script><p>for $f(x)=(x-KF_{T_2})^+$</p><blockquote><p>$f(y)-f(x)&gt;(y-x)f(x) when f’’(x)&gt;0$</p></blockquote><p>Thus, our strategy produces positive amount at inception and at $T_2$. Therefore, there’s an arbitrage.</p><p>Thus, the numerator in the Dupire’s formula is always positive.</p><h2 id="Unit-2-4-Further-aspects-of-the-Dupire-formula-and-local-volatility"><a href="#Unit-2-4-Further-aspects-of-the-Dupire-formula-and-local-volatility" class="headerlink" title="Unit 2.4 Further aspects of the Dupire formula and local volatility"></a>Unit 2.4 Further aspects of the Dupire formula and local volatility</h2><p>To compute the Dupire’s local volatility function in terms of implied volatility $\hat\sigma(T,K)$, first write</p><script type="math/tex; mode=display">C(S_0,T,K)=C^{BS}(S_0,T,K,\hat\sigma(T,K))</script><p>Next, define</p><ul><li>forward price as $F_t=S_0e^{(r-q)(t-t_0)}$</li><li>log strike as $y=ln(\frac{K}{F_t})$</li><li>parameterized volatility as $f(t,y)=(t-t_0)\hat\sigma^2(t,K)$</li></ul><p>Next, replace $C(S_0,T,K)$ in the Dupire’s formula with $C^{BS}(S_0,T,K,\hat\sigma(T,K))$ and compute derivatives using $f$ and $y$ rather than $\hat\sigma$and $K$</p><script type="math/tex; mode=display">\begin{align}C^{BS}(F_t,y,f)&=F_tN(d_1)-KN(d_2)\\&=F_t(N(\frac{-y}{\sqrt{f}}+\frac{\sqrt{f}}{2})-e^{y}N(\frac{-y}{\sqrt{f}}-\frac{\sqrt{f}}{2}))\end{align}</script><h4 id="【Method-1】"><a href="#【Method-1】" class="headerlink" title="【Method 1】"></a>【Method 1】</h4><blockquote><p>这个方法需要求 $\frac{\partial f}{\partial K}$, 此处省略了, 计算比较复杂,以下$C$为$C^{BS}$</p></blockquote><p>With</p><script type="math/tex; mode=display">\frac{\partial C}{\partial K}=\frac{\partial C}{\partial y}\frac{\partial y}{\partial K}+\frac{\partial C}{\partial f}\frac{\partial f}{\partial K}=\frac{1}{K}\frac{\partial C}{\partial y}+\frac{\partial C}{\partial f}\frac{\partial f}{\partial K}</script><script type="math/tex; mode=display">\begin{align}\frac{\partial^2 C}{\partial K^2}&=-\frac{1}{K^2}\frac{\partial C}{\partial y}+\frac{1}{K}\frac{\partial}{\partial K}(\frac{\partial C}{\partial y})+\frac{\partial}{\partial K}(\frac{\partial C}{\partial f})\frac{\partial f}{\partial K}+\frac{\partial C}{\partial f}\frac{\partial^2 f}{\partial K^2}\\&=-\frac{1}{K^2}\frac{\partial C}{\partial y}+\frac{1}{K}(\frac{1}{K}\frac{\partial^2 C}{\partial y^2}+\frac{\partial f}{\partial K}\frac{\partial^2 C}{\partial y\partial f})...\\&...+\frac{\partial f}{\partial K}(\frac{1}{K}\frac{\partial^2 C}{\partial y\partial f}+\frac{\partial f}{\partial K}\frac{\partial^2 C}{\partial f^2})+\frac{\partial C}{\partial f}\frac{\partial^2 f}{\partial K^2}\\&=\frac{1}{K^2}(\frac{\partial^2 C}{\partial y^2}-\frac{\partial C}{\partial y})+\frac{2}{K}\frac{\partial f}{\partial K}\frac{\partial^2 C}{\partial y\partial f}+(\frac{\partial f}{\partial K})^2\frac{\partial^2 C}{\partial f^2}+\frac{\partial C}{\partial f}\frac{\partial^2 f}{\partial K^2}\end{align}</script><p>【Hint】</p><script type="math/tex; mode=display">\begin{align}\frac{\partial}{\partial K}(\frac{\partial C}{\partial y})&=\frac{\partial}{\partial y}(\frac{\partial C}{\partial y})\frac{\partial y}{\partial K}+\frac{\partial}{\partial f}(\frac{\partial C}{\partial y})\frac{\partial f}{\partial K}\\&=\frac{1}{K}\frac{\partial^2 C}{\partial y^2}+\frac{\partial f}{\partial K}\frac{\partial^2 C}{\partial y\partial f}\end{align}</script><script type="math/tex; mode=display">\begin{align}\frac{\partial}{\partial K}(\frac{\partial C}{\partial f})&=\frac{\partial}{\partial y}(\frac{\partial C}{\partial f})\frac{\partial y}{\partial K}+\frac{\partial}{\partial f}(\frac{\partial C}{\partial f})\frac{\partial f}{\partial K}\\&=\frac{1}{K}\frac{\partial^2 C}{\partial y\partial f}+\frac{\partial f}{\partial K}\frac{\partial^2 C}{\partial f^2}\end{align}</script><p>Inserting these equations into</p><script type="math/tex; mode=display">\begin{align}\frac{dC}{dt}=\frac{1}{2}K^2\sigma^2(t,S)\frac{d^2C}{dK^2}-(r-q)K\frac{\partial C}{\partial K}-qC\end{align}</script><h4 id="【Method-2】"><a href="#【Method-2】" class="headerlink" title="【Method 2】"></a>【Method 2】</h4><blockquote><p>以下$c$ 为 $C^{BS}$</p></blockquote><h4 id="Step-1"><a href="#Step-1" class="headerlink" title="Step 1"></a>Step 1</h4><p>按Method 1同样的方法, 但此时C考虑的是K与f不相关,与t相关</p><script type="math/tex; mode=display">\frac{\partial C}{\partial K}=\frac{\partial C}{\partial y}\frac{\partial y}{\partial K}=\frac{1}{K}\frac{\partial C}{\partial y}</script><script type="math/tex; mode=display">\begin{align}\frac{\partial^2 C}{\partial K^2}&=-\frac{1}{K^2}\frac{\partial C}{\partial y}+\frac{1}{K}\frac{\partial}{\partial K}(\frac{\partial C}{\partial y})\\&=-\frac{1}{K^2}\frac{\partial C}{\partial y}+\frac{1}{K}(\frac{1}{K}\frac{\partial^2 C}{\partial y^2}+\frac{\partial f}{\partial K}\frac{\partial^2 C}{\partial y\partial f})\\&=\frac{1}{K^2}(\frac{\partial^2 C}{\partial y^2}-\frac{\partial C}{\partial y})\end{align}</script><p>Since $K=S_0e^{(r-q)(t-t_0)}$ so that $\frac{\partial K}{\partial t}=K(r-q)=K\mu$. And $\frac{\partial y}{\partial K}=\frac{1}{K}$</p><script type="math/tex; mode=display">\frac{\partial C}{\partial t}=\frac{\partial C}{\partial t}+\frac{\partial C}{\partial y}\frac{\partial y}{\partial K}K\mu=\frac{\partial C}{\partial t}+\frac{\partial C}{\partial y}\mu</script><p>we substitute into Equation</p><script type="math/tex; mode=display">\begin{align}\frac{dC}{dt}=\frac{1}{2}K^2\sigma^2(t,S)\frac{d^2C}{dK^2}+(r-q)(C-K\frac{\partial C}{\partial K})\end{align}</script><blockquote><p>因为考虑的是forward，不用把C折现，所以不减去rC</p></blockquote><p>We get</p><script type="math/tex; mode=display">\begin{align}\frac{\partial C}{\partial t}+\frac{\partial C}{\partial y}\mu&=\frac{1}{2}\sigma^2(\frac{\partial^2 C}{\partial y^2}-\frac{\partial C}{\partial y})+\mu(C-\frac{\partial C}{\partial y})\\\frac{\partial C}{\partial t}&=\frac{1}{2}\sigma^2(\frac{\partial^2 C}{\partial y^2}-\frac{\partial C}{\partial y})+\mu C\end{align}</script><h4 id="Step-2"><a href="#Step-2" class="headerlink" title="Step 2"></a>Step 2</h4><p>By taking derivatives of the Black-Scholes formula, we obtain</p><blockquote><p>这个部分我还没推过，但在More的第二个连接里有过程</p></blockquote><script type="math/tex; mode=display">\frac{\partial^2c}{\partial f^2}=(-\frac{1}{8}-\frac{1}{2f}+\frac{y^2}{2f^2})\frac{\partial c}{\partial f}</script><script type="math/tex; mode=display">\frac{\partial^2 c}{\partial y\partial f}=(\frac{1}{2}-\frac{y}{f})\frac{\partial c}{\partial f}</script><script type="math/tex; mode=display">\frac{\partial^2 c}{\partial y^2}-\frac{\partial c}{\partial y}=2\frac{\partial c}{\partial f}</script><p>and we have</p><script type="math/tex; mode=display">\frac{\partial C}{\partial y}=\frac{\partial c}{\partial y}+\frac{\partial c}{\partial f}\frac{\partial f}{\partial y}</script><script type="math/tex; mode=display">\begin{align}\frac{\partial^2 C}{\partial y^2}&=\frac{\partial^2 c}{\partial^2 y}+\frac{\partial^2 c}{\partial y\partial f}\frac{\partial f}{\partial y}+(\frac{\partial^2 c}{\partial f\partial y}+\frac{\partial^2 c}{\partial f^2}\frac{\partial f}{\partial y})\frac{\partial f}{\partial y}+\frac{\partial c}{\partial f}\frac{\partial^2 f}{\partial y^2}\\&=\frac{\partial^2 c}{\partial^2 y}+2\frac{\partial^2 c}{\partial y\partial f}\frac{\partial f}{\partial y}+\frac{\partial^2 c}{\partial f^2}(\frac{\partial f}{\partial y})^2+\frac{\partial c}{\partial f}\frac{\partial^2 f}{\partial y^2}\end{align}</script><script type="math/tex; mode=display">\frac{\partial C}{\partial t}=\frac{\partial c}{\partial t}+\frac{\partial c}{\partial f}\frac{\partial f}{\partial t}=(r-q)c+\frac{\partial c}{\partial f}\frac{\partial f}{\partial t}</script><p>Inserting these equations into</p><script type="math/tex; mode=display">\frac{\partial C}{\partial t}=\frac{\sigma^2}{2}(\frac{\partial^2 C}{\partial y^2}-\frac{\partial C}{\partial y})+(r-q)C</script><p>The local volatility function is then given as</p><script type="math/tex; mode=display">\sigma^2(t,S)=\frac{\frac{df}{dt}}{(\frac{y}{2f}\frac{df}{dy}-1)^2+\frac{1}{2}\frac{d^2f}{dy^2}-\frac{1}{4}(\frac{1}{4}+\frac{1}{f})(\frac{df}{dy})^2}|_{y=ln(\frac{S}{F_t})}</script><p>As in the markets, the option prices are only available for discrete strikes and maturities, to use the Dupire’s formula, we need to interpolate between the available strikes and maturities, and extrapolate outside the market range.</p><p><strong>Issues with Dupire’s Local Volatility Model</strong></p><ul><li>The local volatility surface obtained by the Dupire’s formula is very sensitive to the method of data interpolation</li><li>The only risky asset used is the underlying asset which does not account for the volatility risk (affected by random shocks)</li><li>The calibrated local volatility surface is not stable with the passage of time (in practice the local volatility surface is is changing all the time)</li><li>The dynamics of the volatility process assumed by the model does not correspond to that observed in the market</li></ul><h4 id="More"><a href="#More" class="headerlink" title="More"></a>More</h4><p><a href="https://wenku.baidu.com/view/539e67b7910ef12d2af9e763.html">Derivation of Loval Volatility</a></p><p><a href="http://frouah.com/finance%20notes/Dupire%20Local%20Volatility.pdf">Dupire Local Volatility</a></p><p><a href="https://max.book118.com/html/2017/0322/96459464.shtm">Local volatility modelling</a></p><p><a href="http://web.math.ku.dk/~rolf/teaching/ctff03/Gatheral.1.pdf">Stochastic Volatility and Local Volatility</a></p><h4 id="CEV-Model"><a href="#CEV-Model" class="headerlink" title="CEV Model"></a>CEV Model</h4><p>Constant Elasticity of Variance (CEV) model is given as</p><script type="math/tex; mode=display">\frac{dS_t}{S_t}=rdt+\frac{\sigma}{S_t^{1-a}}dW_t</script><blockquote><p>If $a$ less than one, then we have that non constant local volatility function</p></blockquote><p>Under the risk-neutral measure, by assuming that the forward price is given as $F_t=S_te^{r(T-t)}$, the CEV model can be re-written as</p><script type="math/tex; mode=display">dF_t=\sigma_0F_t^adW_t,\ 0<a\leq1</script><p>The implied volatility is given by the asymptotic approximation</p><script type="math/tex; mode=display">\sigma^{imp}(T,K)=\frac{\sigma_0}{F_m^{(1-a)}}(1+\frac{(1-a)(2+a)}{24}(\frac{F_0-K}{F_m})^2+\frac{(1-a)^2}{24}\frac{\sigma^2_0T}{F_m^{2-2a}}+...)</script><p>with $F_m=\frac{1}{2}(F_0+K)$</p><h4 id="Trinomial-Pricing-Tree"><a href="#Trinomial-Pricing-Tree" class="headerlink" title="Trinomial Pricing Tree"></a>Trinomial Pricing Tree</h4><p>The issue of non-recombining binomial tree is addressed by using a trinomial tree model where the prices are given by</p><script type="math/tex; mode=display">\hat{S}_{t_{i+1}}=\begin{cases}u\hat{S}_{t_i}&p\\(1+r\Delta t)\hat{S}_{t_i}&1-p-q\\d\hat{S}_{t_i}&q\end{cases}</script><p>For the trinomial tree to converge to a continuous process, we further impose</p><script type="math/tex; mode=display">\mathbb{E}[\hat{S}_{t_{i+1}}|\hat{S}_{t_i}]=(1+r\Delta t)\hat{S}_{t_i}</script><script type="math/tex; mode=display">Var(\hat{S}_{t_{i+1}}|\hat{S}_{t_i})=\hat{S}_{t_i}^2\sigma^2(t_i,\hat{S}_{t_i})\Delta t</script><p>For a recombining tree (i.e. the number of nodes increase linearly and not exponentially), we need $u d=(1+\Delta t)^2$ </p><p>The probabilities are given as</p><script type="math/tex; mode=display">\begin{align}p(t_i,\hat{S}_{t_i})&=\frac{\sigma(t_i,\hat{S}_{t_i})^2\Delta t}{(u-d)(u-1-r\Delta t)}\\q(t_i,\hat{S}_{t_i})&=\frac{\sigma(t_i,\hat{S}_{t_i})^2\Delta t}{(u-d)(1+r\Delta t-d)}\end{align}</script><p>To ensure the absence of arbitrage in the model, we need that $p + q\leq 1$ whic is ensured if</p><script type="math/tex; mode=display">1 + r\Delta t - d > \sigma(t_i, \hat S_{t_i}) \sqrt{∆t}</script><p>Such that the above inequality is always satisfied, we choose</p><script type="math/tex; mode=display">d=1+r\Delta t-\bar\sigma\sqrt{\Delta t}</script><p>where $\sigma &gt; \sigma(t, S)$ for all the nodes in the trinomial tree</p><p>By choosing $\bar\sigma$ sufficiently large, in the limit, we obtain the following model which does not admit arbitrage</p><script type="math/tex; mode=display">\frac{dS_t}{S_t}=rdt+\min(\bar\sigma,\sigma(t,S))dW_t</script><h2 id="Unit-2-5：Stochastic-Volatility"><a href="#Unit-2-5：Stochastic-Volatility" class="headerlink" title="Unit 2.5：Stochastic Volatility"></a>Unit 2.5：Stochastic Volatility</h2><p>For local volatility</p><script type="math/tex; mode=display">d\sigma(t,S_t)=\frac{\partial}{\partial t}\sigma(t,S_t)dt+\frac{1}{2}\frac{\partial^2}{\partial S^2}\sigma(t,S_t)dS_tdS_t+\frac{\partial}{\partial S}\sigma(t,S_t)dS_t</script><p>The last part show that the randomness of volatility is totally depended on the randomness of stock. However, the empirical data we will find that the randomness in the stock and the randomness in the volatility differ from each other. So the volatility should affected by other sources of randomness.</p><p>The class of models where volatility is supposed to be a stochastic process is called <strong>stochastic volatility models</strong></p><script type="math/tex; mode=display">\frac{dS_t}{S_t}=\mu_tdt+\sigma_tdW_t</script><script type="math/tex; mode=display">d\sigma_t=a_tdt+b_tdW'_t,\ d\langle W,W'\rangle_t=\rho dt</script><h2 id="Unit-2-6：Pricing-Equation"><a href="#Unit-2-6：Pricing-Equation" class="headerlink" title="Unit 2.6：Pricing Equation"></a>Unit 2.6：Pricing Equation</h2><h4 id="Incomplete-Market"><a href="#Incomplete-Market" class="headerlink" title="Incomplete Market"></a>Incomplete Market</h4><p>In an incomplete market, the <strong>risk from volatility (vega)</strong> cannot be eliminated by trading only in the underlying asset</p><p>We have two sources of randomness. However we only allow trading in the money market account. So the market is incomplete. We can make an incomplete market complete by adding additional assets (like option or future).</p><p>We create a self-financing portfolio using two risky assets $S$ and option $C^0$</p><script type="math/tex; mode=display">\frac{dS_t}{S_t}=\mu_tdt+\sigma_tdW_t</script><script type="math/tex; mode=display">d\sigma_t=a_tdt+b_tdW'_t,\ d\langle W,W'\rangle_t=\rho dt</script><script type="math/tex; mode=display">\frac{dB_t}{B_t}=rdt</script><p>The coefficients $a_t$, $b_t$ and $C^0$ are functions of ($t, S_t, \sigma$)</p><p>Often the volatility process will be chosen as a <strong>mean-reverting process</strong></p><p>Suppose $V_t$ denotes the value of a self-financing portfolio with $\delta_t$ shares in $S$ and $\omega_t$ units of $C^0$</p><script type="math/tex; mode=display">dV_t=(V_t-\delta_tS_t-\omega_tC^0_t)rdt+\delta_tdS_t+\omega_tdC^0_t</script><p>By using Ito’s formula, we get</p><script type="math/tex; mode=display">\begin{align}dC^0_t&=\frac{\partial C^0}{\partial t}dt+\frac{\partial C^0}{\partial S_t}dS_t+\frac{\partial C^0}{\partial \sigma_t}d\sigma_t...\\&...+\frac{1}{2}\frac{\partial^2 C^0}{\partial S_t^2}(dS_t)^2+\frac{1}{2}\frac{\partial^2 C^0}{\partial \sigma_t^2}(d\sigma_t)^2+\frac{\partial^2 C^0}{\partial S_t\partial \sigma_t}dS_td\sigma_t\\&=(\frac{\partial C^0}{\partial t}+\frac{1}{2}S_t^2\sigma_t^2\frac{\partial^2 C^0}{\partial S_t^2}+\frac{1}{2}b_t^2\frac{\partial^2 C^0}{\partial \sigma_t^2}+S_t\sigma_tb_t\rho\frac{\partial^2 C^0}{\partial S_t\partial \sigma_t})dt...\\&...+\frac{\partial C^0}{\partial S_t}dS_t+\frac{\partial C^0}{\partial \sigma_t}d\sigma_t\\&=\mathscr{L}_tC^0dt+\frac{\partial C^0}{\partial S_t}dS_t+\frac{\partial C^0}{\partial \sigma_t}d\sigma_t\end{align}</script><p>where $\mathscr{L}_t$ is a <strong>operator</strong></p><script type="math/tex; mode=display">dV_t=(V_t-\delta_tS_t-\omega_tC^0_t)rdt+(\delta_t+\omega_t\frac{\partial C^0}{\partial S_t})dS_t+\omega_t\frac{\partial C^0}{\partial \sigma_t}d\sigma_t+\omega_t\mathscr{L}_tC^0dt</script><p>The value of portfolio to match the option price of C</p><script type="math/tex; mode=display">dV_t\Rightarrow dC_t=\mathscr{L}_tCdt+\frac{\partial C}{\partial S_t}dS_t+\frac{\partial C}{\partial \sigma_t}d\sigma_t</script><p>For the two expressions of dV<em>t</em> to match, we need</p><script type="math/tex; mode=display">\omega_t=\frac{\frac{\partial C}{\partial \sigma_t}}{\frac{\partial C^0}{\partial \sigma_t}},\ \delta_t=\frac{\partial C}{\partial S_t}-\omega_t\frac{\partial C^0}{\partial S_t}</script><p>Set $V_t=C$ and substitute it to</p><script type="math/tex; mode=display">\begin{align}\mathscr{L}_tCdt-\frac{\frac{\partial C}{\partial \sigma_t}}{\frac{\partial C^0}{\partial \sigma_t}}\mathscr{L}_tC^0dt&=(V_t-S_t\frac{\partial C}{\partial S_t}+S_t\frac{\frac{\partial C}{\partial \sigma_t}}{\frac{\partial C^0}{\partial \sigma_t}}\frac{\partial C^0}{\partial S_t}-\frac{\frac{\partial C}{\partial \sigma_t}}{\frac{\partial C^0}{\partial \sigma_t}}C^0_t)rdt\\\mathscr{L}_tC-rC+rS_t\frac{\partial C}{\partial S_t}+&=\frac{\partial C}{\partial \sigma_t}\frac{rS_t\frac{\partial C^0}{\partial S_t}-rC^0_t+\mathscr{L}_tC^0}{\frac{\partial C^0}{\partial \sigma_t}}\\\end{align}</script><p>In the pricing equation for $C$, there is a factor which depends on $C^0$, which we add to our portfolio to complete the market </p><p>Denote</p><script type="math/tex; mode=display">\lambda(t,S_t,\sigma_t)=-\frac{rS_t\frac{\partial C^0}{\partial S_t}-rC^0_t+\mathscr{L}_tC^0}{\frac{\partial C^0}{\partial \sigma_t}}</script><p>Thus, by argument of creating a self-replicating portfolio, we have shown that the price $C$ of a European option with payoff $h(S_T)$, solves the following equation</p><script type="math/tex; mode=display">\mathscr{L}_tC-rC+rS_t\frac{\partial C}{\partial S_t}+\lambda(t,S_t,\sigma_t)\frac{\partial C}{\partial \sigma_t}=0,\ C(T,S_T,\sigma_T)=h(S)</script><p>with</p><script type="math/tex; mode=display">\mathscr{L}_t=\frac{\partial}{\partial t}+\frac{1}{2}S_t^2\sigma_t^2\frac{\partial^2}{\partial S_t^2}+\frac{1}{2}b_t^2\frac{\partial^2}{\partial \sigma_t^2}+S_t\sigma_tb_t\rho\frac{\partial^2}{\partial S_t\partial \sigma_t}</script><p>if chosen $\lambda=0$, the difference of BS-PDE is the last two part of $\mathscr{L}$ with $b_t$</p><h2 id="Unit-2-7：Risk-Neutral-Measure-and-Risk-Premia"><a href="#Unit-2-7：Risk-Neutral-Measure-and-Risk-Premia" class="headerlink" title="Unit 2.7：Risk Neutral Measure and Risk Premia"></a>Unit 2.7：Risk Neutral Measure and Risk Premia</h2><h4 id="Finding-the-Risk-Neutral-Measure"><a href="#Finding-the-Risk-Neutral-Measure" class="headerlink" title="Finding the Risk-Neutral Measure"></a>Finding the Risk-Neutral Measure</h4><p>From its definition, under the risk-neutral measure, price $C_t$ of a European satisfies</p><script type="math/tex; mode=display">dC_t=rC_tdt+\text{ a random term with zero mean}</script><p>Applying the Ito’s formula and using the equation (PDE) in previous part, we get</p><script type="math/tex; mode=display">\begin{align}dC_t&=\mathscr{L}_tC_tdt+\frac{\partial C_t}{\partial S_t}dS_t+\frac{\partial C_t}{\partial \sigma_t}d\sigma_t\\&=(rC_t-rS_t\frac{\partial C_t}{\partial S_t}-\lambda(t,S_t,\sigma_t)\frac{\partial C_t}{\partial \sigma_t})dt+\frac{\partial C_t}{\partial S_t}dS_t+\frac{\partial C_t}{\partial \sigma_t}d\sigma_t\\&=rC_tdt+\frac{\partial C_t}{\partial S_t}(dS_t-rS_tdt)+\frac{\partial C_t}{\partial \sigma_t}(d\sigma_t-\lambda_tdt)\end{align}</script><p>Thus, under the risk-neutral measure (cancels out the $dt$ part in parenthese of the function above), we must have the following</p><script type="math/tex; mode=display">\frac{dS_t}{S_t}=rdt+\sigma_tdW_t</script><script type="math/tex; mode=display">d\sigma_t=\lambda_tdt+b_tdW'_t,\ d\langle W,W'\rangle_t=\rho dt</script><p>Under the risk-neutral measure, the price of a European option is written as</p><script type="math/tex; mode=display">C(t,s,\sigma)=\mathbb{E}[e^{-rT}h(S_T)|\sigma_t=\sigma,S_t=s]</script><p>For the choice of model under physical measure</p><script type="math/tex; mode=display">\frac{dS_t}{S_t}=\mu_tdt+\sigma_tdW_t</script><script type="math/tex; mode=display">d\sigma_t=\alpha_tdt+b_tdW'_t</script><p>By matching the coefficients, we get</p><script type="math/tex; mode=display">\mu_t=r+\sigma_t\beta_t,\ \alpha_t=\lambda_t+b_t\phi_t</script><p>where $\beta_t$(<strong>market prices of risk</strong>) and $\phi_t$ are bounded processes </p><blockquote><p>$dW_t^\mathbb{P}+\theta_tdt=dW_t^\mathbb{Q}$, $\mathbb{P}:$现实测度</p></blockquote><h4 id="Risk-Premiums"><a href="#Risk-Premiums" class="headerlink" title="Risk Premiums"></a>Risk Premiums</h4><p>$\beta_t$ is typically called the risk premium. Analogously, $\phi_t$ is called the risk premium of volatility</p><script type="math/tex; mode=display">\beta_t=\frac{\mu_t-r}{\sigma_t},\ \phi_t=\frac{\alpha_t-\lambda_t}{b_t}</script><p>$\lambda_t$ is calibrated directly under the risk-neutral measure (chosen by market)</p><h2 id="Unit-2-8：Estimation-Error"><a href="#Unit-2-8：Estimation-Error" class="headerlink" title="Unit 2.8：Estimation Error"></a>Unit 2.8：Estimation Error</h2><p><strong>Estimation of Volatility</strong></p><p>We could approximate $\sigma_t$ by its <strong>average</strong> over a period of T estimated using the historical data. However, estimation of historical volatility faces the following issues</p><ul><li>Variance of the estimator decreases with T</li><li>Bias of the approximation of $\sigma_t$ by average volatility increases with T</li></ul><p>Recall that</p><script type="math/tex; mode=display">dlogS_t=(\mu_t-\frac{1}{2}\sigma_t^2)dt+\sigma_tdW_t</script><p>Thus, the quadratic variation of $log S_t$ is given as</p><script type="math/tex; mode=display">\langle log S\rangle_t=\int_0^t\sigma_s^2ds</script><p>Recall from the definition of quadratic variation of a random process</p><script type="math/tex; mode=display">\langle X\rangle_t=\lim_{N\to\infty}\sum_{i=1}^N(X_{\frac{i}{N}t}-X_{\frac{i-1}{N}t})^2</script><p>Denote the log-returns of asset price as</p><script type="math/tex; mode=display">r(t,h):=log\frac{S_{t+h}}{S_t}</script><blockquote><p>$dlogS_t=(logS_{t+1}-logS_t)dt=log\frac{S_{t+1}}{S_t}dt$</p></blockquote><p>Then, we have</p><script type="math/tex; mode=display">\langle log S\rangle_t=\int_0^t\sigma_s^2ds=\lim_{N\to\infty}\sum_{i=1}^Nr(\frac{i-1}{N}t,\frac{t}{N})^2</script><h4 id="Realised-Variance"><a href="#Realised-Variance" class="headerlink" title="Realised Variance"></a>Realised Variance</h4><p>Therefore, we could estimate the integrated variance by the <strong>realised variance</strong></p><script type="math/tex; mode=display">VR_t^N:=\sum_{i=1}^Nr(\frac{i-1}{N}t,\frac{t}{N})^2</script><p>Next, suppose that</p><ul><li>$\sigma_t$ is independent of Brownian motion W driving asset prices S </li><li>Drift function $\mu$ is deterministic</li></ul><p>Then, for a fixed volatility path (由已知数据得出), the log-returns $R_i:=r(\frac{i-1}{N}t,\frac{t}{N})$  are <strong>independent Gaussian random variables</strong> with variance &amp; mean</p><script type="math/tex; mode=display">v_i=\int_{\frac{i-1}{N}t}^{\frac{i}{N}t}\sigma_s^2ds,\ m_i=\int_{\frac{i-1}{N}t}^{\frac{i}{N}t}(\mu_s-\frac{\sigma_s^2}{2})ds</script><h4 id="Error-in-Realised-Variance"><a href="#Error-in-Realised-Variance" class="headerlink" title="Error in Realised Variance"></a>Error in Realised Variance</h4><blockquote><p>Thank the Professor Ankush Agarwal and Christian Ewald. They provide the precise process of following.</p></blockquote><p>If we compute thxe expectation of realised variance $VR^N_t$ for a given volatility path $\sigma_t$, we get</p><script type="math/tex; mode=display">\begin{align}\mathbb{E}_\sigma[VR_t^N]&=\sum_{i=1}^NE_\sigma[R_i^2]=\sum_{i=1}^N(v_i+m_i^2)\\&=\sum_{i=1}^N\int_{\frac{i-1}{N}t}^{\frac{i}{N}t}\sigma_s^2ds+\sum_{i=1}^Nm_i^2\\&=\int_0^t\sigma_s^2ds+\sum_{i=1}^Nm_i^2\end{align}</script><blockquote><p>$E(x^2)=Var(x)+E(x)^2$</p></blockquote><p>with</p><script type="math/tex; mode=display">m_i^2=(\int_{\frac{i-1}{N}t}^{\frac{i}{N}t}(\mu_s-\frac{\sigma_s^2}{2})ds)^2\approx(\mu_{\frac{i-1}{N}t}-\sigma_{\frac{i-1}{N}t}^2/2)^2\frac{t^2}{N^2}</script><blockquote><p>直接取一个固定值来代替这一段的积分，积分在t时间上的宽度是 t/N​</p></blockquote><p>Then</p><script type="math/tex; mode=display">\begin{align}\sum_{i=1}^Nm_i^2&\approx\sum_{i=1}^N\frac{t^2}{N^2}(\mu_{\frac{i-1}{N}t}-\sigma_{\frac{i-1}{N}t}^2/2)^2\\&=\frac{t}{N}\sum_{i=1}^N\frac{t}{N}(\mu_{\frac{i-1}{N}t}-\sigma_{\frac{i-1}{N}t}^2/2)^2\\&\approx\frac{t}{N}\sum_{i=1}^N\int_{\frac{i-1}{N}t}^{\frac{i}{N}t}(\mu_{s}-\frac{\sigma_{s}^2}{2})^2ds\\&=\frac{t}{N}\int_{0}^{t}(\mu_{s}-\frac{\sigma_{s}^2}{2})^2ds\end{align}</script><script type="math/tex; mode=display">\begin{align}&\ (Estimator) (True\ Value) \\&\quad\ \overbrace{\mathbb{E}_\sigma[VR_t^N]}\approx\overbrace{\int_0^t\sigma_s^2ds}+\frac{t}{N}\int_0^t(\mu_s-\frac{\sigma_s^2}{2})^2ds\end{align}</script><p>Thus, the bias of estimating the integrated variance with realised variance</p><script type="math/tex; mode=display">Bias:=\mathbb{E}[True\ Value-Estimator]\approx\mathscr{O}(\frac{t}{N})</script><p>Similarly, the variance of $VR^N_t$ for a given volatility path $\sigma_t$ is</p><script type="math/tex; mode=display">Var(VR_t^N)=E[(VR_t^N-(E[VR_t^N])^2)]=E[(\sum_{i=1}^N(R_i^2-v_i-m_i^2))^2]</script><p>$R_i$ are iid</p><script type="math/tex; mode=display">E[(\sum_{i=1}^N(R_i^2-v_i-m_i^2))^2]=\sum_{i=1}^NE[(R_i^2-v_i-m_i^2)^2]</script><p>For every i</p><script type="math/tex; mode=display">\begin{align}E[(R_i^2-v_i-m_i^2)^2]&=E[R_i^4-2v_iR_i^2-2m_i^2R_i^2+v_i^2+2v_im_i^2+m_i^4]\\&=E[R_i^4]-2(v_i+m_i^2)(v_i+m_i^2)+v_i^2+2v_im_i^2+m_i^4\\&=E[R_i^4]-v_i^2-2v_im_i^2-m_i^4\\\end{align}</script><p>With $E[R_i^4]=m_i^4+6m_i^2v_i+3v_i^2$</p><blockquote><p>关于这一定理可以参考 <a href="https://zhuanlan.zhihu.com/p/148408669">如何通俗的理解矩母函数</a>，以及 <a href="https://en.wikipedia.org/wiki/Normal_distribution">wiki</a> 中展示的 Order 4 的 Non-central moment</p><p>本站更多参考 <a href="https://achlier.github.io/2021/06/17/Normal_Distribution_and_E(x4">正态分布与矩母函数</a>/)</p></blockquote><script type="math/tex; mode=display">E[(R^2-v-m^2)^2]=2v_i^2+4v_im_i^2</script><p>and</p><script type="math/tex; mode=display">Var(VR_t^N)=\sum_{i=1}^N\mathbb{E}_\sigma[(R_i^2-v_i-m_i^2)^2]=\sum_{i=1}^N(2v_i^2+4v_im_i^2)</script><p>Repeat the same step as above</p><script type="math/tex; mode=display">\sum_{i=1}^Nv_i^2\approx\frac{t}{N}\int_0^t\sigma_s^4ds</script><p>Also</p><script type="math/tex; mode=display">\begin{align}\sum_{i=1}^Nv_im_i^2&\approx\sum_{i=1}^N\frac{t}{N}\sigma_{\frac{i-1}{N}t}^2\frac{t^2}{N^2}(\mu_{\frac{i-1}{N}t}-\sigma_{\frac{i-1}{N}t}^2/2)^2\\&\approx\frac{t^2}{N^2}\sum_{i=1}^N\int_{\frac{i-1}{N}t}^{\frac{i}{N}t}\sigma_s^2(\mu_{s}-\frac{\sigma_{s}^2}{2})^2ds\\&=\frac{t^2}{N^2}\int_{0}^{t}\sigma^2_s(\mu_{s}-\frac{\sigma_{s}^2}{2})^2ds\end{align}</script><p>Approximately, the variance of $VR^N_t$ for a given volatility path  $\sigma_t$ is</p><script type="math/tex; mode=display">Var(VR_t^N)\approx\frac{2t}{N}\int_0^t\sigma_s^4ds+\frac{4t^2}{N^2}\int_0^t\sigma_s^2(\mu_s-\frac{\sigma_s^2}{2})^2ds</script><p>Next, we note that the root mean squared error (RMSE) of an estimator is given by</p><script type="math/tex; mode=display">RMSE=\sqrt{Bias+Variance}</script><p>Therefore, the dominant term in the error of realised variance is</p><script type="math/tex; mode=display">\sqrt{\frac{2t}{N}\int_0^t\sigma_s^4ds}</script><script type="math/tex; mode=display">Relative\ error=\frac{\sqrt{\frac{2t}{N}\int_0^t\sigma_s^4ds}}{\int_0^t\sigma_s^2ds}</script><p>If the Relative error is large. We should check out the Greek (sensitive of option price to the Volatility). Insensitive $\to$ no matter that much</p><h4 id="Supplymental-reading"><a href="#Supplymental-reading" class="headerlink" title="Supplymental reading"></a>Supplymental reading</h4><p><a href="https://faculty.washington.edu/ezivot/econ589/econ512realizedvariance.pdf">link</a></p><p><strong>defination</strong></p><ul><li>$p_t$ = log-price of asset at time $t$ = $logS_t$</li><li>$\Delta$ = fraction of a trading session associated with the implied sampling frequency</li><li>$m=1/\Delta$ = number of sampled observations per trading session</li><li>$T$ = number of days in the sample $\Rightarrow$ $mT$ total observations</li><li>$r_{t-1+j\Delta}=p_{t-1+j\Delta}-p_{t-1+(j-1)\Delta}=log\frac{S_{t-1+j\Delta}}{S_{t-1+(j-1)\Delta}}$</li><li>$r_t=r_{t-1+\Delta}+r_{t-1+2\Delta}+…+r_t=log\frac{S_t}{S_{t-1}}$</li><li>Realized variance (RV=VR) on day $t$</li></ul><script type="math/tex; mode=display">RV_t^m=\sum_{j=1}^mr_{t-1+j\Delta}^2</script><ul><li><p>Realized volatility (RVOL) on day $t$</p><script type="math/tex; mode=display">RVOL_t^m=\sqrt{RV_t^m}</script></li><li><p>Realized log-volatility (RLVOL) :</p></li></ul><script type="math/tex; mode=display">RLVOL_t^m=ln(RVOL_t^m)</script><ul><li>Arithematic Brownian Motion (只参考，我们运用的$\mu,\sigma$不是固定的)</li></ul><script type="math/tex; mode=display">dp(t)=\mu dt+\sigma dW(t)</script><script type="math/tex; mode=display">p(t)=p(0)+\mu t+\sigma W(t)</script><script type="math/tex; mode=display">r(t,t-1)=p(t)-p(t-1)</script><ul><li>The quadratic variation (QV) of the return process from time $0$ to $t$ is</li></ul><script type="math/tex; mode=display">[r](t)=\lim_{m\to\infty}\sum_{j=0}^{m-1}(p(t_{j+1})-p(t_j))^2</script><ul><li>Let $p(t)$ be described by the stochastic differential equation</li></ul><script type="math/tex; mode=display">dp(t)=\mu(t) dt+\sigma(t) dW(t)</script><script type="math/tex; mode=display">r(t,t-1)=\int_{t-1}^t\mu(s)ds+\int_{t-1}^t\sigma(s)dW(s)</script><script type="math/tex; mode=display">[r](t)=\int_0^t\sigma^2(s)ds</script><ul><li>IV$_t$ denotes integrated variance for day $t$</li></ul><script type="math/tex; mode=display">QV_T \equiv [r](t)-[r](t-1)=\int_{t-1}^t\sigma^2(s)ds=IV_t</script><p><strong>Example: QV for Wiener process</strong></p><script type="math/tex; mode=display">dp(t)=dW(t),\ \sigma(t)=1</script><script type="math/tex; mode=display">[r](t)=\int_0^t\sigma^2(s)ds=\int_0^tds=t</script><script type="math/tex; mode=display">QV_t=\int_{t-1}^t\sigma^2(s)ds=\int_{t-1}^tds=1</script><p><strong>Q1 What does RV estimate?</strong></p><script type="math/tex; mode=display">RV_t^m \xrightarrow{p} [r](t)-[r](t-1)\equiv QV_t,\ as\ m\to\infty</script><p>That is, daily RV converges in probability to the daily increment in QV.</p><script type="math/tex; mode=display">var(r(t,t-1)|\mathcal{F}_{t-1})=E[QV_t|\mathcal{F}_{t-1}]=E[RV_t^m|\mathcal{F}_{t-1}]</script><p><strong>ABDL (2003)</strong></p><script type="math/tex; mode=display">r(t,t-1)\sim N(\int_{t-1}^t\mu(s)ds,IV_t)</script><ul><li>Since $\int^t_{t−1}\mu(s)ds$ is generally very small for daily returns and $RV_t^m$ is a consistent estimator of $IV_t$, for Itô processes daily returns should follow a normal mixture distribution with $RV_t^m$ as the mixing variable. As a result, returns standardized by realized volatility should be standard normal</li></ul><script type="math/tex; mode=display">r_t/RVOL_t^m \approx N(0,1)</script><ul><li>If there are jumps in $dp (t)$, then $RV_t^m \xrightarrow{p} IV_t$ IVt but returns are no longer conditionally normally distributed.</li></ul><p><strong>Define the error</strong></p><script type="math/tex; mode=display">u_t(\Delta)=RV_t^m-IV_t</script><p><strong>BNS (2001)</strong> : For the Ito diffusion model under the assumption that mean and volatility processes are jointly independent of $W(t)$</p><script type="math/tex; mode=display">\sqrt{m}\frac{u_t(\Delta)}{\sqrt{2\ IQ_t}}=\sqrt{m}\frac{(RV_t^m-IV_t)}{\sqrt{2\ IQ_t}}\xrightarrow{d} N(0,1),\ as\ m\to\infty</script><p>where is the integrated quarticity (IQ)</p><script type="math/tex; mode=display">IQ_t=\int_{t-1}^t\sigma^4(s)ds</script><p>Hence,</p><script type="math/tex; mode=display">RV_t^m\sim N(IV_t,\frac{2\ IQ_t}{m})</script><p>IQ$_t$ may be consistently estimated using the following scaled version of realized quarticity (RQ)</p><script type="math/tex; mode=display">RQ_t^m=\sum_{j=1}^mr_{t-1+j\Delta}^4</script><script type="math/tex; mode=display">\frac{m}{3}RQ_t^m\xrightarrow{p}IQ_t,\ as\ m\to\infty</script><p>The feasible asymptotic distribution for $RV_t^m$ is</p><script type="math/tex; mode=display">RV_t^m\sim N(IV_t,\frac{2}{3}RQ_t^m)</script><h2 id="Unit-2-9：The-Heston-Model"><a href="#Unit-2-9：The-Heston-Model" class="headerlink" title="Unit 2.9：The Heston Model"></a>Unit 2.9：The Heston Model</h2><h3 id="Heston’s-Stochastic-Volatility-Model"><a href="#Heston’s-Stochastic-Volatility-Model" class="headerlink" title="Heston’s Stochastic Volatility Model"></a>Heston’s Stochastic Volatility Model</h3><p>Under the <strong>risk-neutral measure</strong>, Heston’s stochastic volatility model is given as</p><script type="math/tex; mode=display">\frac{dS_t}{S_t}=rdt+\sigma_tdW_t</script><script type="math/tex; mode=display">\begin{align}&d\sigma_t^2=k(\theta-\sigma_t^2)dt+\delta\sigma_tdW'_t,\ d\langle W,W'\rangle_t=\rho dt\\or,\ &dv_t=k(\theta-v_t)dt+\delta\sqrt{v_t}dW'_t,\ with\ v_t=\sigma_t^2\end{align}</script><blockquote><p>本课的模型都是在风险中性 (鞅) 的测度下，对于有些文章会按现实测度写，但实际是效果都相同</p></blockquote><p>If we have $W_1,\tilde W$ where $\langle W _1,\tilde W\rangle=0$</p><script type="math/tex; mode=display">W_2=\rho W_1+\sqrt{1-\rho^2}\tilde W</script><script type="math/tex; mode=display">\begin{align}d\langle W_1,W_2\rangle&=d\langle W_1,\rho W_1+\sqrt{1-\rho^2}\tilde W\rangle_t\\&=\rho d\langle W_1,W_1\rangle+\sqrt{1-\rho^2} d\langle W _1,\tilde W\rangle\\&=\rho dt\end{align}</script><p>The variance process $v_t$ is also known by the name of <strong>Cox-Ingersoll-Rubinstein (CIR)</strong> process</p><p>To model the variance of asset prices, we need $v_t$ to remain positive</p><p><strong>（Advantage）</strong>For $\frac{2k\theta}{\delta^2}&gt;1$ the process never hits zero. This constraint on parameters is also known as <strong>Feller condition</strong></p><p>This process is <strong>mean reverting</strong></p><p>For the square root process</p><script type="math/tex; mode=display">dv_t=k(\theta-v_t)dt+\delta\sqrt{v_t}dW'_t</script><ul><li>$\theta$ is the long term mean</li><li>k is the speed of mean-reversion</li><li>$\delta$ is volatility of volatility</li></ul><p>First we define the log-price $X_t$ by $S_t=S_0e^{rt+X_t}$</p><p>Next, by using the Ito’s formula, we get</p><script type="math/tex; mode=display">dX_t=-\frac{1}{2}\sigma_t^2dt+\sigma_tdW_t</script><p>European call option price with maturity T and strike K is given as</p><script type="math/tex; mode=display">C(K)=e^{-rT}\mathbb{E}[(S_0e^{rt+X_T}-K)^+]=S_0\mathbb{E}[(e^{X_T}-\frac{Ke^{-rT}}{S_0})^+]</script><p>For log-strike</p><script type="math/tex; mode=display">K:=log\frac{Ke^{-rT}}{S_0},\ C(K)=S_0\mathbb{E}[(e^{X_T}-e^k)^+]</script><p>We first find the characteristic function of $X_T$</p><script type="math/tex; mode=display">f(t,u,x,v):=\mathbb{E}[e^{iuX_T}|X_t=x,v_t=v]</script><p>To compute $C(K)=S_0\mathbb{E}[(e^{X_T}-e^k)^+]$ , we then use the <strong>Fourier transform</strong> $f (t, u, x, v)$ of $X_T$</p><h4 id="European-Call-Option-Price-Formula"><a href="#European-Call-Option-Price-Formula" class="headerlink" title="European Call Option Price Formula"></a>European Call Option Price Formula</h4><script type="math/tex; mode=display">C(x,v;T-t,K)=e^xP_1-Ke^{-r(T-t)}P_2, where\ for j=1,2</script><script type="math/tex; mode=display">P_j(x,v;T-t,lnK):=\frac{1}{2}+\frac{1}{\pi}\int_0^\infty Re(\frac{e^{-i\phi lnK}f_j(\phi;T-t,x,v)}{i\phi})d\phi</script><p>where $Re(a+ib)=a$, We can only solve the $P_j$ numerical</p><script type="math/tex; mode=display">f_j(\phi;T-t,x,v):=exp(C_j(T-t,\phi)+D_j(T-t,\phi)+i\phi x)</script><script type="math/tex; mode=display">C_j(\tau,\phi):=ri\phi\tau+\frac{a}{\delta^2}((b_j-\rho\delta i\phi+d_j)\tau-2ln\frac{1-g_je^{d_j\tau}}{1-g_j})</script><script type="math/tex; mode=display">D_j(\tau,\phi):=\frac{b_j-\rho\delta i\phi+d_j}{\delta^2}(\frac{1-e^{d_j\tau}}{1-g_je^{d_j\tau}})</script><script type="math/tex; mode=display">g_j:=\frac{b_j-\rho\delta i\phi+d_j}{b_j-\rho\delta i\phi-d_j}</script><script type="math/tex; mode=display">d_j=\sqrt{(b_j-\rho\delta i\phi)^2-\delta^2(2iu_j\phi-\phi^2)}</script><h2 id="Unit-2-10：Introduction-to-Calibration"><a href="#Unit-2-10：Introduction-to-Calibration" class="headerlink" title="Unit 2.10：Introduction to Calibration"></a>Unit 2.10：Introduction to Calibration</h2><h4 id="Exotic-Option"><a href="#Exotic-Option" class="headerlink" title="Exotic Option"></a>Exotic Option</h4><p><strong>Not traded on the market and $\to$ need to be priced by a model</strong></p><ul><li><p>A forward start option: $(S_T-aS_{T_1})^+$</p></li><li><p>A cliquet: $\sum_{i=1}^{n-1}(S_{T_{i+1}}-aS_{T_i})^+$</p></li><li><p>A barrier option: $(S_T-K)^+1_{sup_{t\in[0,T]}S_t\leq B}$</p></li></ul><p><strong>Identify the hedging instruments</strong> : liquid products (small bid-ask spread) quoted on a market</p><p>we aim at constructing a hedging portfolio of the form</p><script type="math/tex; mode=display">V_t=\Delta_t^0B_t+\Delta_tS_t+\sum_{i=1}^n\Delta_t^{C,i}Call^i+\sum_{j=1}^m\Delta_t^{P,j}Put^j</script><p><strong>Choose a model</strong></p><p>Reproduce the prices of simple instruments quoted on the market.  (This step is <strong>model calibration</strong>)</p><p>Then compute the hedging strategies $\Delta^0,\Delta,\Delta^{C,i},\Delta^{P,j}$</p><h4 id="General-Considerations"><a href="#General-Considerations" class="headerlink" title="General Considerations"></a>General Considerations</h4><p><strong>Model calibration</strong> = determine the model parameters from market data of liquid instruments</p><p><strong>Two approaches in model calibration</strong></p><ol><li><strong>Statistical</strong> parameter estimation<ul><li>from <strong>historical</strong> observations</li><li>done under the physical (market) measure</li></ul></li><li><strong>Calibration</strong><ul><li>based on quotes of option prices (typically calls/puts)</li><li>done under the <strong>risk-neutral measure</strong></li><li>reflects the market view on the future evolution of the asset</li></ul></li></ol><p><strong>Which price? Bid or Ask?</strong></p><ul><li>Typically one calibrates to the mid-price</li></ul><h4 id="Model-Calibration"><a href="#Model-Calibration" class="headerlink" title="Model Calibration"></a>Model Calibration</h4><p>In general, a “good” model should have</p><ul><li><p>A parsimonious parametrization and should be intuitive</p></li><li><p>An efficient numerical calibration method</p></li></ul><p>We want to find $\theta$ such that</p><script type="math/tex; mode=display">P^{model(\theta)}(T_i,K_j)=P^{market(\theta)}(T_i,K_j)</script><p>or a <strong>least squares approach</strong></p><script type="math/tex; mode=display">\min_{\theta}\sum_{i,j}(P^{model}(T_i,K_j)-P^{market}(T_i,K_j))^2</script><h4 id="Calibration-of-local-volatility-models"><a href="#Calibration-of-local-volatility-models" class="headerlink" title="Calibration of local volatility models"></a>Calibration of local volatility models</h4><p>The inverse problem of finding the local volatility function with finite number of call option prices is then ill posed. To overcome the difficulty, typically two approaches are used</p><ul><li><p><strong>Implied volatility interpolation</strong> using either parametric or semi-parametric form</p><ul><li>Non-parametric methods of interpolation, for example, the method of splines(三次样条插值), provide very mediocre performance for such problems</li><li>Implied volatility interpolation methods are very intuitive and fast, but could lead to <strong>infeasible volatility surface</strong></li></ul></li><li><p><strong>Regularisation approach</strong></p><ul><li>Regularisation methods provide the best <strong>performance</strong> in terms of precision and regularity of the volatility surface</li></ul></li></ul><h4 id="Stochastic-Volatility-Inspired-SVI-Parametrisation-by-Jim-Gatheral"><a href="#Stochastic-Volatility-Inspired-SVI-Parametrisation-by-Jim-Gatheral" class="headerlink" title="Stochastic Volatility Inspired(SVI) Parametrisation (by Jim Gatheral)"></a>Stochastic Volatility Inspired(SVI) Parametrisation (by Jim Gatheral)</h4><p>It is a parametrisation of implied volatility as a function of parameters in terms of log-strike $k=log\frac{K}{S}-rT$</p><p>In the parametrisation, for a given maturity $T$, the total implied variance $V(T, k) := I^2(T, k)T$ satisfies</p><script type="math/tex; mode=display">V(T, k)=a+b(\rho(k-m)+\sqrt{(k-m)^2+\sigma^2})</script><p>with</p><ul><li><p>$a\ge 0$: global level of smile</p></li><li><p>$b\ge 0$: slope of the wings</p></li><li><p>$\rho\in[-1,1]$: asymmetry (rotation of the smile)</p></li><li><p>$m\in\mathbb{R}$: translation to the right</p></li><li><p>$\sigma\ge 0$: at-the-money convexity</p></li></ul><p><strong>Step</strong></p><ul><li>For a given maturity $T_i$, we compute the implied volatility $I(T_i, k_j)$ for all the strikes $K_j$ of the liquidly traded call options</li></ul><script type="math/tex; mode=display">\sigma^2(T,k)=\frac{\frac{\partial V(T,k)}{\partial T}}{(1-\frac{k}{2V}\frac{\partial V}{\partial k})^2+\frac{1}{2}\frac{\partial^2V}{\partial k^2}-\frac{1}{4}(\frac{1}{4}+\frac{1}{V})(\frac{\partial V}{d k})^2}</script><ul><li><p>Then using an optimisation procedure, for example, <strong>least-squares</strong>, we compute the optimal values for parameters $a,b,\rho,m$ and $\sigma$ for maturity $T_i$</p><ul><li>The parameters are estimated for each maturity separately</li></ul></li><li><p>For the intermediate maturities without liquidly traded options, the implied volatility can be computed using linear <strong>interpolation</strong> and the SVI parameters can be computed</p></li></ul><p><strong>Absence of Arbitrage</strong></p><ul><li>Due to the interpolation procedure, SVI parametrisation can lead to arbitrage opportunities in the model<ul><li>Option price function $P(T, k)$ which is not convex with respect to $k$</li><li>$\frac{\partial^2P(T,k)}{\partial k^2}&lt;0$</li></ul></li></ul><p><img src="http://mathworld.wolfram.com/images/eps-gif/ConcaveConvexFunction_1000.gif" alt></p><ul><li><p>To ensure the absence of arbitrage: $\lim_{k\to\infty}C^{BS}(T,k)=0$</p></li><li><p>The absence of arbitrage of the “calendar spread” type: $\frac{\partial V(T,k)}{\partial T}\ge 0$</p><ul><li>The above condition implies that the total implied variance is an increasing function with respect to maturity. This is equivalent to non-crossing of the curves of total implied variance for different maturities</li></ul></li><li><p>The absence of arbitrage of the “butterfly” type</p><ul><li>The condition leads to the convexity of option prices with respect to $k$</li></ul></li></ul><script type="math/tex; mode=display">d(T,k)=(1-\frac{k}{2V}\frac{\partial V}{\partial k})^2+\frac{1}{2}\frac{\partial^2V}{\partial k^2}-\frac{1}{4}(\frac{1}{4}+\frac{1}{V})(\frac{\partial V}{d k})^2\ge 0</script><h4 id="Regularisation-Approach"><a href="#Regularisation-Approach" class="headerlink" title="Regularisation Approach"></a>Regularisation Approach</h4><p>The calibration of volatility surface is posed as an optimisation problem using <strong>Tikhonov regularisation</strong></p><p>Minimise the functional</p><script type="math/tex; mode=display">J(\sigma):=\sum_{i,j=1}^{n,m}w_{ij}(C(T_i,K_j,\sigma)-C^{market}(T_i,K_j))^2+\alpha||\nabla\sigma||_2^2</script><script type="math/tex; mode=display">||\nabla\sigma||_2^2=\int_{K_{min}}^{K_{max}}dK\int_{T_{min}}^{T_{max}}dT((\frac{\partial\sigma}{\partial K})^2+(\frac{\partial\sigma}{\partial T})^2)</script><p>To minimise $J(\sigma)$, we use, for example, the method of <strong>gradient descent</strong> or the method of <strong>conjugate gradient</strong></p><p><strong>Typical algortihm</strong></p><ul><li>Discretise local volatility function on a mesh of space and time</li><li>Make an initial guess $\sigma^{(0)}$,for example, a constant function</li><li>Evaluate the gradient of $J(\sigma)$ at point $\sigma^{(0)}$to calculate the direction of descent $\lambda^{(0)}$ </li><li>Solve the one-dimensional minimisation problem</li></ul><script type="math/tex; mode=display">h^*=arg\min_{h}J(\sigma^{(0)}+h\lambda^{(0)})</script><ul><li>Set $\sigma^{(1)}:=\sigma^{(0)}+h^*\lambda^{(0)}$ and iterate again</li></ul><p>The local volatility function is discretised using different methods, for example, finite differences or trinomial tree model</p><p>The regularisation using $||\nabla\sigma||$ is the same in regions of the surface where the influence of volatility on the price is very high and in the regions where it is very small</p><h1 id="Unit-3-1：Monte-Carlo-methods"><a href="#Unit-3-1：Monte-Carlo-methods" class="headerlink" title="Unit 3.1：Monte Carlo methods"></a>Unit 3.1：Monte Carlo methods</h1><p>Readings for the module on Monte Carlo Methods</p><ul><li>Chapter 3 Section 3.1, Section 3.2 - Monte Carlo Methods in Financial Engineering by Paul Glasserman</li><li>Chapter 6 Section 6.1 - Monte Carlo Methods in Financial Engineering by Paul Glasserman</li></ul><h2 id="Unit-3-1-1：Introduction"><a href="#Unit-3-1-1：Introduction" class="headerlink" title="Unit 3.1.1：Introduction"></a>Unit 3.1.1：Introduction</h2><p>Monte Carlo methods are preferable in high dimensions as their accuracy is independent of dimensionality</p><p>If f is integrable over [0, 1], then by strong <strong>law of large numbers</strong> (SLLN)</p><blockquote><p>大数定律的定义是，当随机事件发生的次数足够多时，随机事件发生的频率趋近于预期的概率。可以简单理解为样本数量越多，其平概率越接近于期望值。大数定律的条件：1、独立重复事件；2、重复次数足够多。</p></blockquote><p>for</p><script type="math/tex; mode=display">\alpha=\int_0^1f(x)dx=\mathbb{E}[f(U)]</script><script type="math/tex; mode=display">\hat{\alpha}_N=\frac{1}{N}\sum_{i=1}^Nf(U_i),U_i\sim U</script><script type="math/tex; mode=display">\hat{\alpha}_N\to \alpha\ w.p.\ 1\ as\ N\to\infty</script><blockquote><p>w.p. 1 (with probability 1)</p></blockquote><p>If f is also square integrable, for</p><script type="math/tex; mode=display">\sigma_f^2=\int_0^1(f(x)-\alpha)^2dx=\mathbb{E}[(f(U)-\alpha)^2]</script><p><strong>the error in the estimator</strong> $\hat\alpha_N$ is approximately normally distributed with mean 0 and standard deviation $\frac{\sigma_f}{\sqrt{N}}$</p><p>Typically $\sigma_f$ is <strong>unknown</strong> and is estimated as</p><script type="math/tex; mode=display">s_f=\sqrt{\frac{1}{N-1}\sum_{i=1}^N(f(U_i)-\hat\alpha_N)^2}</script><h3 id="Monte-Carlo-Estimation-for-European-Option"><a href="#Monte-Carlo-Estimation-for-European-Option" class="headerlink" title="Monte Carlo Estimation for European Option"></a>Monte Carlo Estimation for European Option</h3><p>Monte Carlo samples $S_i(T)$ of $S(T)$ can be generated as</p><script type="math/tex; mode=display">S_i(T)=S_0exp((r-\frac{1}{2}\sigma^2)T+\sigma\sqrt{T}Z_i)</script><p>where $Z_i\sim N(0,1)$</p><blockquote><p>用 $\sqrt TZ_i$ 代替 $W_t$ 可以减少 noise</p></blockquote><p>Call price estimator is given as</p><script type="math/tex; mode=display">\hat C_N=\frac1N\sum_{i=1}^Ne^{-rT}(S_i(T)-K)^+</script><p>The estimator $\hat C_N$ is unbiased in the sense that</p><script type="math/tex; mode=display">\mathbb{E}[\hat C_N]=\mathbb{E}[\frac1N\sum_{i=1}^Ne^{-rT}(S_i(T)-K)^+]=\mathbb{E}[\frac1N\sum_{i=1}^NC_i]=C(T,K)</script><h2 id="Unit-3-1-2：Efficiency-of-Monte-Carlo-methods"><a href="#Unit-3-1-2：Efficiency-of-Monte-Carlo-methods" class="headerlink" title="Unit 3.1.2：Efficiency of Monte Carlo methods"></a>Unit 3.1.2：Efficiency of Monte Carlo methods</h2><h4 id="Confidence-Interval"><a href="#Confidence-Interval" class="headerlink" title="Confidence Interval"></a>Confidence Interval</h4><p>Using estimator $\hat C_N$ makes sense with a confidence interval</p><script type="math/tex; mode=display">[\hat C_N-z_{\delta/2}\frac{s_C}{\sqrt{N}},\hat C_N+z_{\delta/2}\frac{s_C}{\sqrt{N}}]</script><p>where</p><script type="math/tex; mode=display">s_C=\sqrt{\frac{1}{N-1}\sum_{i=1}^N(C_i-\hat C_N)^2}</script><ul><li>$2z_{\delta/2}\frac{s_C}{\sqrt{N}}$ is called the width of the confidence interval</li><li>$z_\delta$ denotes the $1-\delta$ quantile of the standard normal distribution<ul><li>$\mathbb{P}(Z\leq z_\delta)=1-\delta$ for $Z\sim N(0,1)$</li><li>For $\delta = 0.05, z_\delta/2 \approx 1.96$, we get a 95% confidence interval</li></ul></li></ul><h4 id="Central-limit-theorem-CLT"><a href="#Central-limit-theorem-CLT" class="headerlink" title="Central limit theorem (CLT)"></a>Central limit theorem (CLT)</h4><p>With unbiased estimator $\hat C_N=\frac1N\sum_{i=1}^NC_i$ for iid samples $C_i$, $\mathbb{E}[C_i]=C$ and $Var(C_i)=\sigma_C^2&lt;\infty$</p><script type="math/tex; mode=display">\frac{\hat C_N-C}{\sigma_C/\sqrt{N}}\sim N(0,1)</script><ul><li>$\sigma_C$ can only be estimated</li></ul><p>Suppose it takes $\tau$ time to generate $C_i$. Given computational budget $\Gamma$,  can generate $\Gamma/\tau$ samples and create estimator $\hat C_{\Gamma/\tau}$</p><ul><li>$\sqrt{\Gamma/\tau}(\hat C_{\Gamma/\tau}-C)\sim N(0,\sigma_C^2)$</li><li><p>as $\Gamma\to\infty$, $\sqrt{\Gamma}(\hat C_{\Gamma/\tau}-C)\sim N(0,\sigma_C^2\tau)$</p></li><li><p>Given a choice, we should use an estimator with lower value of $\sigma_C^2\tau$</p></li></ul><h4 id="Mean-Square-Error"><a href="#Mean-Square-Error" class="headerlink" title="Mean Square Error"></a>Mean Square Error</h4><p>For an estimator $\hat\alpha$ of true value $\alpha$</p><script type="math/tex; mode=display">MSE(\hat\alpha)=\mathbb{E}[(\hat\alpha-\alpha)^2]=(\mathbb{E}\hat\alpha-\alpha)^2+\mathbb{E}[(\hat\alpha-\mathbb{E}\hat\alpha)^2]=Bias^2(\hat\alpha)+Variance(\hat\alpha)</script><blockquote><p>两边可以尝试配平</p></blockquote><p>Landau’s notation: For parameter $h\to 0$</p><script type="math/tex; mode=display">f(h)=\mathscr{O}(h^n)\Rightarrow |f(h)|\leq Mh^n</script><script type="math/tex; mode=display">f(h)=o(h^n)\Rightarrow \lim_{h\to 0}f(h)/h^n \to 0</script><blockquote><p>类似于算法复杂度，大 O 是上界，小 o 是下届</p></blockquote><h2 id="Unit-3-1-3：Euler-Method"><a href="#Unit-3-1-3：Euler-Method" class="headerlink" title="Unit 3.1.3：Euler Method"></a>Unit 3.1.3：Euler Method</h2><p>Consider an ordinary differential equation (ODE) in time interval [0, 1]</p><script type="math/tex; mode=display">\frac{dX(t)}{dt}=\dot x(t)=b(t,x(t)),\ x(0)=x_0</script><p>Divide interval into $N$, $h=1/N$ </p><p>The above ODE can be solved approximately using an <strong>Euler scheme</strong></p><script type="math/tex; mode=display">x_0^h=x_0,\ x_n^h=x_{n-1}^h+b(t_{n-1}^h,x_{n-1}^h)h</script><p>where</p><script type="math/tex; mode=display">x_n^h:=x^h(t_n^h),\ t_n^h:=nh,\ h=\frac1N</script><ul><li>Error criterion $e(h):=|x(1)-x^h(1)|$</li><li>Under suitable assumptions $e(h)=\mathscr{O}(h)=\mathscr{O}(1/N)$</li></ul><blockquote><p>Euler Method更多解释可参考数值分析的部分</p></blockquote><h4 id="Euler-Discretisation-for-BM"><a href="#Euler-Discretisation-for-BM" class="headerlink" title="Euler Discretisation for BM"></a>Euler Discretisation for BM</h4><p>with $h=\frac TN,t_n^h:=nh,\Delta W_n^h:=W(t_n^h)-W(t_{n-1}^h)$,  the Euler scheme for BM is given as</p><script type="math/tex; mode=display">W_n^h:=W(t_n^h)=\Delta W_1^h+...+\Delta W_n^h</script><p>Note that $\Delta W_n^h$ are iid increments which are normally distributed $N(0,h)$</p><h4 id="Euler-Method-for-SDEs"><a href="#Euler-Method-for-SDEs" class="headerlink" title="Euler Method for SDEs"></a>Euler Method for SDEs</h4><script type="math/tex; mode=display">dX(t)=b(t,X(t))dt+\sigma(t,X(t))dW_t</script><p>The Euler scheme for $X(t)$ is given as $X^h(0)=x_0$</p><script type="math/tex; mode=display">X_n^h:=X(t_n^h)=X_{n-1}^h+b(t_{n-1}^h,X_{n-1}^h)h+\sigma(t_{n-1}^h,X_{n-1}^h)\Delta W_n^h</script><p>If we wish to price options based on <strong>the path of</strong> the SDE, for example, Asian option with price</p><script type="math/tex; mode=display">\mathbb{E}[e^{-rT}(\frac1M\sum_{j=1}^MS(t_j)-K)^+]</script><p>we need a good approximation of the <strong>sample path</strong> of $X$ which leads to the error criterion (<strong>strong error</strong>)</p><script type="math/tex; mode=display">e_s(h):=\mathbb E|X(T)-X_N^h(T)|</script><p>If we wish to price options based only on <strong>the terminal value</strong> of the SDE, for example, European option with price</p><script type="math/tex; mode=display">\mathbb{E}[e^{-rT}(S(T)-K)^+]</script><p>we need a good approximation of the distribution of $X(T)$ which leads to the error criterion (<strong>weak error</strong>)</p><script type="math/tex; mode=display">e_w(h):=|\mathbb E_gX(T)-\mathbb E_gX_N^h(T)|</script><p>for smooth functions g</p><blockquote><p>光滑函数（smooth function）:在其定义域内无穷阶数连续可导的函数</p><p>g 可以取 $(S(T)-K)^+$</p></blockquote><p>We say that $X^h$ converges to $X$ with order $\beta &gt; 0$</p><ul><li>strongly with order $\beta$ if $e_s(h)=\mathscr O(h^\beta)$</li><li>weakly with order $\beta$ if $e_w(h)=\mathscr O(h^\beta)$</li></ul><p>Under some regularity conditions on functions $b$ and $\sigma$, Euler scheme converges strongly with order $\beta = 1/2$ (Euler) and weakly with order $\beta = 1$ (Milstein)</p><blockquote><p>当 $\beta$ 数越大，收敛速度越快，越准确</p></blockquote><h2 id="Unit-3-1-4：Milstein-Scheme"><a href="#Unit-3-1-4：Milstein-Scheme" class="headerlink" title="Unit 3.1.4：Milstein Scheme"></a>Unit 3.1.4：Milstein Scheme</h2><p>Consider the SDE</p><script type="math/tex; mode=display">X(t_{n-1}+h)-X(t_{n-1})=\int_{t_{n-1}}^{t_{n-1}+h}b(s,X(s))ds+\int_{t_{n-1}}^{t_{n-1}+h}\sigma(s,X(s))dW(s)</script><p>and its Euler scheme approximation</p><script type="math/tex; mode=display">X_n^h-X_{n-1}^h=b(t_{n-1}^h,X_{n-1}^h)h+\sigma(t_{n-1}^h,X_{n-1}^h)\Delta W_n^h</script><p>Thus, the Euler scheme approximates</p><script type="math/tex; mode=display">\int_{t_{n-1}}^{t_{n-1}+h}\sigma(s,X(s))dW(s)\sim\sigma(t_{n-1}^h,X_{n-1}^h)\Delta W_n^h</script><p><strong>Milstein scheme is an improvement on the Euler scheme</strong>. The main idea is to approximate the stochastic integral in a better way</p><p>Let us estimate the error in Euler scheme by applying Itô’s formula on $\sigma(t,X(t))$. Suppose $t_{n-1}=0$</p><script type="math/tex; mode=display">\begin{align}d(\sigma(s,X(s)))&=\partial_t\sigma ds+\partial_x\sigma dX(s)+\frac12\partial_x^2\sigma dX(s)dX(s)\\&=\partial_t\sigma ds+\partial_x\sigma (bds+\sigma dW(s))+\frac12\partial_x^2\sigma\sigma^2 ds\end{align}</script><p>Then</p><script type="math/tex; mode=display">\begin{align}&\int_0^h\sigma(t,X(t))dW(t)-\sigma(0,X(0))W(h)\\=&\int_0^h(\sigma(t,X(t))-\sigma(0,X(0)))dW(t)\end{align}</script><p>Combined with</p><script type="math/tex; mode=display">\int_0^hd(\sigma(s,X(s)))=\sigma(t,X(t))-\sigma(0,X(0))</script><p>So we have</p><script type="math/tex; mode=display">\begin{align}\int_0^h\int_0^t[\partial_t\sigma+\partial_x\sigma b+\frac12\partial_x^2\sigma\sigma^2]dsdW(t)+\int_0^h\int_0^t\partial_x\sigma\sigma dW(s)dW(t)\\\sim\mathscr{O}(h^{3/2})+\partial_x\sigma(0,X(0))\sigma(0,X(0))\int_0^h\int_0^tdW(s)dW(t)\end{align}</script><blockquote><p>$W(h)\sim o(h^{1/2})$，$\sigma$ 采用 0 点时</p></blockquote><script type="math/tex; mode=display">\int_0^h\int_0^tdW(s)dW(t)=\int_0^hW(t)dW(t)=\frac12(W^2(h)-h)</script><blockquote><p>这一步过程看 <a href="https://achlier.github.io/2021/06/11/Ito%E7%A7%AF%E5%88%86%E4%B8%8E%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%E3%80%90%E7%AC%94%E8%AE%B0_%E7%9F%A5%E4%B9%8E%E3%80%91/">定义</a></p></blockquote><p>Thus, the Milstein scheme is given as $X^h(0)=x_0$</p><script type="math/tex; mode=display">X_n^h=X(t_n^h)=X_{n-1}^h+bh+\sigma\Delta W_n^h+\frac12\partial_x\sigma\sigma((\Delta W_n^h)^2-h)</script><blockquote><p>如果 payoff 只取决于最终的价格，两种方法不明显，如果取决于path，Milstein 会明显提高</p></blockquote><h1 id="Unit-3-2：Variance-reduction-methods"><a href="#Unit-3-2：Variance-reduction-methods" class="headerlink" title="Unit 3.2：Variance reduction methods"></a>Unit 3.2：Variance reduction methods</h1><p>Readings for the module on variance reduction methods</p><ul><li>Chapter 4 Section 4.1, 4.2 - Monte Carlo Methods in Financial Engineering by Paul Glasserman</li></ul><h2 id="Unit-3-2-1：Control-variate-method"><a href="#Unit-3-2-1：Control-variate-method" class="headerlink" title="Unit 3.2.1：Control variate method"></a>Unit 3.2.1：Control variate method</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>In financial markets and the insurance industry, most quantities of interest can be expressed as</p><script type="math/tex; mode=display">\alpha=\mathbb{E}[\psi(x)],\ p=\mathbb{P}(x\in A)</script><p>Suppose the goal is to compute $p$. Then, use the Monte Carlo method:</p><ul><li><p>Generate $(X_i)_{1\leq i\leq N}$ i.i.d. samples of $X$ &amp; set</p><script type="math/tex; mode=display">\hat p_N:=(N)^{-1}\sum_{i=1}^N1_{X_i\in A}</script></li><li><p>By the Central Limit Theorem (CLT)</p><script type="math/tex; mode=display">\sqrt{N}(\hat p_N-\mathbb{P}(x\in A))\Rightarrow N(0,p(1-p))</script><blockquote><p>binomial 分布, p 是存在的概率</p></blockquote></li><li><p>95% confidence interval</p><script type="math/tex; mode=display">(\hat p_N-1.96\sqrt{\frac{p(1-p)}{N}},\hat p_N+1.96\sqrt{\frac{p(1-p)}{N}})</script></li></ul><p>The <strong>relative error</strong> is given as</p><script type="math/tex; mode=display">\frac{Estimator\ error}{True\ Value}=\sqrt{p(1-p)}/(p\sqrt{N})\approx(\sqrt{Np})^{-1}</script><p>which is large for small value of $p$</p><p>Thus, to estimate small $p$, using the crude Monte Carlo method, we may need a <strong>large number of samples</strong> $N$</p><blockquote><p>如果 $p = 0.01 (10^{-2})$, $N$ 至少 $=10^6$ 才使得 relative error $=(\sqrt{10^4})^{-1}=10^{-2}$</p></blockquote><p>As discussed in the last lecture, the estimator error is given by $s_p/\sqrt{N}$ where $s_p$ is the estimate of standard deviation of estimator $\hat p_N$</p><p>The aim of <strong>variance reduction methods</strong> is to produce an alternative estimator $\hat p_N^{var}$ such that $\mathbb{E}[\hat p_N^{var}]=p$ but with <strong>smaller variance</strong> than estimator $\hat p_N$</p><h3 id="Control-Variates"><a href="#Control-Variates" class="headerlink" title="Control Variates"></a>Control Variates</h3><p>Let $Y_1, Y_2, . . . , Y_N$ be i.i.d. outputs from $N$ replications of a simulation. For example, $Y_i$ could be the discounted payoff of a derivative security on the $i$th simulated path.</p><p>Suppose that our aim is to compute $\alpha=\mathbb{E}[Y_i]$ and the crude Monte Carlo estimator $\alpha_N:=\sum_{i=1}^N\frac{Y_i}N$ is unbiased and converges with probability (w.p.) 1 as $N\to\infty$</p><p>Suppose on each replication, we generate another output $X_i$ along with $Y_i$</p><p>Suppose that $(X_i,Y_i)$ are i.i.d. $i=1,…,N$ and that $\alpha_0=\mathbb{E}[X_i]$ is known</p><p>Furthermore, denote $(X, Y)$ as a generic pair of $(X_i,Y_i)$</p><p>For fixed $b$, calculate</p><script type="math/tex; mode=display">Y_i(b):=Y_i-b(X_i-\alpha_0)</script><p>and compute the sample mean</p><script type="math/tex; mode=display">\hat\alpha_N(b):=\hat\alpha_N-b(N_{-1}\sum_{i=1}^NX_i-\alpha_0)=\frac1N\sum_{i=1}^NY_i(b)</script><p>$\hat\alpha_N(b)$ is a <strong>control variate estimator</strong> and the observable error $N^{-1}\sum_{i=1}^NX_i-\alpha_0$ acts as a control in estimating $\alpha$</p><p>The control variate estimator is <strong>unbiased</strong></p><script type="math/tex; mode=display">\mathbb{E}[\hat\alpha_N(b)]=\frac1N\sum_{i=1}^N\mathbb{E}[Y_i(b)]=\alpha</script><script type="math/tex; mode=display">\mathbb{E}[\hat\alpha_N(b)]=\mathbb{E}[\hat\alpha_N]-\mathbb{E}[b(N_{-1}\sum_{i=1}^NX_i-\alpha_0)]=\alpha-(\alpha_0-\alpha_0)</script><p>$\hat\alpha_N(b)$ is also <strong>strongly consistent</strong></p><script type="math/tex; mode=display">Var(\hat\alpha_N(b))=\frac{Var(\sum_{i=1}^NY_i(b))}{N^2}=\frac{N\sigma^2(b)}{N^2}=\frac{\sigma^2(b)}{N}</script><p>Each $Y_i(b)$ has variance which is equal to</p><script type="math/tex; mode=display">\begin{align}Var(Y_i(b))&=Var(Y_i-b(X_i-\alpha_0))\\&=\sigma_Y^2-2b\sigma_X\sigma_Y\rho_{XY}+b^2\sigma_X^2\equiv\sigma^2(b)\end{align}</script><script type="math/tex; mode=display">\sigma_X^2=Var(X),\sigma_Y^2=Var(Y),\rho_{XY}=Correl(X,Y)</script><script type="math/tex; mode=display">Var(\hat\alpha_N(b))=\frac{\sigma^2(b)}N,Var(\hat\alpha_N)=\frac{\sigma^2_Y}N</script><p>$\hat\alpha_N(b)$ <strong>provides variance reduction</strong> if</p><script type="math/tex; mode=display">b\sigma_X<2\sigma_Y\rho_{XY}</script><p>Optimal coefficient $b^<em>$ <em>*minimizes</em></em> $\sigma^2(b)$ and is given as</p><script type="math/tex; mode=display">b^*=\frac{\sigma_Y\rho_{XY}}{\sigma_X}=\frac{Cov(X,Y)}{Var(X)}</script><p>The ratio of the variance of optimally controlled estimator to that of uncontrolled</p><script type="math/tex; mode=display">\frac{Var(\hat\alpha_N(b^*))}{Var(\hat\alpha_N)}=1-\rho_{XY}^2</script><p>The <strong>variance reduction factor</strong> is given as</p><script type="math/tex; mode=display">\frac{Var(\hat\alpha_N)}{Var(\hat\alpha_N(b^*))}=\frac{1}{1-\rho_{XY}^2}</script><blockquote><p>$Var(\hat\alpha_N)\times(1-\rho_{XY}^2)={Var(\hat\alpha_N(b^*))}$ 如果要达到原来的值，需要用 $N/(1-\rho_{XY}^2)$ 个样本</p></blockquote><p>For example, for $|\rho_{XY}| = 0.95$, leads to 10-times variance reduction, whereas $|\rho_{XY}| = 0.90$, leads to 5-times variance reduction (usually 5)</p><h3 id="Computing-b"><a href="#Computing-b" class="headerlink" title="Computing $b^*$"></a>Computing $b^*$</h3><p>As $\alpha=\mathbb E[Y]$ is unknown, in practice, $\sigma_Y$ or $\rho_{XY}$ are also unknown</p><p>Estimate $b^*$ as</p><script type="math/tex; mode=display">\hat b_N=\frac{\sum_{i=1}^N(X_i-\frac{\sum_{j=1}^NX_j}N)(Y_i-\frac{\sum_{j=1}^NY_j}N)}{\sum_{i=1}^N(X_i-\frac{\sum_{j=1}^N X_j}N)^2}</script><p>Then, instead of $Y_i(b)$, we use</p><script type="math/tex; mode=display">Y_i(\hat b_N):=Y_i-\hat b_N(X_i-\alpha_0)</script><p>Replacing $b$ with $\hat b_N$ introduces bias as the samples $Y_i(\hat b_N)$ are not independent any more, thus, application of CLT is not clear</p><p>Estimate $\alpha$ as $\hat\alpha_N(\hat b_N)=\frac1N\sum_{i=1}^NY_i(\hat b_N)$</p><h2 id="Unit-3-2-2：Application-of-control-variate-estimator"><a href="#Unit-3-2-2：Application-of-control-variate-estimator" class="headerlink" title="Unit 3.2.2：Application of control variate estimator"></a>Unit 3.2.2：Application of control variate estimator</h2><h3 id="Using-Underlying-Assets"><a href="#Using-Underlying-Assets" class="headerlink" title="Using Underlying Assets"></a>Using Underlying Assets</h3><p>Consider the Black-Scholes model</p><script type="math/tex; mode=display">\frac{dS_t}{S_t}=rdt+\sigma dW_t,\ S_0=s_0</script><p>Suggest a Monte Carlo control variate method to estimate the price of option</p><h3 id="Asian-Options"><a href="#Asian-Options" class="headerlink" title="Asian Options"></a>Asian Options</h3><p>An arithmetic Asian call option with discounted payoff $e^{-rT}(\bar S_m^A(T)-K)^+$ where</p><script type="math/tex; mode=display">\bar S_m^A(T):=\frac{1}{m}\sum_{j=1}^mS_{t_j},\ t_j=j\ \frac Tm,\ j=1,...,m</script><p>we have a closed-form formula for geometric Asian call option with discounted payoff $e^{-rT}(\bar S_m^G(T)-K)^+$</p><script type="math/tex; mode=display">\bar S_m^G(T):=(\prod_{j=1}^mS_{t_j})^{1/m},\ t_j=j\ \frac Tm,\ j=1,...,m</script><h2 id="Unit-3-2-3：Antithetic-variate-method"><a href="#Unit-3-2-3：Antithetic-variate-method" class="headerlink" title="Unit 3.2.3：Antithetic variate method"></a>Unit 3.2.3：Antithetic variate method</h2><p>Method of <strong>antithetic variates</strong> attempts to reduce variance by introducing <strong>negative dependence</strong> between pair of replications</p><ul><li><p>Note that if $U$ is uniformly distributed over [0, 1] then so is $1 – U$</p><ul><li>$U_i$ and $1 – U_i$ form an antithetic pair in the sense that a big value of one is accompanied by a small value of the other</li><li>Thus, a large value of the function value computed on one path is compensated by the small value on the antithetic path, leading to reduction in variance</li></ul></li><li><p>If $Z$ is distributed as $N (0, 1)$ then so is $–Z$</p><ul><li><p>Suppose we generate a path $Y_i$ using a sample $Z_1, Z_2 , . . . , Z_n$ of normally distributed random variable, we can create an antithetic path $\tilde Y_i$ using the sample $–Z_1, –Z_2, . . . , –Z_n$</p></li><li><p>Suppose we generate N antithetic pairs $(Y_i, \tilde Y_i )^N_{i=1}$</p><script type="math/tex; mode=display">\hat Y_N^{AV}=\frac{1}{2N}(\sum_{i=1}^NY_i+\sum_{i=1}^N\tilde Y_i )=\frac{1}{N}\sum_{i=1}^N\frac12(Y_i+\tilde Y_i )</script></li><li><p>The confidence interval is given as</p><script type="math/tex; mode=display">(\hat Y_N^{AV}-z_{\delta/2}\frac{s_N^{AV}}{\sqrt{N}},\hat Y_N^{AV}+z_{\delta/2}\frac{s_N^{AV}}{\sqrt{N}})</script></li><li><p>Antithetic sampling reduces variance when $Cov(Y_i,\tilde Y_i)&lt;0$</p></li></ul></li></ul><h1 id="Unit-4-1：Finite-difference-methods"><a href="#Unit-4-1：Finite-difference-methods" class="headerlink" title="Unit 4.1：Finite difference methods"></a>Unit 4.1：Finite difference methods</h1><h2 id="Unit-4-1-1：Introduction"><a href="#Unit-4-1-1：Introduction" class="headerlink" title="Unit 4.1.1：Introduction"></a>Unit 4.1.1：Introduction</h2><p>The finite difference method solves a partial differential equation on a discrete grid in time and space</p><h4 id="Consider-a-general-equation-as"><a href="#Consider-a-general-equation-as" class="headerlink" title="Consider a general equation as"></a>Consider a general equation as</h4><script type="math/tex; mode=display">\partial_t V+b(x,t)\partial_x V+\frac12 a(x,t)\partial_x^2 V-r(x,t)V+f(x,t)=0</script><script type="math/tex; mode=display">V(x,T)=g(x),\ (x,t)\in \Omega\times[0,T)</script><ul><li>$f$ is called the <strong>source term</strong></li><li>$a, b, r,$ are assumed to be bounded and continuous</li><li>$a$ is assumed to be nonnegative</li></ul><h4 id="The-Black-Scholes-equation-is-given-as"><a href="#The-Black-Scholes-equation-is-given-as" class="headerlink" title="The Black-Scholes equation is given as"></a>The Black-Scholes equation is given as</h4><script type="math/tex; mode=display">\partial_t V+xr\partial_x V+\frac12 \sigma^2x^2\partial_x^2 V-rV=0</script><script type="math/tex; mode=display">V(x,T)=g(x),\ (x,t)\in \mathbb R_+\times[0,T)</script><p>we note that</p><script type="math/tex; mode=display">b(x,t)=rx,a(x,t)=\sigma^2x^2\ and\ r(x,t)=r</script><p>Change of variable</p><script type="math/tex; mode=display">z=logx\ and\ v(z,t)=V(e^z,t)</script><script type="math/tex; mode=display">v_t=V_t,\ v_z=e^zV_x=xV_x,\ v_{zz}=e^{2z}V_{xx}+e^zV_x=x^2V_{xx}+xV_x</script><p>In the Black-Scholes equation, we then plug</p><script type="math/tex; mode=display">xV_x=v_z,\ x^2V_{xx}=v_{zz}-v_z</script><p>The transformed Black-Scholes equation with bounded coefficients is then given as</p><script type="math/tex; mode=display">v_t+(r-\frac12 \sigma^2)v_z+\frac12 \sigma^2v_{zz}-rv=0</script><script type="math/tex; mode=display">V(e^z,T)=g(e^z),\ (z,t)\in \mathbb R\times[0,T)</script><p>The above equation has bounded coefficients and is suitable to apply finite difference methods</p><h2 id="Unit-4-1-2：Explicit-Scheme"><a href="#Unit-4-1-2：Explicit-Scheme" class="headerlink" title="Unit 4.1.2：Explicit Scheme"></a>Unit 4.1.2：Explicit Scheme</h2><p>Consider the equation</p><script type="math/tex; mode=display">V_t+\frac12 a(x,t)V_{xx}+f(x,t)=0</script><script type="math/tex; mode=display">V(x,T)=g(x),\ (x,t)\in \Omega\times[0,T)</script><p>For positive integer N discretise the domain with time step size $h_0=\frac TN$ and space step size $h_1&gt;0$</p><p>Denote by $v_j^k\approx V(jh_1,kh_0)$, $j\in \mathbb Z$, $k=0,1,…,N$</p><p>Standard explicit finite difference scheme is written as</p><script type="math/tex; mode=display">\frac{v_j^k-v_j^{k-1}}{h_0}+\frac12a_j^k\frac{v_{j+1}^k+v_{j-1}^k-2v_j^k}{h_1^2}+f_j^k=0</script><script type="math/tex; mode=display">v_j^N=g_j</script><p>In the scheme, we define</p><script type="math/tex; mode=display">a_j^k:=a(jh_1,kh_0),\ f_j^k:=f(jh_1,kh_0),\ g_j:=g(jh_1)</script><p>The ordered form of the equation is written as</p><script type="math/tex; mode=display">v_j^{k-1}=(1-\frac{h_0}{h_1^2}a_j^k)v_j^k+\frac12\frac{h_0}{h_1^2}a_j^k(v_{j-1}^k+v_{j+1}^k)+h_0f_j^k</script><p>The coefficients of the values at previous time step are all nonnegative if the following <strong>monotonicity condition</strong> holds:</p><script type="math/tex; mode=display">\frac{h_0}{h_1^2}||a||_\infty\leq 1</script><blockquote><p>$||a||_\infty$ : Maximum possible value of $a$</p></blockquote><h4 id="Example-Digital-Option"><a href="#Example-Digital-Option" class="headerlink" title="Example: Digital Option"></a>Example: Digital Option</h4><p>Consider the digital option with payoff $g(x)=1_{x&gt;0}(x)$. Suppose $f(x,t)=0$ and $a(x,t)=1$</p><script type="math/tex; mode=display">\begin{cases}v_j^{k-1}=\frac12(v_{j-1}^k+v_{j+1}^k),& if\ h_0=h_1^2\\v_j^{k-1}=\frac12v_j^k+\frac14(v_{j-1}^k+v_{j+1}^k),& if\ h_0=\frac12h_1^2\\\end{cases}</script><p>Suppose the spatial domain is taken as $[–1, 1]$ and $T = 1$. For the boundary condition</p><script type="math/tex; mode=display">V(-1,t)=0,\ V(1,t)=1,\ t\in[0,T]</script><p>we solve the explicit scheme</p><h2 id="Unit-4-1-3：Implicit-Scheme"><a href="#Unit-4-1-3：Implicit-Scheme" class="headerlink" title="Unit 4.1.3：Implicit Scheme"></a>Unit 4.1.3：Implicit Scheme</h2><p>For $j\in \mathbb Z$, $k=0,1,…,N$</p><script type="math/tex; mode=display">\frac{v_j^{k+1}-v_j^k}{h_0}+\frac12a_j^k\frac{v_{j+1}^k+v_{j-1}^k-2v_j^k}{h_1^2}+f_j^k=0</script><script type="math/tex; mode=display">v_j^N=g_j</script><p>the fixed-point form of the equation is written as</p><script type="math/tex; mode=display">v_j^k=(1+\frac{h_0}{h_1^2}a_j^k)^{-1}(\frac12\frac{h_0}{h_1^2}a_j^k(v_{j-1}^k+v_{j+1}^k)+v_j^{k+1}+h_0f_j^k)</script><ul><li>The scheme is monotonic without any condition</li></ul><h2 id="Unit-4-1-4：Family-of-theta-Schemes"><a href="#Unit-4-1-4：Family-of-theta-Schemes" class="headerlink" title="Unit 4.1.4：Family of $\theta$ Schemes"></a>Unit 4.1.4：Family of $\theta$ Schemes</h2><p>For $\theta\in [0, 1]$, consider the following scheme</p><script type="math/tex; mode=display">\frac{v_j^{k+1}-v_j^k}{h_0}+\frac12\theta a_j^k\frac{v_{j+1}^k+v_{j-1}^k-2v_j^k}{h_1^2}+\frac12(1-\theta) a_j^{k+1}\frac{v_{j+1}^{k+1}+v_{j-1}^{k+1}-2v_j^{k+1}}{h_1^2}+f_j^k=0</script><script type="math/tex; mode=display">v_j^N=g_j</script><p><strong>The scheme is explicit if $\theta=0$, and implicit otherwise (standard implicit for $\theta=1$)</strong></p><p>The scheme is monotonic if</p><script type="math/tex; mode=display">(1-\theta)\frac{h_0}{h_1^2}||a||_\infty\leq 1</script><h4 id="Application-Option-Pricing"><a href="#Application-Option-Pricing" class="headerlink" title="Application: Option Pricing"></a>Application: Option Pricing</h4><p>Consider the transformed Black-Scholes equation</p><script type="math/tex; mode=display">v_t+\frac12 \sigma^2v_{xx}+(r-\frac12 \sigma^2)v_x-rv=0</script><script type="math/tex; mode=display">V(T,x)=(e^x-K)^+</script><p>Choose the domain $D=[0,T]\times[X_{min},X_{max}]$ with $-\infty&lt;X_{min}&lt;X_{max}&lt;\infty$</p><p>Approximate $D$ with a uniform mesh</p><script type="math/tex; mode=display">\mathscr D=\{(t^k,x_j):k=0,1,...,N,j=0,1,...,M\}</script><p>where $t^k=kh_0$ and $x_j=X_{min}+jh_1$ for $h_0=T/N$ and $h_1=(X_{max}-X_{min})/M$</p><p>Denote $v(t^k,x_j)=v_j^k$. Then, we use the finite difference derivative approximation based on the $\theta$ scheme</p><script type="math/tex; mode=display">\frac{\partial v}{\partial t}(t^k,x_j)\approx \frac{v_j^{k+1}-v_j^k}{h_0}</script><script type="math/tex; mode=display">\frac{\partial v}{\partial x}(t^k,x_j)\approx \theta\frac{v_{j+1}^k-v_j^k}{h_1}+(1-\theta)\frac{v_{j+1}^{k+1}-v_j^{k+1}}{h_1}</script><script type="math/tex; mode=display">\frac{\partial^2 v}{\partial x^2}(t^k,x_j)\approx \theta \frac{v_{j+1}^k+v_{j-1}^k-2v_j^k}{h_1^2}+ (1-\theta) \frac{v_{j+1}^{k+1}+v_{j-1}^{k+1}-2v_j^{k+1}}{h_1^2}</script><p>where $\theta\in [0, 1]$ is a constant parameter.</p><p>We also replace $v_j^k$ by $\theta v_j^k+(1-\theta)v_j^{k+1}$.  For $\theta=0.5$ the method corresponds to Crank-Nicholson method</p><p>We can formulate a tridiagonal system at each time step $k = N, . . . , 0$ which can be solved by the well-known Thomas algorithm (MATLAB command: tridiag)</p><script type="math/tex; mode=display">Av_k=b^{k+1}</script><p>with non-zero coefficients of the tridiagonal matrix $A = (a_{ij})$ given by</p><script type="math/tex; mode=display">\begin{align}&a_{0,0}=1,\ a_{0,1}=0,\\&a_{M,M-1}=0,\ a_{M,M}=1,\\&a_{i,i}=1+2\omega\theta+\kappa\theta+\rho\theta,\\&a_{i,i+1}=-\omega\theta-\kappa\theta,\\&a_{i-1,i}=-\omega\theta,\quad i=1,...,M-1\end{align}</script><p>The time dependent vector $b^{k+1}$ is given as:</p><script type="math/tex; mode=display">b_0^{k+1}=v_0^{k+1},\ b_M^{k+1}=v_M^{k+1},</script><script type="math/tex; mode=display">\begin{align}b_i^{k+1}&=\omega(1-\theta)v_{i-1}^{k+1}+(1-2\omega(1-\theta)-\kappa(1-\theta)-\rho(1-\theta))v_i^{k+1}...\\&...+(\omega(1-\theta)+\kappa(1-\theta))v_{i+1}^{k+1}\end{align}</script><p>where $v_0^{k+1},v_M^{k+1}$ are given by the boundary conditions and the remaining constants are defined as below</p><script type="math/tex; mode=display">\omega=\frac{h_0\sigma^2}{2h_1^2},\ \kappa=\frac{(r-\frac12\sigma^2)h_0}{h_1},\ \rho=rh_0</script><p>The $i$th coordinate of the vector $v^k$ is the approximation of the value $v(t^k,x_i)$</p><h1 id="Unit-4-2：Optimisation-methods-in-finance"><a href="#Unit-4-2：Optimisation-methods-in-finance" class="headerlink" title="Unit 4.2：Optimisation methods in finance"></a>Unit 4.2：Optimisation methods in finance</h1><h4 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h4><p>In finance, the parameters in stochastic models are estimated using the available market data. This procedure is called <strong>model calibration</strong></p><p>Most calibration problems can be seen as either a <strong>root-finding procedure</strong> or as an <strong>optimisation problem</strong></p><h4 id="Convex-Functions"><a href="#Convex-Functions" class="headerlink" title="Convex Functions"></a>Convex Functions</h4><p>Let $\mathscr U$ denote a convex set and let $f :\mathscr U \to \mathbb R$ be a function. Then, $f$ is <strong>convex</strong> if for all $u_1, u_2 \in \mathscr U$ , for all $\lambda \in [0, 1]$,</p><script type="math/tex; mode=display">f(\lambda u_1+(1-\lambda)u_2)\leq\lambda f(u_1)+(1-\lambda)f(u_2)</script><p>Any local minimun of a convex function is also its global minimum</p><p>If $w_1,…,w_n\ge0$ and $f_1,…,f_n$ are all convex, then $\sum_{i=1}^n w_if_i$ is also aconvex function</p><p>If $f_1,…,f_n$ are convex, then $g(x):=max(f_1,…,f_n)$ is also a convex function</p><h2 id="Unit-4-2-1：Newton’s-Method"><a href="#Unit-4-2-1：Newton’s-Method" class="headerlink" title="Unit 4.2.1：Newton’s Method"></a>Unit 4.2.1：Newton’s Method</h2><p>Basic approach:</p><ul><li>Approximate the function $f$ by its tangent at a given point</li><li>The point at which the tangent crosses the x-axis is taken as an approximate solution to the equation $f (x) = 0$</li><li>The process is repeated with the new point</li></ul><p>Given an initial guess $x_0$, a sequence of points is constructed using the recurrence relation</p><script type="math/tex; mode=display">x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)}</script><p>For the method to converge, we need, at least, that $|f′′| \leq K$ and the initial guess is close to the true solution</p><h4 id="Example-Implied-Volatility"><a href="#Example-Implied-Volatility" class="headerlink" title="Example: Implied Volatility"></a>Example: Implied Volatility</h4><p>Consider $C(\sigma)$ as the call option price formula given strike $K$ and time to maturity $T$ with volatility $\sigma$ as the parameter</p><p>Aim is to find the implied volatility for call option with market price $C_0$</p><p>Given an initial guess $\sigma_0$, Newton’s method can be used to construct a sequence of points as</p><script type="math/tex; mode=display">\sigma_{n+1}=\sigma_n-\frac{C(\sigma_n)-C_0}{\frac{\partial_\sigma C(\sigma_n)}{\partial \sigma}}</script><p>For error tolerance $\epsilon$, stop the iteration for some $n + 1$, when $|\sigma_{n+1} – \sigma_n| &lt; \epsilon$ (convergence)</p><h2 id="Unit-4-2-2：Descent-Methods"><a href="#Unit-4-2-2：Descent-Methods" class="headerlink" title="Unit 4.2.2：Descent Methods"></a>Unit 4.2.2：Descent Methods</h2><p>To solve optimisation problems, Newton’s method cannot be used as it can guarantee only <strong>local convergence</strong> for a good initial guess</p><p>In practice, to solve optimisation problems, we need methods with <strong>global convergence</strong>, that is convergence from an arbitrary initial guess (starting point)</p><p>The overall idea of descent methods is to construct a sequence of points as</p><script type="math/tex; mode=display">x_{n+1}=x_n+\mu_np_n</script><p>where $\mu_n$ is a non-increasing sequence of learning rate and $p_n$  is direction vector</p><h3 id="Gradient-Descent-Method"><a href="#Gradient-Descent-Method" class="headerlink" title="Gradient Descent Method"></a>Gradient Descent Method</h3><p>For model parameter $u$ taking values in the space $\mathscr U$ , we consider the problem</p><script type="math/tex; mode=display">\min_{u\in\mathscr U} J(u)</script><p>The sequence of points is constructed as</p><script type="math/tex; mode=display">u_{n+1}=u_n-\mu\Delta J(u_n)</script><p>where $\mu &gt; 0$ and $\Delta J(u_n)$ is the gradient of cost function evaluated at $u_n$</p><p>$\mu$ has to be carefully chosen to ensure convergence of the method</p><h3 id="Gradient-Descent-Method-with-Constraints"><a href="#Gradient-Descent-Method-with-Constraints" class="headerlink" title="Gradient Descent Method with Constraints"></a>Gradient Descent Method with Constraints</h3><p>Under some constraints on the parameters, we look to solve the problem</p><script type="math/tex; mode=display">\min_{u\in K} J(u)</script><p>where $K$ is a closed convex subset of the parameter space $\mathscr U$</p><p>For $\mu &gt; 0$, a sequence of points is constructed as</p><script type="math/tex; mode=display">u_{n+1}=P_K(u_n-\mu\Delta J(u_n))</script><p>where $P_K(u)$ is the orthogonal projection of $u$ on $K$</p><p>For $x \in \mathscr U$ , its orthogonal projection in $K$ is given by $x_K$ where</p><script type="math/tex; mode=display">||x-x_K||=\min_{y\in K}||x-y||</script><h4 id="Penalisation-of-Constraints"><a href="#Penalisation-of-Constraints" class="headerlink" title="Penalisation of Constraints"></a>Penalisation of Constraints</h4><p>We can convert a minimisation problem with constraints into an optimisation problem without constraints</p><p>The idea is to <strong>penalise</strong> the constraints and form a new unconstrained minimisation problem</p><p>Consider the constrained minimisation problem with continuous convex cost function $J:\mathbb R^d\to\mathbb R$</p><script type="math/tex; mode=display">\min_{F(u)\leq 0}J(u)</script><p>where $F : \mathbb R^d \to \mathbb R^M$ is a continuous convex function representing thec onstraints on parameter $u \in \mathbb R^d$</p><p>An unconstrained problem is then given as</p><script type="math/tex; mode=display">\min_{u\in\mathbb R^d}(J(u)+\frac1\epsilon\sum_{i=1}^M[\max(F_i(u),0)]^2)</script><p>where the constraint $F_i(u) \leq 0$ has been penalised</p><p>The above problem can be solved using descent methods</p><p>For small value of $\epsilon &gt; 0$, the solution of unconstrained problem approximates the solution of constrained problem</p><h2 id="Unit-4-2-3：Stochastic-Gradient-Descent"><a href="#Unit-4-2-3：Stochastic-Gradient-Descent" class="headerlink" title="Unit 4.2.3：Stochastic Gradient Descent"></a>Unit 4.2.3：Stochastic Gradient Descent</h2><p>Unlike the gradient descent methods which are deterministic, stochastic gradient methods choose the direction of descent randomly</p><p>Gradient descent methods perform well for convex cost functions whereas stochastic gradient descent methods can handle non-convex cost functions</p><p>Consider the model parameter $\theta \in \mathbb R^d$</p><p><strong>For example:</strong> </p><p>consider the Heston’s stochastic volatility model</p><script type="math/tex; mode=display">\frac{d S_t}{S_t}=rdt+\sqrt{v_t}dW_t</script><script type="math/tex; mode=display">dv_t=\kappa(\theta-v_t)dt+\delta\sqrt{v_t}dW_t',\ d\langle W,W'\rangle=\rho dt</script><p>The parameter vector $\theta = (\kappa,\theta,\delta,\rho)\in \mathbb R^4$</p><p>Next, consider the cost function $J:\mathbb R^d\to\mathbb R$</p><p><strong>For example:</strong></p><p> Given market prices $P^{market}$ of call options with strike<br>$K_j, 1 \leq j \leq N$ and time to maturity $T_i, 1 \leq i \leq M$, the cost function for Heston’s model calibration can be written as</p><script type="math/tex; mode=display">J(\theta;\{K\}_{j=1}^N,\{T\}_{i=1}^M)=\frac1{MN}\sum_{i=1}^M\sum_{j=1}^N(P^\theta(T_i,K_j)-P^{market}(T_i,K_j))^2</script><p>where $P^\theta$ is the call option price function under Heston’s model</p><p>Unlike the gradient descent methods, which use the entire dataset $\{K\}^N_{j=1}$, $\{T\}^M_{i=1}$, to construct the points sequence, the stochastic gradient descent methods use only a fraction of the dataset to construct the sequence</p><h4 id="Stochastic-Gradient-Descent-Algorithm"><a href="#Stochastic-Gradient-Descent-Algorithm" class="headerlink" title="Stochastic Gradient Descent Algorithm"></a>Stochastic Gradient Descent Algorithm</h4><p>Stochastic gradient descent (SGD) method constructs the sequence as</p><script type="math/tex; mode=display">\theta_{n+1}=\theta_n-\mu\Delta_\theta J(\theta_n;K_j,T_i)</script><p>where $\mu &gt; 0$ is a positive scalar and the update is performed for a uniformly randomly chosen sample $K_j$ and $T_i$ from the dataset</p><p>The SGD method updates frequently with a high variance which leads to a slower convergence</p><p>On the other hand, due to high variance, the SGD method is able to better explore the parameter space and is able to jump to better local minima for non-convex cost functions</p><h4 id="Mini-batch-Gradient-Descent"><a href="#Mini-batch-Gradient-Descent" class="headerlink" title="Mini-batch Gradient Descent"></a>Mini-batch Gradient Descent</h4><p>Mini-batch gradient descent algorithm randomly picks a sample from the dataset to compute the derivative of the cost function</p><p>Uniformly randomly select m samples $(K_i,T_j)$ from the dataset $\{K\}^N_{j=1}$, $\{T\}^M_{i=1}$, and denote it by $\{X_i\}^m_{i=1}$ , called the mini-batch</p><p>Compute the derivative of the cost function using the mini-batch, that is, compute $\Delta_\theta J(\theta;\{X_i\}^m_{i=1})$</p><p>Construct the sequence using the recursion</p><script type="math/tex; mode=display">\theta_{n+1}=\theta_n-\mu\Delta_\theta J(\theta_n;\{X_i\}_{i=1}^m)</script><p>Small batch sizes lead to noisy updates whereas large batch sizes require considerable computation time</p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>Stochastic gradient descent algorithms can be further improved using different statistical features. The most famous algorithms are</p><ul><li>AdaGrad</li><li>AdaDelta</li><li>AdaM</li></ul><p>The above variations of the stochastic gradient algorithm are mostly used for very large datasets</p><p>For most model calibration purposes, mini-batch gradient descent method provides good performance</p>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Financial Engineering</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【练习】Option Pricing</title>
    <link href="/2021/05/06/Exercise_1/"/>
    <url>/2021/05/06/Exercise_1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于ECON5020期末考试试题;</p><p>Option pricing;</p></blockquote><span id="more"></span><h2 id="Question"><a href="#Question" class="headerlink" title="Question:"></a>Question:</h2><p><strong>Consider a multi-period market model $M=(B,S)$ with two assets: the saving account $B$ and the risky asset $S$. For a natural number $T$, consider the following model for the price of the risky asset $S$:</strong></p><script type="math/tex; mode=display">S_t = S_0 +Y_1,Y_2+...+Y_t,</script><p><strong>where the random variables $Y_1,…,Y_T$ are independent and identically distributed under the real-world probability measure $\mathbb{P}$, specifically,</strong></p><script type="math/tex; mode=display">P(Y_1=+a)=.25,\ P(Y_1=-a)=.75</script><p><strong>where $a&gt;0$ is a strictly positive constant. We assume that the risk-free rate $r=0$ so that the savings account equals $B_t=1$ for every $t=0,1,…,T$.</strong></p><ol><li>Check whether the model $M=(B,S)$ is arbitrage-free and complete.</li><li>Find the option price process $\pi_t(X)$, $t=0,1,2,3$ and the replicating strategy $\varphi=(\varphi_0,\varphi_1)$</li></ol><h2 id="Answer"><a href="#Answer" class="headerlink" title="Answer:"></a>Answer:</h2><h3 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h3><p>我们可以看到，在给定前一个时刻的股票价格时，每个时间$t$都存在两个状态。分别是$+a$增长一个值，或者$-a$减少一个值，所以这是个$binomial tree$。为了判断模型是不是无套利的，我可以用定义：当$d&lt;1+r&lt;u$ 时无套利。其中$d=\frac{s_t}{s_{t-1}}=\frac{s_{t-1}-a}{s_{t-1}}=1-\frac{a}{s_{t-1}}$,$u=\frac{s_t}{s_{t-1}}=\frac{s_{t-1}+a}{s_{t-1}}=1+\frac{a}{s_{t-1}}$, 所以等式成立。</p><h3 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h3><p>主要流程使用 $Backward induction$.</p><p>已知$T=3$,可以先画出股价的变动图。后续会往内补充数字：</p><div class="table-container"><table><thead><tr><th>t=0</th><th>t=1</th><th>t=2</th><th>t=3</th><th>value at T</th></tr></thead><tbody><tr><td></td><td></td><td></td><td>$S_0+3a$ , $\omega_1$</td><td>$\gets x_1$</td></tr><tr><td></td><td></td><td>$S_0+2a$</td><td></td><td></td></tr><tr><td></td><td>$S_0+a$</td><td></td><td>$S_0+a$ , $\omega_2$</td><td>$\gets x_2$</td></tr><tr><td>$S_0$</td><td></td><td>$S_0$</td><td></td><td></td></tr><tr><td></td><td>$S_0-a$</td><td></td><td>$S_0-a$ , $\omega_3$</td><td>$\gets x_3$</td></tr><tr><td></td><td></td><td>$S_0-2a$</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>$S_0-3a$ , $\omega_4$</td><td>$\gets x_4$</td></tr></tbody></table></div><p>因为$X$ 没给定明确的值，我们假设在时间$T$ 有四个状态$\{\omega_1,\omega_2,\omega_3,\omega_4\}$, 同时还有对应的价值$\{x_1,x_2,x_3,x_4\}$。对应$multi-period$ 的模型，需要有$self-financing$ 的过程:</p><script type="math/tex; mode=display">\varphi_0^t+\varphi_1^tS_{t+1}=\varphi_0^{t+1}+\varphi_1^{t+1}S_{t+1}</script><p>对应最后时间$T$我们需要有以下式子:</p><script type="math/tex; mode=display">\varphi_0^2+\varphi_1^2S_{t+1}=h(X)</script><p>然后开始从后向前推导:</p><h4 id="From-t-2-to-3-where-A-1-omega-1-omega-2"><a href="#From-t-2-to-3-where-A-1-omega-1-omega-2" class="headerlink" title="From $t:2 \to 3$ where $A_1=\{\omega_1,\omega_2\}$"></a>From $t:2 \to 3$ where $A_1=\{\omega_1,\omega_2\}$</h4><script type="math/tex; mode=display">\begin{cases}\varphi_0^2+\varphi_1^2(S_0+3a)=x_1\\\varphi_0^2+\varphi_1^2(S_0+a)=x_2\end{cases}\to\begin{cases}\varphi_1^2·2a=x_1-x_2\\\varphi_0^2=x_1-\varphi_1^2(S_0+3a)\end{cases}</script><p>we find that $(\varphi_0^2,\varphi_1^2)=(x_1-\frac{(S_0+3a)(x_1 - x_2)}{2a},\frac{x_1-x_2}{2a})$</p><p>and $\pi_2(A_1)=x_1-\frac{(S_0+3a)(x_1 - x_2)}{2a}+\frac{(S_0+2a)(x_1-x_2)}{2a}=x_1-\frac{x_1 - x_2}{2}=\frac{x_1 + x_2}{2}$</p><h4 id="From-t-2-to-3-where-A-2-omega-2-omega-3"><a href="#From-t-2-to-3-where-A-2-omega-2-omega-3" class="headerlink" title="From $t:2 \to 3$ where $A_2=\{\omega_2,\omega_3\}$"></a>From $t:2 \to 3$ where $A_2=\{\omega_2,\omega_3\}$</h4><script type="math/tex; mode=display">\begin{cases}\varphi_0^2+\varphi_1^2(S_0+a)=x_2\\\varphi_0^2+\varphi_1^2(S_0-a)=x_3\end{cases}\to\begin{cases}\varphi_1^2·2a=x_2-x_3\\\varphi_0^2=x_2-\varphi_1^2(S_0+a)\end{cases}</script><p>we find that $(\varphi_0^2,\varphi_1^2)=(x_2-\frac{(S_0+a)(x_2 - x_3)}{2a},\frac{x_2-x_3}{2a})$</p><p>and $\pi_2(A_2)=x_2-\frac{(S_0+a)(x_2 - x_3)}{2a}+\frac{S_0(x_2-x_3)}{2a}=x_2-\frac{x_2 - x_3}{2}=\frac{x_2 + x_3}{2}$</p><h4 id="From-t-2-to-3-where-A-3-omega-3-omega-4"><a href="#From-t-2-to-3-where-A-3-omega-3-omega-4" class="headerlink" title="From $t:2 \to 3$ where $A_3=\{\omega_3,\omega_4\}$"></a>From $t:2 \to 3$ where $A_3=\{\omega_3,\omega_4\}$</h4><script type="math/tex; mode=display">\begin{cases}\varphi_0^2+\varphi_1^2(S_0-a)=x_3\\\varphi_0^2+\varphi_1^2(S_0-3a)=x_4\end{cases}\to\begin{cases}\varphi_1^2·2a=x_3-x_4\\\varphi_0^2=x_3-\varphi_1^2(S_0-a)\end{cases}</script><p>we find that $(\varphi_0^2,\varphi_1^2)=(x_3-\frac{(S_0-a)(x_3 - x_4)}{2a},\frac{x_3-x_4}{2a})$</p><p>and $\pi_2(A_3)=x_3-\frac{(S_0-a)(x_3 - x_4)}{2a}+\frac{(S_0-2a)(x_3-x_4)}{2a}=x_2-\frac{x_3 - x_4}{2}=\frac{x_3 + x_4}{2}$</p><h4 id="From-t-1-to-2-where-A-u-A-1-A-2"><a href="#From-t-1-to-2-where-A-u-A-1-A-2" class="headerlink" title="From $t:1 \to 2$ where $A_u=\{A_1,A_2\}$"></a>From $t:1 \to 2$ where $A_u=\{A_1,A_2\}$</h4><script type="math/tex; mode=display">\begin{cases}\varphi_0^1+\varphi_1^1(S_0+2a)=\frac{x_1 + x_2}{2}\\\varphi_0^1+\varphi_1^1S_0=\frac{x_2 + x_3}{2}\end{cases}\to\begin{cases}\varphi_1^1·2a=\frac{x_1 - x_3}{2}\\\varphi_0^1=\frac{x_1 + x_2}{2}-\varphi_1^1(S_0+2a)\end{cases}</script><p>we find that $(\varphi_0^1,\varphi_1^1)=(\frac{x_1 + x_2}{2}-\frac{(S_0+2a)(x_1 - x_3)}{4a},\frac{x_1-x_3}{4a})$</p><p>and $\pi_1(A_u)=\frac{x_1 + x_2}{2}-\frac{(S_0+2a)(x_1 - x_3)}{4a}+\frac{(S_0+a)(x_1-x_3)}{4a}=\frac{x_1 + x_2}{2}-\frac{x_1 - x_3}{4}=\frac{x_1 + 2x_2-x_3}{4}$</p><h4 id="From-t-1-to-2-where-A-d-A-2-A-3"><a href="#From-t-1-to-2-where-A-d-A-2-A-3" class="headerlink" title="From $t:1 \to 2$ where $A_d=\{A_2,A_3\}$"></a>From $t:1 \to 2$ where $A_d=\{A_2,A_3\}$</h4><script type="math/tex; mode=display">\begin{cases}\varphi_0^1+\varphi_1^1S_0=\frac{x_2 + x_3}{2}\\\varphi_0^1+\varphi_1^1(S_0-2a)=\frac{x_3 + x_4}{2}\end{cases}\to\begin{cases}\varphi_1^1·2a=\frac{x_2 - x_4}{2}\\\varphi_0^1=\frac{x_2 + x_3}{2}-\varphi_1^1S_0\end{cases}</script><p>we find that $(\varphi_0^1,\varphi_1^1)=(\frac{x_2 + x_3}{2}-\frac{S_0(x_2 - x_4)}{4a},\frac{x_2-x_4}{4a})$</p><p>and $\pi_1(A_u)=\frac{x_2 + x_3}{2}-\frac{S_0(x_2 - x_4)}{4a}+\frac{(S_0-a)(x_2-x_4)}{4a}=\frac{x_2 + x_3}{2}-\frac{x_2 - x_4}{4}=\frac{x_2 + 2x_3-x_4}{4}$</p><h4 id="From-t-0-to-1-where-A-0-A-u-A-d"><a href="#From-t-0-to-1-where-A-0-A-u-A-d" class="headerlink" title="From $t:0 \to 1$ where $A_0=\{A_u,A_d\}$"></a>From $t:0 \to 1$ where $A_0=\{A_u,A_d\}$</h4><script type="math/tex; mode=display">\begin{cases}\varphi_0^0+\varphi_1^0(S_0+a)=\frac{x_1 + 2x_2-x_3}{4}\\\varphi_0^0+\varphi_1^0(S_0-a)=\frac{x_2 + 2x_3-x_4}{4}\end{cases}\to\begin{cases}\varphi_1^0·2a=\frac{x_1 +x_2 -x_3 -x_4}{4}\\\varphi_0^0=\frac{x_1 + 2x_2-x_3}{4}-\varphi_1^0(S_0+a)\end{cases}</script><p>we find that $(\varphi_0^0,\varphi_1^0)=(\frac{x_1 + 2x_2-x_3}{4}-\frac{(S_0+a)(x_1 +x_2 -x_3 -x_4)}{8a},\frac{x_1 +x_2 -x_3 -x_4}{8a})$</p><p>$\begin{align}\pi_0(A_0)&amp;=\frac{x_1 + 2x_2-x_3}{4}-\frac{(S_0+a)(x_1 +x_2 -x_3 -x_4)}{8a}+\frac{S_0(x_1 +x_2 -x_3 -x_4)}{8a}\ &amp;=\frac{x_1 + 2x_2-x_3}{4}-\frac{x_1 +x_2 -x_3 -x_4}{8}=\frac{x_1 + 3x_2-3x_3 - x_4}{8}\end{align}$</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>题目的难度不大，主要在计算过程中比较繁杂的化简，选择性化简是比较重要的，我们可以发现$(S_0+a)$通常都作为一个整体出现，所以无需拆分。同时因为这道题特别的对仗工整，我们可以发现在同一时间$t$下的计算特别相似，所以有时可以采用直接替换数字。当计算时，如果出现了<em>不友好</em>的数字，比如一些没有规律的，与上下式子不对应的答案，可以检查过程中是否出现，少除，错减之类的。</p><h2 id="Matlab代码"><a href="#Matlab代码" class="headerlink" title="Matlab代码"></a>Matlab代码</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs Matlab">syms s0 a x1 x2 x3 x4<br>r = <span class="hljs-number">0</span>; u = a; d = -a; S0 = s0;imax = <span class="hljs-number">3</span>;<br>SS = sym(<span class="hljs-built_in">zeros</span>(imax+<span class="hljs-number">1</span>,imax+<span class="hljs-number">1</span>));<br>SS(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>) = S0;<br><span class="hljs-keyword">for</span> t = <span class="hljs-number">2</span>:imax+<span class="hljs-number">1</span> <span class="hljs-comment">% 对应股价变化</span><br>    <span class="hljs-keyword">for</span> n = <span class="hljs-number">1</span>:t<br>        SS(n,t) = S0+u*(t-n)+d*(n<span class="hljs-number">-1</span>);<br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br>payoff = [x1;x2;x3;x4]; <span class="hljs-comment">% 在T时的价值</span><br>PayOffMatr = sym(<span class="hljs-built_in">zeros</span>(imax+<span class="hljs-number">1</span>,imax+<span class="hljs-number">1</span>));<br>PayOffMatr(:,imax+<span class="hljs-number">1</span>) = payoff;<br>phiMatr = sym(<span class="hljs-built_in">zeros</span>(imax,imax,<span class="hljs-number">2</span>));<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span>=imax:<span class="hljs-number">-1</span>:<span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> k = <span class="hljs-number">1</span>:<span class="hljs-built_in">j</span><br>        pi1=PayOffMatr(k,<span class="hljs-built_in">j</span>+<span class="hljs-number">1</span>);<br>        pi2=PayOffMatr(k+<span class="hljs-number">1</span>,<span class="hljs-built_in">j</span>+<span class="hljs-number">1</span>);<br>        s1=SS(k,<span class="hljs-built_in">j</span>+<span class="hljs-number">1</span>);<br>        s2=SS(k+<span class="hljs-number">1</span>,<span class="hljs-built_in">j</span>+<span class="hljs-number">1</span>);<br>        phiMatr(k,<span class="hljs-built_in">j</span>,<span class="hljs-number">2</span>)=simplify((pi1-pi2)/(s1-s2)); <span class="hljs-comment">% phi1</span><br>        phiMatr(k,<span class="hljs-built_in">j</span>,<span class="hljs-number">1</span>)=simplify((pi1-phiMatr(k,<span class="hljs-built_in">j</span>,<span class="hljs-number">2</span>)*s1)/(<span class="hljs-number">1</span>+r)); <span class="hljs-comment">% phi0</span><br>        PayOffMatr(k,<span class="hljs-built_in">j</span>)=simplify(phiMatr(k,<span class="hljs-built_in">j</span>,<span class="hljs-number">1</span>)+phiMatr(k,<span class="hljs-built_in">j</span>,<span class="hljs-number">2</span>)*SS(k,<span class="hljs-built_in">j</span>)); <span class="hljs-comment">% pi</span><br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Financial Mathematics</tag>
      
      <tag>Derivatives</tag>
      
      <tag>Arbitrage Price</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】一元线性回归方程中的回归系数</title>
    <link href="/2021/04/30/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%96%B9%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%9B%9E%E5%BD%92%E7%B3%BB%E6%95%B0/"/>
    <url>/2021/04/30/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%96%B9%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%9B%9E%E5%BD%92%E7%B3%BB%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于《计量经济学导论》中文译本；</p><p>关于：</p><ol><li>回归系数的求解；</li><li>系数的无偏性；</li><li>系数的抽样方差；</li><li>sigma的无偏性；</li></ol></blockquote><span id="more"></span><h2 id="1-回归系数的求解"><a href="#1-回归系数的求解" class="headerlink" title="1. 回归系数的求解"></a>1. 回归系数的求解</h2><p>首先，我们拥有一个数据集 $x=\{x_1,x_2…,x_n\}$ , $y=\{y_1,y_2,…,y_n\}$</p><script type="math/tex; mode=display">\bar x =n^{-1} \sum_{i=1}^n x_i\ ,\  \bar y =n^{-1} \sum_{i=1}^n y_i \tag{0}</script><p>对于一个简单的一元线性回归方程</p><script type="math/tex; mode=display">y = \alpha +\beta x+u</script><p>其中 $\alpha , \beta$ 是我们假设的完美情况下存在的系数，$u$ 为得到数据时存在的干扰值/误差</p><p>我们将用普通最小二乘法推导模型</p><script type="math/tex; mode=display">\hat y = \hat\alpha + \hat\beta x</script><p>其中 $\alpha , \beta$ 是我们通过数据推导得到的系数, $\hat{y}$ 是通过模型得到的拟合值</p><p>我们的目标函数</p><script type="math/tex; mode=display">Min\ Q =(y-\hat{y})^2=(y-\hat\alpha - \hat\beta x)^2  \tag{1}</script><p>为了求最小值， (1) 进行对 $\hat{\alpha},\hat{\beta}$ 求偏导，并令其值等于0</p><p>得到</p><script type="math/tex; mode=display">\begin{align}\frac{\partial Q}{\partial \hat\alpha}=(-2)(y-\hat\alpha-\hat\beta x)&=0\\y-\hat\alpha-\hat\beta x&=0 \tag{2}\end{align}</script><script type="math/tex; mode=display">\begin{align}\frac{\partial Q}{\partial \hat\beta}=(-2x)(y-\hat\alpha-\hat\beta x)&=0\\x(y-\hat\alpha-\hat\beta x)&=0 \tag{3}\end{align}</script><p>接下来通过对 $x,y$ 的展开(求和的上下限忽略不写)，从 (2) 中推得性质</p><script type="math/tex; mode=display">\begin{align}\sum (y_i - \hat\alpha - \hat\beta x_i) &=0\\\sum y_i &=\sum (\hat\alpha + \hat\beta x_i) \gets (0) \\n \bar y &=n \hat\alpha + n \hat\beta \bar x\\\bar y &=\hat\alpha + \hat\beta \bar x \tag{4}\end{align}</script><p>将 (4) 代入 (3) 得到</p><script type="math/tex; mode=display">\begin{align}x(y-\bar y + \hat\beta \bar x-\hat\beta x)&=0\\x(y-\bar y)&=\hat\beta x(x-\bar x) \tag{5}\end{align}</script><p>推导两个新特质</p><script type="math/tex; mode=display">\begin{align}\sum (x_i-\bar x_i)^2 &= \sum (x_i^2 + \bar x_i^2 -2\bar xx_i) \\&=\sum x_i^2 + n \bar x_i\bar x_i - 2\bar x\sum x_i \gets (0)\\&=\sum x_i^2 + n \bar x_i n^{-1}\sum x_i - 2\bar x\sum x_i\\&= \sum x_i^2 -\bar x\sum x_i\\&= \sum x_i(x_i-\bar x) \tag{6}\end{align}</script><script type="math/tex; mode=display">\begin{align}\sum (x_i-\bar x_i)(y_i-\bar y_i) &= \sum (x_iy_i + \bar x_i\bar y_i -x_i\bar y_i-y_i\bar x_i) \gets (0)\\&=\sum x_iy_i + n \bar x_i\bar y_i - n\bar x\bar y - n\bar x\bar y \gets (0)\\&=\sum x_iy_i - n \bar y_i n^{-1}\sum x_i\\&= \sum x_iy_i -\bar y\sum x_i\\&= \sum x_i(y_i-\bar y) \tag{7}\end{align}</script><p>将 (6) , (7) 代入 (5) 得</p><script type="math/tex; mode=display">\begin{align}\sum (x_i-\bar x)(y_i-\bar y)&= \sum \hat\beta(x_i-\bar x)^2\\\hat\beta &= \frac{\sum (x_i-\bar x)(y_i-\bar y)}{\sum (x_i-\bar x)^2} \tag{8}\end{align}</script><p><strong>最终我们得到两系数的值</strong></p><script type="math/tex; mode=display">\begin{cases}\hat\beta = \frac{\sum (x_i-\bar x)(y_i-\bar y)}{\sum (x_i-\bar x)^2} \\\hat\alpha = \bar y - \hat\beta \bar x \tag{9}\end{cases}</script><h2 id="2-系数的无偏性"><a href="#2-系数的无偏性" class="headerlink" title="2. 系数的无偏性"></a>2. 系数的无偏性</h2><p>重申一个特质</p><script type="math/tex; mode=display">\begin{align}\sum(x_i-\bar x)&=\sum x_i-n\bar x \gets (0) \\&= n\bar x-n\bar x\\&= 0 \tag{10}\end{align}</script><p>首先对 $\hat\beta$ 进行变换</p><script type="math/tex; mode=display">\begin{align}\hat\beta &= \frac{\sum (x_i-\bar x)(y_i-\bar y)}{\sum (x_i-\bar x)^2} \gets (7)\\&= \frac{\sum (x_i-\bar x)y_i}{\sum (x_i-\bar x)^2}\\&= \frac{\sum (x_i-\bar x)(\alpha +\beta x_i+u_i)}{\sum (x_i-\bar x)^2} \gets (10)\\&= \frac{\sum (x_i-\bar x)(\beta x_i+u_i)}{\sum (x_i-\bar x)^2} \gets (6)\\&= \frac{\sum ((x_i-\bar x)^2\beta+(x_i-\bar x)u_i)}{\sum (x_i-\bar x)^2}\\&= \beta+\frac{\sum (x_i-\bar x)u_i}{\sum (x_i-\bar x)^2} \tag{11}\end{align}</script><p><strong>对 $\hat\beta$ 无偏性的证明</strong></p><script type="math/tex; mode=display">\begin{align}E(\hat\beta) &= \beta + E(\frac{\sum (x_i-\bar x)u_i}{\sum (x_i-\bar x)^2})\\&= \beta + \frac{\sum (x_i-\bar x)E(u_i)}{\sum (x_i-\bar x)^2} \gets SLR.4\\&= \beta\end{align}</script><blockquote><p>SLR.4 : Zero Conditional Mean</p><p>注意在中文版中SLR.3才是零条件均值</p></blockquote><p><strong>对 $\hat\alpha$ 无偏性的证明</strong></p><script type="math/tex; mode=display">\begin{align}E(\hat\alpha) &= E(\bar y - \hat\beta \bar x)\\&= E(\alpha +\beta \bar x+\bar u - \hat\beta \bar x) \gets SLR.4\\&= \alpha + \beta \bar x - \beta \bar x\\&= \alpha\end{align}</script><h2 id="3-系数的抽样方差"><a href="#3-系数的抽样方差" class="headerlink" title="3. 系数的抽样方差"></a>3. 系数的抽样方差</h2><p>提前定义</p><script type="math/tex; mode=display">u_i \sim N(0,\sigma^2)</script><p>重申关于 $Var$ 的知识点</p><script type="math/tex; mode=display">Var(x+y)=Var(x)+Var(y)+2Cov(x,y) \tag{12}</script><script type="math/tex; mode=display">Cov(x,y)=E(xy)-E(x)E(y) \tag{13}</script><script type="math/tex; mode=display">Var(\bar u)=Var(\frac{\sum u_i}{n})=\frac{\sum Var(u_i)}{n^2}=\frac{\sigma^2}{n} \tag{14}</script><p><strong>从 (11) 对 $\hat\beta$ 进行方差的推导</strong></p><script type="math/tex; mode=display">\begin{align}Var(\hat\beta) &= Var(\frac{\sum (x_i-\bar x)u_i}{\sum (x_i-\bar x)^2})\\&= \frac{1}{(\sum (x_i-\bar x)^2)^2}Var(\sum (x_i-\bar x)u_i)\\&= \frac{1}{(\sum (x_i-\bar x)^2)^2}\sum (x_i-\bar x)^2Var(u_i)\\&= \frac{1}{(\sum (x_i-\bar x)^2)^2}\sum (x_i-\bar x)^2\sigma^2\\&= \frac{\sigma^2}{\sum (x_i-\bar x)^2} \tag{15}\end{align}</script><p>推导一个新特质</p><script type="math/tex; mode=display">\begin{align}(13) \to Cov(\bar u,(\beta - \hat\beta) \bar x) &= E((\beta - \hat\beta) \bar x \bar u)-E(\bar u)E((\beta - \hat\beta) \bar x)\\&= E((\beta - \hat\beta) \bar x \bar u) \gets (11) \\&= E(\frac{\sum (x_i-\bar x)u_i\bar u\bar x}{\sum (x_i-\bar x)^2})\\&= (\frac{\sum (x_i-\bar x)\bar x}{\sum (x_i-\bar x)^2})^2E(u_i\bar u) \gets (10)\\&= 0\times E(u_i\bar u) \tag{16}\end{align}</script><p>扩展</p><blockquote><p>这里的 $E(u_i\bar u)$ 不能等于0，因为 $i$ 与 $\bar u$ 中除了编号是 $i$ 的其他残差独立</p><p>$E(u_i\bar u)=\frac{1}{n}\sum_{j=1}^nE(u_iu_j)=\frac{1}{n}E(u_i^2)=\frac{\sigma^2}{n}$</p><p>$E(u_i^2) = Var(u_i)-E(u_i)^2=\sigma^2$</p></blockquote><p><strong>对 $\hat\alpha$ 进行方差的推导</strong></p><script type="math/tex; mode=display">\begin{align}Var(\hat\alpha) &= Var(\bar y - \hat\beta \bar x)\\&= Var(\alpha +\beta \bar x+\bar u - \hat\beta \bar x)\\&= Var(\bar u +(\beta - \hat\beta) \bar x) \gets (12)\\&= Var(\bar u)+Var((\beta - \hat\beta) \bar x)+2Cov(\bar u,(\beta - \hat\beta) \bar x) \gets (14)(15)(16)\\&= \frac{\sigma^2}{n} + \frac{\sigma^2\bar x^2}{\sum (x_i-\bar x)^2}\\&= \frac{\sum (x_i-\bar x)^2\sigma^2+n\sigma^2\bar x^2}{n\sum (x_i-\bar x)^2}\\&= \frac{\sigma^2}{n}\frac{\sum (x_i-\bar x)^2+n\bar x^2}{\sum (x_i-\bar x)^2}\\&= \frac{\sigma^2}{n}\frac{\sum (x_i^2+\bar x^2-2x_i\bar x)+n\bar x^2}{\sum (x_i-\bar x)^2} \gets (0)\\&= \frac{\sigma^2}{n}\frac{\sum x_i^2+n\bar x^2-2n\bar x^2+n\bar x^2}{\sum (x_i-\bar x)^2}\\&= \frac{\sigma^2}{n}\frac{\sum x_i^2}{\sum (x_i-\bar x)^2} \tag{17}\end{align}</script><h2 id="4-sigma的无偏性"><a href="#4-sigma的无偏性" class="headerlink" title="4. sigma的无偏性"></a>4. sigma的无偏性</h2><p>定义</p><ul><li>$u_i$ : 误差</li><li><p>$\hat u_i = y-\hat y = u_i+(\alpha-\hat\alpha)+(\beta-\hat\beta)x_i$ : 残差</p></li><li><p>$\sigma^2 = n^{-1}\sum u_i^2 = (n-2)^{-1}\sum \hat u_i^2 = \frac{SSR}{n-2}$ : 因为包含两个限制条件，所以减少两个自由度</p></li></ul><p>由 (2) 得</p><script type="math/tex; mode=display">\begin{align}0&= y-\hat\alpha-\hat\beta x\\&= \alpha -\hat\alpha +\beta x -\hat\beta x +u\\&= (\alpha -\hat\alpha) +(\beta -\hat\beta)\bar x +\bar u \tag{18}\end{align}</script><p>将原有残差公式与 (18) 相减</p><script type="math/tex; mode=display">\begin{align}\sum \hat u_i &= \sum (u_i-\bar u)+\sum (\beta-\hat\beta)(x_i-\bar x)\\\sum \hat u_i^2 &= \sum (u_i-\bar u)^2 + \sum (\beta-\hat\beta)^2(x_i-\bar x)^2 + \sum 2(u_i-\bar u)(\beta-\hat\beta)(x_i-\bar x)\\\end{align}</script><p>右侧第一项的期望值是样本误差的方差 $(n-1)\sigma^2$</p><p>右侧第二项因为 $E[(\hat\beta-\beta)^2]=Var(\hat\beta)-E[(\hat\beta-\beta)]^2=Var(\hat\beta)$ 代入 (15) 得期望为 $\sigma^2$</p><p>推导一个新特质</p><script type="math/tex; mode=display">\begin{align}(8)\to \sum(u_i-\bar u)(x_i-\bar x) &=\sum u_i(x_i-\bar x)\\&=\sum (y_i-\alpha-\beta x_i)(x_i-\bar x) \gets (10)\\&=\sum (y_i-\beta x_i)(x_i-\bar x) \gets (6) (7)\\&=\sum (y_i-\bar y)(x_i-\bar x)-\sum\beta (x_i-\bar x)^2 \gets (8)\\&=\sum \hat\beta (x_i-\bar x)^2-\sum\beta (x_i-\bar x)^2\\&=(\hat \beta-\beta)\sum(x_i-\bar x)^2 \tag{19}\end{align}</script><p>右侧第三项可代入 (19) 并求期望得 $E[-2(\hat \beta-\beta)^2\sum(x_i-\bar x)^2]=-2\sigma^2$</p><p>将三项放在一起得 $E(\sum\hat u_i^2)=(n-1)\sigma^2+\sigma^2-2\sigma^2=(n-2)\sigma^2$</p><p>因此可证得 $E[SSR/(n-2)]=\sigma^2$</p>]]></content>
    
    
    <categories>
      
      <category>Econometrics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Simple Regression Model</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【课程】Basic Econometrics</title>
    <link href="/2021/04/27/Basic_Econometrics/"/>
    <url>/2021/04/27/Basic_Econometrics/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于格拉斯哥ECON5002的笔记；</p></blockquote><span id="more"></span><h1 id="General-information"><a href="#General-information" class="headerlink" title="General information"></a>General information</h1><p>This course introduces modern econometrics, focusing on regression analysis. The goal is to learn enough theory and get enough practice to be able to read journal articles and for conducting basic empirical research.</p><h2 id="Aims"><a href="#Aims" class="headerlink" title="Aims"></a>Aims</h2><p>The aim of this course is to introduce modern econometrics. The goal is to learn enough theory and get enough practice to be able to read journal articles and for conducting basic empirical research. The emphasis is on applying econometrics to real-world problems. However, a solid understanding of the reviewed inference procedures will require rudiments of probability theory and statistics, and the ability to prove few basic results. The course focuses on <strong>regression analysis</strong> with <strong>cross-section data</strong>, under the familiar assumption of <strong>random sampling</strong>. This setting simplifies the exposition of the main results, requiring assumptions that are relatively straightforward yet realistic. The analysis of <strong>time series data</strong> is postponed to the last part of the course. This allows highlighting potential pitfalls that do not arise with cross-sectional data. Empirical exercises will be solved during computer lab sessions using an econometric software package.</p><h2 id="ILOs"><a href="#ILOs" class="headerlink" title="ILOs"></a>ILOs</h2><p>By the end of the course, students should be able to:</p><ol><li><p>Derive some of the <strong>fundamental numerical and statistical properties</strong> of the OLS estimator.</p></li><li><p>Critically <strong>interpret a regression output</strong> to answer a given research question.</p></li><li><p>Critically <strong>evaluate the assumptions</strong> of the classical linear regression model and the ways they can be modified and with what effects.</p></li><li><p>Translate an economic argument into a <strong>formal testable hypothesis</strong> within a multiple regression model and implement the appropriate testing procedure.</p></li><li><p>Select the appropriate econometric tools and apply them to implement an empirical analysis using an <strong>econometric/statistical software package</strong>.</p></li><li><p>Communicate effectively, using appropriate <strong>technical terms</strong>.</p></li><li><p>Work <strong>collaboratively</strong> in a group to produce a combined output, by liaising with other class members, allocating tasks and co-ordinating</p></li></ol><h1 id="Unit-1：Introduction"><a href="#Unit-1：Introduction" class="headerlink" title="Unit 1：Introduction"></a>Unit 1：Introduction</h1><p><strong>Reading</strong>: Wooldridge, 7th Edition: Chapter 1</p><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition:"></a>Definition:</h3><p><strong>Ceteris Paribus</strong>: Other factors being equal.</p><h3 id="Quiz"><a href="#Quiz" class="headerlink" title="Quiz:"></a>Quiz:</h3><ol><li><u>Income</u>(x) has a causal effect on <u>consumption</u>(y).</li><li>A data set that consists of a variety of other units, taken at a given point in time, is called a(n) <u>cross-sectional data set</u>.</li></ol><h1 id="Unit-2：Regression-Analysis-Estimation"><a href="#Unit-2：Regression-Analysis-Estimation" class="headerlink" title="Unit 2：Regression Analysis: Estimation"></a>Unit 2：Regression Analysis: Estimation</h1><h2 id="Unit-2-1：The-Simple-Regression-Model"><a href="#Unit-2-1：The-Simple-Regression-Model" class="headerlink" title="Unit 2.1：The Simple Regression Model"></a>Unit 2.1：The Simple Regression Model</h2><p><strong>Reading</strong>: Wooldridge, 7th Edition: Chapter 2, including Appendix 2A</p><p><strong>Additional (Optional) Reading</strong>: Hansen (2020), Sections 2.1-2.9, 2.11, 2.14 and 2.15.</p><h3 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition:"></a>Definition:</h3><p><strong>Terminology for Simple Regression</strong>:</p><div class="table-container"><table><thead><tr><th><em>Y</em></th><th><em>X</em></th></tr></thead><tbody><tr><td>Dependent variable</td><td>Independent variable</td></tr><tr><td>Explained variable</td><td>Explanatory variable</td></tr><tr><td>Response variable</td><td>Control variable</td></tr><tr><td>Predicted variable</td><td>Predictor variable</td></tr><tr><td>Regressand</td><td>Regressor</td></tr></tbody></table></div><p><strong>Simple Linear Regression Model</strong>:</p><script type="math/tex; mode=display">y = \beta_0 + \beta_1x+u</script><ul><li><strong>intercept parameter</strong>: $\beta_0$</li><li><strong>slope parameter</strong>: $\beta_1$</li><li><p><strong>error term</strong>: $u$</p><p><strong>population regression function (PRF)</strong>:</p><script type="math/tex; mode=display">E(y|x)=\beta_0+\beta_1x</script><p><strong>The Ordinary Least Squares (OLS) Estimator</strong>:</p><script type="math/tex; mode=display">\begin{cases}\hat{\beta}_0 = \bar{y}-\hat{\beta}_1\bar{x}\\\hat{\beta}_1 = \frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}=\frac{\hat{Cov}(x,y)}{\hat{Var}(x)}\end{cases}</script><p><strong>OLS regression line/Sample Regression Function (SRF)</strong>:</p><script type="math/tex; mode=display">\hat{y}_i = \hat{\beta}_0+\hat{\beta}_1x_i</script><p><strong>Residuals</strong>: </p><script type="math/tex; mode=display">\hat{u}_i = y_i - \hat{y}_i</script><p><img src="/2021/04/27/Basic_Econometrics/pic1-1.jpg" alt></p></li></ul><p><strong>Algebraic Properties of OLS statistics</strong>:</p><ol><li>$\sum_{i=1}^n\hat{u}_i=0$</li><li>$\sum_{i=1}^n\hat{u}_ix_i=0$</li><li>$\bar{y}=\hat{\beta}_0+\hat{\beta}_1\bar{x}$</li><li>$\sum_{i=1}^n\hat{y}_i\hat{u}_i=0$</li><li>$\bar{y}=\frac{1}{n}\sum_{i=1}^n\hat{y}_i$</li></ol><p><strong>Measures of Variation</strong>:</p><ul><li>SST = $\sum_{i=1}^n(y_i-\bar{y})^2$<ul><li><strong>total sum of squares</strong></li></ul></li><li>SSE = $\sum_{i=1}^n(\hat{y}_i-\bar{y})^2$=$\sum_{i=1}^n\hat{\beta}_1^2(x_i-\bar{x})^2$<ul><li><strong>explained sum of squares</strong></li></ul></li><li>SSR = $\sum_{i=1}^n\hat{u}_i^2$<ul><li><strong>residual sum of squares</strong></li></ul></li><li>SST = SSR+ SSR</li><li>$R^2$ = $\frac{SSE}{SST}$ = $1-\frac{SSR}{SST}$, $0\leq R^2 \leq 1$<ul><li><strong>coefficient of determination</strong></li></ul></li></ul><p><strong>Summary of Functional Forms Involving Logarithms</strong>:</p><div class="table-container"><table><thead><tr><th>Model</th><th>Dependent Variable</th><th>Independent Variable</th><th>Interpretation of $\beta_1$</th></tr></thead><tbody><tr><td>Level-level</td><td>y</td><td>x</td><td>$\Delta y=\beta_1\Delta x$</td></tr><tr><td>Level-log</td><td>y</td><td>log(x)</td><td>$\Delta y=(\beta_1/100)\%\Delta x$</td></tr><tr><td>Log-level</td><td>log(y)</td><td>x</td><td>$\%\Delta y=100\beta_1\Delta x$</td></tr><tr><td>Log-log</td><td>log(y)</td><td>log(x)</td><td>$\%\Delta y=\beta_1\%\Delta x$</td></tr></tbody></table></div><h4 id="Unbiasedness-of-OLS"><a href="#Unbiasedness-of-OLS" class="headerlink" title="Unbiasedness of OLS:"></a>Unbiasedness of OLS:</h4><ul><li><strong>Assumption SLR.1</strong> (linearity in the parameters)</li></ul><p>The random variables $(y_1,x_i)$ satisfy the linear regression equation</p><script type="math/tex; mode=display">y_i=\beta_0+\beta_1x_i+u_i</script><ul><li><strong>Assumption SLR.2</strong> (random sampling)</li><li><strong>Assumption SLR.3</strong> (sample variation in <em>x</em>)</li></ul><script type="math/tex; mode=display">0<Var(x_i)<\infty</script><ul><li><strong>Assumption SLR.4</strong> (Zero Conditional Mean)<ul><li>$u_i uncorrelate with x$</li></ul></li></ul><script type="math/tex; mode=display">E(u_i|x_i)=0</script><ul><li>Assumption SLR.2 and SLR.4 imply that the <strong>(Population) Regression Function</strong> is linear.</li><li>Under Assumption SLR.1-SLR.4</li></ul><script type="math/tex; mode=display">E(\hat{\beta}_0)=\beta_0,\ and\ \ E(\hat{\beta}_1)=\beta_1</script><h4 id="Variances-of-the-OLS-estimators"><a href="#Variances-of-the-OLS-estimators" class="headerlink" title="Variances of the OLS estimators:"></a>Variances of the OLS estimators:</h4><ul><li><strong>Assumption SLR.5</strong> (homoskedasticity)</li></ul><script type="math/tex; mode=display">Var(u_i|x_i) = \sigma^2</script><ul><li>Under Assumptions SLR.1-SLR.5</li></ul><script type="math/tex; mode=display">Var(\hat{\beta}_1|x)=\frac{\sigma^2}{\sum_{i=1}^n(x_i-\bar{x})^2}=\frac{\sigma^2}{SST_x}</script><script type="math/tex; mode=display">Var(\hat{\beta}_0|x)=\frac{\sigma^2n^{-1}\sum_{i=1}^nx_i^2}{\sum_{i=1}^n(x_i-\bar{x})^2}</script><script type="math/tex; mode=display">E(\hat{\sigma}^2)=\sigma^2,\ \ \hat{\sigma}^2 = \frac{\sum_{i=1}^n \hat{u}_i^2}{n-2}</script><p><strong>Not robust</strong>: The expectation is sensitive to perturbation in the tails of the distribution.</p><p><strong>y on x</strong></p><h3 id="Quiz-1"><a href="#Quiz-1" class="headerlink" title="Quiz:"></a>Quiz:</h3><ol><li>when the regression equation passes through the origin. $y_i=\beta_1x_i+u_i$<ul><li>$\beta_1 = \frac{\sum_{i=1}^nx_iy_i}{\sum_{i=1}^nx_i^2}$</li></ul></li><li>The observed values of $x$ span a wide range $\to$ SLR.3</li></ol><h2 id="Unit-2-1：The-Multiple-Regression-Model"><a href="#Unit-2-1：The-Multiple-Regression-Model" class="headerlink" title="Unit 2.1：The Multiple Regression Model"></a>Unit 2.1：The Multiple Regression Model</h2><p><strong>Reading</strong>: Wooldridge, 7th Edition: Chapter 3, including Appendix 3A. Chapter 6, Sections 6.1-6.3.</p><p><strong>Additional Reading</strong>: Hansen (2020), Section 2.30</p><h3 id="Definition-2"><a href="#Definition-2" class="headerlink" title="Definition:"></a>Definition:</h3><p><strong>Multiple Linear Regression Model</strong>:</p><script type="math/tex; mode=display">y = \beta_0 + \beta_1x_1+\beta_2x_2+...+\beta_kx_k+u</script><ul><li><strong>intercept parameter</strong>: $\beta_0$</li><li><strong>slope parameter</strong>: $\beta_1,…,\beta_k$</li></ul><h4 id="Unbiasedness-of-OLS-1"><a href="#Unbiasedness-of-OLS-1" class="headerlink" title="Unbiasedness of OLS:"></a>Unbiasedness of OLS:</h4><ul><li><p><strong>Assumption MLR.1</strong> (Linear in Parameters)</p></li><li><p><strong>Assumption MLR.2</strong> (Random Sampling)</p></li><li><strong>Assumption MLR.3</strong> (No Perfect Collinearity)</li></ul><p>In the sample (and in the population), none of the explanatory variables is constant, and there are <strong>no exact linear relationships</strong> among them.</p><ul><li><strong>Assumption MLR.4</strong> (Zero Conditional Mean)</li></ul><script type="math/tex; mode=display">E(u_i|x_{1i},x_{2i},...,x_{ki})=0</script><ul><li>Under Assumption MLR.1-MLR.4</li></ul><script type="math/tex; mode=display">E(\hat{\beta}_j)=\beta_j, \ \ for\ j = 0,1,...,k</script><p><strong>Omitted Variable Bias:</strong></p><p>We should have estimated</p><script type="math/tex; mode=display">\hat{y} = \hat{\beta}_0+\hat{\beta}_1x_1+\hat{\beta}_2x_2</script><p>but we estimate</p><script type="math/tex; mode=display">\tilde{y} = \tilde{\beta}_0+\tilde{\beta}_1x_1</script><p>Recall that</p><script type="math/tex; mode=display">\hat{x}_2 = \tilde{\delta}_0+\tilde{\delta}_1x_1</script><script type="math/tex; mode=display">\hat{y} = \hat{\beta}_0+\hat{\beta}_2\tilde{\delta}_0+(\hat{\beta}_1+\hat{\beta}_2\tilde{\delta}_1)x_1+\epsilon</script><script type="math/tex; mode=display">\tilde{\beta}_1 =\hat{\beta}_1+\hat{\beta}_2\tilde{\delta}_1</script><p>Bias $(\tilde{\beta}_1|x)$=$\beta_2\tilde{\delta}_1$</p><p>if $ n \to \infty$, bias will approach $\frac{Cov(x_{1i},x_{2i})}{Var(x_{1i})}\beta_2$</p><div class="table-container"><table><thead><tr><th></th><th>$Corr(x_1,x_2)&gt;0$</th><th>$Corr(x_1,x_2)&lt;0$</th></tr></thead><tbody><tr><td>$\beta_2&gt;0$</td><td>Positive bias</td><td>Negative bias</td></tr><tr><td>$\beta_2&lt;0$</td><td>Negative bias</td><td>Positive bias</td></tr></tbody></table></div><h4 id="Variance-of-the-OLS-Estimators"><a href="#Variance-of-the-OLS-Estimators" class="headerlink" title="Variance of the OLS Estimators:"></a>Variance of the OLS Estimators:</h4><ul><li><strong>Assumption MLR.5</strong> (Homoskedasticity)</li></ul><script type="math/tex; mode=display">Var(u_i|x_{1i},x_{2i},...,x_{ki})=Var(u_i)=\sigma^2</script><ul><li><p>Assumptions MLR.1 through MLR.5 are called the <strong>Gauss Markov assumptions</strong>.</p></li><li><p>Under Assumptions MLR.1 to MLR.5</p><ul><li>$SST_j = \sum_{i=1}^n(x_{ij}-\bar{x}_j)^2$</li><li>$R_j^2$ is the $R^2$ of the regression</li></ul></li></ul><script type="math/tex; mode=display">Var(\hat{\beta}_j|x)=\frac{\sigma^2}{SST_j(1-R_j^2)},\ \ j=1,2,...,k</script><ul><li>As $R_j^2 \to 1$, $Var(\hat{\beta}_j) \to \infty$  (the estimate of $\beta_j$ is not precise).</li><li>Under the Gauss-Markov assumptions (MLR.1 through MLR.5)<ul><li><strong>standard deviation</strong>: $\sigma$; <strong>standard error</strong>: $\hat{\sigma}$ </li><li>The square root of $\hat{\sigma}^2$,$\hat{\sigma}$, is reported by all regression packages (<strong>standard error of the regression</strong>, or <strong>RMSE</strong>).</li></ul></li></ul><script type="math/tex; mode=display">\hat{\sigma}^2 = (n-k-1)^{-1}\sum_{i=1}^n\hat{u}_i^2 = SSR/df</script><ul><li>Under Assumptions MLR.1 through MLR.5<ul><li>the OLS estimators are the <strong>best linear unbiased estimators (BLUEs)</strong></li></ul></li></ul><p><strong>Variances in Misspecified Models</strong>:</p><p>We run the misspecified and the correctly specified regressions</p><script type="math/tex; mode=display">\begin{align}\tilde{y} &= \tilde{\beta}_0+\tilde{\beta}_1x_1\\\hat{y} &= \hat{\beta}_0+\hat{\beta}_1x_1+\hat{\beta}_2x_2\end{align}</script><p>Whenever $x_{1i}$ and $x_{2i}$ are correlated, $R_1^2 &gt; 0$, and</p><script type="math/tex; mode=display">Var(\tilde{\beta}_1|x)=\frac{\sigma^2}{SST_1}<\frac{\sigma^2}{SST_1(1-R_1^2)}<Var(\hat{\beta}_1|x)</script><ul><li>we can in fact get an estimator with a smaller variance, even though it is biased.</li></ul><p><strong>Adjusted <em>R</em>-Squared</strong>:</p><script type="math/tex; mode=display">\bar{R}^2 = 1-\frac{[SSR/(n-k-1)]}{[SST/(n-1)]} = 1-\frac{\hat{\sigma}^2}{\hat{\sigma}_y^2}</script><h3 id="Quiz-2"><a href="#Quiz-2" class="headerlink" title="Quiz:"></a>Quiz:</h3><ol><li>Exclusion of a relevant variable from a multiple linear regression model leads to the problem of <u>misspecification of the model</u>.</li><li>An explanatory variable is said to be <u>endogenous</u> if it is correlated with the error term.</li></ol><h1 id="Unit-3：Regression-Analysis-Inference"><a href="#Unit-3：Regression-Analysis-Inference" class="headerlink" title="Unit 3：Regression Analysis: Inference"></a>Unit 3：Regression Analysis: Inference</h1><h3 id="Definition-3"><a href="#Definition-3" class="headerlink" title="Definition:"></a>Definition:</h3><h4 id="Normal-distribution-in-a-nutshell"><a href="#Normal-distribution-in-a-nutshell" class="headerlink" title="Normal distribution in a nutshell"></a>Normal distribution in a nutshell</h4><p>If $x\sim N(\mu,\sigma^2)$, then​</p><script type="math/tex; mode=display">Z = \frac{X-\mu}{\sigma}\sim N(0,1)</script><ul><li><strong>Assumption MLR.6 (Normality of error terms)</strong></li></ul><script type="math/tex; mode=display">u_i \sim N(0,\sigma^2)\ \ u_i\ independent\ of\ x_{1i},x_{2i},...,x_{ik}</script><ul><li>Under assumptions MLR.1 – MLR.6: <strong>Classical Linear Regression Model (CLRM) assumptions</strong><ul><li>with estimated standard deviation</li></ul></li></ul><script type="math/tex; mode=display">\frac{\hat{\beta}_j-\beta_j}{se(\hat{\beta}_j)} \sim t_{n-k-1}</script><p>Note: The t-distribution is close to the standard normal distribution if n-k-1 is large.</p><p><strong>Null hypothesis</strong>:</p><script type="math/tex; mode=display">H_0:\beta_j = 0\ \ against\ \ H_1:\beta_j>0</script><script type="math/tex; mode=display">Reject\ if\ t_{\hat{\beta}_j}>c_a\ \ ,\ \ where\ Pr(t>c_a = \alpha)</script><p> <strong>Statistically Significant</strong>:</p><p><img src="/2021/04/27/Basic_Econometrics/pic1-2.jpg" alt></p><p><strong>Confidence Intervals</strong>:</p><p>The $\alpha\%$ confidence interval for $\beta_j$ is of the form</p><script type="math/tex; mode=display">\hat{\beta_j}\pm c_a·se(\hat{\beta}_j) = 1-\alpha\ Confidence\ level</script><ul><li>$c_{0.01}=2.576,c_{0.05}=1.96,c_{0.10}=1.645$</li><li>The effect is significantly different from zero if zero is outside the interval.</li><li>It is not statistically significant if zero lies in the interval.</li></ul><p><strong>The difference between the estimates</strong>:</p><ol><li>$t = \frac{\hat{\beta}_1-\hat{\beta}_2}{se(\hat{\beta}_1-\hat{\beta}_2)}$</li><li>Or Define $\theta_1 = \beta_1-\beta_2$ and test $H_0:\theta_1=0$</li></ol><p><img src="/2021/04/27/Basic_Econometrics/pic1-3.jpg" alt></p><p><strong>The F-test</strong>:</p><script type="math/tex; mode=display">H_0:\beta_2=\beta_3=0</script><script type="math/tex; mode=display">F = \frac{(SSR_r-SSR_{ur})/q}{SSR_{ur}/(n-k-1)}\sim F_{q,n-k-1}</script><p>$R^2$ <strong>form of the F –statistic</strong>:</p><script type="math/tex; mode=display">SSR_r = (1-R^2_r)SST,\ \ \ SSR_{ur} = (1-R^2_{ur})SST</script><script type="math/tex; mode=display">F = \frac{(R^2_{ur}-R^2_r)/q}{(1-R^2_{ur})/(n-k-1)}\sim F_{q,n-k-1}</script><p><strong>Test of overall significance of a regression</strong>:</p><script type="math/tex; mode=display">H_0:\beta_1=\beta_2=...=\beta_k=0</script><script type="math/tex; mode=display">F = \frac{R^2/k}{(1-R^2)/(n-k-1)}\sim F_{k,n-k-1}</script><p><strong>Testing general linear restrictions with the F-test</strong>:</p><script type="math/tex; mode=display">H_0:\beta_1=1,\beta_2=...=\beta_k=0</script><script type="math/tex; mode=display">x_i = y_i-x_{1i},\ \ SSR_r = \sum_{i=1}^n(x_i-\bar{x})^2</script><h3 id="Quiz-3"><a href="#Quiz-3" class="headerlink" title="Quiz:"></a>Quiz:</h3><ol><li>The significance level of a test is: <u>the probability of rejecting the null hypothesis when it is true.</u></li><li>central limit theorem (CLT) </li><li>A <strong>restricted model</strong> will always have <strong>fewer parameters</strong> than its unrestricted model./ <strong>Degrees of freedom</strong> of a <strong>restricted model</strong> is always <strong>more than</strong> the degrees of freedom of an unrestricted model.</li><li>The ordinary least square estimators have the smallest variance among all the unbiased estimators.</li></ol><h1 id="Unit-4：Regression-Analysis-with-Qualitative-Information"><a href="#Unit-4：Regression-Analysis-with-Qualitative-Information" class="headerlink" title="Unit 4：Regression Analysis with Qualitative Information"></a>Unit 4：Regression Analysis with Qualitative Information</h1><h3 id="Definition-4"><a href="#Definition-4" class="headerlink" title="Definition:"></a>Definition:</h3><p><strong>Dummy variable trap</strong> (perfect collinearity) :</p><p>When using dummy variables, one category always has to be omitted</p><p><strong>Benchmark group</strong></p><p><strong>Chow test</strong>:</p><ul><li>$H_0$: equality of regression functions across two groups.</li></ul><script type="math/tex; mode=display">F = \frac{(SSR-(SSR_1+SSR_2)/k+1}{SSR_1+SSR_2/[n-2(k+1)]}</script><p>We can allow for an intercept difference between the groups, and then test for slope difference. Replace $SSR_p$ in Chow F-stat with the residuals from a regression with a dummy.</p><h3 id="Quiz-4"><a href="#Quiz-4" class="headerlink" title="Quiz:"></a>Quiz:</h3><ol><li>In a self-selection problem, the explanatory variables can be: <u>endogenous.</u></li><li>Which of the following Gauss-Markov assumptions is violated by the <strong>linear probability model (LPM)</strong>?<ul><li>The assumption of constant variance of the error term.</li><li>$Var(y|x)=p(x)[1-p(x)]$</li></ul></li><li>Which of the following problems can arise in policy analysis and program evaluation using a multiple linear regression model?<ul><li>The model can produce predicted probabilities that are less than zero and greater than one.</li></ul></li><li>A problem that often arises in policy and program evaluation is that individuals (or firms or cities) choose whether or not to participate in certain behaviors or programs and their choice depends on several other factors. It is not possible to control for these factors while examining the effect of the programs.</li></ol><h1 id="Unit-5：Heteroskedasticity"><a href="#Unit-5：Heteroskedasticity" class="headerlink" title="Unit 5：Heteroskedasticity"></a>Unit 5：Heteroskedasticity</h1><h3 id="Definition-5"><a href="#Definition-5" class="headerlink" title="Definition:"></a>Definition:</h3><p><strong>Heteroscedasticity</strong>: MLR.5 is violated.</p><h4 id="Testing-for-heteroscedasticity"><a href="#Testing-for-heteroscedasticity" class="headerlink" title="Testing for heteroscedasticity:"></a>Testing for heteroscedasticity:</h4><p><strong>Breusch-Pagan test</strong>:</p><script type="math/tex; mode=display">\hat{u}^2 = \delta_0+\delta_1x_1+...+\delta_kx_k+error</script><script type="math/tex; mode=display">H_0:\delta_1=\delta_2=...=\delta_k=0</script><script type="math/tex; mode=display">F = \frac{R^2_{\hat{u}^2}/k}{(1-R^2_{\hat{u}^2})/(n-k-1)}\sim F_{k,n-k-1}</script><script type="math/tex; mode=display">LM = n·R^2_{\hat{u}^2} \sim \chi_k^2</script><p><strong>White test</strong>:</p><script type="math/tex; mode=display">\begin{align}\hat{u}^2 &= \delta_0+\delta_1x_1+\delta_2x_2+\delta_3x_3\\&+\delta_4x_1^2+\delta_5x_2^2+\delta_6x_3^2\\&+\delta_7x_1x_2+\delta_8x_2x_3+\delta_9x_1x_3+error\end{align}</script><script type="math/tex; mode=display">H_0:\delta_1=\delta_2=...=\delta_9=0</script><script type="math/tex; mode=display">LM = n·R^2_{\hat{u}^2} \sim \chi_9^2</script><p><strong>Alternative form of the White test</strong>:</p><script type="math/tex; mode=display">\hat{u}^2 = \delta_0+\delta_1\hat{y}_1+\delta_2\hat{y}_2+error</script><script type="math/tex; mode=display">H_0:\delta_1=\delta_2=0</script><script type="math/tex; mode=display">LM = n·R^2_{\hat{u}^2} \sim \chi_2^2</script><h4 id="Weighted-least-squares-estimation"><a href="#Weighted-least-squares-estimation" class="headerlink" title="Weighted least squares estimation:"></a>Weighted least squares estimation:</h4><script type="math/tex; mode=display">Var(u_i|x_i)=\sigma^2h(x_i),h(x_i)=h_i>0</script><p>The functional form of the heteroscedasticity is known</p><p>set $w_i=\frac{1}{\sqrt{h_i}}$</p><script type="math/tex; mode=display">\begin{align}y_i&=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+...+\beta_kx_{ik}+u_i\\w_iy_i&=w_i\beta_0+w_i\beta_1x_{i1}+w_i\beta_2x_{i2}+...+w_i\beta_kx_{ik}+w_iu_i\\y_i^* &=\beta_0x_{i0}^*+\beta_1x_{i1}^*+\beta_2x_{i2}^*+...+\beta_kx_{ik}^*+u_i^*\end{align}</script><p>where</p><script type="math/tex; mode=display">E(u_i^{*2}|x_i)=\sigma^2</script><p>Observations with a large variance are less informative than observations with small variance and therefore should get less weight</p><p><strong>Important special case of heteroscedasticity</strong>:</p><p>If the observations are reported as averages at the city/county/state/country/firm level, they should be weighted by the size of the unit. $\sigma^2/m_i$</p><p><strong>Unknown heteroscedasticity function (feasible GLS)</strong> :</p><script type="math/tex; mode=display">Var(u|x)=\sigma^2exp(\delta_0+\delta_1x_1+...+\delta_kx_k)=\sigma^2h(x)</script><script type="math/tex; mode=display">\begin{align}u^2&=\sigma^2exp(\delta_0+\delta_1x_1+...+\delta_kx_k)·v\\log(u^2)&=\alpha_0+\delta_1x_1+...+\delta_kx_k+e\\\Rightarrow \hat{h}_i &= exp(\hat{\alpha}_0+\hat{\delta}_1x_1+...+\hat{\delta}_kx_k)\end{align}</script><p><strong>White’s Heteroscedasticity-robust standard variance</strong>:</p><script type="math/tex; mode=display">\hat{Var(\hat{\beta}_1)}_{HC}=\frac{\sum_{i=1}^n(x_1-\bar{x})\hat{u}_i^2}{[\sum_{i=1}^n(x_1-\bar{x})^2]^2}</script><h3 id="Quiz-5"><a href="#Quiz-5" class="headerlink" title="Quiz:"></a>Quiz:</h3><ol><li>A test for <strong>heteroskedasticty</strong> can be significant if<ul><li>the functional form of the regression model is misspecified</li><li>Breusch-Pagan test/White test results in a small <em>p-</em>value</li></ul></li><li>The generalized least square (GLS) is an efficient procedure that weights each squared residual by the:<ul><li>inverse of the conditional variance of $u_i$ given $x_i$.</li></ul></li><li>The heteroskedasticity-robust <u><em>F</em> statistic</u> is also called the heteroskedastcity-robust Wald statistic.</li><li>The linear probability model contains heteroskedasticity unless <u>all the slope parameters are zero</u>.</li><li>The heteroskedasticity-robust <em>t</em> statistics are justified only if the sample size is large.</li><li>In weighted least squares estimation, <strong>less weight</strong> is given to observations with a <strong>higher error variance</strong>.</li><li>The WLS method fails if $\hat{h}_i$ is negative or zero for any observation.</li><li><u>The Hausman test</u> is used to compare the Ordinary Least Squares (OLS) estimates and the Weighted Least Squares (WLS) estimates.</li><li><strong>Multicollinearity</strong> among the independent variables in a linear regression model causes the <strong>heteroskedasticity-robust standard errors to be large</strong>.</li><li>The interpretation of goodness-of-fit ($R^2$) measures is unaffected by the presence of heteroskedasticty.</li></ol><h1 id="Unit-6：Regression-Analysis-with-Time-Series-Data"><a href="#Unit-6：Regression-Analysis-with-Time-Series-Data" class="headerlink" title="Unit 6：Regression Analysis with Time Series Data"></a>Unit 6：Regression Analysis with Time Series Data</h1><p><strong>Reading</strong>: Wooldridge 7th Edition Chapter 10: Basic Regression Analysis with the Time Series</p><h3 id="Definition-6"><a href="#Definition-6" class="headerlink" title="Definition:"></a>Definition:</h3><p><strong>Finite distributed lag models</strong>:</p><p>In finite distributed lag models, the explanatory variables are allowed to influence the dependent variable with a time lag</p><h4 id="Finite-sample-properties-of-OLS-under-classical-assumptions"><a href="#Finite-sample-properties-of-OLS-under-classical-assumptions" class="headerlink" title="Finite sample properties of OLS under classical assumptions:"></a><strong>Finite sample properties of OLS under classical assumptions</strong>:</h4><ul><li><strong>Assumption TS.1 (Linear in parameters)</strong></li><li><strong>Assumption TS.2 (No perfect collinearity)</strong></li><li><strong>Assumption TS.3 (Zero conditional mean)</strong><ul><li>(Contemporaneous) Exogeneity is not enough to ensure unbiasdness.</li></ul></li></ul><script type="math/tex; mode=display">X = \begin{pmatrix}x_{11}&x_{12}&...&x_{1k}\\...&...&...&...\\x_{t1}&x_{t2}&...&x_{tk}\\...&...&...&...\\x_{n1}&x_{n2}&...&x_{nk}\\\end{pmatrix}</script><script type="math/tex; mode=display">\begin{align}Exogeneity&:\ E(u_t|x_t)=0\\Strict\ exogeneity&:\ E(u_t|X)=0\end{align}</script><ul><li><p>Unbiasedness of OLS</p><ul><li>TS.1-TS.3 $\Rightarrow$ $E(\hat{\beta}_j)=\beta_j,  j=0,1,…,k$</li></ul></li><li><p><strong>Assumption TS.4 (Homoscedasticity)</strong></p><ul><li>$Var(u_t|X)=Var(u_t)=\sigma^2$</li></ul></li><li><p><strong>Assumption TS.5 (No serial correlation)</strong></p><ul><li>$Corr(u_t,u_s|X)=0, t\neq s$</li><li>Three types of correlation: <ol><li>$Corr(x_{jt},x_{hs})$</li><li>$Corr(x_{jt},xu{t})$</li><li>$Corr(u_{t},u_{s})$</li></ol></li></ul></li><li><p>OLS sampling variances</p><ul><li>TS.1-TS.5 $\Rightarrow$ $Var(\hat{\beta}_j|X)=\frac{\sigma^2}{SST_j(1-R_j^2)},  j=0,1,…,k$$</li></ul></li><li><p>Unbiased estimation of the error variance</p><ul><li>TS.1-TS.5 $\Rightarrow$ $E(\hat{\sigma}^2)=\sigma^2$</li></ul></li><li><p>Gauss-Markov Theorem:</p><ul><li>Under assumptions TS.1 – TS.5, the OLS estimators have the minimal variance of all linear unbiased estimators of the regression coefficients</li></ul></li><li><p><strong>Assumption TS.6 (Normality)</strong></p><ul><li>$u_t\sim iid N(0,\sigma^2)$ independent of $X$</li></ul></li><li><p>Normal sampling distributions</p><ul><li>Under assumptions TS.1 – TS.6, the OLS estimators have the usual normal distribution (conditional on $X$ ). The usual F- and t-tests are valid. </li></ul></li></ul><p><strong>Modelling a linear time trend</strong>:</p><script type="math/tex; mode=display">y_t = \alpha_0+\alpha_1t+e_t</script><p><strong>Modelling an exponential time trend</strong>:</p><script type="math/tex; mode=display">log(y_t) = \alpha_0+\alpha_1t+e_t</script><h3 id="Quiz-6"><a href="#Quiz-6" class="headerlink" title="Quiz:"></a>Quiz:</h3><ol><li>a static model is <strong>postulated</strong> when a change in z at time t is believed to have an <strong>immediate effect</strong> on y</li><li>Adding a time trend can make an explanatory variable more significant if: the dependent and independent variables have different kinds of trends, but movement in the independent variable about its trend line causes movement in the dependent variable away from its trend line.</li><li>Time series regression is based on the assumption that no independent variable is constant nor a perfect linear combination of the others.</li><li>Which of the following assumption for time series analysis does not hold?<ul><li>No serial correlation</li></ul></li><li>One of the assumptions of time series regression is that there should be no serial correlation in the concerned series.</li><li>Cross-sectional regression <strong>rules out perfect collinearity</strong> among the regressors.</li><li>When a series has the <strong>same average growth rate</strong> from period to period, it can be approximated with an exponential trend.</li><li>Price indexes are necessary for turning a time series measured in nominal value into real value.</li></ol><h1 id="Unit-7：Further-Issues-Using-OLS-with-Time-Series-Data"><a href="#Unit-7：Further-Issues-Using-OLS-with-Time-Series-Data" class="headerlink" title="Unit 7：Further Issues Using OLS with Time Series Data"></a>Unit 7：Further Issues Using OLS with Time Series Data</h1><p><strong>Reading</strong>: Wooldridge 7th Edition Chapter 11: Further Issues in Using OLS with Time Series Data</p><h3 id="Definition-7"><a href="#Definition-7" class="headerlink" title="Definition:"></a>Definition:</h3><p><strong>Stationary stochastic processes</strong>:</p><p>A stochastic $\{x_t:t=1,2…\}$ process is <strong>stationary</strong>, if for every collection of indices  $1\leq t_1\leq t_2\leq…\leq t_m$the joint distribution of $(x_{t_1},x_{t_2},…,x_{t_m})$ , is the same as that of  $(x_{t_1+h},x_{t_2+h},…,x_{t_m+h})$ for all integers $h\ge1$.</p><p><strong>Covariance stationary processes</strong>:</p><p>A stochastic process $\{x_t:t=1,2…\}$ is <strong>covariance stationary</strong>, if its  expected value, its variance, and its covariances are constant over time:</p><ol><li>$E(x_t)=\mu$</li><li>$Var(x_t)=\sigma^2$</li><li>$Cov(x_t,x_{t+h})=f(h)$</li></ol><p><strong>asymptotically uncorrelated</strong>：</p><p>when $h \to \infty,  cov(x_t,x_{t+h}) \to 0$</p><p><strong>Weakly dependent time series</strong>：</p><p>A stochastic process $\{x_t:t=1,2…\}$ is <strong>weakly dependent</strong> , if $x_t$ is “almost independent” of $x_{t+h}$ if $h$ grows to infinity (for all $t$).</p><p><strong>Moving average process of order one (MA(1))</strong>:</p><script type="math/tex; mode=display">x_t=e_t+\alpha_1e_{t-1}</script><p><strong>Autoregressive process of order one (AR(1))</strong>:</p><script type="math/tex; mode=display">y_t=\rho_1y_{t-1}+e_t \Rightarrow Corr(y_t,y_{t+h})=\rho_1^h</script><h4 id="Asymptotic-properties-of-OLS"><a href="#Asymptotic-properties-of-OLS" class="headerlink" title="Asymptotic properties of OLS:"></a>Asymptotic properties of OLS:</h4><ul><li><strong>Assumption TS.1‘ (Linear in parameters)</strong> <ul><li>now the dependent and independent variables are assumed to be stationary and weakly dependent</li><li>Trend-stationary processes also satisfy assumption TS.1‘</li></ul></li><li><strong>Assumption TS.2‘ (No perfect collinearity)</strong></li><li><p><strong>Assumption TS.3‘ (Zero conditional mean)</strong> </p><ul><li>Now the explanatory variables are assumed to be only contemporaneously exogenous rather than strictly exogenous</li></ul></li><li><p>Consistency of OLS：</p><ul><li>TS.1‘-TS.3’ $\Rightarrow$ $plim\hat{\beta}_j=\beta_j,  j=0,1,…,k$</li></ul></li><li><p><strong>Assumption TS.4‘ (Homoscedasticity)</strong></p><ul><li>$Var(u_t|x_t)=Var(u_t)=\sigma^2$</li></ul></li><li><p><strong>Assumption TS.5‘ (No serial correlation)</strong></p><ul><li>$Corr(u_t,u_s|x_t,x_s)=0, t\neq s$</li></ul></li><li><p>Asymptotic normality of OLS:</p><ul><li>Under assumptions TS.1‘ – TS.5‘, the OLS estimators are asymptotically normally distributed. Further, the usual OLS standard errors, t-statistics and F-statistics are asymptotically valid</li></ul></li></ul><h3 id="Random-walks"><a href="#Random-walks" class="headerlink" title="Random walks"></a>Random walks</h3><script type="math/tex; mode=display">y_t = y_{t-1}+e_t</script><ul><li>$E(y_t)=E(y_0)$</li><li>$Var(y_t)=\sigma_e^2t$</li><li>$Corr(y,y_{t+h}) = \sqrt{t/(t+h)}$</li></ul><p><strong>I(1) processes</strong>:</p><script type="math/tex; mode=display">y_t=y_{t-1}+e_t \Rightarrow \Delta y_t=y_t-y_{t-1}=e_t</script><h4 id="Testing-for-serial-correlation"><a href="#Testing-for-serial-correlation" class="headerlink" title="Testing for serial correlation"></a>Testing for serial correlation</h4><p><strong>Testing for AR(1) with strictly exog. regressors</strong> :</p><script type="math/tex; mode=display">H_0:\rho=0\ in\ \hat{u}_t=\rho\hat{u}_{t-1}+error</script><p><strong>Durbin-Watson test under classical assumptions</strong>:</p><script type="math/tex; mode=display">DW = \sum_{t=2}^n(\hat{u}_t-\hat{u}_{t-1})^2/\sum_{t=2}^n\hat{u}_t^2 \approx 2(1-\hat{\rho})</script><ul><li>$H_0 : \rho = 0$</li><li>Reject if $DW<d_L$, accept if $dw> d_U$, else the test is inconclusive.</d_L$,></li></ul><p>When strictly exogeneity does not hold, t-test and DW test are not valid</p><p><strong>Testing for AR(1) with general regressors</strong>:</p><script type="math/tex; mode=display">\hat{u}_t=\alpha_0+\alpha_1x_{t1}+...+\alpha_kx_{tk}+\rho\hat{u}_{t-1}+error</script><ul><li>$H_0:\rho = 0$</li></ul><p><strong>General Breusch-Godfrey test for AR(q)</strong>:</p><script type="math/tex; mode=display">\hat{u}_t=\alpha_0+\alpha_1x_{t1}+...+\alpha_kx_{tk}+\rho\hat{u}_{t-1}+...+\rho_q\hat{u}_{t-q}+...</script><ul><li>$H_0:\rho_1=…=\rho_k = 0$</li></ul><h4 id="Correcting-for-serial-correlation"><a href="#Correcting-for-serial-correlation" class="headerlink" title="Correcting for serial correlation"></a><strong>Correcting for serial correlation</strong></h4><p><strong>with strictly exog. regressors</strong>:</p><script type="math/tex; mode=display">\begin{align}y_t &= \beta_0+\beta_1x_t+u_t\\\rho y_{t-1} &= \rho\beta_0+\rho\beta_1x_{t-1}+\rho u_{t-1}\\\Rightarrow y_t-\rho y_t &= \beta_0(1-\rho)+\beta_1(x_t-\rho x_{t-1})+u_t-\rho u_{t-1}\end{align}</script><script type="math/tex; mode=display">u_t=\rho u_{t-1}+e_t \Rightarrow u_t-\rho u_{t-1}=e_t</script><p><strong>Newey-West formula</strong>:</p><ul><li>$\hat{\alpha}_t=\hat{r}_t\hat{u}_t$</li></ul><script type="math/tex; mode=display">\hat{v}=\sum_{t=1}^n\hat{a}_t^2+2\sum_{h=1}^g[1-h/(g+1)](\sum_{t=h+1}^n\hat{a}_t\hat{a}_{t-h})</script><ul><li><p>The integer g controls how much serial correlation is allowed:</p><ul><li>g=2: $\hat{v}=\sum_{t=1}^n\hat{a}_t^2+\sum_{t=2}^n\hat{a}_t\hat{a}_{t-1}$</li><li>g=3: <script type="math/tex">\hat{v}=\sum_{t=1}^n\hat{a}_t^2+(4/3)\sum_{t=2}^n\hat{a}_t\hat{a}_{t-1}+(2/3)\sum_{t=3}^n\hat{a}_t\hat{a}_{t-2}</script></li></ul></li><li><p>Serial correlation-robust standard errors:</p><ul><li>$se(\hat{\beta}_j)=[“se(\hat{\beta}_j)/\hat{\sigma}”]^2\sqrt{\hat{v}}$</li></ul></li></ul><h3 id="Quiz-7"><a href="#Quiz-7" class="headerlink" title="Quiz:"></a>Quiz:</h3><ol><li>Which of the following is a strong assumption for static and finite distributed lag models?<ul><li><strong>Dynamic completeness</strong></li><li>$E(y_t|x_t,y_{t-1},x_{t-1},…)=E(y_t|x_t)$</li><li>The problem of serial correlation does not exist in dynamically complete models.</li></ul></li><li><strong>sequentially exogenous</strong><ul><li>$E(u_t|x_t,x_{t-1},…)=E(u_t)=0$</li></ul></li><li>A model with a lagged dependent variable cannot satisfy the strict exogeneity assumption.</li><li>A random walk process is not stationary.</li><li>Covariance stationarity focuses only on the first two moments of a stochastic process.</li><li>Under adaptive expectations, the expected current value of a variable adapts to a recently observed value of the variable.</li><li>A smaller standard error means: <u>a larger t statistic.</u></li><li>Consistency of FGLS requires $u_t$ to be uncorrelated with $x_{t-1}$,$x_t$, and$x_{t+1}$</li><li><strong>Prais-Winsten estimation</strong> is an example of FGLS estimation.<ul><li>Prais-Winsten standard errors account for serial correlation, whereas OLS estimations do not.</li></ul></li><li><strong>Breusch-Godfrey test</strong> can be used to check for second order serial correlation.</li><li>The <strong>SC-robust standard errors</strong> work better after quasi-differencing a time series that is expected to be serially correlated.</li><li>Consistency of feasible generalized least square estimators requires the error term to be uncorrelated with lags of the explanatory variable. Correlation will lead to inconsistent estimates.</li><li>The <strong>Cochrane-Orcutt</strong> and <strong>Prais-Winsten</strong> methods are iterative methods of feasible generalized least square (FGLS) estimation.</li><li>The serial correlation-robust standard errors are typically larger than the usual OLS standard errors when there is serial correlation.</li></ol>]]></content>
    
    
    <categories>
      
      <category>Econometrics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Regression Analysis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【课程】Mathematical Finance</title>
    <link href="/2021/04/25/Mathematical_Finance/"/>
    <url>/2021/04/25/Mathematical_Finance/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于格拉斯哥ECON5020的笔记；</p></blockquote><span id="more"></span><h2 id="General-information"><a href="#General-information" class="headerlink" title="General information"></a>General information</h2><h3 id="Aims"><a href="#Aims" class="headerlink" title="Aims"></a>Aims</h3><p>The general aims of this course are to:</p><ul><li>provide an overall introduction to the type of mathematics used extensively in finance;</li><li>provide a necessary foundation for further study of modern finance in the second semester courses.</li></ul><h3 id="ILOs"><a href="#ILOs" class="headerlink" title="ILOs"></a>ILOs</h3><p>By the end of this course students will be able to:</p><ol><li>Analyse <strong>stochastic processes</strong> closely related to finance and apply stochastic calculus</li><li>Discuss <strong>how well</strong> various stochastic processes function as models in finance and explain the <strong>limitations of</strong> these models</li><li>Deploy techniques of mathematical finance within a <strong>problem solving</strong> context</li><li>Demonstrate skills based on <strong>data interpretation and numeracy</strong></li><li>Demonstrate an ability to construct a focused argument based on <strong>coherent general principles</strong></li><li><strong>Explain</strong> financial issues, problems and solutions.</li></ol><h2 id="Unit-1：Introduction"><a href="#Unit-1：Introduction" class="headerlink" title="Unit 1：Introduction"></a>Unit 1：Introduction</h2><p><strong>Two types of Financial markets:</strong></p><ul><li><p>Exchanges (stock exchange, options exchange, futures exchange, etc.)</p></li><li><p>Over-the-counter (OTC) markets.</p></li></ul><p><strong>Exchanges:</strong> </p><ul><li><p>Equity markets: stocks and shares.</p></li><li><p>Bond market: zero-coupon bonds (ZCBs), government bonds and corporate bonds.</p></li><li><p>Futures market: futures contracts.</p></li><li><p>Foreign exchange (FX) market: foreign currencies, options on foreign currencies.</p></li><li><p>Options market: equity options and interest rate options.</p></li><li><p>Commodity market: oil and metals futures.</p></li></ul><p><strong>OTC Markets:</strong> </p><ul><li><p>Interest rate market (mostly OTC): caps, áoors, swaps and swaptions.</p></li><li><p>Exotic options market: barrier options, lookback options, compound options.</p></li><li><p>Credit market (mostly OTC): credit derivatives such as CDSs and CDOs.</p></li></ul><p><strong>Bear and Bull Markets:</strong> </p><ul><li>In over-supply or under-demand, security prices will generally fall. This is referred to as the bear market.</li><li>In under-supply or over-demand, security prices will generally rise. This is called the bull market.</li><li>Prices that satisfy supply and demand are called to be in equilibrium (at least, in the academic literature).</li></ul><h4 id="Perfect-Markets"><a href="#Perfect-Markets" class="headerlink" title="Perfect Markets:"></a>Perfect Markets:</h4><p><strong>Assumption 1</strong>. Markets are <strong>frictionless</strong>, i.e., no transaction costs, no taxes or other costs and there are no penalties for short selling.</p><p><strong>Assumption 2</strong>. <strong>Infinitely divisible</strong> security prices. It is possible to buy or sell any (also non-integer) quantity of any security.</p><p><strong>Assumption 3</strong>. All traders have <strong>access to the same information</strong>. The Efficient Market Hypothesis (EMH) holds:</p><ul><li>Weak-form: Current security prices reflect all past market prices and data. Technical analysis is of no benefit.</li><li>Semi-strong form: Current security prices reflect all publicly available information. Fundamental analysis is of no benefit.</li><li>Strong form: Current security prices reáect all available information. Inside information is of no benefit.</li></ul><p><strong>Assumption 4</strong>. Markets are assumed to be <strong>arbitrage-free</strong>:</p><ul><li><p>Arbitrage is the guarantee of certain future profit without any current investment. Much of the modern financial theory holds under the assumption that efficient financial markets should forbid such an arbitrage opportunity.</p></li><li><p>It follows from the no-arbitrage principle that if two financial securities have the same pattern of future cash-flows, they should have the same price today. This property is commonly known as the law of one price.</p></li></ul><blockquote><p>Standing assumptions 1. to 4. provide a framework in which we can develop mathematical models for primary securities and propose pricing methods for derivative securities.</p></blockquote><p><strong>European Call Option:</strong> </p><script type="math/tex; mode=display">C_T := max(S_T-K,0) = (S_T-K)^+</script><p><strong>European Call Option:</strong>  </p><script type="math/tex; mode=display">P_T := max(K-S_T,0) = (K-S_T,0)^+</script><p> <strong>Zero-Coupon Bond:</strong></p><script type="math/tex; mode=display">B_t = (1+r)^t\ ,\ B(t,T) = \frac{B_t}{B_T}=(1+r)^{-(T-t)}</script><h2 id="Unit-2：Elementary-Market-Model"><a href="#Unit-2：Elementary-Market-Model" class="headerlink" title="Unit 2：Elementary Market Model"></a>Unit 2：Elementary Market Model</h2><p>Stock price movements are more complicated than indicated by the elementary market model. Hence it cannot be claimed that the elementary model gives a realistic picture of the stock price fluctuations.</p><p><strong>Notation:</strong></p><ul><li>Initial Wealth： $x$</li><li>Riskless Asset：$B$ (Bank account)</li><li>Risky Asset：$S$ (Stock)</li><li>Shares of the stock：$\phi$ </li><li>Sample space：$\Omega = \{\omega_1,\omega_2\}$</li><li>Probability measure：$\mathbb{P}(\omega_1)=p&gt;0$ and $\mathbb{P}(\omega_2)=1-p&gt;0$</li><li>A deterministic interest rate：$r &gt; -1$</li><li>The price of a risky asset at time $t$：$S_t$ ，$S0 &gt; 0$</li><li>$u = \frac{S_1(\omega_1)}{S_0}$ and $d = \frac{S_1(\omega_2)}{S_0}$，$0&lt;d&lt;u$</li><li>Model：$M = (B, S)$</li></ul><h4 id="Trading-Strategy-x-phi"><a href="#Trading-Strategy-x-phi" class="headerlink" title="Trading Strategy: $(x,\phi)$"></a>Trading Strategy: $(x,\phi)$</h4><script type="math/tex; mode=display">V_0(x,\phi):=x=(x-\phi S_0)+\phi S_0</script><script type="math/tex; mode=display">V_1(x,\phi)(\omega_i):=(x-\phi S_0)(1+r)+\phi S_1(\omega_i)\ ,\ i=1,2</script><h4 id="Arbitrage"><a href="#Arbitrage" class="headerlink" title="Arbitrage:"></a>Arbitrage:</h4><p>A trading strategy $(x, \phi)$ in the single-period market model is called an <strong>arbitrage opportunity</strong> if</p><ol><li>$x = 0$, that is, no initial investment is required.</li><li>$V_1(x, \phi) \ge 0$, that is, no risk of losing money.</li><li>$\mathbb{E}_{\mathbb{P}}\{V_1(x,\phi)\}&gt;0$, that is, a strictly positive expected payoff.<ol><li>OR There exists an $\omega_i$ such that $V_1(x,\phi)(\omega_i)&gt;0$.</li></ol></li></ol><p><strong>Arbitrage-free:</strong> if no arbitrage opportunity exists in the model.</p><ul><li>The elementary market model $M = (B, S)$ is arbitrage free <strong>if and only if</strong> $d&lt;1+r&lt;u$.</li></ul><p><strong>Contingent claim:</strong> a trading strategy $(x, \phi)$ obtain $X=h(S_1)=V_1(x,\phi)$.</p><h4 id="Replicationg-Strategy-or-a-hedge"><a href="#Replicationg-Strategy-or-a-hedge" class="headerlink" title="Replicationg Strategy (or a hedge):"></a>Replicationg Strategy (or a hedge):</h4><script type="math/tex; mode=display">\begin{align}(x-\phi S_0)(1+r)+\phi S_1(\omega_1)=h(S_1(\omega_1))\\(x-\phi S_0)(1+r)+\phi S_1(\omega_2)=h(S_1(\omega_2))\end{align}</script><p><strong>Arbitrage Price:</strong> If $(x, \phi)$ is a replicating strategy of a contingent claim then $x$ is called the arbitrage price. $x=\pi_0(X)$</p><p><strong>Delta hedging formula:</strong></p><script type="math/tex; mode=display">\phi = \frac{h(S_1(\omega_1))-h(S_1(\omega_2))}{S_1(\omega_1)-S_1(\omega_2)}=\frac{h(uS_0)-h(dS_0)}{(u-d)S_0}</script><script type="math/tex; mode=display">\tilde{p}:=\frac{1+r-d}{u-d}\in(0,1)\ ,\ \tilde{\mathbb{P}}(\omega_1)=\tilde{p}\ ,\ \tilde{\mathbb{P}}(\omega_2)=1-\tilde{p}</script><script type="math/tex; mode=display">x = \frac{1}{1+r}[\tilde{p}h(S_1(\omega_1))+(1-\tilde{p})h(S_1(\omega_2))]</script><p><strong>Market Completeness:</strong></p><p>All contingent claims (that is, all derivative securities) in thethe elementary market model have replicating strategies, the market described by this model is called <strong>complete</strong>.</p><p><strong>Risk-Neutral Probability Measure:</strong></p><p>A probability measure $\mathbb{Q}$ on the sample space  $\Omega = \{\omega_1,\omega_2\}$ is called a <strong>risk-neutral probability measure</strong> (or an <strong>equivalent martingale measure</strong>) for the market model $M = (B, S)$ if <strong>$\mathbb{Q}$</strong> is equivalent to <strong>$\mathbb{P}$</strong> and the following equality holds</p><script type="math/tex; mode=display">\mathbb{E}_{\mathbb{Q}}(\frac{S_1}{1+r})=S_0</script><ul><li>The risk-neutral probability measure for the market model $M = (B, S)$ is unique and it satisfies <strong>if and only if</strong> $d &lt; 1 + r &lt; u$.</li></ul><p><strong>Risk-Neutral Valuation Formula:</strong></p><script type="math/tex; mode=display">\pi_0(X) = \frac{1}{1+r}\mathbb{E}_{\tilde{\mathbb{P}}}(h(S_1))=\mathbb{E}_{\tilde{\mathbb{P}}}(\frac{X}{1+r})</script><p><strong>Put-Call Parity:</strong></p><script type="math/tex; mode=display">C_T - P_T = S_T - B(t,T)K\ ,\ B(t,T) = (1+r)^{-(T-t)}</script><p><strong>Generalisation of the Elementary Market Model:</strong></p><p>If the sample space $\Omega = \{\omega_1,\omega_2,…,\omega_k\}$ where $k&gt;3$.</p><ul><li><p>Some (but not all) contingent claims can be replicated (that is, are attainable). Hence the model $M = (B, S)$ is <strong>incomplete</strong>.</p></li><li><p>The risk-neutral probability measure $\mathbb{Q}$ for the model $M$ exists if and only if $S_1(\omega_k ) &lt; S_0(1 + r) &lt; S_1(\omega_1)$. It is <strong>not unique</strong>.</p></li></ul><h2 id="Unit-3：Single-Period-Market-Model"><a href="#Unit-3：Single-Period-Market-Model" class="headerlink" title="Unit 3：Single Period Market Model"></a>Unit 3：Single Period Market Model</h2><p><strong>General Single-Period Market Model:</strong></p><p>The main differences between the elementary and general single-period market models are:</p><ul><li><p>The investor is allowed to invest in <strong>several risky securities</strong> instead of only one.</p></li><li><p>The sample set is bigger, that is, there are <strong>more possible states</strong> of the world at time $t = 1$.</p></li></ul><h4 id="Trading-Strategy-x-phi-1-…-phi-n"><a href="#Trading-Strategy-x-phi-1-…-phi-n" class="headerlink" title="Trading Strategy: $(x,\phi^1,…,\phi^n)$"></a>Trading Strategy: $(x,\phi^1,…,\phi^n)$</h4><p><strong>Wealth Process:</strong></p><script type="math/tex; mode=display">V_1(x,\phi^1,...,\phi^n):=(x-\sum_{j=1}^n\phi^jS_0^j)(1+r)+\sum_{j-1}^n\phi^jS_1^j</script><p><strong>Gains Process:</strong></p><script type="math/tex; mode=display">\Delta S_1^j = S_1^j-S_0^j</script><script type="math/tex; mode=display">\begin{aligned}G_1(x,\phi^1,...,\phi^n) : &= V_1(x,\phi^1,...,\phi^n)-V_0(x,\phi^1,...,\phi^n)\\&= (x-\sum_{j=1}^n\phi^jS_0^j)r + \sum_{j=1}^n \phi^j \Delta S_1^j\end{aligned}</script><p><strong>Discounted stock prices:</strong></p><script type="math/tex; mode=display">\hat{S}_0^j := S_0^j = \frac{S_0^j}{B_0},\ \hat{S}_1^j := \frac{S_1^j}{1+r} = \frac{S_1^j}{B_1}</script><p><strong>Discounted wealth process:</strong></p><script type="math/tex; mode=display">\hat{V}_0(x,\phi^1,...,\phi^n) := x</script><script type="math/tex; mode=display">\hat{V}_0(x,\phi^1,...,\phi^n) = x + \sum_{j=1}^n \phi^j(\hat{S}_1^j-\hat{S}_0^j)</script><p><strong>Discounted gains process:</strong></p><script type="math/tex; mode=display">\Delta S_1^j = S_1^j-S_0^j</script><script type="math/tex; mode=display">\hat{G_0}(x,\phi^1,...,\phi^n)=0</script><script type="math/tex; mode=display">\hat{G}_1(x,\phi^1,...,\phi^n) := \sum_{j=1}^n\phi^j\Delta\hat{S}_1^j</script><h4 id="Arbitrage-1"><a href="#Arbitrage-1" class="headerlink" title="Arbitrage:"></a>Arbitrage:</h4><p>A trading strategy $(x,\phi^1,…,\phi^n)$ in a general single-period market model is called an arbitrage opportunity if</p><ol><li>$V_0(x,\phi^1,…,\phi^n) = 0$, </li><li>$V_1(x,\phi^1,…,\phi^n)(\omega_i) \ge 0$, for $ i = 1,2…,k,$</li><li>$\mathbb{E}_{\mathbb{P}}\{V_1(x,\phi^1,…,\phi^n)\}&gt;0$, <ul><li>That is $\sum_{i=1}^k V_1(x,\phi^1,…,\phi^n)(\omega_i)\mathbb{P}(\omega_i)&gt;0$</li><li>OR There exists an $\omega_i$ such that $V_1(x,\phi)(\omega_i)&gt;0$.</li></ul></li></ol><blockquote><p>$\hat{V}(x,\phi^1,…,\phi^n)$ can take the place of $V(x,\phi^1,…,\phi^n)$</p><p>When $V_0(x,\phi^1,…,\phi^n)=0$, $\hat{G}(x,\phi^1,…,\phi^n)$ can take the place of $\hat{V}(x,\phi^1,…,\phi^n)$</p></blockquote><p><strong>Risk-Neutral Probability Measure:</strong></p><p>A probability measure $\mathbb{Q}$ on $\Omega$ is called a <strong>risk-neutral probability measure</strong> for a general single-period market model $M$ if:</p><ul><li>$\mathbb{Q}(\omega_i)&gt;0$ for all $\omega_i \in \Omega$</li><li>$\mathbb{E}_{\mathbb{Q}}(\Delta\hat{S}_1^j) = 0$ for $j = 1,2,…,n$<ul><li>OR $\mathbb{E}_{\mathbb{Q}}(\hat{S}_1^j) = \hat{S}_0^j$</li><li>OR $\mathbb{E}_{\mathbb{Q}}(S_1^j) = (1+r)S_0^j$</li></ul></li></ul><h4 id="Fundamental-Theorem-of-Asset-Pricing-FTAP"><a href="#Fundamental-Theorem-of-Asset-Pricing-FTAP" class="headerlink" title="Fundamental Theorem of Asset Pricing (FTAP)"></a>Fundamental Theorem of Asset Pricing (FTAP)</h4><p>A general single-period market model $M = (B, S^1, . . . , S^n)$ is arbitrage-free if and only if there exists a risk-neutral probability measure for $M$, that is, $\mathbb{M}\ne\empty$.</p><p><a href="https://achlier.github.io/2021/02/13/%E6%95%B0%E7%90%86%E9%87%91%E8%9E%8D%E3%80%90%E7%AC%94%E8%AE%B0_1%E3%80%91/">Proof</a></p><p><strong>Contingent Claim:</strong> is a random variable $X$ defined on $\Omega$ and representing a payoff at the maturity date.</p><p><strong>Replication and Arbitrage Price:</strong> </p><p>A trading strategy $(x,\phi^1,…,\phi^n)$ is called a <strong>replicating strategy</strong> (<strong>a hedging strategy</strong>) for a claim X when $V_1(x,\phi^1,…,\phi^n)=X$. Then the initial wealth is also denoted as $\pi_0(X)$ and it is called the <strong>arbitrage price</strong> of $X$.</p><p><strong>No-Arbitrage Principle:</strong></p><p>Assume that a contingent claim X can be replicated by means of a trading strategy $(x,\phi^1,…,\phi^n)$. Then the unique price of X at 0 consistent with no-arbitrage principle equals $V_0(x,\phi^1,…,\phi^n)=x$.</p><h4 id="Stochastic-Volatility-Model"><a href="#Stochastic-Volatility-Model" class="headerlink" title="Stochastic Volatility Model:"></a>Stochastic Volatility Model:</h4><script type="math/tex; mode=display">\Omega = \{\omega_1,\omega_2,\omega_3,\omega_4\}</script><p> The volatility is defined as</p><script type="math/tex; mode=display">v(\omega_i) = \begin{cases} h\ for\ i = 1,4,\\ l\ for\ i = 2,3. \end{cases}</script><p>We furthermore assume that $0 &lt; l &lt; h &lt; 1$. The stock price $S_1$ is given by</p><script type="math/tex; mode=display">S_1(\omega_i) = \begin{cases} (1+v(\omega_i))S_0\ for\ i = 1,2,\\(1-v(\omega_i))S_0\ for\ i = 3,4. \end{cases}</script><p>It is easy to check that the model is arbitrage-free whenever $1-h&lt;1+r&lt;1+h$.</p><p>We claim that for some contingent claims a replicating strategy does not exist. In that case, we say that a claim is <strong>not attainable</strong>.</p><p>To justify this claim, we consider the <strong>digital call option</strong> $X$ with the payoff.</p><script type="math/tex; mode=display">x = \begin{cases} 1\ if\ S_1>K,\\0\ otherwise,\end{cases}</script><p><strong>We assume</strong> that $(1 + l)S_0 &lt; K &lt; (1 + h)S_0$, and ($\Rightarrow$ lead to not attainable)</p><script type="math/tex; mode=display">X(\omega_i)=\begin{cases} 1\ for\ i = 1,\\0\ otherwise.\end{cases}</script><p>Suppose that $(x, \phi)$ is a replicating strategy for $X$. Equality $V_1(x, \phi) = X$ becomes</p><script type="math/tex; mode=display">(x-\phi S_0)\begin{pmatrix}1+r\\1+r\\1+r\\1+r \end{pmatrix}+\phi\begin{pmatrix}(1+h)S_0\\(1+l)S_0\\(1+h)S_0\\(1+l)S_0 \end{pmatrix}=\begin{pmatrix}1\\0\\0\\0 \end{pmatrix}</script><p>It is easy to see that the above system of equations has <strong>no solution</strong> and thus a digital call is <strong>not an attainable contingent claim</strong> within the framework of the stochastic volatility model.</p><p>The heuristic explanation is that the <strong>randomness generated by the volatility cannot be replicated</strong>, we do not have anough traded assets to replicate volatility, since the volatility itself is not a traded asset in this model.</p><p><strong>Attainable Contingent Claim:</strong></p><p>A contingent claim $X$ is called to be attainable if there exists a replicating strategy for $X$.</p><p><strong>Risk-neutral valuation formula:</strong></p><p>Let $X$ be an attainable contingent claim and let $\mathbb{Q}\in\mathbb{M}$ be any risk-neutral probability measure. Then the arbitrage price of $X$ at $t  =  0$ equals</p><script type="math/tex; mode=display">\pi_0(X)=\frac{1}{1+r}\mathbb{E}_{\mathbb{Q}}(X)</script><p>which shows that risk-neutral probability measures can be used to price attainable contingent claims.</p><h4 id="Pricing-Stochastic-Volatility-Model"><a href="#Pricing-Stochastic-Volatility-Model" class="headerlink" title="Pricing Stochastic Volatility Model:"></a>Pricing Stochastic Volatility Model:</h4><p>The increments of the discounted stock price $\hat{S}$ are represented in the following</p><div class="table-container"><table><thead><tr><th></th><th>$\omega_1$</th><th>$\omega_2$</th><th>$\omega_3$</th><th>$\omega_4$</th></tr></thead><tbody><tr><td>$\Delta\hat{S}_1$</td><td>$hS_0$</td><td>$lS_0$</td><td>$-lS_0$</td><td>$-hS_0$</td></tr></tbody></table></div><p>Recall that a vector $(q1, q2, q3, q4)^{\top}$ must satisfy $\sum_{i=1}^4q_i=1$ holds and $q_i &gt; 0$ for $i = 1, 2, 3, 4$.</p><p>The class $\mathbb{M}$ of all risk-neutral probability measures in our stochastic volatility model is therefore given by</p><script type="math/tex; mode=display">\mathbb{M} = \begin{Bmatrix}\begin{pmatrix}q_1\\q_2\\q_3\\q_4\end{pmatrix}\vline \begin{matrix}q_1>0,q_2>0,q_3>0,\\q_1+q_2+q_3<1,\\l(q_2-q_3)=h(1-(2q_1+q_2+q_3))\end{matrix}\end{Bmatrix}</script><p>Indeed, it suffices to take $q_1\in(0,\frac{1}{2})$ and to set</p><script type="math/tex; mode=display">q_4=q_1,q_2=q_3=\frac{1}{2}-q_1</script><script type="math/tex; mode=display">\mathbb{E}_{\mathbb{Q}}(X)=q_1·1+q_2·0+q_3·0+q_4·0=q_1</script><p><strong>Valuation of Non-Attainable Claims:</strong> still using the risk-neutral probability measure.</p><p><strong>Complete and Incomplete Markets:</strong></p><p>A financial market, described by a model, is called <strong>complete</strong> if for any contingent claim $X$ there <strong>exists a replicating strategy</strong> $(x, \phi) \in \mathbb{R}^{n+1}$ . A market is incomplete when there exists a claim $X$ for which a replicating strategy does not exist.</p><p>$M$ is complete if and <strong>only if</strong> the $k\times(n+1)$ matrix A</p><script type="math/tex; mode=display">A=\begin{pmatrix}1+r&S_1^1(\omega_1)&···&S_1^n(\omega_1)\\1+r&S_1^1(\omega_2)&···&S_1^n(\omega_3)\\···&···&···&···\\1+r&S_1^1(\omega_k)&···&S_1^n(\omega_k)\end{pmatrix}=(A_0,A_1,···,A_n)</script><p>has a full row rank, that is, $rank(A) = k$. </p><h2 id="Unit-4：Modelling-Uncertainty"><a href="#Unit-4：Modelling-Uncertainty" class="headerlink" title="Unit 4：Modelling Uncertainty"></a>Unit 4：Modelling Uncertainty</h2><h4 id="sigma-Field"><a href="#sigma-Field" class="headerlink" title="$\sigma$-Field:"></a>$\sigma$-Field:</h4><p>can be used to describe the amount of information available at a given moment.</p><ul><li>A collection $\mathcal{F}$ of subsets of $\Omega$ is called a $\sigma$<strong>-field</strong> (or a $\sigma$<strong>-algebra</strong>)</li><li><p>Most of the literature uses $\sigma$<strong>-algebra</strong> than​ $\sigma$<strong>-field</strong>.</p></li><li><p>Any set $A \in \mathcal{F}$ is interpreted as an observed <strong>event</strong>.</p></li><li>Let $\mathbb{N} = \{1, 2, . . .\}$  be the set of all natural numbers.</li></ul><p><strong>Probability Measure:</strong> A map $\mathbb{P}:\mathcal{F} \to [0,1]$ is called a <strong>probability measure</strong> if</p><ul><li>$\mathbb{P}(\Omega)=1$</li><li>For any sequence $A_i, i \in \mathbb{N}$ of pairwise disjoint events we have</li></ul><script type="math/tex; mode=display">\mathbb{P}(\bigcup_{i\in\mathbb{N}}A_i)=\sum_{i\in\mathbb{N}}\mathbb{P}(A_i)</script><ul><li>The triplet $(\Omega, \mathcal{F}, \mathbb{P})$ is called a <strong>probability space</strong>.</li></ul><p><strong>Partition:</strong> By a partition of $\Omega$, we mean any collection $P = (A_i)_{i \in l}$of non-empty subsets of $\Omega$. </p><p><strong>F-Measurability:</strong> A map $X : \Omega \to \mathbb{R}$ is said to be <strong>F-measurable</strong> (measurable with respect to algebra F) if the function $\omega \to X (\omega)$ is constant on any subset in the partition corresponding to $\mathcal{F}$. Equivalently, for every real number $x$ the subset $\{\omega\in\Omega:X(\omega)=x\}$ is an element of algebra $\mathcal{F}$. If $X$ is $\mathcal{F}$-measurable then $X$ is called a random variable on $(\Omega,\mathcal{F})$.</p><p><strong>Filtration:</strong> A family $(\mathcal{F}_t)_{0\leq t\leq T}$ of $\sigma$-fields on $\Omega$ is called a <strong>filtration</strong> if $\mathcal{F}_s \subset \mathcal{F}_t$ whenever $s \leq t$. For brevity, we denote $\mathbb{F}=(\mathcal{F}_t)_{0\leq t\leq T}$.</p><p><strong>Stochastic Process:</strong> A stochastic process is a real-valued function $S_n (t, \omega) : \{0, 1, …,T\} \times \Omega \to \mathbb{R}$. For each fixed $\omega \to \Omega$ the function $t \to S_n (t, \omega)$ is called <strong>sample path</strong>. For each fixed $t$ the function $\omega \to S_n (t, \omega)$ is a random variable.</p><p><strong>Conditional Expectation:</strong></p><script type="math/tex; mode=display">\mathbb{E}(X|A)=\sum_xx\mathbb{P}(X=x|A)</script><ul><li>Assume that $\mathcal{G}$ is a $\sigma$-field which is contained in $\mathcal{F}$.</li></ul><script type="math/tex; mode=display">\mathbb{E}_{\mathbb{P}}(X|\mathcal{G})(\omega)=\sum_{i\in l}\frac{1}{\mathbb{P}(A_i)}\mathbb{E}_{\mathbb{P}}(X\mathbb{I}_{A_i})\mathbb{I}_{A_i}</script><script type="math/tex; mode=display">\sum_{\omega\in G}X(\omega)\mathbb{P}(\omega)=\sum_{\omega\in G}\mathbb{E}_{\mathbb{P}}(X|\mathcal{G})(\omega)\mathbb{P}(\omega),\ \forall G \in \mathcal{G}</script><p><strong>Properties of Conditional Expectation:</strong></p><p>Let $(\Omega, \mathcal{F}, \mathbb{P})$ be endowed with sub-$\sigma$-fields $\mathcal{G}$ and $\mathcal{G}_1 \subset \mathcal{G}_2$ of $\mathcal{F}$. Then</p><ul><li><strong>Tower property</strong>: If $X : \Omega\to \mathbb{R}$ is an F-measurable random variable, then</li></ul><script type="math/tex; mode=display">\mathbb{E}_{\mathbb{P}}(X|\mathcal{G}_1) =\mathbb{E}_{\mathbb{P}}(\mathbb{E}_{\mathbb{P}}(X|\mathcal{G}_2)|\mathcal{G}_1)=\mathbb{E}_{\mathbb{P}}(\mathbb{E}_{\mathbb{P}}(X|\mathcal{G}_1)|\mathcal{G}_2)</script><ul><li><strong>Taking out what is known</strong>: If $X : \Omega\to\mathbb{R}$  is a $\mathcal{G}$-measurable random variable and $Y : \Omega\to\mathbb{R}$ is an $\mathcal{F}$-measurable random variable, then</li></ul><script type="math/tex; mode=display">\mathbb{E}_{\mathbb{P}}(XY|\mathcal{G})=X\mathbb{E}_{\mathbb{P}}(Y|\mathcal{G})</script><ul><li><strong>Trivial conditioning</strong>: If $X : \Omega\to\mathbb{R}$ is an $\mathcal{F}$-measurable random variable independent of $\mathcal{G}$, then</li></ul><script type="math/tex; mode=display">\mathbb{E}_{\mathbb{P}}(X|\mathcal{G}) = \mathbb{E}_{\mathbb{P}}(X)</script><p><strong>Martingales:</strong> are stochastic processes representing <strong>fair games</strong>.</p><p>An $\mathbb{F}$-adapted process $X = (X_t)_{0\leq t\leq T}$ on a finite probability space $(\Omega, \mathcal{F}, \mathbb{P})$ is called a <strong>martingale</strong> whenever for all $s &lt; t$ </p><script type="math/tex; mode=display">\mathbb{E}_{\mathbb{P}}(X_t|\mathcal{F}_s) = X_s</script><ul><li><strong>supermartingale:</strong></li></ul><script type="math/tex; mode=display">\mathbb{E}_{\mathbb{P}}(X_t|\mathcal{F}_s) \leq X_s</script><ul><li><strong>submartingale:</strong></li></ul><script type="math/tex; mode=display">\mathbb{E}_{\mathbb{P}}(X_t|\mathcal{F}_s) \ge X_s</script><h2 id="Unit-5：Multi-Period-Market-Model"><a href="#Unit-5：Multi-Period-Market-Model" class="headerlink" title="Unit 5：Multi-Period Market Model"></a>Unit 5：Multi-Period Market Model</h2><p><strong>Trading Strategy:</strong></p><ul><li>$\phi_t=(\phi_t^0,\phi_t^1,…,\phi_t^n)$ for $t=0,1,…,T$</li><li>$\phi_t^0$ is the number of ‘shares’ of the money market account $B$ held at time $t$. </li><li>$\phi_t^j$ is the number of shares of the $j$th stock held at time $t$.</li></ul><p><strong>Wealth process:</strong></p><script type="math/tex; mode=display">V_t(\phi) = \phi_t^0B_t + \sum_{j=1}^n\phi_t^jS_t^j</script><p><strong>Self-Financing Trading Strategy:</strong></p><script type="math/tex; mode=display">\phi_t^0B_{t+1}+\sum_{j=1}^n\phi_t^jS_{t+1}^j=\phi_{t+1}^0B_{t+1}+\sum_{j=1}^n\phi_{t+1}^jS_{t+1}^j</script><p><strong>Gains Process:</strong></p><script type="math/tex; mode=display">G_t(\phi):=V_t(\phi)-V_0(\phi)</script><script type="math/tex; mode=display">G_t(\phi) = \sum_{u=0}^{t-1}\phi_u^0B_{u+1} + \sum_{u=0}^{t-1}\sum_{j=1}^n\phi_u^jS_{u+1}^j</script><p><strong>Increment Processes:</strong></p><script type="math/tex; mode=display">\Delta S_{t+1}^j := S_{t+1}^j-S_t^j</script><script type="math/tex; mode=display">\Delta B_{t+1} := B_{t+1}-B_t=(1+r)^tr=B_tr</script><p><strong>Discounted stock prices:</strong></p><script type="math/tex; mode=display">\hat{S}_t^j := \frac{S_t^j}{B_t}</script><p><strong>Discounted wealth process:</strong></p><script type="math/tex; mode=display">\hat{V}_t(\phi) := \frac{V_t(\phi)}{B_t}</script><script type="math/tex; mode=display">\hat{V}_t(\phi) = \hat{V}_0(\phi)+\sum_{u=0}^{t-1}\sum_{j=1}^n\phi_u^j\Delta \hat{S}_{u+1}^j</script><p><strong>Discounted gains process:</strong></p><script type="math/tex; mode=display">\hat{G}_t(\phi):=\hat{V}_t(\phi)-\hat{V}_0(\phi)</script><script type="math/tex; mode=display">\hat{G}_t(\phi) = \sum_{u=0}^{t-1}\sum_{j=1}^n\phi_u^j\Delta \hat{S}_{u+1}^j</script><p>Hence for every $t = 0, . . . ,T-1 $</p><script type="math/tex; mode=display">\Delta\hat{V}_{t+1}(\phi)=\Delta\hat{G}_{t+1}(\phi)=\sum_{j=1}^n\phi_u^j\Delta \hat{S}_{u+1}^j</script><h4 id="Arbitrage-2"><a href="#Arbitrage-2" class="headerlink" title="Arbitrage:"></a>Arbitrage:</h4><p>A trading strategy $\phi \in \Phi$ is an <strong>arbitrage opportunity</strong> if</p><ul><li>$V_0(\phi)=0,$</li><li>$V_T(\phi)(\omega)\ge 0$ for all $\omega \in \Omega$,</li><li>$V_T(\phi)(\omega)&gt; 0$ for some $\omega \in \Omega$,<ul><li>OR $\mathbb{E}_{\mathbb{P}}(V_T(\phi))&gt;0$</li></ul></li></ul><p><strong>Risk-Neutral Probability Measure:</strong></p><p>A probability measure $\mathbb{Q}$ on $\Omega$ is called a <strong>risk-neutral probability measure</strong> for a multi-period market model $M = (B, S^1, . . . , S^n)$ whenever</p><ul><li>$\mathbb{Q}(\omega)&gt;0$ for all $\omega \in \Omega$</li><li>$\mathbb{E}_{\mathbb{Q}}(\Delta\hat{S}_{t+1}^j|\mathcal{F}_t) = 0$ for $j = 1,2,…,n$ and $t=0,…,T-1$.<ul><li>OR $\mathbb{E}_{\mathbb{Q}}(\hat{S}_{t+1}^j|\mathcal{F}_t) = \hat{S}_t^j$</li></ul></li></ul><p><strong>Fundamental Theorem of Asset Pricing:</strong></p><script type="math/tex; mode=display">\mathrm{Class\ } \mathbb{Q} \mathrm{\ is\ non-empty } \Leftrightarrow \mathrm{Market\ model}\ M\ \mathrm{is\ arbitrage-free}</script><p><strong>Replicating Strategy:</strong></p><p>A <strong>replicating strategy</strong> (or a <strong>hedging strategy</strong>) for a contingent claim $X$ is a trading strategy $\phi\in\Phi$ such that $V_T(\phi) = X$, that is, the terminal wealth of the trading strategy matches the claim’s payoff for all $\omega$.</p><p><strong>Attainable Contingent Claim:</strong> A contingent claim $X$ is called to be attainable if there exists a trading strategy $\phi\in\Phi$, which replicates $X$, i.e., $V_T (\phi) = X$.</p><p><strong>Completeness:</strong> A multi period market model is said to be complete if and only if all contingent claims have replicating strategies.</p><p><strong>Risk-neutral valuation formula:</strong></p><script type="math/tex; mode=display">\pi_t(X)=B_t\mathbb{E}_{\mathbb{Q}}(\frac{X}{B_T}|\mathcal{F}_t)</script><p><strong>Completeness:</strong> Assume that a multi-period market model $M = (B, S^1, . . . , S^n)$ is arbitrage-free. Then $M$ is complete if and only if there is only one risk-neutral probability measure, that is, $\mathbb{M} = \{\tilde{\mathbb{P}}\}$ is a singleton.</p><h2 id="Unit-6：Binomial-Asset-Pricing-Model"><a href="#Unit-6：Binomial-Asset-Pricing-Model" class="headerlink" title="Unit 6：Binomial Asset Pricing Model"></a>Unit 6：Binomial Asset Pricing Model</h2><p>If $d &lt; 1 + r &lt; u$ then the CRR market model $M = (B, S)$ is <strong>arbitrage-free</strong> and <strong>complete</strong>.</p><h4 id="Risk-Neutral-Probability-Measure"><a href="#Risk-Neutral-Probability-Measure" class="headerlink" title="Risk-Neutral Probability Measure:"></a>Risk-Neutral Probability Measure:</h4><p>Assume that $d &lt; 1 + r &lt; u$. Then a probability measure $\tilde{\mathbb{P}}$ on $(\Omega, \mathcal{F}_T )$ is a <strong>risk-neutral probability measure</strong> for the CRR model $M = (B, S)$ with parameters $p, u, d,r$ and time horizon $T$ <strong>if and only if</strong>:</p><ul><li>$X_1,X_2,X_3,…,X_T$ are independent under the probability measure $\tilde{\mathbb{P}}$</li><li>$0&lt;\tilde{p}:=\tilde{\mathbb{P}}$(X_t=1)&lt;1$ for all $t = 1,…,T$</li><li>$\tilde{p}u+(1-\tilde{p})d=(1+r)$</li></ul><p>where $X$ is the Bernoulli process governing the stock price $S$.</p><h4 id="CRR-Call-Option-Pricing-Formula"><a href="#CRR-Call-Option-Pricing-Formula" class="headerlink" title="CRR Call Option Pricing Formula"></a><strong>CRR Call Option Pricing Formula</strong></h4><script type="math/tex; mode=display">C_0=S_0\sum_{k=\hat{k}}^T\begin{pmatrix}T\\k\end{pmatrix}\hat{p}^k(1-\hat{p})^{T-k}-\frac{K}{(1+r)^T}\sum_{k=\hat{k}}^T\begin{pmatrix}T\\k\end{pmatrix}\tilde{p}^k(1-\tilde{p})^{T-k}</script><p>where</p><script type="math/tex; mode=display">\tilde{p}=\frac{1+r-d}{u-d},\ \ \hat{p}=\frac{\tilde{p}u}{1+r}</script><p>and $\hat{k}$ is the smallest integer k such that</p><script type="math/tex; mode=display">klog(\frac{u}{d})>log(\frac{K}{S_0d^T})</script><h4 id="Put-Call-Parity"><a href="#Put-Call-Parity" class="headerlink" title="Put-Call Parity"></a>Put-Call Parity</h4><p>Set $\mathbb{P}(S_T=S_0u^kd^{T-k})=\begin{pmatrix}T\\k\end{pmatrix}p^k(1-p)^{T-k}$</p><script type="math/tex; mode=display">C_t:=S_t\hat{\mathbb{P}}(D|\mathcal{F}_t)-KB(t,T)\tilde{\mathbb{P}}(D|\mathcal{F}_t)</script><script type="math/tex; mode=display">P_t:=-S_t\hat{\mathbb{P}}(\bar{D}|\mathcal{F}_t)+KB(t,T)\tilde{\mathbb{P}}(\bar{D}|\mathcal{F}_t)</script><p>where $D = \{\omega\in\Omega:S_T(\omega)&gt;K\}, \bar{D}=\{\omega\in\Omega:S_T(\omega)&lt;K\}$</p><p>Therefore:</p><script type="math/tex; mode=display">\begin{align}C_t-P_t &=S_t(\hat{\mathbb{P}}(D|\mathcal{F}_t)+\hat{\mathbb{P}}(\bar{D}|\mathcal{F}_t))-KB(t,T)(\tilde{\mathbb{P}}(D|\mathcal{F}_t)+\tilde{\mathbb{P}}(\bar{D}|\mathcal{F}_t))\\&=S_t-KB(t,T)\end{align}</script><p>where $B(t,T)=(1+r)^{-(T-t)}$</p><h4 id="American-Call-Option"><a href="#American-Call-Option" class="headerlink" title="American Call Option"></a>American Call Option</h4><p>By an arbitrage free price of the American call we mean a price process $C_t^a, t \leq T$, such that the extended financial market model - that is, a market with trading in riskless bonds, stocks and the American call option - remains arbitrage-free.</p><script type="math/tex; mode=display">C_t^a=\max_\tau \mathbb{E}_{\tilde{\mathbb{P}}}((1+r)^{-(\tau-t)}(S_\tau-K)^+|\mathcal{F}_t),\ \forall t\leq T</script><script type="math/tex; mode=display">\tau^*_t = min\{u\ge t|(S_u-K)^+\ge C_u^a \}</script><script type="math/tex; mode=display">C_t^a\ge C_t\ge S_t-\frac{K}{(1+r)^{T-t}}>S_t-K</script><p>The result only holds for non-dividend-paying stock.</p><h4 id="American-Put-Option"><a href="#American-Put-Option" class="headerlink" title="American Put Option"></a>American Put Option</h4><script type="math/tex; mode=display">P_t^a=\max_\tau \mathbb{E}_{\tilde{\mathbb{P}}}((1+r)^{-(\tau-t)}(K-S_\tau)^+|\mathcal{F}_t),\ \forall t\leq T</script><script type="math/tex; mode=display">\tau^*_t = min\{u\ge t|(K-S_u)^+\ge P_u^a \}</script><p>The stopping time $\tau^*_t$ is called the rational exercise time of an American put option that is assumed to be still alive at time $t$.</p><p><strong>Dynamic Programming Recursion:</strong></p><p>In the CRR model, the arbitrage pricing of the American call/put option reduces to the following recursive recipe, for $t \leq T-1$, </p><script type="math/tex; mode=display">C_t^a=max\{(S_t-K)^+,(1+r)^{-1}(\tilde{p}C_{t+1}^{au}+(1-\tilde{p})C_{t+1}^{ad})\}</script><script type="math/tex; mode=display">P_t^a=max\{(K-S_t)^+,(1+r)^{-1}(\tilde{p}P_{t+1}^{au}+(1-\tilde{p})P_{t+1}^{ad})\}</script><p>with the terminal condition</p><script type="math/tex; mode=display">C_T^a = (S_T-K)^+\ ,\ P_T^a = (K-S_T)^+</script><p>The quantities $C_{t+1}^{au}/P_{t+1}^{au}$ and $C_{t+1}^{ad}P/_{t+1}^{ad}$ represent the values of the American call/put in the next step corresponding to the upward and downward movements of the stock price starting from a given node on the CRR lattice.</p><h4 id="Derivation-of-u-and-d-from-r-and-sigma"><a href="#Derivation-of-u-and-d-from-r-and-sigma" class="headerlink" title="Derivation of $u$ and $d$ from $r$ and $\sigma$"></a>Derivation of $u$ and $d$ from $r$ and $\sigma$</h4><p><strong>The Cox-Ross-Rubinstein (CRR) parametrisation:</strong> </p><script type="math/tex; mode=display">u = e^{\sigma\sqrt{\Delta t}}\ and\ d=\frac{1}{u}</script><p>Assume that $B_{k\Delta t}=(1+r\Delta t)^k$ for every $k = 0, 1, . . . , n$. Then the risk-neutral probability measure  $\tilde{\mathbb{P}}$ satisfies</p><script type="math/tex; mode=display">\tilde{\mathbb{P}}(S_{t+\Delta t}=S_tu|S_t)=\frac{1+r\Delta t-d}{u-d}=\frac{1}{2}+\frac{r-\frac{\sigma^2}{2}}{2\sigma}\sqrt{\Delta t}+o(\sqrt{\Delta t})</script><blockquote><p>BS-PDE是这个 CRR 求的</p><p>$\tilde{\mathbb{P}}$ 部分可以用泰勒展开约到 $o(\Delta t)$求</p></blockquote><p><strong>The Jarrow-Rudd (JR) parameterisation:</strong></p><script type="math/tex; mode=display">u=e^{(r-\frac{\sigma^2}{2})\Delta t+\sigma\sqrt{\Delta t}}\ and \ d=e^{(r-\frac{\sigma^2}{2})\Delta t-\sigma\sqrt{\Delta t}}</script><p>Let  $B_{k\Delta t}=(1+r\Delta t)^k$ for every $k = 0, 1, . . . , n$. Then the risk-neutral probability measure  $\tilde{\mathbb{P}}$ satisfies</p><script type="math/tex; mode=display">\tilde{\mathbb{P}}(S_{t+\Delta t}=S_tu|S_t)=\frac{1}{2}+o(\sqrt{\Delta t})</script><h4 id="MatlabCode"><a href="#MatlabCode" class="headerlink" title="MatlabCode"></a>MatlabCode</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs matlab">r = <span class="hljs-number">0.008333333</span>; u = <span class="hljs-number">1.095583494</span>; d = <span class="hljs-number">0.912755628</span>; <br>strike = <span class="hljs-number">53</span>; S0 = <span class="hljs-number">50</span>; T = <span class="hljs-number">5</span>; N = T;<br>SS = <span class="hljs-built_in">zeros</span>(N,T);<br>SS(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>) = S0;<br><span class="hljs-keyword">for</span> t = <span class="hljs-number">2</span>:T<br>    <span class="hljs-keyword">for</span> n = <span class="hljs-number">1</span>:t<br>        SS(n,t) = S0*u^(t-n)*d^(n<span class="hljs-number">-1</span>);<br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br>payoff = <span class="hljs-built_in">max</span>((strike-SS(:,T)),<span class="hljs-number">0</span>); <span class="hljs-comment">% put</span><br>rnp = (<span class="hljs-number">1</span>+r-d)/(u-d);<br>PayOffMatr = <span class="hljs-built_in">zeros</span>(N,T);<br>PayOffMatr(:,T) = payoff;<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span>=T<span class="hljs-number">-1</span>:<span class="hljs-number">-1</span>:<span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> k = <span class="hljs-number">1</span>:N<span class="hljs-number">-1</span><br>        PayOffMatr(k,<span class="hljs-built_in">j</span>) = <span class="hljs-built_in">max</span>(((PayOffMatr(k,<span class="hljs-built_in">j</span>+<span class="hljs-number">1</span>)*rnp+ PayOffMatr(k+<span class="hljs-number">1</span>,<span class="hljs-built_in">j</span>+<span class="hljs-number">1</span>)*(<span class="hljs-number">1</span>-rnp))/(<span class="hljs-number">1</span>+r)),(strike-SS(k,<span class="hljs-built_in">j</span>))); <br>        <span class="hljs-comment">% American put</span><br>        <span class="hljs-comment">% PayOffMatr(k,j) = (PayOffMatr(k,j+1)*rnp + PayOffMatr(k+1,j+1)*(1-rnp))/(1+r); </span><br>        <span class="hljs-comment">% European put</span><br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><h2 id="Unit-7：Black-Scholes-Formula"><a href="#Unit-7：Black-Scholes-Formula" class="headerlink" title="Unit 7：Black-Scholes Formula"></a>Unit 7：Black-Scholes Formula</h2><h4 id="Wiener-Process"><a href="#Wiener-Process" class="headerlink" title="Wiener Process:"></a>Wiener Process:</h4><p>A stochastic process $W = (W_t, t \to \mathbb{R}_+)$ on $\Omega$ is called the <strong>Wiener process</strong> if the following conditions hold:</p><ul><li>W(0) = 0</li><li>Sample paths of $W$ are continuous functions.</li><li>For any $0 \leq s &lt; t, W (t) - W(s) \sim N(0,t-s)$ where $N(\mu,\sigma^2)$ denotes the normal distribution with expected value $\mu$ and variance $\sigma^2$.</li><li>The process $W_t$ has independent increments, are mutually independent.</li></ul><p>Let $N$ denote the normal distribution.  Probability distribution function (pdf) or a normally distributed variable is</p><script type="math/tex; mode=display">f(x,\mu,\sigma) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}</script><p>For any $t&gt;0,W_t \sim N(0,t)$ and thus $(\sqrt{t})^{-1}W_t \sim N(0,1)$. The random variable  $W_t$ has the pdf given by</p><script type="math/tex; mode=display">p(t,x)=\frac{1}{\sqrt{2\pi t}}e^{-\frac{x^2}{2t}}</script><p>Hence for any real numbers $a\leq b$</p><script type="math/tex; mode=display">\mathbb{P}(W_t\in[a,b])=\int_a^b\frac{1}{\sqrt{2\pi t}}e^{-\frac{x^2}{2t}}dx = N(\frac{b}{\sqrt{t}})-N(\frac{a}{\sqrt{t}})</script><h4 id="Markov-Property"><a href="#Markov-Property" class="headerlink" title="Markov Property"></a>Markov Property</h4><script type="math/tex; mode=display">\mathbb{P}(W_t\leq x|W_{t_1}=x_1,...,W_{t_n}=x_n)=\mathbb{P}(W_t\leq x|W_{t_n}=x_n)</script><script type="math/tex; mode=display">\mathbb{P}(W_t\leq y|W_s=x) = \int_{-\infty}^yp(t-s,z-x)dz</script><script type="math/tex; mode=display">p(t-s,z-x)=\frac{1}{\sqrt{2\pi (t-s)}}exp(-\frac{(z-x)^2}{2(t-s)})</script><script type="math/tex; mode=display">\mathbb{E}_{\mathbb{P}}(W_t|W_s)=W_s</script><p><strong>Stochastic Differential Equation:</strong></p><script type="math/tex; mode=display">dS_t = rS_tdt + \sigma S_tdW_t</script><p><strong>Geometric Brownian motion:</strong></p><script type="math/tex; mode=display">S_t = S_0 exp(\sigma W_t+(r-\frac{1}{2}\sigma^2)t)</script><p><strong>Random Walk Approximation:</strong></p><p>Let $Y_t^h$ for $t = 0,\Delta t, . . . , $ be a random walk starting at 0.</p><script type="math/tex; mode=display">\mathbb{P}(Y_{t+\Delta t}^h=y+h|Y_t^h=y)=\mathbb{P}(Y_{t+\Delta t}^h=y-h|Y_t^h=y)=0.5</script><script type="math/tex; mode=display">W_t = \lim_{h\to0}Y_t^h</script><p><strong>Approximation of the Stock Price:</strong></p><script type="math/tex; mode=display">S_t = S_s e^{(r-\frac{1}{2}\sigma^2)(t-s)+\sigma (W_t-W_s)}</script><script type="math/tex; mode=display">W_t-W_{t-\Delta t} \approx Y_t-Y_{t-\Delta t}=\pm h = \pm\sqrt{\Delta t}</script><h4 id="Black-Scholes-market-model"><a href="#Black-Scholes-market-model" class="headerlink" title="Black-Scholes market model"></a>Black-Scholes market model</h4><p><strong>Assumptions:</strong></p><ul><li>There are no arbitrage opportunities in the class of trading strategies.</li><li>It is possible to borrow or lend any amount of cash at a constant interest rate $r \ge 0$.</li><li>The stock price dynamics are governed by a geometric Brownian motion.</li><li>It is possible to purchase any amount of a stock and short-selling is allowed.</li><li>The market is frictionless: there are no transaction costs (or any other costs).</li><li>The underlying stock does not pay any dividends.</li></ul><p><strong>Discounted Stock Price:</strong></p><script type="math/tex; mode=display">\mathbb{E}_{\tilde{\mathbb{P}}}(\hat{S}_t|\hat{S}_s,s\leq t)=\hat{S}_t</script><p>Recall $W_t-W_s = Z\sqrt{t-s}$ where $Z \sim N(0,1)$, and thus $e^{z} \sim$ Log-Normal Distribution</p><script type="math/tex; mode=display">\mathbb{E}_{\tilde{\mathbb{P}}}(e^{aZ})=e^{a^2/2}</script><script type="math/tex; mode=display">\mathbb{E}_{\tilde{\mathbb{P}}}(e^{\sigma Z\sqrt{t-s}})=e^{\frac{1}{2}\sigma^2(t-s)}</script><h4 id="The-Black-Scholes-Formula"><a href="#The-Black-Scholes-Formula" class="headerlink" title="The Black-Scholes Formula"></a>The Black-Scholes Formula</h4><script type="math/tex; mode=display">C_t(S_t)=S_tN(d_+(S_t,T-t))-Ke^{-r(T-t)}N(d_{\_}(S_t,T-t))</script><script type="math/tex; mode=display">P_t(S_t)=Ke^{-r(T-t)}N(-d_{\_}(S_t,T-t))-S_tN(-d_+(S_t,T-t))</script><script type="math/tex; mode=display">C_t-P_t = S_T-Ke^{-r(T-t)}</script><p>where</p><script type="math/tex; mode=display">d_\pm(S_t,T-t)=\frac{ln\frac{S_t}{K}+(r\pm\frac{1}{2}\sigma^2)(T-t)}{\sigma\sqrt{(T-t)}}</script><p><a href="https://achlier.github.io/2021/06/16/Black_Scholes_Model%E6%8E%A8%E5%AF%BC_%E8%BF%9B%E9%98%B6%E7%89%88/">推导过程</a></p><h4 id="The-Black-Scholes-PDE"><a href="#The-Black-Scholes-PDE" class="headerlink" title="The Black-Scholes PDE"></a>The Black-Scholes PDE</h4><p>Let the price of the contingent claim at t given the current stock price $S_t = x$ be denoted by $V (t, x)$. Then $V (t, x)$ is the solution of the <strong>Black-Scholes partial differential equation</strong>.</p><script type="math/tex; mode=display">\frac{\partial}{\partial t}V(t,x)+\frac{\sigma^2x^2}{2}\frac{\partial^2}{\partial x^2}V(t,x)+rx\frac{\partial}{\partial x}V(t,x)-rV(t,x)=0</script><p>with the terminal condition $V (T, x) = h(x)$.</p><p><a href="https://achlier.github.io/2021/03/14/Feynman-Kac_To_Black-Scholes-PDE/">推导过程</a></p><h4 id="To-summarise-Black-Scholes-equation-is-written-in-the-form"><a href="#To-summarise-Black-Scholes-equation-is-written-in-the-form" class="headerlink" title="To summarise, Black-Scholes equation is written in the form"></a>To summarise, Black-Scholes equation is written in the form</h4><script type="math/tex; mode=display">\frac{\partial C}{\partial t}+\frac{1}{2}\sigma^2S^2\frac{\partial^2 C}{\partial S^2}+bS\frac{\partial C}{\partial S}-rC=0</script><p>where $b$ is the cost-to-carry:</p><div class="table-container"><table><thead><tr><th>Asset with no dividend</th><th>$b = r$</th></tr></thead><tbody><tr><td><strong>Asset with dividend $D$</strong></td><td>$b = r - D$</td></tr><tr><td><strong>foreign currency with return $r_f$</strong></td><td>$b = r - r_f$</td></tr><tr><td><strong>Commodity with storage cost $q$</strong></td><td>$b = r + q$</td></tr><tr><td><strong>Futures</strong></td><td>$b = 0$</td></tr></tbody></table></div><h2 id="Unit-8：Greeks-Hedging-and-limits-of-Black-Scholes"><a href="#Unit-8：Greeks-Hedging-and-limits-of-Black-Scholes" class="headerlink" title="Unit 8：Greeks, Hedging and limits of Black-Scholes"></a>Unit 8：Greeks, Hedging and limits of Black-Scholes</h2><p><strong>Suppose that the stock price satisfies the Black-Scholes assumption:</strong></p><script type="math/tex; mode=display">\mathbb{E}_{\mathbb{Q}}\{S_t\} = S_0e^{rt}</script><script type="math/tex; mode=display">Var(S_t) = S_0^2e^{2rt}(e^{\sigma^2t}-1)</script><p>Two ideas to estimate $σ$ in the Black-Scholes model:</p><ol><li>Collect some historical stock prices to evaluate the variance $ν$ and then apply equation:</li></ol><script type="math/tex; mode=display">v \approx S_0^2e^{2rt}(e^{\sigma^2t}-1)</script><ol><li>Collect some historical stock prices per $\Delta t$, and define the return $R$. Then compute the variance of $R$ and</li></ol><script type="math/tex; mode=display">\sigma^2 \approx \frac{Var(R)}{\Delta t}</script><p><strong>The leads to Idea 2:</strong></p><p>Since $dlnS_t \approx lnS_{t+\Delta t}-lnS_t$ and</p><script type="math/tex; mode=display">dlnS_t = \frac{dS_t}{S_t} \approx \frac{S_{t+\Delta t}-S_t}{S_t} = R_t</script><p>we  have</p><script type="math/tex; mode=display">R_t \approx lnS_{t+\Delta t}-lnS_t = (r - \frac{\sigma^2}{2})\Delta t +\sigma(W^*(t+\Delta t)- W^*(t)).</script><p>Then $Var(R) = \sigma^2 \Delta t$</p><p><strong>Numerical methods are important in mathematical finance:</strong></p><ul><li><p>The Monte Carlo scheme</p></li><li><p>Bellman equations: The finite difference methods, the Markov chain approach, or the projection methods.</p></li></ul><h4 id="Greeks"><a href="#Greeks" class="headerlink" title="Greeks"></a>Greeks</h4><div class="table-container"><table><thead><tr><th>Delta</th><th>Gamma</th><th>Rho</th><th>Theta</th><th>Vega</th></tr></thead><tbody><tr><td>$\Delta$</td><td>$\Gamma$</td><td>$\rho$</td><td>$\Theta$</td><td>$vega$</td></tr><tr><td>$\frac{\partial C}{\partial S}$</td><td>$\frac{\partial^2 C}{\partial S^2}$</td><td>$\frac{\partial C}{\partial r}$</td><td>$\frac{\partial C}{\partial t}$</td><td>$\frac{\partial C}{\partial \sigma}$</td></tr></tbody></table></div><script type="math/tex; mode=display">\Phi'(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}x^2}</script><script type="math/tex; mode=display">S\Phi'(d_1)-e^{-r(T-t)}K\Phi'(d_2)=0</script><h4 id="Call-option"><a href="#Call-option" class="headerlink" title="Call option"></a>Call option</h4><p><strong>Delta</strong>:  always <strong>positive</strong> : An increase in the asset price increases the likely payoff and therefore the price of the option.</p><script type="math/tex; mode=display">\Delta = \Phi(d_1)</script><p><strong>Gamma</strong>:</p><script type="math/tex; mode=display">\Gamma = \frac{\Phi'(d_1)}{S\sigma\sqrt{T-t}}</script><p><strong>Rho</strong>: always <strong>positive</strong> : An increase in the interest rate is equivalent to lowering the strike price $K$ ( the present price of this future payment decreases with an increase of the interest rate ). This again makes payoff more likely which in e§ect increases the price of the option.</p><script type="math/tex; mode=display">\rho = (T-t)Ke^{-r(T-t)}\Phi(d_2)</script><p><strong>Theta</strong>: always <strong>negative</strong> : The option price is decreasing in time, given that everything else is fixed. This fact can be deduced from a no arbitrage argument.</p><script type="math/tex; mode=display">\Theta = \frac{-S\sigma}{2\sqrt{T-t}}\Phi'(d_1)-rKe^{-r(T-t)}\Phi(d_2)</script><p><strong>Vega</strong>:  always <strong>positive</strong> : This can be understood by considering that an increase in volatility leads to a wider spread of asset prices. However the payoff from a European call option is bounded from below, so that this spread has a more positive effect then a negative effect and is therefore increasing the payoff. The increase in payoff leads to an increase of the price of the option.</p><script type="math/tex; mode=display">vega = S\sqrt{T-t}\Phi'(d_1)</script><p><strong>Implied Volatility:</strong></p><p>The solution of equation is called an implied volatility.</p><script type="math/tex; mode=display">C(t,T, \sigma_{impl},K) = C^{obs}(t)</script><p>We can therefore compute its zeros numerically by applying the Newton method.</p><script type="math/tex; mode=display">\sigma_{k+1} = \sigma_k - \frac{C(t,T, \sigma_k,K)-C^{obs}(t)}{\frac{\partial}{\partial \sigma}C(t,T, \sigma_k,K)}</script><p>one can cure some of these problems by using either local volatility models ( nowadays quite famous among financial institutions ) or stochastic volatility models ( for example the Heston model ).</p>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Financial Mathematics</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【课程】Financial Markets Securities and Derivatives</title>
    <link href="/2021/04/22/Financial_Markets_Securities_and_Derivatives/"/>
    <url>/2021/04/22/Financial_Markets_Securities_and_Derivatives/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于格拉斯哥ECON5009的笔记；</p></blockquote><span id="more"></span><h1 id="General-information"><a href="#General-information" class="headerlink" title="General information"></a>General information</h1><h2 id="Aims"><a href="#Aims" class="headerlink" title="Aims"></a>Aims</h2><p>This course focuses on providing a broad overview of the financial markets with emphasis on <strong>pricing and hedging</strong> of different securities and derivatives. The issues related to trading of different financial instruments are discussed in detail and the <strong>option pricing</strong> methodology is taught using the basic market models such as the <strong>binomial model and Black-Scholes model</strong>. The course also teaches the construction of investment portfolios using interest rates-based instruments such as <strong>bonds and credit default swaps</strong>. The hedging techniques involving the computation of <strong>option Greeks</strong> are also covered. The practical implementation of many of the theoretical concepts is taught in the <strong>computer lab</strong> sessions using the <strong>Monte Carlo method</strong>.</p><h2 id="ILOs"><a href="#ILOs" class="headerlink" title="ILOs"></a>ILOs</h2><p>By the end of this course students will be able to:</p><ol><li>Analyse the <strong>effectiveness</strong> of different models used in the financial markets</li><li>Calculate the <strong>price and hedging portfolios</strong> of popular derivatives traded in the financial markets</li><li>Formulate investment portfolios using <strong>interest-rates based financial instruments</strong>.</li></ol><h1 id="Unit-1-Mean-Variance-Analysis-and-the-Capital-Asset-Pricing-Model"><a href="#Unit-1-Mean-Variance-Analysis-and-the-Capital-Asset-Pricing-Model" class="headerlink" title="Unit 1: Mean Variance Analysis and the Capital Asset Pricing Model"></a>Unit 1: Mean Variance Analysis and the Capital Asset Pricing Model</h1><h2 id="Unit-1-1"><a href="#Unit-1-1" class="headerlink" title="Unit 1.1"></a>Unit 1.1</h2><p><strong>Holding period return (including dividends) </strong>:</p><script type="math/tex; mode=display">R_t = \frac{P_t-P_0+D_t}{P_0}</script><p><strong>Discussion</strong>: why do we choose simple rate of return $\frac{Pt − P0}{P0}$ over log return $ln\frac{Pt}{P0}$ for portfolio analysis?</p><blockquote><p>Because using the simple rate of returns implies that returns are additive</p></blockquote><h2 id="Unit-1-4"><a href="#Unit-1-4" class="headerlink" title="Unit 1.4"></a>Unit 1.4</h2><p><strong>Variance of Portfolio</strong></p><script type="math/tex; mode=display">\sigma_p^2=w_1^2\sigma_1^2+w_2^2\sigma_2^2+2w_1w_2\sigma_{12}</script><p><strong>Covariance</strong></p><script type="math/tex; mode=display">\begin{align}\sigma_{12}&=E((R_{1j}-E(R_1))(R_{2j}-E(R_2)))\\&=E(R_1R_2)-E(R_1)E(R_2)\end{align}</script><blockquote><p> The covariance measures the <strong>comovement</strong> of the returns on two assets.</p></blockquote><h2 id="Unit-1-5"><a href="#Unit-1-5" class="headerlink" title="Unit 1.5"></a>Unit 1.5</h2><p><strong>Correlation Coefficient</strong></p><script type="math/tex; mode=display">\rho_{12}=\frac{\sigma_{12}}{\sigma_1\sigma_2}</script><blockquote><p>The correlation coefficient measures the <strong>direction</strong> and <strong>strength</strong> of the comovement between two variables.</p></blockquote><p><strong>When ρXY = 1</strong></p><script type="math/tex; mode=display">\sigma_p = w_x\sigma_x+w_y\sigma_y</script><p><strong>When ρXY = -1</strong></p><script type="math/tex; mode=display">\begin{align}\sigma_p &= |w_x\sigma_x-w_y\sigma_y|\\\sigma_p &=0,\ when \ w_x = \frac{\sigma_y}{\sigma_x+\sigma_y}\end{align}</script><h2 id="Unit-1-6"><a href="#Unit-1-6" class="headerlink" title="Unit 1.6"></a>Unit 1.6</h2><p><strong>Minimum-risk Portfolio</strong></p><script type="math/tex; mode=display">w_x = \frac{\sigma_y^2-\sigma_x\sigma_y\rho_{xy}}{\sigma_x^2+\sigma_y^2-2\sigma_x\sigma_y\rho_{xy}}</script><p><strong>Maximum Sharp-ratio</strong><a href="https://achlier.github.io/2021/02/13/%E5%9F%BA%E4%BA%8E%E6%96%9C%E7%8E%87%E6%9C%80%E5%A4%A7%E7%9A%84%E8%B5%84%E4%BA%A7%E7%BB%84%E5%90%88%E4%BC%98%E5%8C%96/">（推导步骤）</a></p><script type="math/tex; mode=display">w_x =\frac{(\bar{R}_x-rf)\sigma_y^2-(\bar{R}_y-rf)\rho_{xy}\sigma_x\sigma_y}{(\bar{R}_x-rf)\sigma_y^2+(\bar{R}_y-rf)\sigma_x-(\bar{R}_x-rf+\bar{R}_x-rf)\rho_{xy}\sigma_x\sigma_y}</script><p><strong>Efficient Frontier</strong></p><p>The efficient set consists of the portfolio possibilities curve of all portfolios that lie between the <strong>global minimum-risk portfolio</strong> and the <strong>maximum expected return portfolio</strong>. This set of portfolios is called the <strong>efficient frontier</strong>.</p><h2 id="Unit-1-7"><a href="#Unit-1-7" class="headerlink" title="Unit 1.7"></a>Unit 1.7</h2><p><strong>Effectiveness of Diversification for Large Portfolios (N）</strong></p><script type="math/tex; mode=display">\begin{align}\sigma_p^2 &= \frac{1}{N}\sum_{j=1}^N(\frac{\sigma_j^2}{N})+\frac{N-1}{N}\sum_{j=1}^N\sum_{k=1,k\ne j}^N(\frac{\sigma_{jk}}{N(N-1)})\\&= \frac{1}{N}\bar{\sigma}_j^2+\frac{N-1}{N}\bar{\sigma}_{jk}\end{align}</script><p>Can be divided into:</p><ol><li><p><strong>Diversifiable risk / Unsystematic risk</strong></p><script type="math/tex; mode=display">lim_{N\to \infty}(\frac{1}{N}\bar{\sigma}_j^2)=0</script></li><li><p><strong>Undiversifiable risk / Systematic risk</strong></p><script type="math/tex; mode=display">lim_{N\to \infty}(\frac{N-1}{N}\bar{\sigma}_{jk})=\bar{\sigma}_{jk}</script></li></ol><h2 id="Unit-1-8"><a href="#Unit-1-8" class="headerlink" title="Unit 1.8"></a>Unit 1.8</h2><p><strong>Problems of Short Sales</strong></p><ol><li><p><strong>Unlimited losses</strong>: the loss of a short sale <strong>can</strong> theoretically be infinite because the stock price can theoretically <strong>rise to infinity</strong>.</p></li><li><p><strong>Short squeeze</strong>: the price of a heavily shorted stock <strong>suddenly increases sharply</strong>, forcing the short sellers to close out their short position.</p></li><li><strong>Not working in the long run</strong>: historically, over long period of time, stock prices have <strong>positive drift</strong>.</li><li><strong>Costs associated with margin trading</strong>: the minimum maintenance requirement must be met. As stock price increases, the value of <strong>margin call</strong> might be too high to be fulfilled by the investor.</li></ol><blockquote><p><strong>Initial margin requirements</strong> : the Federal Reserve Board requires all short sale accounts to have 150% of the value of the short sale at the time the sale is initiated.</p><p><strong>Maintenance margin requirements</strong> :  it is 100% of market value of short sale plus at least 25% of total market value of securities in the margin account.</p></blockquote><h2 id="Unit-1-9"><a href="#Unit-1-9" class="headerlink" title="Unit 1.9"></a>Unit 1.9</h2><p><strong>Other Methods to Reduce Short Sales Risk</strong></p><ol><li><p><strong>Stop buy order</strong>: when the increasing stock price reaches the execution price, the order is executed to limit the loss.</p></li><li><p><strong>Portfolio of two assets</strong>: short selling the asset with low return and use the proceeds to purchase the asset with high return.</p></li><li><p><strong>Out-of-the-money call option</strong>: if underlying stock price increases, the investor can exercise the option and buy the stock at the strike price.</p></li></ol><h2 id="Unit-1-10"><a href="#Unit-1-10" class="headerlink" title="Unit 1.10"></a>Unit 1.10</h2><p><strong>The Efficient Frontier with Riskless Lending and Borrowing</strong></p><p>The expected return on the combination of riskless asset <em>F</em> and risky portfolio <em>A</em> is:</p><script type="math/tex; mode=display">E(R_C)=w_FR_F+w_AE(R_A)</script><p>combinate with:</p><script type="math/tex; mode=display">\begin{align}\sigma_C &= (w_F^2\sigma_{R_F}^2+w_A^2\sigma_A^2+2w_Aw_F\rho_{AF}\sigma_A\sigma_{R_F})^{\frac{1}{2}}\\&= w_A\sigma_A\end{align}</script><p>Therefore, we have:</p><script type="math/tex; mode=display">E(R_C)=R_F+(\frac{E(R_A)-R_F}{\sigma_A})\sigma_C</script><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic1-1.jpg" alt></p><h2 id="Unit-1-13"><a href="#Unit-1-13" class="headerlink" title="Unit 1.13"></a>Unit 1.13</h2><p><strong>The Single-Index Model</strong> </p><script type="math/tex; mode=display">R_i=a_i+\beta_iR_m</script><blockquote><p>a is the component of security’s return that is independent of the return of the market index.</p><p>β is a constant that measures <strong>how sensitive a security’s return is to the return on the market index</strong>. </p><p>β &gt; 1: stock is riskier than the market.</p></blockquote><p>we assume that:</p><script type="math/tex; mode=display">a_i = \alpha_i+e_i</script><p>Therefore, we have:</p><script type="math/tex; mode=display">R_i=\alpha_i+\beta_iR_m+e_i</script><p> <strong>Variance of Single-Index Model</strong></p><script type="math/tex; mode=display">\sigma_p^2=\sum_{i=1}^Nw_i^2\beta_i^2\sigma_m^2+\sum_{i=1}^N\sum_{j=1,i\ne j}^Nw_iw_j\beta_i\beta_j\sigma_m^2+\sum_{i=1}^Nw_i^2\sigma_{ei}^2</script><blockquote><p>With N Portfolios, This is a total of merely 3<em>N</em> + 2 estimates. By contrast, when analysing portfolio without the Single-Index Model, the total number of estimates is 2<em>N</em> + <em>N</em>(<em>N</em> − 1)/2.</p></blockquote><h2 id="Unit-1-14"><a href="#Unit-1-14" class="headerlink" title="Unit 1.14"></a>Unit 1.14</h2><p><strong>Variance can be directly written as</strong> :</p><script type="math/tex; mode=display">\sigma_p^2=\beta_p^2\sigma_m^2+\sum_{i=1}^Nw_i^2{\sigma_{ei}^2}</script><p>assuming $w_i = 1/N$</p><script type="math/tex; mode=display">\sigma_p^2=\beta_p^2\sigma_m^2+\frac{1}{N}\bar{\sigma}_{ei}^2</script><p>Can be divided into:</p><ol><li><p><strong>Diversifiable risk / Unsystematic risk / nonmarket risk</strong></p><script type="math/tex; mode=display">lim_{N\to \infty}(\frac{1}{N}\bar{\sigma}_{ei}^2)=0</script></li><li><p><strong>Undiversifiable risk / Systematic risk / market risk</strong></p><script type="math/tex; mode=display">\beta_p^2\sigma_m^2</script></li></ol><h2 id="Unit-1-16"><a href="#Unit-1-16" class="headerlink" title="Unit 1.16"></a>Unit 1.16</h2><p><strong>Capital Asset Pricing Model (CAPM)</strong></p><script type="math/tex; mode=display">E(R_i)=R_F+\beta_i(E(R_M)-R_F)</script><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic1-2.jpg" alt></p><blockquote><p>The higher the beta is for any security, the higher must be its equilibrium return.</p><p>This arbitrage would continue until all investments converged to the straight line. As a result, all investments and all portfolios of investments must lie along a straight line in expected return-beta space. This straight line is called <strong>the security market line</strong>. </p></blockquote><h2 id="Unit-1-21"><a href="#Unit-1-21" class="headerlink" title="Unit 1.21"></a>Unit 1.21</h2><p>From the results of the Single-Index Model:</p><script type="math/tex; mode=display">\sigma_{iM} = \beta_i\beta_M\sigma_{M}^2 \to \beta_i = \frac{\sigma_{iM}}{\sigma_M^2}</script><p>replace the CAPM model:</p><script type="math/tex; mode=display">E(R_i)=R_F+(\frac{E(R_M)-R_F}{\sigma_M})\frac{\sigma_{iM}}{\sigma_M}</script><p>we can also get that:</p><script type="math/tex; mode=display">\sigma_i = \frac{\sigma_{iM}}{\sigma_M}</script><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic1-3.jpg" alt></p><blockquote><p> The straight line $R_F-M$ is referred to as <strong>the capital market line</strong>.</p><p>Where $\frac{E(R_M)-R_F}{\sigma_M}$ is referred to as <strong>the market price of risk</strong> for efficient portfolios.</p><p>$\frac{\sigma_{iM}}{\sigma_M}$ is the measure of how the risk on a security affects the risk of the market portfolio.</p></blockquote><h1 id="Unit-2-Forwards-Futures-and-Options"><a href="#Unit-2-Forwards-Futures-and-Options" class="headerlink" title="Unit 2: Forwards, Futures and Options"></a>Unit 2: Forwards, Futures and Options</h1><h2 id="Unit-2-1"><a href="#Unit-2-1" class="headerlink" title="Unit 2.1"></a>Unit 2.1</h2><h4 id="Forward-Contracts"><a href="#Forward-Contracts" class="headerlink" title="Forward Contracts"></a>Forward Contracts</h4><p>A forward contract is an <strong>agreement</strong>, i.e. a binding commitment, to buy or sell an asset at a certain future time for a certain price. A forward contract is traded in the <strong>over-the-counter market</strong>. </p><h4 id="Futures-Contracts"><a href="#Futures-Contracts" class="headerlink" title="Futures Contracts"></a>Futures Contracts</h4><p>A futures contract is an <strong>agreement</strong> between two parties to buy or sell an asset at a certain time in the future for a certain price <strong>with (daily) clearing</strong> through a margin account. Unlike forward contracts, futures contracts are normally <strong>traded on an exchange</strong>. This suggests that, the exchange specifies certain standardized features of the contract</p><h4 id="Margin-Accounts"><a href="#Margin-Accounts" class="headerlink" title="Margin Accounts"></a>Margin Accounts</h4><p>One of the key roles of the exchange is to use <strong>margin accounts</strong> to organize trading so that contract defaults are avoided. The extra funds deposited are known as a variation margin. If the investor does not provide the variation margin, the broker <strong>closes out the position by entering into the opposite trade to the original one</strong>.</p><div class="table-container"><table><thead><tr><th>Forward</th><th>Futures</th></tr></thead><tbody><tr><td>traded in the OTC market</td><td>traded on the exchange</td></tr><tr><td>not standardized</td><td>standardized contract</td></tr><tr><td>usually one specified delivery date</td><td>range of delivery dates</td></tr><tr><td>settled at the expiry</td><td>settled daily</td></tr><tr><td>usually leading to delivery or cash settlement</td><td>usually closed out prior to maturity</td></tr><tr><td>some credit risk</td><td>virtually no credit risk</td></tr></tbody></table></div><h2 id="Unit-2-2"><a href="#Unit-2-2" class="headerlink" title="Unit 2.2"></a>Unit 2.2</h2><p><strong>Continuous Compounding</strong></p><script type="math/tex; mode=display">lim_{m\to \infty}(1+\frac{R_m}{m})^{m}=e^{R_c}</script><script type="math/tex; mode=display">R_c=m·ln(1+\frac{R_m}{m})</script><p>where $R_c$ denotes the annualized continuous-compounding yield; <em>m</em> is the compounding frequency; $R_m$  represents the annualized discrete-compounding yield.</p><p><strong>Forward Price</strong> : $F_0=S_0e^{rT}$</p><p><strong>Forward Price with coupon payment</strong> : $F_0=(S_0-G)e^{rT}$</p><p><strong>Forward Price with  Yield  (continued)</strong> : $F_0=S_0e^{(r-q)T}$</p><p><strong>The value of forward contract</strong> : $f_t=(F_t-K)e^{-(T-t)}$</p><h2 id="Unit-2-4"><a href="#Unit-2-4" class="headerlink" title="Unit 2.4"></a>Unit 2.4</h2><p><strong>Future price</strong> :</p><ul><li>if the interest rate rises, then the spot price is likely rising as well <em>⇒</em> due to the daily setllement in the futures contract, money can be released from the margin account and be invested at a higher interest rate</li><li>if the interest rate falls, then the spot price is likely falling as well <em>⇒</em> due to the daily settlement, money needs to be paid into the margin account, but this money can now be borrowed at a lower interest rate</li><li>relative to a forward contract, which is not affect by any of this, the futures contract benefits from interest rate movements, and this raises the futures price as compared to the forward price</li></ul><h2 id="Unit-2-6"><a href="#Unit-2-6" class="headerlink" title="Unit 2.6"></a>Unit 2.6</h2><h4 id="Hedging"><a href="#Hedging" class="headerlink" title="Hedging"></a>Hedging</h4><p><strong>Short Hedges</strong>: a short hedge is a hedge that involves taking a <strong>short position</strong> in futures contracts.</p><ul><li>if the exposure is such that the company gains when the price of the asset increases and loses when the price of the asset decreases, a short hedge is appropriate.</li></ul><p><strong>Long Hedges</strong>: a long hedge is a hedge that involves taking a long position in futures contracts.</p><ul><li>if the exposure is such that the company gains when the price of the asset decreases and loses when the price of the asset increases, a long hedge is appropriate.</li></ul><p><strong>Cross Hedging</strong>: the asset underlying the futures contract is different from the asset whose price is being hedged. </p><ul><li>an airline may want to hedge the fluctuation in the price of jet fuel. Because futures on jet fuel are not actively traded, the airline could use heating oil futures contracts to hedge its exposure to jet fuel price fluctuation.</li></ul><p><strong>Hedge Ratio</strong>: the ratio of the size of the position taken in futures contracts relative to the size of the exposure.</p><ul><li>When cross hedging occurs, the hedger needs to choose a value for the hedge ratio such that <strong>the variance of the value of the hedged position is minimised</strong>. This value of the hedge ratio is referred to as  <strong>the minimum variance hedge ratio</strong>.</li></ul><h4 id="Minimum-Variance-Hedge-Ratio"><a href="#Minimum-Variance-Hedge-Ratio" class="headerlink" title="Minimum Variance Hedge Ratio"></a>Minimum Variance Hedge Ratio</h4><p>Consider the case where the investor takes a long position in asset <em>S</em> and a</p><p>short position in the futures contract <em>F</em>. </p><ul><li>∆S: change in spot price during a period of time equal to the life of the hedge;</li><li>∆F: change in futures price during a period of time equal to the life of the hedge;</li><li>$σ_S$: standard deviation of ∆S; </li><li>$σ_F$: standard deviation of ∆F; </li><li>$ρ_{SF}$: correlation between ∆S and ∆F; </li><li>h: minimum variance hedge ratio;</li><li>∆U = ∆S - h∆F: <strong>hedged position</strong>;</li></ul><p>In order to find the min Var(∆U)</p><script type="math/tex; mode=display">\begin{align}Var(∆U) &= Var(∆S - h∆F)\\&= \sigma^2_S+h^2\sigma_F^2-2h\rho_{SF}\sigma_S\sigma_F\end{align}</script><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic2-1.jpg" alt></p><script type="math/tex; mode=display">\begin{align}\frac{\partial Var(∆U)}{\partial h} = 2h\sigma_F^2-2\rho_{SF}\sigma_S\sigma_F &= 0\\\rho_{SF}\frac{\sigma_S}{\sigma_F} &= h\end{align}</script><blockquote><p>The hedge ratio is <strong>the slope coeffficient obtained from a linear regression of</strong> ∆<em>S</em> <strong>against</strong> ∆<em>F</em>.</p></blockquote><h2 id="Unit-2-7"><a href="#Unit-2-7" class="headerlink" title="Unit 2.7"></a>Unit 2.7</h2><h4 id="Optimal-Number-of-Contracts"><a href="#Optimal-Number-of-Contracts" class="headerlink" title="Optimal Number of Contracts"></a>Optimal Number of Contracts</h4><ul><li>$N^*$: optimal number of futures contracts used for hedging;</li><li>$Q_A$: size of position being hedged; e.g. number of units of assets</li><li>$Q_F$: size of one futures contract; i.e the number of units of the underlying one future contract refers to</li></ul><script type="math/tex; mode=display">N^* = \frac{hQ_A}{Q_F}</script><h4 id="Using-Stock-Index-Futures-to-Hedge-Equity-Portfolios"><a href="#Using-Stock-Index-Futures-to-Hedge-Equity-Portfolios" class="headerlink" title="Using Stock Index Futures to Hedge Equity Portfolios"></a>Using Stock Index Futures to Hedge Equity Portfolios</h4><ul><li>$V_A$: current value of the equity portfolio;</li><li>$V_F$: current nominal value of one futures contract (i.e. the futures price times the contract size).</li><li>each futures contract is on 250 times the index value.</li></ul><p><strong>If the portfolio mirrors the index</strong> : i.e. ρ<em>AF</em> = 1 and σ<em>A</em> = σ<em>F</em>, the optimal hedge ratio <em>h</em> could be assumed to be 1.</p><script type="math/tex; mode=display">N^* = \frac{V_A}{V_F}</script><p><strong>In the case that the portfolio does not mirror the stock index</strong></p><script type="math/tex; mode=display">N^* = \beta \frac{V_A}{V_F}</script><h4 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h4><div class="table-container"><table><thead><tr><th></th><th>T0</th><th>3 months</th></tr></thead><tbody><tr><td>Value of S&amp;P 500 Index</td><td>1000</td><td>900</td></tr><tr><td>S&amp;P 500 futures price (short h)</td><td>1010</td><td>902</td></tr><tr><td>Value of the portfolio (long)</td><td>5050000</td><td>4286187</td></tr><tr><td>Risk-free interest rate</td><td>4% per annum</td><td>-</td></tr><tr><td>Dividend yield on index</td><td>1% per annum</td><td>-</td></tr><tr><td>Beta of the portfolio</td><td>1.5</td><td>-</td></tr></tbody></table></div><script type="math/tex; mode=display">N^* = 1.5 \times \frac{5050000}{250 \times 1010}=30</script><p>Gain form short:</p><script type="math/tex; mode=display">30 \times (1010 - 902)\times 250 = 810000</script><p>Loss on stock index: $|(900-1000)/1000|=10\%$</p><p>Taking the dividends into accont: $-10\%+1\% \times 3/12 = -9.75\%$</p><p>The expected return on the portfolio can be computed as:$1\%+1.5\times(-9.75\%-1\%)=-15.125\%$</p><p>The expected value of the portfolio at the end of the 3 months: $5050000\times(1−15.125\%) = 4286187$</p><p>Thus, the expected value of the hedger’s position:  $4286187 + 810000 = 5096187$</p><h2 id="Unit-2-8"><a href="#Unit-2-8" class="headerlink" title="Unit 2.8"></a>Unit 2.8</h2><h4 id="Option-Contract"><a href="#Option-Contract" class="headerlink" title="Option Contract"></a>Option Contract</h4><p>Option vs. Forward and Futures: it should be noted that an option gives the holder <strong>the right, but not the obligation</strong>, to buy or sell an asset.</p><p><strong>Option Styles</strong>: depending on when the options can be exercised, options can be classified into European options and American options:</p><ul><li><p><strong>European options</strong>: European options can be exercised <strong>only on the expiration date itself</strong>. </p></li><li><p><strong>American options</strong>: American options can be exercised <strong>at any time up to the expiration date</strong>.</p></li></ul><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic2-2.jpg" alt></p><p>When the investor <strong>writes a call option</strong>, the investor’s position can either be covered or naked:</p><ul><li><p><strong>Covered Call</strong>: a short position in a call option on an asset combined with a long position in the underlying asset.</p></li><li><p><strong>Naked Call</strong>: a short position in a call option that is not combined with a long position in the underlying asset.</p></li></ul><p><strong>Intrinsic Value</strong>: </p><ul><li><p>intrinsic value of <strong>call</strong> option: $max(S_t − K, 0)$; </p></li><li><p>intrinsic value of <strong>put</strong> option: $max(K − S_t, 0)$;</p></li></ul><p><strong>Moneyness</strong>: </p><ul><li><p><strong>Call</strong> Option:</p><ul><li><em>S</em> &gt; <em>K</em>: in the money</li><li><em>S</em> = <em>K</em>: at the money</li><li><em>S</em> &lt; <em>K</em>: out of the money</li></ul></li><li><p><strong>Put</strong> Option:</p><ul><li><em>S</em> &lt; <em>K</em>: in the money</li><li><em>S</em> = <em>K</em>: at the money</li><li><em>S</em> &gt; <em>K</em>: out of the money</li></ul></li><li>an option will be exercised only when it is in the money</li></ul><h2 id="Unit-2-9"><a href="#Unit-2-9" class="headerlink" title="Unit 2.9"></a>Unit 2.9</h2><p><strong>Put-Call Parity</strong> :</p><script type="math/tex; mode=display">C + Ke^{−rT} = P + S_0</script><script type="math/tex; mode=display">C − P = S_0 − Ke^{−rT} = (F_0 − K)e^{−rT} = f</script><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic2-3.jpg" alt></p><h2 id="Unit-2-10"><a href="#Unit-2-10" class="headerlink" title="Unit 2.10"></a>Unit 2.10</h2><h4 id="Trading-an-Option-and-the-Underlying-Asset"><a href="#Trading-an-Option-and-the-Underlying-Asset" class="headerlink" title="Trading an Option and the Underlying Asset :"></a>Trading an Option and the Underlying Asset :</h4><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic2-4.jpg" alt></p><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic2-5.jpg" alt></p><p><strong>Bull Spread</strong></p><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic2-6.jpg" alt></p><p>a bull spread limits both the upside profit potential and downside risk. The investor gives up some upside potential from the call with low <em>K</em> by selling another call with high <em>K</em>. In return for giving up the upside potential, the investor receives the up-front payment of the call with high <em>K</em>.</p><p><strong>Bear Spread</strong></p><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic2-7.jpg" alt></p><p>the bear spread limits both the upside profit potential and the downside risk. The investor gives up some of the upside profit potential by selling a put with a lower <em>K</em>. In return for the profit given up, the investor receives the up-front payment of the option sold.</p><p><strong>Butterfly Spread</strong></p><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic2-8.jpg" alt></p><p>a butterfly spread leads to a profit if the stock price stays close to <em>K</em>2, but yields a small loss if there is a large stock price movement in either direction. Thus, a butterfly is appropriate when the investor expects that large stock price movement is unlikely</p><p><strong>Straddle</strong></p><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic2-9.jpg" alt></p><p><strong>Strangle</strong></p><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic2-10.jpg" alt></p><p>a straddle is usually purchased at the money by someone who expects the underlying asset to either rise or fall, but not to remain at the same level (i.e. bottom straddle or straddle purchase). For instance, a straddle could be bought just before the announcement of a company’s major news, on the announcement the company stock price could suddenly move either up or down. </p><p><strong>Strangle</strong> &amp; <strong>Strangle</strong> are <strong>volatility trades</strong>. Because of the relationship between the price of an option and the volatility of the asset, the investor can speculate on the direction of volatility.</p><h1 id="Unit-3-Option-Pricing-Binomial-Model-Black-Scholes-Model-Volatility-and-Greeks"><a href="#Unit-3-Option-Pricing-Binomial-Model-Black-Scholes-Model-Volatility-and-Greeks" class="headerlink" title="Unit 3: Option Pricing: Binomial Model, Black Scholes Model, Volatility and Greeks"></a>Unit 3: Option Pricing: Binomial Model, Black Scholes Model, Volatility and Greeks</h1><h2 id="Unit-3-2"><a href="#Unit-3-2" class="headerlink" title="Unit 3.2"></a>Unit 3.2</h2><p><strong>The option price derived from the risk-neutral valuation</strong></p><p>In order to create a risk-free portfolio</p><script type="math/tex; mode=display">\Delta = \frac{f_u-f_d}{S_0u-S_0d} , \ p = \frac{e^{rT}-d}{u-d}</script><p> The present value of the portfolio is</p><script type="math/tex; mode=display">(S_0u\Delta-f_u)e^{-rT} \ or \ (pf_u+(1-p)f_d)e^{-rT}</script><p> The cost of setting up the portfolio is</p><script type="math/tex; mode=display">S_0\Delta -f</script><blockquote><p>Equation does not involve the real-world probability of stock pricesmoving up or down. Only the <strong>risk-neutral probability</strong> <em>p</em> is relevant in the binomial model.</p></blockquote><h2 id="Unit-3-5"><a href="#Unit-3-5" class="headerlink" title="Unit 3.5"></a>Unit 3.5</h2><p><strong>Symmetric Random Walk ( process $M_k$)</strong></p><script type="math/tex; mode=display">X_j = \begin{cases}1 &\mbox{if }w_j = H, \\ -1 &\mbox{if }w_j = T,\end{cases}</script><script type="math/tex; mode=display">M_0 = 0 \ , \ M_k = \sum_{j=1}^kX_j, \ k = 1,2,...</script><script type="math/tex; mode=display">Var(M_{k_{i+1}}-M_{k_i}) = k_{i+1}-k_i</script><p><strong>Brownian Motion W(t)</strong> </p><script type="math/tex; mode=display">W^{(n)}(t) = \frac{1}{\sqrt{n}}M_{nt}\ ,\ W(t) \sim \epsilon \sqrt{t}\ , \ \epsilon \sim N(0,1)</script><h2 id="Unit-3-6"><a href="#Unit-3-6" class="headerlink" title="Unit 3.6"></a>Unit 3.6</h2><h4 id="Geometric-Brownian-motion-GBM"><a href="#Geometric-Brownian-motion-GBM" class="headerlink" title="Geometric Brownian motion (GBM)"></a>Geometric Brownian motion (GBM)</h4><p>A stochastic process $S_t$ is said to follow a <strong>geometric Brownian motion (GBM)</strong> if it satisfies the following <strong>stochastic differential equation (SDE)</strong>:</p><script type="math/tex; mode=display">dS_t = \mu S_tdt + \sigma S_tdW_t</script><p><strong>Ito’s lemma for GBM</strong>:</p><script type="math/tex; mode=display">dG = (\frac{\partial G}{\partial S}\mu S+\frac{\partial G}{\partial t}+\frac{1}{2}\frac{\partial^2 G}{\partial S^2}\sigma^2S^2)dt+\frac{\partial G}{\partial S}\sigma SdW</script><p>Let $G = lnS$, we have:</p><script type="math/tex; mode=display">\frac{\partial G}{\partial S} = \frac{1}{S},\ \frac{\partial^2 G}{\partial S^2} = -\frac{1}{S^2},\ \frac{\partial G}{\partial t} = 0</script><p>we obtain:</p><script type="math/tex; mode=display">dlnS_t = (\mu - \frac{\sigma^2}{2})dt + \sigma dW_t</script><p>Taking the exponential:</p><script type="math/tex; mode=display">S_t = S_0exp((\mu - \frac{\sigma^2}{2})t+\sigma W_t)</script><p>The solution to the GBM implies that:</p><script type="math/tex; mode=display">lnS_T \sim N(lnS_0 + (\mu - \frac{\sigma^2}{2})T, \sigma^2T)</script><p>or：</p><script type="math/tex; mode=display">ln\frac{S_T}{S_0} \sim N((\mu - \frac{\sigma^2}{2})T, \sigma^2T)</script><h2 id="Unit-3-7"><a href="#Unit-3-7" class="headerlink" title="Unit 3.7"></a>Unit 3.7</h2><h4 id="Deriving-the-BSM-Partial-Differential-Equation"><a href="#Deriving-the-BSM-Partial-Differential-Equation" class="headerlink" title="Deriving the BSM Partial Differential Equation"></a>Deriving the BSM Partial Differential Equation</h4><p> Assuming $\delta$ is the number of shares needed to hedge one call option.</p><script type="math/tex; mode=display">\delta \sigma S \Delta W = \frac{\partial f}{\partial S}\sigma S \Delta W</script><p>where $\delta = \frac{\partial f}{\partial S}$ is called the <strong>delta</strong> of the option.</p><p>Define $\Pi$ as the value of this portfolio, therefore:</p><script type="math/tex; mode=display">\Pi = -f + \frac{\partial f}{\partial S}S</script><p>The change in the value of portfolio during time interval ∆<em>t</em> is given by:</p><script type="math/tex; mode=display">\Delta\Pi = -\Delta f +\frac{\partial f}{\partial S}\Delta S</script><p>yields:</p><script type="math/tex; mode=display">\begin{align}\Delta\Pi &= -(\frac{\partial f}{\partial S}\mu S+\frac{\partial f}{\partial t}+\frac{1}{2}\frac{\partial^2 f}{\partial S^2}\sigma^2S^2)\Delta t-\frac{\partial f}{\partial S}\sigma S\Delta W+\frac{\partial f}{\partial S}(\mu S\Delta t + \sigma S\Delta W)\\&= (-\frac{\partial f}{\partial t}-\frac{1}{2}\frac{\partial^2 f}{\partial S^2}\sigma^2S^2)\Delta t\end{align}</script><p><strong>In the absence of arbitrage opportunities, the risk-free portfolio must instantaneously earn the risk-free rate</strong> <em>r</em>. Otherwise, there would be arbitrage opportunities. Therefore, we have:</p><script type="math/tex; mode=display">\Delta \Pi = r \Pi \Delta t</script><p>Substituting equations above, we obtain the BSM partial differential equation:</p><script type="math/tex; mode=display">\frac{\partial f}{\partial t}+rS\frac{\partial f}{\partial S}+\frac{1}{2}\sigma^2S^2\frac{\partial^2 f}{\partial S^2} = rf</script><p><strong><a href="https://achlier.github.io/2021/03/14/Feynman-Kac_To_Black-Scholes-PDE/">其他方法</a></strong></p><h4 id="BSM-European-Option-Pricing-Formula"><a href="#BSM-European-Option-Pricing-Formula" class="headerlink" title="BSM European Option Pricing Formula:"></a>BSM European Option Pricing Formula:</h4><script type="math/tex; mode=display">\begin{align}c &= S_tN(d_1)- e^{-r (T-t)}KN(d_2)\\p &= e^{-r (T-t)}KN(-d_2)- S_tN(-d_1)\end{align}</script><p>With:</p><script type="math/tex; mode=display">\begin{align}d_1&=\frac{1}{\sigma \sqrt{T-t}}(ln\frac{S_t}{K}+(r+\frac{1}{2}\sigma^2)(T-t))\\d_2&=\frac{1}{\sigma \sqrt{T-t}}(ln\frac{S_t}{K}+(r-\frac{1}{2}\sigma^2)(T-t))\\&=d1 - \sigma \sqrt{T-t}\end{align}</script><p><strong><a href="https://achlier.github.io/2021/06/16/Black_Scholes_Model%E6%8E%A8%E5%AF%BC_%E8%BF%9B%E9%98%B6%E7%89%88/">推导步骤</a></strong></p><p><strong>Matlab function</strong></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">[Call,Put] = blsprice(Price,Strike,Rate,Time,Volatility)<br></code></pre></td></tr></table></figure><p><strong>Factors affecting option prices</strong></p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">European Call</th><th style="text-align:center">European Put</th><th style="text-align:center">American Cal</th><th style="text-align:center">American Put</th></tr></thead><tbody><tr><td style="text-align:center">$S_t$</td><td style="text-align:center">+</td><td style="text-align:center">-</td><td style="text-align:center">+</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">$K$</td><td style="text-align:center">-</td><td style="text-align:center">+</td><td style="text-align:center">-</td><td style="text-align:center">+</td></tr><tr><td style="text-align:center">$T-t$</td><td style="text-align:center">+</td><td style="text-align:center">+</td><td style="text-align:center">+</td><td style="text-align:center">+</td></tr><tr><td style="text-align:center">$r$</td><td style="text-align:center">+</td><td style="text-align:center">-</td><td style="text-align:center">+</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">$\sigma$</td><td style="text-align:center">+</td><td style="text-align:center">+</td><td style="text-align:center">+</td><td style="text-align:center">+</td></tr></tbody></table></div><h4 id="Volatility"><a href="#Volatility" class="headerlink" title="Volatility"></a>Volatility</h4><ul><li><strong>Historical volatility</strong> :The volatility of a stock price can be estimated empirically from historical data.</li><li><strong>Implied Volatility</strong> :Implied volatility is the volatility parameter implied from market option price using the Black-Scholes-Merton option pricing formula.</li></ul><p><strong>Matlab function</strong></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">Volatility = blsimpv(St,K,r,T − t, c)<br></code></pre></td></tr></table></figure><p><strong>Volatility Smile</strong> : Volatility smile is the relationship between implied volatility and strike price for a particular maturity.</p><ul><li><p>volatility smile</p><ul><li>之所以被称为“波动率微笑”， 是指价外期权和价内期权（out of money和 in the money）的波动率高于在价期权（at the money）的波动率，使得波动率曲线呈现出中间低两边高的向上的半月形，也就是微笑的嘴形，叫波动率微笑。</li></ul></li><li><p>volatility skew</p><ul><li>volatility曲线从左到右向下倾斜。这种情况在股票期权中最常见，因为股票的put option是一种保险，通常供不应求。而有时改变$\Delta t$也会造成从smile到skew的转变。</li></ul></li></ul><h5 id="Option-Greeks-read-more-about-it"><a href="#Option-Greeks-read-more-about-it" class="headerlink" title="Option Greeks , read more about it"></a>Option Greeks <a href="https://achlier.github.io/2021/03/05/Option_Greeks/">, read more about it</a></h5><h1 id="Unit-4-Bonds-interest-rate-swaps-and-credit-derivatives"><a href="#Unit-4-Bonds-interest-rate-swaps-and-credit-derivatives" class="headerlink" title="Unit 4: Bonds, interest rate swaps and credit derivatives"></a>Unit 4: Bonds, interest rate swaps and credit derivatives</h1><h2 id="Unit-4-1"><a href="#Unit-4-1" class="headerlink" title="Unit 4.1"></a>Unit 4.1</h2><h3 id="Part-1"><a href="#Part-1" class="headerlink" title="Part 1"></a>Part 1</h3><h4 id="Introduction-to-Bond"><a href="#Introduction-to-Bond" class="headerlink" title="Introduction to Bond"></a>Introduction to Bond</h4><p><strong>Definition</strong>: A bond is a debt instrument requiring the <strong>issuer</strong> (also called the <strong>debtor</strong> or <strong>borrower</strong>) to repay to the lender/investor the amount borrowed plus interest over a specified period of time.</p><p><strong>Type of Issuer</strong>: There are three types of bond issuers: </p><ol><li>The government and its agencies (Treasury bonds, UK gilts, German bunds)</li><li>Municipal governments (municipal bonds or munis)</li><li>Corporations (corporate bonds)</li></ol><p><strong>Term to Maturity</strong>: The term to maturity of a bond is the number of years over which the issuer has promised to meet the conditions of the obligation.</p><ul><li>Short-term bonds (bills): maturities are between 1 to 5 years;</li><li>Intermediate-term bonds (notes): maturities are between 5 to 12 years;</li><li>Long-term bonds (bonds): maturities are longer than 12 years;</li></ul><p><strong>Principal</strong>: the <strong>principal value</strong> (or simply principal) of a bond is the amount that the issuer agrees to repay the bondholder at the maturity date.  Also referred to as the <strong>redemption value</strong>, <strong>maturity value</strong>, <strong>par</strong> <strong>value</strong>, or <strong>face value</strong>. </p><p><strong>Coupon Rate</strong>: the <strong>coupon rate</strong>, also called the <strong>nominal rate</strong>, is the interest rate that the issuer agrees to pay each year. </p><h4 id="Yield-to-maturity-YTM"><a href="#Yield-to-maturity-YTM" class="headerlink" title="Yield to maturity (YTM)"></a>Yield to maturity (YTM)</h4><script type="math/tex; mode=display">P = \sum_{t=1}^n\frac{C_t}{(1+y)^t}+\frac{M}{(1+y)^n}</script><p><strong>Spot Rate</strong>:  The n-year zero-coupon interest rate is sometimes also referred to as the n-year <strong>spot rate</strong>, the n-year <strong>zero rate</strong>. In other words, the spot rate is the yield to maturity on the zero-coupon bond.</p><p><strong>Bootstrap Method</strong>: A procedure for calculating the zero-coupon yield curve from market data.</p><h3 id="Part-2"><a href="#Part-2" class="headerlink" title="Part 2"></a>Part 2</h3><h4 id="Duration"><a href="#Duration" class="headerlink" title="Duration"></a>Duration</h4><p>Duration is a measure of a bond’s price sensitivity to yield changes. </p><p><strong>Macaulay duration</strong>: </p><script type="math/tex; mode=display">[\frac{1C}{1+y}+\frac{2C}{(1+y)^2}+...+\frac{nC}{(1+y)^n}+\frac{nM}{(1+y)^n}]\frac{1}{P}</script><blockquote><p> <strong>Macaulay duration</strong> is a measure of how long on average the holder of the bond has to wait before receiving cash payments.</p></blockquote><p><strong>Modified duration</strong>:</p><script type="math/tex; mode=display">-\frac{dP}{dy}\frac{1}{P} = \frac{1}{1+y}\times Macaulay \ duration</script><blockquote><p><strong>Modified duration</strong> can be interpreted as the approximate percentage change in bond price for a 1-percent change in yield.</p><p>当按月计算，会有些不同</p></blockquote><p><strong>Percentage Price Change</strong></p><script type="math/tex; mode=display">Modified \ duration\times dy = -\frac{dP}{P}</script><p><strong>Convexity measure</strong></p><script type="math/tex; mode=display">convexity \ measure = \frac{d^2P}{dy^2}\frac{1}{P}</script><p> the second derivative of the price equation is:</p><script type="math/tex; mode=display">\frac{d^2P}{dy^2} = \sum_{t=1}^n \frac{t(t+1)C}{(1+y)^{t+2}}+\frac{n(n+1)M}{(1+y)^{n+2}}</script><p><strong>Duration matching</strong> / <strong>Portfolio immunization</strong>:  the strategy makes a portfolio relatively insensitive to interest rates.</p><h2 id="Unit-4-2"><a href="#Unit-4-2" class="headerlink" title="Unit 4.2"></a>Unit 4.2</h2><h3 id="Part-1-1"><a href="#Part-1-1" class="headerlink" title="Part 1"></a>Part 1</h3><p><strong>Interest Rate Swap</strong>: an exchange of <strong>a fixed rate of interest</strong> on a certain notional principal for <strong>a floating rate of interest</strong> on the same notional principal. The most popular (plain vanilla) interest rate swap is one where <strong>LIBOR</strong> is exchanged for a fixed rate of interest</p><p><strong>London Interbank Offered Rate (LIBOR)</strong> is the rate of interest at which a bank with an AA credit rating is able to borrow from other banks.</p><p><strong>Example  1</strong>: </p><p>Microsoft agrees to pay Intel an interest rate of 5% per annum on a principal of 100 million, and in return Intel agrees to pay Microsoft the 6-month LIBOR rate on the same principal. In this case, Microsoft is the <strong>fixed-rate payer</strong>; Intel is the <strong>floating-rate payer</strong>. </p><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic4-1.jpg" alt></p><h3 id="Part-2-1"><a href="#Part-2-1" class="headerlink" title="Part 2"></a>Part 2</h3><p><strong>Role of Financial Intermediary</strong>: Usually two nonfinancial companies such as Intel and Microsoft do not get in touch directly to arrange a swap in the way indicated in Example 1. They each deal with a financial intermediary e.g. a bank or other financial institution. The LIBOR-for-fixed swaps are usually structured so that the financial institution earns about <strong>3 or 4 basis points (0.03% or 0.04%)</strong> on a pair of offsetting transactions.</p><p><strong>Example 2 Transform a Liability:</strong> </p><p>Microsoft has arranged to borrow 100 million at LIBOR plus 10 basis points (i.e. 0.1%). After Microsoft has entered into the swap, it has the following three cash flows:</p><ul><li><p>It pays LIBOR plus 0.1% to its outside lenders.</p></li><li><p>It receives LIBOR under the terms of the swap.</p></li><li><p>It pays 5.015% under the terms of the swap.</p></li></ul><p>Suppose that Intel has a 3-year 100 million loan outstanding on which it pays 5.2%. After it has entered into the swap, it has the following three sets of cash flows:</p><ul><li><p>It pays 5.2% to its outside lenders.</p></li><li><p>It pays LIBOR under the terms of the swap.</p></li><li><p>It receives 4.985% under the terms of the swap.</p></li></ul><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic4-2.jpg" alt></p><p><strong>Example 3 Transform an Asset</strong>:</p><p>Suppose that Microsoft owns 100 million in bonds that will provide interest at 4.7% per annum over the next 3 years. After Microsoft has entered into the swap, it has the following three cash flows:</p><ul><li><p>It receives 4.7% on the bonds.</p></li><li><p>It receives LIBOR under the terms of the swap.</p></li><li><p>It pays 5.015% under the terms of the swap.</p></li></ul><p>Suppose that Intel has an investment of 100 million that yields LIBOR minus 20 basis points. After it has entered into the swap, it has the following three sets of cash flows:</p><ul><li><p>It receives LIBOR minus 20 basis points on its investment.</p></li><li><p>It pays LIBOR under the terms of the swap.</p></li><li><p>It receives 4.985% under the terms of the swap.</p></li></ul><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic4-3.jpg" alt></p><h3 id="Part-3"><a href="#Part-3" class="headerlink" title="Part 3"></a>Part 3</h3><p><strong>Role of Market Makers</strong>: In practice, it is unlikely that two companies will contact a financial institution at the same time and want to take opposite positions in exactly the same swap. As a result, many large financial institutions act as <strong>market makers for swaps</strong>. This means that they are prepared to enter into a swap without having an offsetting swap with another counter-party. This type of swap is sometimes referred to as warehousing swap.</p><p>In general, the market makers quote, for different maturities, the bid and offer fixed rates they are prepared to exchange for the floating rate.</p><ul><li><p>Bid rate: the fixed rate that a swap market maker is prepared to <strong>pay</strong> in exchange <strong>for receiving LIBOR</strong>.</p></li><li><p>Offer rate: the fixed rate that a swap market maker is prepared to <strong>receive</strong> in return <strong>for paying LIBOR</strong>.</p></li></ul><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic4-4.jpg" alt></p><p>The average of the bid and offer fixed rates is known as the <strong>swap rate</strong>. </p><p><strong>Credit risk</strong> refers to the risk that a loss will be experienced because of a default by the counterparty in a derivatives transaction. </p><p>The methods to reduce the credit risk include:</p><ul><li><p>Central Clearing: to reduce credit risk in over-the-counter swap markets, regulators require standardized over-the-counter derivatives to be cleared through central counterparties (CCPs). The CCP requires initial margin and variation margin from both sides in a transaction. <strong>LCH.Clearnet</strong> is the largest CCP for interest rate swaps.</p></li><li><p>Credit Default Swaps (CDS): CDS is a swap that allows companies to hedge credit risks. A CDS is like an insurance contract that pays off if a particular company or country defaults.</p></li></ul><h2 id="Unit-4-3"><a href="#Unit-4-3" class="headerlink" title="Unit 4.3"></a>Unit 4.3</h2><h3 id="Part-1-2"><a href="#Part-1-2" class="headerlink" title="Part 1"></a>Part 1</h3><p>From the point of view of the <strong>floating-rate payer</strong>, a swap can be regarded as a long position in a fixed rate bond and a short position in a floating-rate bond, that is:</p><script type="math/tex; mode=display">V_{swap} = B_{fix}-B_{fl}</script><p>From the point of view of the <strong>fixed-rate payer</strong>, a swap is a long position in a floating-rate bond and a short position in a fixed-rate bond, so that the value of the swap is:</p><script type="math/tex; mode=display">V_{swap} = B_{fl}-B_{fix}</script><p><strong>Valuation of Interest Rate Swaps in Terms of the Floating-rate Bond</strong></p><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic4-5.jpg" alt></p><ul><li><p>$t’$: the last payment date</p></li><li><p>$t^*$: first payment date (denoted by ) </p></li><li>except maturity: any other subsequent payment date</li><li>$k^*$:  the floating payment that be made at first payment date</li><li>The floating-rate bond can therefore be regarded as an instrument providing a single cash flow of <em>L</em> + $k^*$ at first payment date.</li></ul><p><strong>Example 4:</strong></p><p>Suppose that some time ago a financial institution agreed to receive 6-month LIBOR and pay 3% per annum (with semi-annual compounding) on a notional principal of 100 million. The swap has a remaining life of 1.25 years. The LIBOR rates with continuous compounding for 3-month, 9-month, and 15- month maturities are 2.8%, 3.2%, and 3.4%, respectively. The 6-month LIBOR rate at the last payment date was 2.9% (with semi-annual compounding).</p><div class="table-container"><table><thead><tr><th>Time</th><th>cc_rate</th><th>Bfix cash flow</th><th>Bfl cash flow</th><th>Discount factor</th><th>PV of Bfix cash flow</th><th>PV of Bfl cash flow</th></tr></thead><tbody><tr><td>0.25</td><td>2.80%</td><td>1.5</td><td>101.45</td><td>0.993024443</td><td>1.489536664</td><td>100.7423297</td></tr><tr><td>0.75</td><td>3.20%</td><td>1.5</td><td></td><td>0.97628571</td><td>1.464428565</td><td></td></tr><tr><td>1.25</td><td>3.40%</td><td>101.5</td><td></td><td>0.958390466</td><td>97.27663225</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td><strong>Sum</strong></td><td>100.2305975</td><td>100.7423297</td></tr><tr><td></td><td></td><td></td><td></td><td><strong>V_swap</strong></td><td>0.511732256</td></tr></tbody></table></div><h3 id="Part-2-2"><a href="#Part-2-2" class="headerlink" title="Part 2"></a>Part 2</h3><p><strong>Forward Rate</strong></p><script type="math/tex; mode=display">e^{R_F(T_2-T_1)}\times e^{R_1T_1} = e^{R_2T_2}\ ,\ or\ R_F = \frac{R_2T_2-R_1T_1}{T_2-T_1}</script><blockquote><p>此处为连续的利率时计算，如果是非连续的</p></blockquote><script type="math/tex; mode=display">(1+R_1/n)^{T_1n}(1+R_F/n)=(1+R_2/n)^{T_2n}</script><p><strong>Valuation of FRAs</strong></p><script type="math/tex; mode=display">V_{FRA}=L(R_K-R_F)(T_2-T_1)e^{-R_2T_2}</script><blockquote><p>因为第一种得到的FRA是连续的，以上的是非连续的计算，所以有时需要进行转换，如果是连续的</p></blockquote><script type="math/tex; mode=display">V_{FRA}=L(e^{R_K(T_2-T_1)}-e^{R_F(T_2-T_1)})e^{-R_2T_2}</script><blockquote><p>折现时的利率默认连续，如果不是需要进行转换</p></blockquote><h3 id="Part-3-1"><a href="#Part-3-1" class="headerlink" title="Part 3"></a>Part 3</h3><p><strong>Valuation of Interest Rate Swaps in Terms of FRAs</strong></p><p><strong>Example 5:</strong></p><p>Under the terms of a swap, a financial institution has agreed to receive 6-month LIBOR and pay 3% per annum (with semiannual compounding) on a notional principal of 100 million. The swap has a remaining life of 1.25 years. The LIBOR rates with continuous compounding for 3-month, 9-month, and 15-month maturities are 2.8%, 3.2%, and 3.4%, respectively. The 6-month LIBOR rate at the last payment date was 2.9% (with semiannual compounding).</p><div class="table-container"><table><thead><tr><th>Time</th><th>cc_rate</th><th>RF_CC</th><th>RF_DD</th><th>fix cash flow</th><th>fl cash flow</th><th>Discount factor</th><th>PV of fix cash flow</th><th>PV of fl cash flow</th></tr></thead><tbody><tr><td>0.25</td><td>2.80%</td><td>2.90%</td><td>2.90%</td><td>1.5</td><td>1.4500</td><td>0.993024443</td><td>1.489536664</td><td>1.439885442</td></tr><tr><td>0.75</td><td>3.20%</td><td>3.40%</td><td>3.43%</td><td>1.5</td><td>1.7145</td><td>0.97628571</td><td>1.464428565</td><td>1.673873318</td></tr><tr><td>1.25</td><td>3.40%</td><td>3.70%</td><td>3.73%</td><td>1.5</td><td>1.8672</td><td>0.958390466</td><td>1.437585698</td><td>1.789524424</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td><strong>Sum</strong></td><td>4.391550927</td><td>4.903283183</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td><strong>V_swap</strong></td><td>0.511732256</td></tr></tbody></table></div><h2 id="Unit-4-4"><a href="#Unit-4-4" class="headerlink" title="Unit 4.4"></a>Unit 4.4</h2><h3 id="Part-1-3"><a href="#Part-1-3" class="headerlink" title="Part 1"></a>Part 1</h3><p><strong>Credit risk</strong> refers to the risk that a loss will be experienced because of a default by the counterparty in a derivatives transaction.</p><p><strong>Credit derivatives</strong> allows companies to trade credit risk. These are contracts which involve cashflows/payoffs between two parties that are linked to the credit characteristics of another reference entity.</p><p><strong>Types of Credit Derivatives</strong></p><ol><li><strong>Event instruments</strong>: if a credit event, for example, a default can jeopardise your investment, then you may want to buy protection against that type of credit event by buying a credit default swap (CDS) providing a payoff that depends on the financial outcomes of that event.</li><li><strong>Total return instruments</strong>: in this case you can transfer the financial gains of a credit risky asset against a pre-specified rate such as LIBOR plus a spread; examples are total return swaps.</li></ol><p>The following definitions are useful in understanding of the functioning of CDS:</p><ul><li><p><strong>Credit Event</strong> : a failure to make a payment as it becomes due, a restructuring of debt, or a bankruptcy.</p></li><li><p><strong>Reference Entity</strong> : a specified entity (sovereign, financial institution, corporation, or one among a basket of such specified entities).</p></li><li><p><strong>Protection Buyer</strong> : also the ‘Buyer’, the party paying a (periodic) fee in return for a contingent payment by the other party following a credit event of the reference entity.</p></li><li><p><strong>Protection Seller</strong> : also the ‘Seller’, the party receiving a (periodic) fee in return for making a contingent payment.</p></li></ul><p><strong>CDS Cash Flows</strong></p><p>CDS generally includes three parties:</p><ol><li>the issuer of the debt security (the reference entity)</li><li>the buyer of the debt security (protection buyer)</li><li>a third party who sells a CDS to the buyer of the debt security (protection seller)</li></ol><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic4-6.jpg" alt></p><p><strong>CDS spread</strong>: The total amount paid per year, as a percentage of the notional principal, to buy protection.</p><p><strong>Recovery Rate</strong>: </p><script type="math/tex; mode=display">loss\ given\ default = 1 - recovery\ rate</script><blockquote><p>The payoff from CDS is given as L(1 − R) where L is the notional principal and R is the recovery rate.</p></blockquote><p>It then makes sense for the company to buy bonds on the reference entity such that the bonds are cheapest-to-deliver under the terms of CDS. That is, the bonds with minimum CDS-bond basis</p><script type="math/tex; mode=display">CDS\_bond\_basis = CDS\_spead − Excess\_bond\_yield\_over\_risk-free\_rate</script><h3 id="Part-2-3"><a href="#Part-2-3" class="headerlink" title="Part 2"></a>Part 2</h3><h4 id="Valuation-of-CDS"><a href="#Valuation-of-CDS" class="headerlink" title="Valuation of CDS"></a>Valuation of CDS</h4><p><strong>step 1</strong>: unconditional default and survival probabilities table</p><p>Suppose the default probability of the reference entity in the CDS is 2% in any year conditional on no earlier default.</p><div class="table-container"><table><thead><tr><th>Year</th><th>Default p</th><th>Survival p</th></tr></thead><tbody><tr><td>1</td><td>0.02</td><td>0.98</td></tr><tr><td>2</td><td>0.0196</td><td>0.9604</td></tr><tr><td>3</td><td>0.019208</td><td>0.941192</td></tr><tr><td>4</td><td>0.01882384</td><td>0.92236816</td></tr><tr><td>5</td><td>0.018447363</td><td>0.903920797</td></tr></tbody></table></div><p><strong>step 2</strong>: Calculation of the Present Value of Expected Payments</p><p>Suppose that risk-free rate is 5% per annum with continuous compounding.</p><p>Suppose that a spread of <em>s</em> is paid per year to the protection seller on a notional principal of $1.</p><div class="table-container"><table><thead><tr><th>Year</th><th>Survival p</th><th>Expected payment</th><th>Discount factor</th><th>PV of payment</th></tr></thead><tbody><tr><td>1</td><td>0.98</td><td>0.98</td><td>0.951229425</td><td>0.932204836</td></tr><tr><td>2</td><td>0.9604</td><td>0.9604</td><td>0.904837418</td><td>0.869005856</td></tr><tr><td>3</td><td>0.941192</td><td>0.941192</td><td>0.860707976</td><td>0.810091462</td></tr><tr><td>4</td><td>0.92236816</td><td>0.92236816</td><td>0.818730753</td><td>0.755171178</td></tr><tr><td>5</td><td>0.903920797</td><td>0.903920797</td><td>0.778800783</td><td>0.703974224</td></tr><tr><td></td><td></td><td></td><td><strong>Total</strong></td><td>4.070447557</td></tr></tbody></table></div><p><strong>step 3</strong>: Calculation of the Present Value of Expected Accrual Payment</p><p>If a credit event occurs, it is assumed that it happens in the middle of the year. As the protection buyer makes the payment in arrears, we need to compute the expected accrual payment by protection buyer.</p><div class="table-container"><table><thead><tr><th>Year</th><th>Default p</th><th>Expected payment</th><th>Discount factor</th><th>PV of payment</th></tr></thead><tbody><tr><td>0.5</td><td>0.02</td><td>0.01</td><td>0.975309912</td><td>0.009753099</td></tr><tr><td>1.5</td><td>0.0196</td><td>0.0098</td><td>0.927743486</td><td>0.009091886</td></tr><tr><td>2.5</td><td>0.019208</td><td>0.009604</td><td>0.882496903</td><td>0.0084755</td></tr><tr><td>3.5</td><td>0.01882384</td><td>0.00941192</td><td>0.839457021</td><td>0.007900902</td></tr><tr><td>4.5</td><td>0.018447363</td><td>0.009223682</td><td>0.798516219</td><td>0.007365259</td></tr><tr><td></td><td></td><td></td><td><strong>Total</strong></td><td>0.042586647</td></tr></tbody></table></div><p><strong>step 4</strong>: Calculation of the Present Value of Expected Payoff</p><p>Suppose that the recovery rate is 40%.</p><div class="table-container"><table><thead><tr><th>Year</th><th>Default p</th><th>Expected payment</th><th>Discount factor</th><th>PV of payment</th></tr></thead><tbody><tr><td>0.5</td><td>0.02</td><td>0.012</td><td>0.975309912</td><td>0.011703719</td></tr><tr><td>1.5</td><td>0.0196</td><td>0.01176</td><td>0.927743486</td><td>0.010910263</td></tr><tr><td>2.5</td><td>0.019208</td><td>0.0115248</td><td>0.882496903</td><td>0.0101706</td></tr><tr><td>3.5</td><td>0.01882384</td><td>0.011294304</td><td>0.839457021</td><td>0.009481083</td></tr><tr><td>4.5</td><td>0.018447363</td><td>0.011068418</td><td>0.798516219</td><td>0.008838311</td></tr><tr><td></td><td></td><td></td><td><strong>Total</strong></td><td>0.051103977</td></tr></tbody></table></div><p>The present value of the expected payments is the sum of <strong>total present value of the expected payments in the case of no credit event</strong>  and <strong>total present value of the expected accrual payments in a credit event</strong>.</p><script type="math/tex; mode=display">4.0704s+0.0426s=4.1130s</script><p>We choose the value of CDS spread <em>s</em> such that <strong>the present value of* expected CDS payments</strong> equals <strong>the present value of expected payoff from the CDS</strong>. </p><script type="math/tex; mode=display">4.1130s = 0.0511</script><p><em>s</em> = 0.0124. In other words, The mid-market CDS spread for the 5-year deal we have considered should be 0.0124 times the principal or 124 basis points per year.</p><p><strong>Marking-to-market</strong>:</p><p>If  CDS was entered at a spread value of 150 basis points. </p><script type="math/tex; mode=display">4.1130 \times 0.0150 = 0.0617 > 0.0511</script><p>To the protection <strong>seller</strong>, the CDS would be worth $0.0617-0.0511 = 0.0106$ times the principal.</p><h4 id="Other-Types-of-CDS"><a href="#Other-Types-of-CDS" class="headerlink" title="Other Types of CDS:"></a>Other Types of CDS:</h4><p><strong>Binary CDS</strong>: It is a type of CDS which pays a fixed payoff of 1 dollar instead of 1 − <em>R</em> dollars in a credit event.</p><p><strong>Basket CDS</strong>: In a basket CDS, there are more than one reference entity and a payoff is due when one or more reference entity defaults. There are different sub-types of a basket CDS</p><ul><li><p><em>Add-up basket CDS</em>: provides a payoff when any one of the reference entities default.</p></li><li><p><em>First-to-default CDS</em>: provides a payoff only when the first default occurs.</p></li><li><p><em>Second-to-default CDS</em>: provides a payoff only when the second default occurs.</p></li></ul><h3 id="Part-3-2"><a href="#Part-3-2" class="headerlink" title="Part 3"></a>Part 3</h3><p><strong>Collateralized Debt Obligation (CDO)</strong>  is an asset-backed security which is backed by a diversified pool of assets such as investment grade and high-yield corporate bonds, residential mortgage-backed securities, bank loans, etc.</p><p>Typically, the payments and obligations based on the collected pool of CDSs are divided into different tranches: <strong>senior, mezzanine and junior or equity</strong>.</p><ul><li><p><strong>senior</strong>:  is considered almost <strong>without any risk</strong>. Receives the lowest CDS spread payments.</p></li><li><p><strong>equity</strong>: is based on the <strong>riskiest</strong> CDSs and is usually held by the originator itself or is sold to hedge funds.</p></li><li><p><strong>mezzanine</strong>: is based on the remaining CDSs and is the <strong>hardest tranche to sell</strong>.</p></li></ul><p><img src="/2021/04/22/Financial_Markets_Securities_and_Derivatives/pic4-7.jpg" alt></p>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Derivatives</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【课程】金融科技工具箱</title>
    <link href="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/"/>
    <url>/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于B站 up 无机言nokay 的视频<a href="https://www.bilibili.com/video/BV1DE411y7nz?spm_id_from=333.999.0.0">《金融科技工具箱——面向经管金融同学的Python、爬虫、机器学习课》</a>的笔记，此视频偏向面对金融系学生的基础讲解；</p><p>优点：快速入门，全面，有主讲人个人研究时的想法；</p><p>缺点：因为面向群众不是计算机系且时间有限，比较零碎，深入需要自学；</p></blockquote><span id="more"></span><h2 id="0-其他资料"><a href="#0-其他资料" class="headerlink" title="0. 其他资料"></a>0. 其他资料</h2><ol><li><a href="https://www.liaoxuefeng.com/">廖雪峰的官方网站</a></li><li><a href="https://zhuanlan.zhihu.com/p/57372332">《Python数据科学手册》</a></li><li><a href="https://www.zhihu.com/question/39602876">《利用python进行数据分析》</a></li></ol><h2 id="1-基础部分"><a href="#1-基础部分" class="headerlink" title="1. 基础部分"></a>1. 基础部分</h2><ul><li>跳过，有时间另外整一版统一复习</li></ul><h3 id="1-5-数据结构"><a href="#1-5-数据结构" class="headerlink" title="1.5 数据结构"></a>1.5 数据结构</h3><p>用于导出$Jason$的数据结构，爬虫时应该会用到</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br>l1 = [[<span class="hljs-string">&#x27;李磊&#x27;</span>,<span class="hljs-number">25</span>,[&#123;<span class="hljs-string">&#x27;name&#x27;</span>:<span class="hljs-string">&#x27;韩梅梅&#x27;</span>,<span class="hljs-string">&#x27;age&#x27;</span>:<span class="hljs-string">&#x27;23&#x27;</span>&#125;]],[<span class="hljs-string">&#x27;王二蛋&#x27;</span>,<span class="hljs-number">21</span>,[]],[<span class="hljs-string">&#x27;朱一旦&#x27;</span>,<span class="hljs-number">35</span>,[&#123;<span class="hljs-string">&#x27;name&#x27;</span>:<span class="hljs-string">&#x27;赵大&#x27;</span>,<span class="hljs-string">&#x27;age&#x27;</span>:<span class="hljs-string">&#x27;23&#x27;</span>&#125;,&#123;<span class="hljs-string">&#x27;name&#x27;</span>:<span class="hljs-string">&#x27;钱二&#x27;</span>,<span class="hljs-string">&#x27;age&#x27;</span>:<span class="hljs-string">&#x27;21&#x27;</span>,<span class="hljs-string">&#x27;ex&#x27;</span>:[<span class="hljs-string">&#x27;周五&#x27;</span>,<span class="hljs-string">&#x27;吴六&#x27;</span>,<span class="hljs-string">&#x27;郑七&#x27;</span>]&#125;]]]<br>js = json.dumps(l1, sort_keys=<span class="hljs-literal">True</span>, indent=<span class="hljs-number">4</span>, separators=(<span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;:&#x27;</span>),ensure_ascii=<span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(js)<br></code></pre></td></tr></table></figure><p>导出/导入$Jason$文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">root_dir = !echo %cd% <span class="hljs-comment"># 在notebook里面运用的系统查找当前路径的方法</span><br><span class="hljs-comment"># 或os.getcwd()</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(root_dir+<span class="hljs-string">&#x27;exs&#x27;</span>+ <span class="hljs-string">&#x27;.json&#x27;</span>,<span class="hljs-string">&#x27;wb+&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    f.write(json.dumps(l1).encode(<span class="hljs-string">&#x27;utf-8&#x27;</span>))<br><span class="hljs-keyword">del</span> l1<br>l1 = json.load(<span class="hljs-built_in">open</span>(root_dir+<span class="hljs-string">&#x27;exs.json&#x27;</span>))<br></code></pre></td></tr></table></figure><h3 id="1-6-常用函数"><a href="#1-6-常用函数" class="headerlink" title="1.6 常用函数"></a>1.6 常用函数</h3><p>$cmd$操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">os.system(<span class="hljs-built_in">str</span>格式的命令)<br></code></pre></td></tr></table></figure><p>按位</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 按位与&amp; 参与运算的两个值，如果其二进制值对应位都为1，则该位的结果为1，否则该位为 0</span><br><span class="hljs-comment"># 按位或| 只要对应的二个二进位有一个为 1 时，结果位就为 1，只有对应为都是 0， 结果为才是 0</span><br><span class="hljs-comment"># 二进制运算符</span><br></code></pre></td></tr></table></figure><p>复制</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># .copy()</span><br></code></pre></td></tr></table></figure><p>打乱</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br>l_1 = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]<br>random.shuffle(l_1)<br><span class="hljs-built_in">print</span>(l_1)<br></code></pre></td></tr></table></figure><p>计个时</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">ltime = time.asctime( time.localtime(time.time()) )<br><span class="hljs-built_in">print</span> (ltime)<br></code></pre></td></tr></table></figure><p>查看文档</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">?要查的fun名<br></code></pre></td></tr></table></figure><h3 id="1-7-作业"><a href="#1-7-作业" class="headerlink" title="1.7 作业"></a>1.7 作业</h3><p>有趣的$tips$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">[<span class="hljs-number">1</span>,*[<span class="hljs-number">0.1</span>]] <span class="hljs-comment"># 做一个list首位是1，后面连接[0.1],类似[1]+[0.1]</span><br></code></pre></td></tr></table></figure><p>画红❤</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span>  time,os,math<br>[(time.sleep(<span class="hljs-number">0.001</span>),  <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\033[91m&quot;</span>+i,end=<span class="hljs-string">&quot;&quot;</span>,flush=<span class="hljs-literal">True</span>)) <br><span class="hljs-comment">#\033[91m 红色 flush 滑动特效</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> (<span class="hljs-string">&#x27; *&#x27;</span>+<span class="hljs-string">&#x27;\n *&#x27;</span>.join([<span class="hljs-string">&#x27;&#x27;</span>.join([(<span class="hljs-string">&#x27; I love U&#x27;</span>[(x-y)%<span class="hljs-number">9</span>] <span class="hljs-comment"># 画出错位效果</span><br><span class="hljs-keyword">if</span>((x*<span class="hljs-number">0.05</span>)**<span class="hljs-number">2</span>+(y*<span class="hljs-number">0.15</span>)**<span class="hljs-number">2</span>-<span class="hljs-number">1</span>)**<span class="hljs-number">3</span>-(x*<span class="hljs-number">0.05</span>)**<span class="hljs-number">2</span>*(y*<span class="hljs-number">0.15</span>)**<span class="hljs-number">3</span>&lt;=<span class="hljs-number">0</span> <span class="hljs-keyword">else</span><span class="hljs-string">&#x27; &#x27;</span> <br><span class="hljs-comment"># 心型的函数，注释掉就是一面表白墙（↑）</span><br>)<span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(-<span class="hljs-number">30</span>,<span class="hljs-number">30</span>)])+<span class="hljs-string">&#x27;*&#x27;</span> <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">15</span>,-<span class="hljs-number">15</span>,-<span class="hljs-number">1</span>)]))<br>]<br></code></pre></td></tr></table></figure><p><img src="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/pic1-1.jpg" alt></p><p>图片颜色代替（不提供材料，可在原视频下载）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> os<br><span class="hljs-comment">#cv2 是OpenCV，一个专门用于图像处理的包</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>root_dir = <span class="hljs-string">&#x27;C:/Users/lenovo/Desktop/.....&#x27;</span> <span class="hljs-comment">#替换</span><br><span class="hljs-comment">#定义根目录</span><br><br><span class="hljs-comment">#------------------------</span><br><span class="hljs-comment">#此部分用于读取文件夹lego brick所有图片，并根据文件名，构建颜色名和颜色RGB的字典</span><br>work_dir = root_dir + <span class="hljs-string">&#x27;lego&#x27;</span><br>color_dic = &#123;&#125;<br><br><span class="hljs-keyword">for</span> parent, dirnames, filenames <span class="hljs-keyword">in</span> os.walk(work_dir,  followlinks=<span class="hljs-literal">True</span>):<br>    <span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> filenames:<br>        <span class="hljs-comment">#file_path = os.path.join(parent, filename)</span><br>        file_path = work_dir+<span class="hljs-string">&#x27;/&#x27;</span>+filename<br>        <span class="hljs-comment">#print(file_path)</span><br>        <span class="hljs-comment"># 以上为遍历work_dir中所有文件</span><br>        <span class="hljs-keyword">if</span> file_path[-<span class="hljs-number">3</span>:] != <span class="hljs-string">&#x27;jpg&#x27;</span> <span class="hljs-keyword">and</span> file_path[-<span class="hljs-number">3</span>:] != <span class="hljs-string">&#x27;png&#x27;</span>:<br>            <span class="hljs-keyword">continue</span><br>        <br>        <span class="hljs-comment"># cv2.imread()接口读图像，读进来直接是BGR 格式数据格式在 0~255，通道格式为(W,H,C)</span><br>        img = cv2.imread(file_path)<br>        x_size = <span class="hljs-built_in">len</span>(img)<br>        y_size = <span class="hljs-built_in">len</span>(img[<span class="hljs-number">0</span>])<br>        mid_point = img[x_size//<span class="hljs-number">2</span>][y_size//<span class="hljs-number">2</span>] <span class="hljs-comment">#选中点</span><br>        color_dic[filename.split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>]] = mid_point<br>        <br>col_list=[]<br><span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> color_dic:<br>    col_list.append(color_dic[key].astype(<span class="hljs-string">&#x27;float64&#x27;</span>))<br><span class="hljs-comment">#------------------------</span><br><span class="hljs-comment">#此部分用于读取待处理图片，并截取中心1：1比例，并resize至le*le</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">img_mosaic</span>(<span class="hljs-params">file_name,base_len</span>):<br>    raw_img = cv2.imread(file_name)<br>    xlen = <span class="hljs-built_in">len</span>(raw_img)<br>    ylen = <span class="hljs-built_in">len</span>(raw_img[<span class="hljs-number">0</span>])<br>    min_len = <span class="hljs-built_in">min</span>(xlen,ylen)<br>    <br>    sq_img = raw_img[xlen//<span class="hljs-number">2</span>-min_len//<span class="hljs-number">2</span>:xlen//<span class="hljs-number">2</span>+min_len//<span class="hljs-number">2</span>][ylen//<span class="hljs-number">2</span>-min_len//<span class="hljs-number">2</span>:ylen//<span class="hljs-number">2</span>+min_len//<span class="hljs-number">2</span>]<br>    <span class="hljs-comment"># 按最小长or宽截图</span><br>    mc_img = cv2.resize(sq_img,(base_len,base_len))<br>    <span class="hljs-comment"># 按比例压缩</span><br>    <span class="hljs-keyword">return</span> mc_img<br><span class="hljs-comment">#------------------------</span><br><span class="hljs-comment">#此部分用于替换颜色，按照RGB数之差的平方的最小值选择</span><br>le=<span class="hljs-number">350</span> <span class="hljs-comment">#resize值</span><br>mc_lena = img_mosaic(root_dir+<span class="hljs-string">&#x27;lena.jpg&#x27;</span>,le)<br><br><span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(le):<br>    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(le):<br>        diff = np.<span class="hljs-built_in">sum</span>(np.subtract(mc_lena[x,y],col_list)**<span class="hljs-number">2</span>,axis=<span class="hljs-number">1</span>)<br>        index = np.argmin(diff)<br>        mc_lena[x,y]=col_list[index]<br>        <br>cv2.imwrite(root_dir+<span class="hljs-string">&#x27;lena_mc.jpg&#x27;</span>, mc_lena) <span class="hljs-comment"># 保存</span><br></code></pre></td></tr></table></figure><p><img src="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/pic1-2.jpg" alt></p><h2 id="2-Numpy和Pandas"><a href="#2-Numpy和Pandas" class="headerlink" title="2. Numpy和Pandas"></a>2. Numpy和Pandas</h2><h3 id="2-1-Numpy"><a href="#2-1-Numpy" class="headerlink" title="2.1 Numpy"></a>2.1 Numpy</h3><ul><li>$array$所有元素都会变成同一个格式</li><li>注意 $dtype$ 格式，有时候（格式不对会导致计算错误，如非10进制的格式）</li></ul><h4 id="初始化函数"><a href="#初始化函数" class="headerlink" title="初始化函数"></a>初始化函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 矩阵生成</span><br>np.zeros/np.empty/np.ones/np.identity<br>np.full(维度,值)<br>np.eye(维,度,k = 偏移)<br><span class="hljs-comment"># 区间生成</span><br>np.arange(首,尾,步长)<br>np.linspace(首,尾,分离点个数)<br><span class="hljs-comment"># 随机数生成</span><br>np.random.random/np.random.normal/np.random.randint<br>np.random.seed(num) <span class="hljs-comment"># 伪随机数</span><br></code></pre></td></tr></table></figure><h4 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 维度</span><br>arr.ndim <span class="hljs-comment"># 第一层维度 = len(arr)</span><br>arr.shape <span class="hljs-comment"># 所有维度 = (len(arr),len(arr[0]),len(arr[0][0]))</span><br>arr.size <span class="hljs-comment"># 总数</span><br><span class="hljs-comment"># 数据类型</span><br><span class="hljs-comment"># arr_浮点数.dtype &gt; arr_整数.dtype</span><br><span class="hljs-comment"># arr_字符串.dtype 与其他无法比较</span><br>arr.itemsize <span class="hljs-comment"># 每一个元素所占字节数</span><br>arr.nbytes <span class="hljs-comment"># 共占多大</span><br>arr.astype(np.<span class="hljs-built_in">float</span>) <span class="hljs-comment"># 改数据类型</span><br></code></pre></td></tr></table></figure><h4 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h4><ul><li>更换新数字时如果$type$不同将无法替换</li><li>但如果是字符串包数字，可以放</li><li>$array$内截取的部分是$point$,如果改动截取的部分,原矩阵也会改变</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 数字索引</span><br>arr[首:尾:步长]<br>arr = np.array(<span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>))<br>arr[<span class="hljs-number">3</span>::<span class="hljs-number">3</span>]<br>arr[<span class="hljs-number">5</span>::-<span class="hljs-number">1</span>]<br>arr[:<span class="hljs-number">10</span>:-<span class="hljs-number">2</span>]<br><span class="hljs-comment"># 布尔索引</span><br>arr[(arr &gt; <span class="hljs-number">0</span>)&amp;(arr &lt; <span class="hljs-number">10</span>)]<br></code></pre></td></tr></table></figure><h4 id="变形，拼接和分裂"><a href="#变形，拼接和分裂" class="headerlink" title="变形，拼接和分裂"></a>变形，拼接和分裂</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">arr.T<br>arr.reshape<br>np.concatenate <span class="hljs-comment"># 有 axis</span><br>np.vstack/np.hstack<br>np.split/np.vsplit/np.hsplit<br></code></pre></td></tr></table></figure><h4 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">arr = np.arange(<span class="hljs-number">100000</span>)<br>li = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">100000</span>))<br>%time arr = arr*<span class="hljs-number">2</span><br>%time li = [l*<span class="hljs-number">2</span> <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> li]<br><span class="hljs-comment"># 高级函数</span><br>l1 =<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x:x*<span class="hljs-number">2</span>,li) <span class="hljs-comment"># 此时只是map函数本身的对象，需要list()操作</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fun</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> x*<span class="hljs-number">2</span><br>l1 =<span class="hljs-built_in">map</span>(fun,li) <span class="hljs-comment"># 同等上面的</span><br><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> reduce<br>l2 = reduce(<span class="hljs-keyword">lambda</span> x,y:x+y,li)<br><span class="hljs-comment"># 运算</span><br><span class="hljs-comment"># +-*/ // ** %</span><br>np.sin/cos/tan/arcsin<br>np.log/log2/log10/exp/exp2/exp10<br>np.expm1(x) <span class="hljs-comment"># = exp(x) - 1 </span><br>np.log1p(x) <span class="hljs-comment"># = log(1 + x)</span><br>arr1.dot(arr2)/np.dot(arr1,arr2)<br><span class="hljs-comment"># tips:np有matrix函数，利于矩阵计算</span><br></code></pre></td></tr></table></figure><h5 id="Numpy中可用的聚合函数"><a href="#Numpy中可用的聚合函数" class="headerlink" title="Numpy中可用的聚合函数"></a>Numpy中可用的聚合函数</h5><div class="table-container"><table><thead><tr><th>函数名称</th><th>描述</th><th>函数名称</th><th>描述</th></tr></thead><tbody><tr><td>np.sum</td><td>计算元素的和</td><td>np.argmin</td><td>找出最小值的索引</td></tr><tr><td>np.prod</td><td>计算元素的积</td><td>np.argmax</td><td>找出最大值的索引</td></tr><tr><td>np.mean</td><td>计算元素的平均值</td><td>np.median</td><td>计算元素的中位数</td></tr><tr><td>np.std</td><td>计算元素的标准差</td><td>np.percentile</td><td>计算基于元素排序的统计值</td></tr><tr><td>np.var</td><td>计算元素的方差</td><td>np.quantile</td><td>计算基于元素排序的统计值</td></tr><tr><td>np.min</td><td>找出最小值</td><td>np.any</td><td>验证任何一个元素是否为真</td></tr><tr><td>np.max</td><td>找出最大值</td><td>np.all</td><td>验证所以元素是否为真</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 排序</span><br>np.sort/np.argsort/arr.sort<br>li.sort(key = <span class="hljs-keyword">lambda</span> x:x%<span class="hljs-number">3</span>) <span class="hljs-comment"># 有 axis</span><br>np.sort(arr)[::-<span class="hljs-number">1</span>]/li.sort(...,reverse=<span class="hljs-literal">True</span>) <span class="hljs-comment"># 降序排序</span><br></code></pre></td></tr></table></figure><h3 id="2-2-Pandas"><a href="#2-2-Pandas" class="headerlink" title="2.2 Pandas"></a>2.2 Pandas</h3><h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 一维</span><br>pd.Series(arr,index = []) <span class="hljs-comment"># index 可重复</span><br>pd.Series(<span class="hljs-built_in">dict</span>)<br><span class="hljs-comment"># 二维</span><br>pd.DataFrame(&#123;col1:sr1,col2:sr2&#125;)<br></code></pre></td></tr></table></figure><h4 id="定位"><a href="#定位" class="headerlink" title="定位"></a>定位</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">df.loc[[index],col]<br>df.iloc[num]<br><span class="hljs-comment"># df.ix 综合以上两种方法,不推荐</span><br><span class="hljs-comment"># 缺失值</span><br>df.isnull()/df.notnull() <span class="hljs-comment"># 找缺失值</span><br>df.dropna() <span class="hljs-comment"># 删除整行</span><br>df.fillna(method = <span class="hljs-string">&quot;ffill&quot;</span>) <span class="hljs-comment"># 按前位填充 有 axis</span><br>df.fillna(&#123;col1:num1,col2:num2&#125;,limit = fillnum, inplace = <span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h4 id="合并"><a href="#合并" class="headerlink" title="合并"></a>合并</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">pd.concate <span class="hljs-comment"># 用于纵向合并</span><br><span class="hljs-comment"># join = &quot;inner&quot; 交集 &quot;outer&quot; 并集</span><br>pd.merge <span class="hljs-comment"># 用于横向合并</span><br><span class="hljs-comment"># on 依照哪个变量拼接 left_on/right_on 不同名称对应拼接</span><br></code></pre></td></tr></table></figure><h4 id="Group"><a href="#Group" class="headerlink" title="Group"></a>Group</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">df.groupby(col)<br>df.describe() <span class="hljs-comment"># 描述性统计</span><br></code></pre></td></tr></table></figure><h4 id="Jason转DF"><a href="#Jason转DF" class="headerlink" title="Jason转DF"></a>Jason转DF</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">all_res = []<br><span class="hljs-keyword">for</span> ii <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    this_line = &#123;&#125;<br>    this_line[<span class="hljs-string">&#x27;num&#x27;</span>] = ii<br>    this_line[<span class="hljs-string">&#x27;奇偶&#x27;</span>] = <span class="hljs-number">0</span>   <span class="hljs-comment"># 0是奇数</span><br>    <span class="hljs-keyword">if</span> ii % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>:<br>        this_line[<span class="hljs-string">&#x27;奇偶&#x27;</span>] = <span class="hljs-number">1</span><br>    all_res.append(this_line)<br><span class="hljs-keyword">import</span> json<br>js = json.dumps(all_res, sort_keys=<span class="hljs-literal">True</span>, indent=<span class="hljs-number">4</span>, separators=(<span class="hljs-string">&#x27;,&#x27;</span>,<span class="hljs-string">&#x27;:&#x27;</span>),ensure_ascii=<span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(js)<br>df_l = pd.DataFrame(all_res)<br>df_l<br></code></pre></td></tr></table></figure><h4 id="保存、读取"><a href="#保存、读取" class="headerlink" title="保存、读取"></a>保存、读取</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">df.to_csv(root_dir+<span class="hljs-string">&#x27;df.csv&#x27;</span>,encoding=<span class="hljs-string">&#x27;utf-8_sig&#x27;</span>) <span class="hljs-comment"># sig 有中文时</span><br>df_in = pd.read_csv(root_dir+<span class="hljs-string">&#x27;df.csv&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="3-可视化"><a href="#3-可视化" class="headerlink" title="3. 可视化"></a>3. 可视化</h2><ul><li>跳过，有时间另外整一版统一复习</li><li>可视化不只是画图，而是为了更好地表达（如:南丁格尔玫瑰图）</li><li>画图工具包$pyecharts$</li></ul><h2 id="4-爬虫"><a href="#4-爬虫" class="headerlink" title="4. 爬虫"></a>4. 爬虫</h2><ul><li>跳过，有时间另外整一版统一复习</li></ul><h4 id="BeautifulSoup"><a href="#BeautifulSoup" class="headerlink" title="BeautifulSoup"></a>BeautifulSoup</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">html.strip() <span class="hljs-comment"># 刚爬取到网页之后以防格式问题需要提前去头掐尾</span><br>html.find()/html.find_all() <span class="hljs-comment"># 可包含 class_=</span><br>parse.quote() <span class="hljs-comment"># 汉字编码</span><br></code></pre></td></tr></table></figure><h4 id="selenium"><a href="#selenium" class="headerlink" title="selenium"></a>selenium</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">driver.find_element_by_xpath() <span class="hljs-comment"># 可以使用xpath查找</span><br></code></pre></td></tr></table></figure><h4 id="API"><a href="#API" class="headerlink" title="API"></a>API</h4><ul><li>高德地图,$FutuQuant,Tushare,RiceQuant$等</li></ul><h2 id="5-自然语言处理"><a href="#5-自然语言处理" class="headerlink" title="5. 自然语言处理"></a>5. 自然语言处理</h2><ul><li>有监督算法的描述-情绪判断，作者识别</li><li>无监督算法的描述-主题模型，词嵌入</li></ul><h4 id="独热编码（One-Hot）"><a href="#独热编码（One-Hot）" class="headerlink" title="独热编码（One-Hot）"></a>独热编码（One-Hot）</h4><p>主要是采用N位状态寄存器来对N个状态进行编码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing  <br>   <br>enc = preprocessing.OneHotEncoder()  <br>enc.fit([[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>],[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>]])  <br><span class="hljs-comment"># 这里一共有4个数据，3种特征</span><br>   <br>array = enc.transform([[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>]]).toarray()  <br><span class="hljs-comment"># 这里使用一个新的数据来测试</span><br>   <br><span class="hljs-built_in">print</span> (array)   <span class="hljs-comment"># [[ 1  0 | 0  1  0 | 0  0  0  1]]</span><br></code></pre></td></tr></table></figure><h3 id="5-1-词袋模型（bag-of-words）"><a href="#5-1-词袋模型（bag-of-words）" class="headerlink" title="5.1 词袋模型（bag of words）"></a>5.1 词袋模型（bag of words）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> gensim.corpora <span class="hljs-keyword">import</span> Dictionary<br><br>texts = [[<span class="hljs-string">&#x27;human&#x27;</span>,<span class="hljs-string">&#x27;interface&#x27;</span>,<span class="hljs-string">&#x27;computer&#x27;</span>]]<br>dct = Dictionary(texts)<br>dct.add_documents([[<span class="hljs-string">&#x27;cat&#x27;</span>,<span class="hljs-string">&#x27;say&#x27;</span>,<span class="hljs-string">&#x27;moon&#x27;</span>],[<span class="hljs-string">&#x27;dog&#x27;</span>]])<br>dct.doc2bow([<span class="hljs-string">&#x27;dog&#x27;</span>,<span class="hljs-string">&#x27;computer&#x27;</span>,<span class="hljs-string">&#x27;non_existent_word&#x27;</span>])<br><span class="hljs-comment"># output:[(0,1),(6,1)] -&gt; (index,num)</span><br></code></pre></td></tr></table></figure><h4 id="TF-IDF（term-frequency–inverse-document-frequency）"><a href="#TF-IDF（term-frequency–inverse-document-frequency）" class="headerlink" title="TF-IDF（term frequency–inverse document frequency）"></a>TF-IDF（term frequency–inverse document frequency）</h4><p>TF用以评估一字词对于一个文章的重要程度</p><script type="math/tex; mode=display">tf_{i,j}=\frac{n_{i,j}}{\sum _kn_{k,j}}</script><ul><li>$n_{i,j}$ 词 $i$ 在 $j$ 中出现的次数</li></ul><p>IDF用以评估一字词对于一个文章的不相关程度</p><script type="math/tex; mode=display">idf_i = lg\frac{\left|D\right|}{\left|\{j:t_i\in d_j\}\right|}</script><ul><li>$D$ 文章总数</li><li>$\{j:t_i\in d_j\}$ 包含词 $t_i$ 的文件数目</li></ul><script type="math/tex; mode=display">tfidf_{i,j}=tf_{i,j}\times idf_i</script><h4 id="时间转换工具"><a href="#时间转换工具" class="headerlink" title="时间转换工具"></a>时间转换工具</h4><p>用于时间排序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">large_time</span>(<span class="hljs-params">raw_str</span>):<br>    tt = time.strptime(raw_str,<span class="hljs-string">&#x27;%Y-%m-%d&#x27;</span>)<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(tt[<span class="hljs-number">0</span>])*<span class="hljs-number">10000</span>+<span class="hljs-built_in">float</span>(tt[<span class="hljs-number">1</span>])*<span class="hljs-number">100</span>+<span class="hljs-built_in">float</span>(tt[<span class="hljs-number">2</span>])<br><span class="hljs-comment"># time.localtime/time.mktime</span><br><span class="hljs-comment"># 注意冬令时夏令时切换会少一小时</span><br></code></pre></td></tr></table></figure><h4 id="英文文章预处理"><a href="#英文文章预处理" class="headerlink" title="英文文章预处理"></a>英文文章预处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x:x[<span class="hljs-string">&#x27;content&#x27;</span>].upper(),all_text))<br></code></pre></td></tr></table></figure><h4 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> jieba<br>trial_str = <span class="hljs-string">&#x27;该书根据邓小平同志建设有中国特色的社会主义理论，把生产关系的研究与生产力的研究结合起来，把政治经济学与宏观经济学结合起来，把经济运动质的规律性与量的规律性的研究结合起来，形成了一个独具特色的国民经济学的理论体系&#x27;</span><br>r1 = jieba.cut(trial_str)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;/ &quot;</span>.join(r1))<br>r2 = jieba.cut(trial_str,cut_all=<span class="hljs-literal">True</span>) <span class="hljs-comment"># cut_all所有可能</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;/ &quot;</span>.join(r2))<br>jieba.add_word(<span class="hljs-string">&#x27;宏观经济学&#x27;</span>, <span class="hljs-literal">True</span>) <span class="hljs-comment"># 增加新词 防止切开</span><br>jieba.suggest_freq(<span class="hljs-string">&#x27;与量&#x27;</span>, <span class="hljs-literal">False</span>) <span class="hljs-comment"># 降低切割频率</span><br>r1 = jieba.cut(trial_str,HMM=<span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;/ &quot;</span>.join(r1))<br><span class="hljs-comment"># 增加新词典</span><br>jieba.set_dictionary(root_dir+<span class="hljs-string">&#x27;dict.txt.big&#x27;</span>) <span class="hljs-comment"># 官方提供</span><br>jieba.load_userdict(root_dir+<span class="hljs-string">&quot;user_dict.txt&quot;</span>)<br><span class="hljs-comment"># 词 频率 词性(可选)</span><br></code></pre></td></tr></table></figure><h4 id="以防万一，先保存"><a href="#以防万一，先保存" class="headerlink" title="以防万一，先保存"></a>以防万一，先保存</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">all_para = []<br><span class="hljs-keyword">for</span> li <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(ptext)):<br>    cutted = jieba.cut(ptext[li])<br>    all_para.append(<span class="hljs-built_in">list</span>(cutted))<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(root_dir+<span class="hljs-string">&#x27;sub_cutted&#x27;</span>+ <span class="hljs-string">&#x27;.json&#x27;</span>,<span class="hljs-string">&#x27;wb+&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    f.write(json.dumps(all_para).encode(<span class="hljs-string">&#x27;utf-8&#x27;</span>))<br></code></pre></td></tr></table></figure><h4 id="添加停用词"><a href="#添加停用词" class="headerlink" title="添加停用词"></a>添加停用词</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">stwf = <span class="hljs-built_in">open</span>(root_dir+<span class="hljs-string">&#x27;stop_words.txt&#x27;</span>,<span class="hljs-string">&#x27;r&#x27;</span>,encoding = <span class="hljs-string">&#x27;utf-8&#x27;</span>)<br>stset = stwf.readlines()<br>stop_words = []<br><span class="hljs-keyword">for</span> sti <span class="hljs-keyword">in</span> stset[:-<span class="hljs-number">1</span>]:<br>    stop_words.append(sti[:-<span class="hljs-number">1</span>])<br>stoplist = <span class="hljs-built_in">set</span>(stop_words)<br><span class="hljs-comment"># 开始去除</span><br>texts = [[word <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> doc <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stoplist]<br>         <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> all_para]<br></code></pre></td></tr></table></figure><h4 id="去除低频词"><a href="#去除低频词" class="headerlink" title="去除低频词"></a>去除低频词</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict<br>frequency = defaultdict(<span class="hljs-built_in">int</span>)<br><span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> texts:<br>    <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> text:<br>        frequency[token] += <span class="hljs-number">1</span><br>            <br>texts = [[token <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> text <span class="hljs-keyword">if</span> frequency[token] &gt; <span class="hljs-number">1</span>]<br>         <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> texts]<br></code></pre></td></tr></table></figure><h4 id="小容量储存"><a href="#小容量储存" class="headerlink" title="小容量储存"></a>小容量储存</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> gensim <span class="hljs-keyword">import</span> corpora, models, similarities<br>dic = corpora.Dictionary(texts)<br><span class="hljs-built_in">print</span>(dic.token2id)<br>dic.save(root_dir+<span class="hljs-string">&#x27;sub_rmrb.dict&#x27;</span>) <span class="hljs-comment"># 向前兼容</span><br></code></pre></td></tr></table></figure><h4 id="转为语料格式"><a href="#转为语料格式" class="headerlink" title="转为语料格式"></a>转为语料格式</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> gensim.corpora <span class="hljs-keyword">import</span> MmCorpus<br>corpus = [dic.doc2bow(text) <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> texts]<br>output_fname = root_dir+<span class="hljs-string">&#x27;sub_rmrb.mm&#x27;</span><br>MmCorpus.serialize(output_fname, corpus)<br></code></pre></td></tr></table></figure><h4 id="TF-IDF-模型"><a href="#TF-IDF-模型" class="headerlink" title="TF-IDF 模型"></a>TF-IDF 模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> gensim.models <span class="hljs-keyword">import</span> TfidfModel<br>tf_model = TfidfModel(corpus)<br>vector = tf_model[corpus[<span class="hljs-number">0</span>]]<br></code></pre></td></tr></table></figure><p>更多可查看 <a href="https://radimrehurek.com/gensim/">gensim官方网站</a></p><h3 id="5-2-主题模型"><a href="#5-2-主题模型" class="headerlink" title="5.2 主题模型"></a>5.2 主题模型</h3><h4 id="Unigram"><a href="#Unigram" class="headerlink" title="Unigram"></a>Unigram</h4><h5 id="step-1"><a href="#step-1" class="headerlink" title="step 1"></a>step 1</h5><p><img src="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/pic1-3.jpg" alt></p><script type="math/tex; mode=display">p(W)=\prod_{n=1}^Np(w_n)</script><ul><li>$N:$ 文档</li><li>$w:$ 词</li><li>$Unigram$ 认为,每篇文章的词语是从一个独立多项式分布中抽取出来的</li></ul><h5 id="step-2"><a href="#step-2" class="headerlink" title="step 2"></a>step 2</h5><p>引入了一个主题的概念</p><p><img src="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/pic1-4.jpg" alt></p><script type="math/tex; mode=display">p(W)=\sum_zp(z)\prod_{n=1}^Np(w_n|z)</script><ul><li>$z:$ 主题</li></ul><h5 id="step-3"><a href="#step-3" class="headerlink" title="step 3"></a>step 3</h5><p>提出了混合主题，概率潜语义分析（pLSA/pLSI）</p><p><img src="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/pic1-5.jpg" alt></p><script type="math/tex; mode=display">p(d,w_n)=p(d)\sum_zp(w_n|z)p(z|d)</script><h5 id="step-4"><a href="#step-4" class="headerlink" title="step 4"></a>step 4</h5><p>为参数引入先验分布，潜狄利克雷分布（LDA）</p><p><img src="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/pic1-6.jpg" alt></p><ul><li>主题 $z$ 是一个参数为 $\theta$ 的多项式分布，这个参数的先验分布是一个参数为$\alpha$ 的狄利克雷分布</li><li>主题是否包含一个词是一个参数为 $\eta$ 的多项式分布，这个参数的先验分布是一个参数为 $\beta$ 的狄利克雷分布</li><li>如果主题数目为 $K$ ,则 $\alpha = 50/K$ </li><li>如果词数量为 $W$ ,则 $\beta = 200/W $</li></ul><h4 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h4><p>动态主题模型</p><p><img src="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/pic1-7.jpg" alt></p><h4 id="代码部分"><a href="#代码部分" class="headerlink" title="代码部分"></a>代码部分</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> gensim.models <span class="hljs-keyword">import</span> LdaMulticore<br>num_topics = <span class="hljs-number">20</span> <span class="hljs-comment">#主题数</span><br>lda_fst = LdaMulticore(<br>    corpus=corpus, num_topics=num_topics, id2word=dic,<br>    workers=<span class="hljs-number">6</span>, eval_every=<span class="hljs-literal">None</span>, passes=<span class="hljs-number">10</span>, batch=<span class="hljs-literal">True</span><br>)<br><span class="hljs-comment"># 以下步骤仅在Jupyter notebook内显示</span><br><span class="hljs-keyword">import</span> pyLDAvis.gensim<br>pyLDAvis.enable_notebook()<br>vis_sub_10 = pyLDAvis.gensim.prepare(lda_fst, corpus, dic, sort_topics = <span class="hljs-literal">False</span>)<br><br>pyLDAvis.display(vis_sub_10)<br>lda_fst.save(root_dir+<span class="hljs-string">&#x27;tiny_10.lda&#x27;</span>)<br><br><span class="hljs-comment"># 读取的方法</span><br>lda_fst = LdaMulticore.load(<span class="hljs-string">&#x27;tiny_10.lda&#x27;</span>)<br>dic = corpora.Dictionary.load(root_dir+<span class="hljs-string">&#x27;sub_rmrb.dict&#x27;</span>)<br>corpus = MmCorpus(root_dir+<span class="hljs-string">&#x27;sub_rmrb.mm&#x27;</span>)<br><br><span class="hljs-comment"># 某篇文章对应主题的概率,可不用训练集</span><br><span class="hljs-built_in">print</span>(lda_fst.get_document_topics(corpus[<span class="hljs-number">0</span>],minimum_probability=<span class="hljs-number">0.5</span>))<br></code></pre></td></tr></table></figure><p><img src="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/pic1-8.jpg" alt></p><h5 id="主题相关性检验"><a href="#主题相关性检验" class="headerlink" title="主题相关性检验"></a>主题相关性检验</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 官方文档给的代码</span><br><span class="hljs-keyword">from</span> string <span class="hljs-keyword">import</span> punctuation<br><span class="hljs-keyword">from</span> nltk <span class="hljs-keyword">import</span> RegexpTokenizer<br><span class="hljs-keyword">from</span> nltk.stem.porter <span class="hljs-keyword">import</span> PorterStemmer<br><span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> stopwords<br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> fetch_20newsgroups<br>%matplotlib inline<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_difference_plotly</span>(<span class="hljs-params">mdiff, title=<span class="hljs-string">&quot;&quot;</span>, annotation=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Plot the difference between models.</span><br><span class="hljs-string">    Uses plotly as the backend.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">import</span> plotly.graph_objs <span class="hljs-keyword">as</span> go<br>    <span class="hljs-keyword">import</span> plotly.offline <span class="hljs-keyword">as</span> py<br>    annotation_html = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">if</span> annotation <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        annotation_html = [<br>            [<br>                <span class="hljs-string">&quot;+++ &#123;&#125;&lt;br&gt;--- &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-string">&quot;, &quot;</span>.join(int_tokens), <span class="hljs-string">&quot;, &quot;</span>.join(diff_tokens))<br>                <span class="hljs-keyword">for</span> (int_tokens, diff_tokens) <span class="hljs-keyword">in</span> row<br>            ]<br>            <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> annotation<br>        ]<br>    data = go.Heatmap(z=mdiff, colorscale=<span class="hljs-string">&#x27;RdBu&#x27;</span>, text=annotation_html)<br>    layout = go.Layout(width=<span class="hljs-number">950</span>, height=<span class="hljs-number">950</span>, title=title, xaxis=<span class="hljs-built_in">dict</span>(title=<span class="hljs-string">&quot;topic&quot;</span>), yaxis=<span class="hljs-built_in">dict</span>(title=<span class="hljs-string">&quot;topic&quot;</span>))<br>    py.iplot(<span class="hljs-built_in">dict</span>(data=[data], layout=layout))<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_difference_matplotlib</span>(<span class="hljs-params">mdiff, title=<span class="hljs-string">&quot;&quot;</span>, annotation=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Helper function to plot difference between models.</span><br><span class="hljs-string">    Uses matplotlib as the backend.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>    fig, ax = plt.subplots(figsize=(<span class="hljs-number">18</span>, <span class="hljs-number">14</span>))<br>    data = ax.imshow(mdiff, cmap=<span class="hljs-string">&#x27;RdBu_r&#x27;</span>, origin=<span class="hljs-string">&#x27;lower&#x27;</span>)<br>    plt.title(title)<br>    plt.colorbar(data)<br><span class="hljs-keyword">try</span>:<br>    get_ipython()<br>    <span class="hljs-keyword">import</span> plotly.offline <span class="hljs-keyword">as</span> py<br><span class="hljs-keyword">except</span> Exception:<br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment"># Fall back to matplotlib if we&#x27;re not in a notebook, or if plotly is</span><br>    <span class="hljs-comment"># unavailable for whatever reason.</span><br>    <span class="hljs-comment">#</span><br>    plot_difference = plot_difference_matplotlib<br><span class="hljs-keyword">else</span>:<br>    py.init_notebook_mode()<br>    plot_difference = plot_difference_plotly<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> gensim.models <span class="hljs-keyword">import</span> LdaMulticore,LdaModel<br>lda_sub_10 = LdaModel.load(root_dir+<span class="hljs-string">&#x27;sub_10.lda&#x27;</span>)<br>mdiff, annotation = lda_sub_10.diff(lda_sub_10, distance=<span class="hljs-string">&#x27;jaccard&#x27;</span>, num_words=<span class="hljs-number">50</span>)<br>plot_difference(mdiff, title=<span class="hljs-string">&quot;Topic difference (one model) [jaccard distance]&quot;</span>, annotation=annotation)<br></code></pre></td></tr></table></figure><p>当集体颜色偏红，且对角一条为蓝点，则拟合成功</p><p><img src="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/pic1-9.jpg" alt></p><h3 id="5-3-词向量模型"><a href="#5-3-词向量模型" class="headerlink" title="5.3 词向量模型"></a>5.3 词向量模型</h3><ul><li>$Word2vec$ 简单扩展：$doc2vec$</li></ul><h5 id="针对主题"><a href="#针对主题" class="headerlink" title="针对主题"></a>针对主题</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> gensim.models <span class="hljs-keyword">import</span> Word2Vec<br><span class="hljs-comment"># 输入doc2bow之前的texts</span><br>model = Word2Vec(texts, size=<span class="hljs-number">50</span>, window=<span class="hljs-number">5</span>, min_count=<span class="hljs-number">1</span>, workers=-<span class="hljs-number">1</span>)<br><span class="hljs-comment"># workers=-1 ， 最大-1</span><br>model.train(sentences = texts,total_words = <span class="hljs-built_in">len</span>(dic),epochs = <span class="hljs-number">50</span>)<br>model.wv.most_similar(<span class="hljs-string">&quot;中国&quot;</span>)<br><br><span class="hljs-comment"># 保存和读取</span><br>model.save(root_dir+<span class="hljs-string">&#x27;sub.w2v&#x27;</span>)<br>model = Word2Vec.load(root_dir+<span class="hljs-string">&#x27;sub.w2v&#x27;</span>)<br></code></pre></td></tr></table></figure><h5 id="针对文章"><a href="#针对文章" class="headerlink" title="针对文章"></a>针对文章</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> gensim.models.doc2vec <span class="hljs-keyword">import</span> Doc2Vec, TaggedDocument<br>documents = [TaggedDocument(doc, [i]) <span class="hljs-keyword">for</span> i, doc <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(texts)]<br>model = Doc2Vec(documents, size=<span class="hljs-number">50</span>)<br>model.train(sentences = documents,total_examples=<span class="hljs-built_in">len</span>(documents),epochs = <span class="hljs-number">40</span>)<br></code></pre></td></tr></table></figure><h2 id="6-机器学习"><a href="#6-机器学习" class="headerlink" title="6. 机器学习"></a>6. 机器学习</h2><ul><li>公式推导可参考B站另一视频<a href="https://www.bilibili.com/video/BV1aE411o7qd">【机器学习】【白板推导系列】【合集 1～23】</a></li><li>理论知识可阅读 林轩田机器学习基石 (本视频采用课件来源)+西瓜书+<a href="https://www.jianshu.com/p/0800a33fd86e">ESL</a></li></ul><h3 id="6-1-一些概念"><a href="#6-1-一些概念" class="headerlink" title="6.1 一些概念"></a>6.1 一些概念</h3><h4 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h4><ul><li>有监督 : 有标签的数据，人能指出的</li><li>无监督 : 无标签的数据，理论上无法给出完美答案</li><li>半监督 : 部分数据带标签, 如部分带标签的情绪识别</li><li>强化学习 : 含隐藏标签</li></ul><h4 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h4><ul><li>$Batch$ 批处理 : 一次性训练所有数据</li><li>$Online$ : 一批一批使用数据</li><li>$Mini-batch$ : 以上两者结合</li><li>$Active Learning$ : 机器自己选择需要的数据</li></ul><h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><ul><li>特征数据 : 有具体的含义</li><li>原始数据 : 图像声音本身</li><li>抽象数据 : 无意义的$UID$，主成分，其他中间结果</li></ul><h4 id="大数定律"><a href="#大数定律" class="headerlink" title="大数定律"></a>大数定律</h4><p>由于不可能真正地存在完整的数据，输入数据$E_{in}(simple)$和真正完美的数据$E_{out}$ 必然存在误差；由于大数定理，及霍夫丁不等式 $(Hoeffding’s  inequality)$ 得</p><script type="math/tex; mode=display">\mathbb{P}[|E_{in}(h)-E_{out}(h)|>\epsilon]\leq 2exp(-2\epsilon^2N)</script><p>如果$|E_{in}(h)-E_{out}(h)|$ 过大，则为坏数据</p><p>当存在$Breakpoint$, 则增长函数存在上限, 得$Vapnik-Chervonenkis (VC) bound$</p><script type="math/tex; mode=display">\mathbb{P}[\exist h\in \mathcal{H} s.t.|E_{in}(h)-E_{out}(h)|>\epsilon]\leq 4(2N)^{k-1}exp(-\frac{1}{8}\epsilon^2N)</script><p>因此，机器学习不仅要使$E_{in}$的误差尽量小，还需要使$E_{in}(h) \approx E_{out}(h)$ ；对此需要求得 $dvc (OLS，线性中为变量+1)$ , $N = 10 dvc$</p><h3 id="6-2-线性回归"><a href="#6-2-线性回归" class="headerlink" title="6.2 线性回归"></a>6.2 线性回归</h3><ul><li>$Lasso$ 和 岭回归 此类带正则的通常不是无偏， 而计量经济中多为对系数的解释，通常不用此方法</li><li>超参数（$hyperparameter$）</li></ul><h3 id="6-3-SVM-Support-Vector-Machine"><a href="#6-3-SVM-Support-Vector-Machine" class="headerlink" title="6.3 SVM (Support Vector Machine)"></a>6.3 SVM (Support Vector Machine)</h3><ul><li><p>$fewer  dichotomies \to smaller  ‘VC  dim’$</p></li><li><p>$SVM$ 虽然不是无偏的，但 $B$ 变量可大于 $N$ 样本量</p></li><li><p>$CV(Cross-Validation)$ 交叉验证，可用 $K-Fold$ $(sklearn包)$</p></li><li>反向扩充(基础)<ul><li>$PLA(perceptron  learning  algorithm)$ -&gt; $Pocket$算法 (前者改进)</li><li>$KNN(k-NearestNeighbor)$</li></ul></li></ul><h3 id="6-4-决策树-Decision-Tree"><a href="#6-4-决策树-Decision-Tree" class="headerlink" title="6.4 决策树 (Decision Tree)"></a>6.4 决策树 (Decision Tree)</h3><h4 id="节点选择-切分策略"><a href="#节点选择-切分策略" class="headerlink" title="节点选择/切分策略"></a>节点选择/切分策略</h4><ul><li>$ID3$算法，选择信息熵增大的最优算法</li><li>$C4.5$算法，选择信息增益比最大的切分点，限制了$ID3$多切带来的过拟合</li><li>$CART$算法，每一步切分使得数据正确率提升最多</li></ul><h4 id="停止切分"><a href="#停止切分" class="headerlink" title="停止切分"></a>停止切分</h4><ul><li>剩余数据$y$相同</li><li>剩余数据$x$相同</li><li>设定最小收益值</li></ul><h4 id="决策树的正则化"><a href="#决策树的正则化" class="headerlink" title="决策树的正则化"></a>决策树的正则化</h4><ul><li>剪枝，减去几个带来收益最小的分叉节点</li><li>$Early Stopping$，提升停止的最小值阈值</li><li>限制树高</li></ul><h4 id="实操建议"><a href="#实操建议" class="headerlink" title="实操建议"></a>实操建议</h4><ul><li>特征数量大容易过拟合</li><li>应预先进行维度压缩 $(PCA,ICA)$</li><li>对不同树的构建方法应有了解</li><li>提前将样本调平<ul><li>把劣势数据复制多份</li></ul></li></ul><h4 id="融合算法-Blending​"><a href="#融合算法-Blending​" class="headerlink" title="融合算法 (Blending​)"></a>融合算法 (Blending​)</h4><ul><li>$t = 1,2,3…T$</li><li>$D_t$ : the data at time $t$</li><li>Obtain $g_t$ by $A(D)$</li></ul><script type="math/tex; mode=display">\bar{g} = \lim_{T \to \infty} G = \lim_{T \to \infty} \frac{1}{T}\sum_{t=1}^Tg_t = \varepsilon A(D)</script><h4 id="Bootstrap-Aggregation-Bagging"><a href="#Bootstrap-Aggregation-Bagging" class="headerlink" title="Bootstrap Aggregation (Bagging)"></a>Bootstrap Aggregation (Bagging)</h4><p>在$Size$为$N$的数据里面抽$N’$个数据作为第一个子样本，放回去，再抽$N’$个数据作为第二个子样本</p><h4 id="随机森林-Random-Forest"><a href="#随机森林-Random-Forest" class="headerlink" title="随机森林 (Random Forest)"></a>随机森林 (Random Forest)</h4><script type="math/tex; mode=display">Random \ Forest = Bagging + Decision \ Tree</script><h4 id="Out-of-Bag"><a href="#Out-of-Bag" class="headerlink" title="Out of Bag"></a>Out of Bag</h4><ul><li>当数据足够大时，一定有约等于 $\frac{1}{e}$的数据没有被抽取到</li></ul><script type="math/tex; mode=display">(1-\frac{1}{N})^N = \frac{1}{(\frac{N}{N-1})^N} = \frac{1}{(1+\frac{1}{N-1})^N}\approx \frac{1}{e}</script><ul><li>样本外数据可以用于 对$G$的$Validation$<ul><li>$G_N^-(x)=average(g_{没被用到的t})$</li><li>$E_{oob}(G)=\frac{1}{N}\sum_{n=1}^Nerr(y_n,G_n^-(x_n))$</li></ul></li></ul><h4 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h4><ul><li>变量重要性筛选 $permutation$ : 把变量打乱，$x_1 \to y_5$ ，差距越大越重要<ul><li>对于$Dummy Variable$ 这种方法肯能会低估，因为打乱不充足</li></ul></li></ul><h4 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h4><ul><li>计算$E_{in}$的时候，减少对做错过的$g_t$的$err$的权重<ul><li>所有做错的权重只占1/2</li><li>当错$=n_1$，对$=n_2$<ul><li>$incorrect: u_n^{(t)}·n_2 \to u_n^{(t+1)}$</li><li>$correct: u_n^{(t)}·n_1 \to u_n^{(t+1)}$</li></ul></li><li>$\epsilon_t = \frac{\sum_{n=1}^N u_n^{(t)}[y_n \neq g_t(x_n)]}{\sum_{n=1}^N u_n^{(t)}}$，$\Diamond_t=\sqrt\frac{1-\epsilon_t}{\epsilon_t}$，$\alpha_t=ln(\Diamond_t)$<ul><li>$incorrect: u_n^{(t)}·\Diamond_t \to u_n^{(t+1)}$</li><li>$correct: u_n^{(t)}/\Diamond_t \to u_n^{(t+1)}$</li><li>$G(x)=sign(\sum_{t=1}^T\alpha_tg_t(x))$</li></ul></li></ul></li><li>决策树中，在再抽样的步骤完成$u^{(t)}\to u^{(t+1)}$的变换（复制多份）</li><li>对于连续值：$GradientBoost$</li></ul><h3 id="6-5-编程的流程"><a href="#6-5-编程的流程" class="headerlink" title="6.5 编程的流程"></a>6.5 编程的流程</h3><ul><li>数据的准备<ul><li>数据的获取与存储方式</li><li>数据的标签化（特征化）</li><li>数据的清洗与预处理</li></ul></li><li>方法的选择<ul><li>合适的方法</li><li>合适的超参数</li><li>编程实现</li></ul></li><li>工程流水线<ul><li>标准流程</li><li>训练、测试集切分</li><li>正确的评价</li></ul></li><li>结果呈现<ul><li>表达准确</li><li>易于理解</li><li>飒</li></ul></li></ul><p>( 编程包 $sklearn$ )</p><h2 id="7-深度学习"><a href="#7-深度学习" class="headerlink" title="7 深度学习"></a>7 深度学习</h2><h3 id="7-1-基础部分"><a href="#7-1-基础部分" class="headerlink" title="7.1 基础部分"></a>7.1 基础部分</h3><ul><li>对元和层的理解<ul><li>单元数表达更细致的切分</li><li>多层表达更复杂的非线性组合方式</li></ul></li><li>$Sigmoid$<ul><li>代替$sign$求导</li><li>$S(x)=\frac{1}{1+e^{-x}}$</li><li>$S’(x)=\frac{e^{-x}}{(1+e^{-x})^2}=S(x)(1-S(x))$</li></ul></li><li>$VC-dimension$<ul><li>$V = $神经元的数量， $D = $权重的数量 （前一个元数$+1$再乘后一个元数）</li></ul></li><li>正则化<ul><li>$L2$正则， 由于$sign$中心趋近0，且为了保持可导，通常用其他方法</li><li>$Early Stopping$</li><li>加入白噪音</li><li>$Dropout$</li></ul></li><li>发展进程<ul><li>$BP$神经网络（1986，$Hinton$）</li><li>手写体识别（1989，$LeCun$）</li><li>预处理 ：权重训练方法的革新（2007，$Bengio$）</li><li>正式提出$CNN$（2012，$Hinton$）<ul><li>图像分类，输入的是$3(RGB)\times224\times224$ (三维张量$tensor$)</li></ul></li></ul></li></ul><h3 id="7-2-卷积神经网络（CNN）"><a href="#7-2-卷积神经网络（CNN）" class="headerlink" title="7.2 卷积神经网络（CNN）"></a>7.2 卷积神经网络（CNN）</h3><h4 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h4><ul><li>$input$为一个矩阵</li><li>同时设定一个$filter$作为特征，和$step$值作为每次平移的步长</li><li>$input$最左上角切割出一个同$filter$同大小的矩阵，并与其相乘，得到$output$中的第一块</li><li>按照步长平移最终得到完整的$output$</li></ul><p><img src="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/pic1-10.jpeg" alt></p><ul><li>卷积神经网络中会取一个值$b$，$output=sign(output-b)$</li><li>达到了<strong>稀疏连接</strong>与<strong>参数共享</strong>的效果</li></ul><h4 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h4><ul><li>把数据变小，并保留最敏感的数$（Max Pooling）$</li><li>对应可放大缩小的性质</li></ul><h4 id="扩充"><a href="#扩充" class="headerlink" title="扩充"></a>扩充</h4><ul><li>根据图片的特性推断，卷积神经网络适用于拥有以下特征的某些事物<ul><li>小特征决定</li><li>放缩旋转存在</li><li>放大缩小不改变性质</li></ul></li><li>不够数据的时候可以补0​</li></ul><h3 id="7-3-循环神经网络（RNN）"><a href="#7-3-循环神经网络（RNN）" class="headerlink" title="7.3 循环神经网络（RNN）"></a>7.3 循环神经网络（RNN）</h3><ul><li>把握时序特征（$Recurrent NN$）<ul><li>隐藏层有一个循环</li><li>历史输出端作为隐藏层的元素</li><li>双向$RNN$</li></ul></li><li>当权重$w$跨过1的临界值时，如果迭代次数大，会有一个断崖式的变化，解决方法：<ul><li>$Clipping$<ul><li>$(2013,Pascanu)$</li></ul></li><li>$Long  Short-Term  Memory$<ul><li>$(1997,Sepp  Hochreiter \&amp; Jurgen  Schmidhuber)$</li><li>建立遗忘门</li></ul></li></ul></li></ul><h3 id="7-4-聚类算法"><a href="#7-4-聚类算法" class="headerlink" title="7.4 聚类算法"></a>7.4 聚类算法</h3><h4 id="算法总览"><a href="#算法总览" class="headerlink" title="算法总览"></a>算法总览</h4><p><img src="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/pic1-11.jpg" alt></p><div class="table-container"><table><thead><tr><th>Method name</th><th>Parameters</th><th>Scalability</th><th>Usecase</th><th>Geometry (metric used)</th></tr></thead><tbody><tr><td><a href="https://scikit-learn.org/stable/modules/clustering.html#k-means">K-Means</a></td><td>number of clusters</td><td>Very large <code>n_samples</code>, medium <code>n_clusters</code> with <a href="https://scikit-learn.org/stable/modules/clustering.html#mini-batch-kmeans">MiniBatch code</a></td><td>General-purpose, even cluster size, flat geometry, not too many clusters</td><td>Distances between points</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/clustering.html#affinity-propagation">Affinity propagation</a></td><td>damping, sample preference</td><td>Not scalable with n_samples</td><td>Many clusters, uneven cluster size, non-flat geometry</td><td>Graph distance (e.g. nearest-neighbor graph)</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/clustering.html#mean-shift">Mean-shift</a></td><td>bandwidth</td><td>Not scalable with <code>n_samples</code></td><td>Many clusters, uneven cluster size, non-flat geometry</td><td>Distances between points</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/clustering.html#spectral-clustering">Spectral clustering</a></td><td>number of clusters</td><td>Medium <code>n_samples</code>, small <code>n_clusters</code></td><td>Few clusters, even cluster size, non-flat geometry</td><td>Graph distance (e.g. nearest-neighbor graph)</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering">Ward hierarchical clustering</a></td><td>number of clusters or distance threshold</td><td>Large <code>n_samples</code> and <code>n_clusters</code></td><td>Many clusters, possibly connectivity constraints</td><td>Distances between points</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering">Agglomerative clustering</a></td><td>number of clusters or distance threshold, linkage type, distance</td><td>Large <code>n_samples</code> and <code>n_clusters</code></td><td>Many clusters, possibly connectivity constraints, non Euclidean distances</td><td>Any pairwise distance</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/clustering.html#dbscan">DBSCAN</a></td><td>neighborhood size</td><td>Very large <code>n_samples</code>, medium <code>n_clusters</code></td><td>Non-flat geometry, uneven cluster sizes</td><td>Distances between nearest points</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/clustering.html#optics">OPTICS</a></td><td>minimum cluster membership</td><td>Very large <code>n_samples</code>, large <code>n_clusters</code></td><td>Non-flat geometry, uneven cluster sizes, variable cluster density</td><td>Distances between points</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/mixture.html#mixture">Gaussian mixtures</a></td><td>many</td><td>Not scalable</td><td>Flat geometry, good for density estimation</td><td>Mahalanobis distances to  centers</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/clustering.html#birch">Birch</a></td><td>branching factor, threshold, optional global clusterer.</td><td>Large <code>n_clusters</code> and <code>n_samples</code></td><td>Large dataset, outlier removal, data reduction.</td><td>Euclidean distance between points</td></tr></tbody></table></div><h2 id="7-5-PCA"><a href="#7-5-PCA" class="headerlink" title="7.5 PCA"></a>7.5 PCA</h2><p>将数据投射为波动最大的$n$维</p><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul><li>缓解维度灾难，提高可视度</li><li>降噪，提高模型稳定性</li><li>特征独立</li><li>可以对数据进行放缩（各向同性）</li></ul><h4 id="风险"><a href="#风险" class="headerlink" title="风险"></a>风险</h4><ul><li>$PCA$的根据源于训练集，可能会过拟合</li><li>如果在训练数据进行了放缩，那么测试集要进行同参数的$mean-shift$和$variance$</li><li>不要先放缩再分割样本</li></ul><h4 id="Auto-Encoder"><a href="#Auto-Encoder" class="headerlink" title="Auto-Encoder"></a>Auto-Encoder</h4><ul><li>输入输出长度相等</li><li>扩展：$Denoising  AutoEncoder$</li></ul><h3 id="7-6-生成模型"><a href="#7-6-生成模型" class="headerlink" title="7.6 生成模型"></a>7.6 生成模型</h3><ul><li>$GAN   Generative  Adversarial  Network$<ul><li>人脸生成</li><li>图片上色</li><li>照片补充</li><li>根据文字生成图片</li></ul></li></ul><h2 id="8-特征工程"><a href="#8-特征工程" class="headerlink" title="8 特征工程"></a>8 特征工程</h2><p>从数据到变量</p><h3 id="8-1-结构化与缺失值"><a href="#8-1-结构化与缺失值" class="headerlink" title="8.1 结构化与缺失值"></a>8.1 结构化与缺失值</h3><h4 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h4><ul><li>先思考缺失本身是不是就是一种信息<ul><li>确保缺失是纯随机的</li><li>缺失是在哪个环境造成的<ul><li>原始收集环节/采集环节/清洗环节</li></ul></li></ul></li><li>是否可以承担删变量带来的风险<ul><li>主要变量与控制变量，应该补上</li><li>其他缺失如果超过阈值（一般为60%），应该删去</li></ul></li><li>处理方法<ul><li>$Sklearn 6.4$ 专门用于缺失值处理</li><li>单变量填充（固定值，统计值）</li><li>多变量填充，近邻填充</li><li>先分割再填充</li></ul></li></ul><h4 id="结构化"><a href="#结构化" class="headerlink" title="结构化"></a>结构化</h4><ul><li>数据<ul><li>分类信息：性别，学历</li><li>文本信息：$one-hot$</li></ul></li><li>$Encoding$<ul><li>$Ordinary  encoder$<ul><li>0,1,2;</li></ul></li><li>$one-hot  encoder$<ul><li>类似计量中的方法：$FixedEffect$</li><li>0,1 ; 0,1 ; 0,1 ;</li></ul></li></ul></li><li>$Embedding$ ： 嵌入<ul><li>$Doc2vec$：每一段（篇）文章一个向量</li><li>$Glove$：考虑上下文窗口之外的其他文本</li><li>$Elmo$：考虑不同文本在不同环境下的变义</li><li>图片嵌入<ul><li>$VAE(variation  auto-encoder)$</li></ul></li></ul></li></ul><h3 id="8-2-改变分布"><a href="#8-2-改变分布" class="headerlink" title="8.2 改变分布"></a>8.2 改变分布</h3><p>正则项和系数有关系，而系数又和数据有关系，所以要先做标准化</p><p>树方法的正则化不是来自于对系数的惩罚，可省略</p><h4 id="前奏"><a href="#前奏" class="headerlink" title="前奏"></a>前奏</h4><ul><li><p>清洗异常值</p></li><li><p>变形，删除极端值（$winsor$)</p></li></ul><h4 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h4><ul><li><p>（变量-均值）/标准差</p></li><li><p>测试集的标准化按训练集来</p></li><li><p>$preprocessing.StandardScaler()+scaler.transform()$</p></li><li><p>其他类似处理</p><ul><li>$MinMaxScaler$</li><li>$MaxAbsScaler$</li></ul></li></ul><h4 id="非线性变化：不惜一切变正态分布"><a href="#非线性变化：不惜一切变正态分布" class="headerlink" title="非线性变化：不惜一切变正态分布"></a>非线性变化：不惜一切变正态分布</h4><ul><li><p>方法</p><ul><li>$Box-Cox$</li><li>$Yeo-Johnson$</li><li>$Quantile  transform$</li></ul></li><li><p>可以 $Lognormal，Ohi-squared，Weibull$</p></li><li><p>不建议 $Gaussian，Uniform，Bimodal$，会损失信息</p></li><li><p>改进了线性模型的预测能力</p><ul><li>看$R^2$和$MAE$</li></ul></li></ul><h4 id="连续值变成分段值"><a href="#连续值变成分段值" class="headerlink" title="连续值变成分段值"></a>连续值变成分段值</h4><ul><li><p>增强稳健性：对异常值和非线性</p></li><li><p>试用于分类算法：信用风险模型，征信模型</p></li><li><p>$preprocessing.KBinsDiscretizer()$</p></li></ul><h3 id="8-3-变量选择"><a href="#8-3-变量选择" class="headerlink" title="8.3 变量选择"></a>8.3 变量选择</h3><p>$sklearn.feature_selection$</p><h4 id="为什么"><a href="#为什么" class="headerlink" title="为什么"></a>为什么</h4><ul><li>方法制约</li><li>解释制约</li><li>预测制约</li><li>实践制约</li></ul><h4 id="单变量选择"><a href="#单变量选择" class="headerlink" title="单变量选择"></a>单变量选择</h4><p>单纯地从一个变量数据的分布进行筛选：$variation$大</p><ul><li>$VarianceThreshold$：$variance$大于某值的</li><li>$SelectKBest$：筛选$K$个$variance$最高</li><li>$SelectPercentile$：筛选高于某个阈值的<ul><li>用于回归方法的分布：$f_regression,mutual_info_regression$</li><li>用于分类方法的分布：$chi2,f_classif,mutual_info_classif$</li></ul></li></ul><h4 id="多变量选择"><a href="#多变量选择" class="headerlink" title="多变量选择"></a>多变量选择</h4><p>多次共线性的影响</p><ul><li>方差膨胀系数（$variance inflation factor$）<ul><li>$VIF_i = \frac{1}{1-R_i^2}$</li><li>当$VIF&gt;10(or 5)$时，可以删去</li><li>当变量比较重要，删去与它相关的变量</li></ul></li></ul><h4 id="算法选择"><a href="#算法选择" class="headerlink" title="算法选择"></a>算法选择</h4><p>最稳健的方法</p><ul><li>$SelectFromModel$ 统一接口</li><li>后台算法<ul><li>$L1-based$</li><li>$Support vector based$</li><li>$Tree based$</li></ul></li></ul><h3 id="8-4-实践：金融风控"><a href="#8-4-实践：金融风控" class="headerlink" title="8.4 实践：金融风控"></a>8.4 实践：金融风控</h3><ul><li>方法基础：评分卡模型，逻辑回归</li><li>变量处理：离散化</li><li>变量筛选：单变量，多变量</li><li>重要方法：$WOE$与$IV$<ul><li>$WOE_i = ln(\frac{py_i}{pn_i}) = ln(\frac{y_i/y_T}{n_i/n_T}) = ln(\frac{y_i/n_i}{y_T/n_T})$</li><li>$IV_i = (py_i-pn_i)*WOE_i$</li><li>$i = 1$ 是男生</li><li>$py_1 ： $男生违约占比</li><li>$pn_1 ： $男生不违约占比</li><li>$y_1 : $男生违约数量</li><li>$n_1 : $男生不违约数量</li><li>$y_T : $总体违约数量</li><li>$n_T : $总体不违约数量</li></ul></li></ul><div class="table-container"><table><thead><tr><th>IV范围</th><th>预测效果</th><th>英文描述</th></tr></thead><tbody><tr><td>&lt;0.02</td><td>几乎没有</td><td>Useless for prediction</td></tr><tr><td>0.02~0.1</td><td>弱</td><td>Weak predictor</td></tr><tr><td>0.1~0.3</td><td>中等</td><td>Medium predictor</td></tr><tr><td>0.3~0.5</td><td>强</td><td>Strong predictor</td></tr><tr><td>&gt;0.5</td><td>难以置信</td><td>Suspicious or too good to be true</td></tr></tbody></table></div><h2 id="9-训练框架"><a href="#9-训练框架" class="headerlink" title="9 训练框架"></a>9 训练框架</h2><h3 id="9-1-度量指标：二分类问题"><a href="#9-1-度量指标：二分类问题" class="headerlink" title="9.1 度量指标：二分类问题"></a>9.1 度量指标：二分类问题</h3><h4 id="一个标准"><a href="#一个标准" class="headerlink" title="一个标准"></a>一个标准</h4><p><img src="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/pic1-12.jpg" alt></p><h5 id="四个定义（数据-模型）"><a href="#四个定义（数据-模型）" class="headerlink" title="四个定义（数据-模型）"></a>四个定义（数据-模型）</h5><ul><li>$True-positives$：数据+，模型+</li><li>$False-positives$：数据-，模型+</li><li>$False-negatives$：数据+，模型-</li><li>$True-negatives$：数据-，模型-</li></ul><h5 id="两个公式"><a href="#两个公式" class="headerlink" title="两个公式"></a>两个公式</h5><ul><li>$Precision = True-positives$/ 模型+</li><li>$Recall = True-positives$/ 数据+</li></ul><h5 id="一个指标：F1-score"><a href="#一个指标：F1-score" class="headerlink" title="一个指标：F1_score"></a>一个指标：F1_score</h5><script type="math/tex; mode=display">F_1 = (\frac{2}{recall^{-1}+precision^{-1}})=2·\frac{precision·recall}{precision+recall}</script><h4 id="另一个标准：ROC曲线与ROC面积（AUROC）"><a href="#另一个标准：ROC曲线与ROC面积（AUROC）" class="headerlink" title="另一个标准：ROC曲线与ROC面积（AUROC）"></a>另一个标准：ROC曲线与ROC面积（AUROC）</h4><p><img src="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/pic1-13.jpg" alt></p><h5 id="两个指标"><a href="#两个指标" class="headerlink" title="两个指标"></a>两个指标</h5><ul><li>真正例率（$TPR$）：召回的同义词 ，$sensitivity$<ul><li>$TPR = \frac{TP}{TP+FN}$</li></ul></li><li>假正例率（$FPR$）$specifity$<ul><li>$FPR = \frac{FP}{FP+TN}$</li></ul></li></ul><h4 id="扩展：多分类问题"><a href="#扩展：多分类问题" class="headerlink" title="扩展：多分类问题"></a>扩展：多分类问题</h4><ul><li>三个指标：F1_micro，F1_macro，F1_weighted</li></ul><h3 id="9-2-度量指标：回归"><a href="#9-2-度量指标：回归" class="headerlink" title="9.2 度量指标：回归"></a>9.2 度量指标：回归</h3><ul><li>$MAE = \frac{1}{N}\sum_{t=1}^N|y_i-\hat{y}|$</li><li>$MSE = \frac{1}{N}\sum_{t=1}^N(y_i-\hat{y})^2$</li><li>$RMSE = \sqrt{MSE}$</li><li>$R^2 = 1-\frac{\sum(y_i-\hat{y})^2}{\sum(y_i-\bar{y})^2} = 1-\frac{MSE(\hat{y},y)}{Var(y)}$</li></ul><h3 id="9-3-超参搜寻"><a href="#9-3-超参搜寻" class="headerlink" title="9.3 超参搜寻"></a>9.3 超参搜寻</h3><h4 id="搜索方法"><a href="#搜索方法" class="headerlink" title="搜索方法"></a>搜索方法</h4><ul><li>$Grid Layout$</li><li>$Random Layout$</li><li>步骤<ul><li>阅读论文找范围</li><li>不同尺度的$Grid Layout$</li><li>$Random Layout$</li></ul></li><li>暴力手段之外<ul><li>$Model specific cross-validation$</li><li>$AIC，BIC$</li><li>$Out of Bag Estimates$</li></ul></li></ul><h3 id="9-4-交叉验证"><a href="#9-4-交叉验证" class="headerlink" title="9.4 交叉验证"></a>9.4 交叉验证</h3><p>$sklearn.model_selection$</p><h4 id="数据切割"><a href="#数据切割" class="headerlink" title="数据切割"></a>数据切割</h4><ul><li><p>训练数据（7）验证数据（2）测验数据（1）</p></li><li><p>时间上的泄漏：注意时序数据中途没有被其他情况影响</p></li><li>数据分组上的泄漏：一家人不能分开处理</li><li>统计特征上的泄漏：先分割后处理</li></ul><h4 id="怎么划分"><a href="#怎么划分" class="headerlink" title="怎么划分"></a>怎么划分</h4><p><img src="/2021/04/14/%E9%87%91%E8%9E%8D%E7%A7%91%E6%8A%80%E5%B7%A5%E5%85%B7%E7%AE%B1/pic1-14.jpeg" alt></p><ul><li>$KFold$</li><li>随机抽取 = $ShuffleSplit$</li><li>抽取时要保证类别间的平衡$= StratifiedShuffleSplit$</li><li>当有小组时 $= GroupKFold$</li><li>当有时间存在，训练集必须早于验证集 = $TimeSeriesSplit$</li></ul><h2 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h2><ol><li><p>问题提出</p></li><li><p>文献搜集</p><ul><li>做过吗</li><li>怎么做</li><li>与课题有何差别</li><li>能改什么方法</li></ul></li><li>数据搜集<ul><li>典型数据库</li><li>特异数据源</li><li>数据更新管理</li><li>成本控制</li></ul></li><li>特征工程<ul><li>抽取哪些变量</li><li>生成那些指标</li><li>是否要改特征</li><li>是否能改特征</li></ul></li><li>模型选择<ul><li>符合假设</li><li>能力优化</li><li>容易解释</li><li>开销合理</li></ul></li><li>模型优化<ul><li>变量</li><li>结构</li><li>超参数</li><li>训练技巧</li></ul></li><li>结构呈现<ul><li>数据可视化</li><li>关键词提炼</li><li>模型更新策略</li><li>边界与预警</li></ul></li></ol><hr><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://www.bilibili.com/video/BV1DE411y7nz">金融科技工具箱——面向经管金融同学的Python、爬虫、机器学习课</a></li><li><a href="https://zhuanlan.zhihu.com/p/65511873">文本挖掘从小白到精通（二）—-语料库和词向量空间</a></li><li><a href="https://www.bilibili.com/video/BV1Cx411i7op?p=1">林轩田机器学习基石(国语)</a></li><li><a href="https://scikit-learn.org/stable/modules/clustering.html#clustering">scikit-learn</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Web Crawler</tag>
      
      <tag>Natural Language Processing</tag>
      
      <tag>Machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【留言板置顶】</title>
    <link href="/2021/03/17/%E7%95%99%E8%A8%80%E6%9D%BF%E7%BD%AE%E9%A1%B6/"/>
    <url>/2021/03/17/%E7%95%99%E8%A8%80%E6%9D%BF%E7%BD%AE%E9%A1%B6/</url>
    
    <content type="html"><![CDATA[<h4 id="本站是学习笔记专用博客，为了方便查阅过去所学知识所用，不怎么正式且各种省略，可能会有许多笔误，欢迎大家指正讨论。"><a href="#本站是学习笔记专用博客，为了方便查阅过去所学知识所用，不怎么正式且各种省略，可能会有许多笔误，欢迎大家指正讨论。" class="headerlink" title="本站是学习笔记专用博客，为了方便查阅过去所学知识所用，不怎么正式且各种省略，可能会有许多笔误，欢迎大家指正讨论。"></a>本站是学习笔记专用博客，为了方便查阅过去所学知识所用，不怎么正式且各种省略，<del>可能</del>会有许多笔误，欢迎大家指正讨论。</h4><span id="more"></span><h2 id="公告"><a href="#公告" class="headerlink" title="公告"></a>公告</h2><ol><li>留言板功能暂停，如有问题请加我微信。微信二维码在 ABOUT 页面。</li><li>数学公式插件因为重装导致之前的公式显示异常，需要更换。但如果所有公式都无法正常显示，可能是被浏览器阻止了 JS 加载，请允许网站加载 JS 后刷新页面。</li></ol><h2 id="更多资料连接"><a href="#更多资料连接" class="headerlink" title="更多资料连接"></a>更多资料连接</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/106318956?from_voters_page=true">高等数学公式大全</a></li><li><a href="https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/">Top 50 matplotlib Visualizations</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>【Others】</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Blog</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【推导】Feynman-Kac To Black-Scholes-PDE</title>
    <link href="/2021/03/14/Feynman-Kac_To_Black-Scholes-PDE/"/>
    <url>/2021/03/14/Feynman-Kac_To_Black-Scholes-PDE/</url>
    
    <content type="html"><![CDATA[<blockquote><p>首先对Feynman-Kac theorem进行基本函数定义，推导并证明基本特性;</p><p>其次，展示五个版本的Black-Scholes-PDE推导，前三个采用了Feynman-Kac theorem，但是给的公式都不相同，后两个用的配无风险组合；</p></blockquote><span id="more"></span><h1 id="Feynman-Kac-theorem"><a href="#Feynman-Kac-theorem" class="headerlink" title="Feynman-Kac theorem"></a>Feynman-Kac theorem</h1><blockquote><p>Cox-Ross-Robinsten 决定的 u and d</p></blockquote><p>基于B站 <a href="https://space.bilibili.com/275959084">Jerry Xu</a> 视频的笔记</p><p><strong>衍生品的 Probabilistic model</strong></p><script type="math/tex; mode=display">\mathbb{E}^\mathbb{Q}[e^{-r(T-t)}F(S_T)|\mathcal{F}_t]=u(t,x)</script><p>where $F(·):$ payoff, $u(t,x) :$ value at time t </p><p><strong>衍生品的 Partial differential equation</strong></p><script type="math/tex; mode=display">\frac{\partial u}{\partial t}+rx\frac{\partial u}{\partial x}+\frac{1}{2}\sigma^2x^2\frac{\partial^2 u}{\partial x^2}=rx</script><p><strong>Feynman-Kac theorem</strong> 将两者联系起来，只要两者知一，就能知道另一个</p><h3 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h3><p><strong>Kronecker delta（克罗内克函数）</strong></p><script type="math/tex; mode=display">\delta_{ij}=\begin{cases}0&,i\ne j\\1&,i=j\end{cases}</script><p><strong>股票价值</strong></p><script type="math/tex; mode=display">\overrightarrow{X}_t=(x_t^{(1)},x_t^{(2)},...,x_t^{(d)})^T\in\mathbb{R}^{d\times 1}</script><script type="math/tex; mode=display">dX_t=\mu(t,X_t)dt+\sigma(t,X_t)dB_t</script><script type="math/tex; mode=display">\begin{bmatrix}\mu_1\\ \mu_2\\...\\ \mu_d\end{bmatrix}_{d\times 1}+\begin{bmatrix}\sigma_{11}&\sigma_{12}&...&\sigma_{1m}\\\sigma_{21}&\sigma_{22}&...&\sigma_{2m}\\...&...&...&...\\\sigma_{d1}&\sigma_{d2}&...&\sigma_{dm}\\\end{bmatrix}_{d\times m}\times\begin{bmatrix}dB_t^{(1)}\\ dB_t^{(2)}\\...\\ dB_t^{(m)}\end{bmatrix}_{m\times 1}</script><p>$B_t$: m-dimensioned BM [uncorrelated]</p><script type="math/tex; mode=display">dB_idB_j=\begin{cases}dt&,i= j\\ \rho dt=0&,i\ne j\end{cases}</script><p>Also can be shown as</p><script type="math/tex; mode=display">\begin{align}dx_t^{(i)}&=\mu_idt+\sum_{k=1}^m\sigma_{ik}dB_t^{(k)},\ i\in \{1,2,...,d\}\\dx_t^{(j)}&=\mu_jdt+\sum_{l=1}^m\sigma_{jl}dB_t^{(l)},\ j\in \{1,2,...,d\}\end{align}</script><p>So we have</p><script type="math/tex; mode=display">\begin{align}dx_t^{(i)}dx_t^{(j)}&=(\sum_{k=1}^m\sigma_{ik}dB_t^{(k)})(\sum_{l=1}^m\sigma_{jl}dB_t^{(l)})\\&=\sum_{k=1}^m\sum_{l=1}^m\sigma_{ik}\sigma_{jl}dB_t^{(k)}dB_t^{(l)}\\&=\sum_{k=1}^m\sum_{l=1}^m\sigma_{ik}\sigma_{jl}\delta_{kl}dt\\&=\sum_{k=1}^m\sigma_{ik}\sigma_{jK}dt\end{align}</script><p><strong>Generator</strong></p><script type="math/tex; mode=display">A=\sum_{i=1}^d\mu_i\frac{\partial}{\partial x_i}+\frac{1}{2}\sum_{i=1}^d\sum_{j=1}^d(\sigma \sigma^T)_{ij}\frac{\partial^2}{\partial x_i\partial x_j}</script><p>with</p><script type="math/tex; mode=display">\begin{matrix}u(t,\underbrace{x_1,x_2,...,x_d})\\ \quad x_t^{(1)},x_t^{(2)},...,x_t^{(d)} \end{matrix}</script><p>With $u(t,\overrightarrow{X}_t)$ and $r(t,\overrightarrow{X}_t)$, <strong>prove $M_t$ is a martingale</strong></p><script type="math/tex; mode=display">M_t=e^{-\int_0^trds}u-\int_0^te^{-\int_0^srdv}(\frac{\partial u}{\partial t}+Au-ru)ds</script><p><strong>Proof</strong>：</p><p>Set $F_t=e^{-\int_0^trds}u$</p><script type="math/tex; mode=display">\begin{align}dF_t&=[de^{-\int_0^trds}]u+e^{-\int_0^trds}du+0\\&=-re^{-\int_0^trds}udt+e^{-\int_0^trds}[\frac{\partial u}{\partial t}dt+\sum_{i=1}^d\frac{\partial u}{\partial x_i}dx_t^{(i)}...\\&...+\frac{1}{2}\sum_{i=1}^d\sum_{j=1}^d\frac{\partial^2 u}{\partial x_i\partial x_j}dx_t^{(i)}dx_t^{(j)}]\\&=e^{-\int_0^trds}[-rudt+\frac{\partial u}{\partial t}dt+\sum_{i=1}^d\frac{\partial u}{\partial x_i}\mu_idt+\sum_{i=1}^d\frac{\partial u}{\partial x_i}\sum_{k=1}^m\sigma_{ik}dB_t^{(k)}...\\&...+\frac{1}{2}\sum_{i=1}^d\sum_{j=1}^d\frac{\partial^2 u}{\partial x_i\partial x_j}\sum_{k=1}^m\sigma_{ik}\sigma_{jK}dt]\\&=e^{-\int_0^trds}[-ru+\frac{\partial u}{\partial t}+\sum_{i=1}^d\frac{\partial u}{\partial x_i}\mu_i+\frac{1}{2}\sum_{i=1}^d\sum_{j=1}^d\frac{\partial^2 u}{\partial x_i\partial x_j}(\sigma \sigma^T)_{ij}]dt...\\&...+e^{-\int_0^trds}(\nabla u)^T\sigma dB_t\\&=e^{-\int_0^trds}[-ru+\frac{\partial u}{\partial t}+Au]dt+e^{-\int_0^trds}(\nabla u)^T\sigma dB_t\end{align}</script><p>So</p><script type="math/tex; mode=display">\begin{align}dM_t&=dF_t-e^{-\int_0^trdv}(\frac{\partial u}{\partial t}+Au-ru)dt\\&=e^{-\int_0^trds}(\nabla u)^T\sigma dB_t\end{align}</script><p>$\Rightarrow M_t$ is a Martingale</p><p><strong>Similarly</strong></p><p>Set $t\leq t’\leq T$ with $X_t^{t,x}=x$</p><script type="math/tex; mode=display">\tilde{M}_{t'}=e^{-\int_t^{t'}rds}u-\int_t^{t'}e^{-\int_t^srdv}(\frac{\partial u}{\partial t}+Au-ru)ds</script><p>$\Rightarrow \tilde{M}_{t’}$ is also a Martingale</p><p>So $\mathbb{E}[\tilde{M}_T]=\mathbb{E}[\tilde{M}_t]=\tilde{M}_t=u(t,x)$</p><h3 id="Feynman-Kac-证明"><a href="#Feynman-Kac-证明" class="headerlink" title="Feynman-Kac 证明"></a>Feynman-Kac 证明</h3><p>( Feynman-Kac Formula ) Let $X_t$ is an Ito diffusion given by</p><script type="math/tex; mode=display">d\overrightarrow{X}_t=\mu(t,\overrightarrow{X}_t)dt+\sigma(t,\overrightarrow{X}_t)d\overrightarrow{B}_t</script><p>with generator A and initial condition $X_t^{t,x}=x$</p><p>Let $u(t,\overrightarrow{X}_t)$, $t\in\mathbb{R}^+$, $\overrightarrow{X}_t\in\mathbb{R}^{d\times 1}$ satisfy</p><script type="math/tex; mode=display">\frac{\partial u}{\partial t}+Au-ru=0 \tag{1}</script><p>with final condition $u(T,x)=f(x)$</p><p>Then</p><script type="math/tex; mode=display">\begin{align}u(t,x)&=\mathbb{E}[e^{-\int_t^Tr(s,x_s)ds}f(X_T)|\mathcal{F}_t]\\&=\mathbb{E}[e^{-\int_t^Tr(s,x_s)ds}f(X_T)|X(t)=x]\\&=\mathbb{E}[e^{-\int_t^Tr(s,X_s^{t,x})ds}f(X_T^{t,x})]\end{align}</script><p>Proof：</p><p>we have </p><script type="math/tex; mode=display">\mathbb{E}[\tilde{M}_{T}]=\mathbb{E}[e^{-\int_t^{T}r(S,X_s^{t,x})ds}u(T,X_T^{t,x})-\int_t^{T}e^{-\int_t^sr(v,X_v^{t,x})dv}(\frac{\partial u}{\partial t}+Au-ru)(s,X_s^{t,x})ds]</script><p>Under condition (1)</p><script type="math/tex; mode=display">\mathbb{E}[\tilde{M}_{T}]=\mathbb{E}[e^{-\int_t^{T}r(S,X_s^{t,x})ds}u(T,X_T^{t,x})]</script><p>and final condition</p><script type="math/tex; mode=display">\mathbb{E}[\tilde{M}_{T}]=\mathbb{E}[e^{-\int_t^{T}r(S,X_s^{t,x})ds}f(X_T^{t,x})] \tag{2}</script><p><strong>总结：凡是满足以上的所有条件的，都能写成期望公式(2)的格式，因此两种形式可以互通</strong></p><h1 id="Black-Scholes-PDE推导"><a href="#Black-Scholes-PDE推导" class="headerlink" title="Black-Scholes-PDE推导"></a>Black-Scholes-PDE推导</h1><h3 id="1-三个采用Feynman-Kac-theorem的推导"><a href="#1-三个采用Feynman-Kac-theorem的推导" class="headerlink" title="1. 三个采用Feynman-Kac theorem的推导"></a>1. 三个采用Feynman-Kac theorem的推导</h3><h4 id="【第一版-B站版】"><a href="#【第一版-B站版】" class="headerlink" title="【第一版-B站版】"></a>【第一版-B站版】</h4><p>根据B站<a href="https://space.bilibili.com/453522144">杨维强老师</a>的讲解，将Feynman-Kac theorem比作了一个连接SDE与PDE的桥梁</p><p>Recall：</p><script type="math/tex; mode=display">SDE: dX_t = \mu(X_t)dt + \sigma(X_t)dB_t \ , \ X_0 = x</script><p>Feynman-Kac theorem 使用概率方法去解出PDE：</p><script type="math/tex; mode=display">u(t,x) = E^X[e^{-\int_0^t\lambda(X_s)ds}f(X_t)]</script><p>其中：</p><script type="math/tex; mode=display">PDE: u_t = \mu(x)u_x+\frac{1}{2}\sigma^2(x)u_{xx}-\lambda(x)u \ , \ u(0,x)=f(x)</script><p>有些资料会以另一个方式写(相当于做一个时间变换)：</p><script type="math/tex; mode=display">PDE：u_t + \mu(x)u_x+\frac{1}{2}\sigma^2(x)u_{xx}-\lambda(x)u = 0 \ , \ u(T,x)=f(x)</script><p>由原有方程：</p><script type="math/tex; mode=display">dX_t = rX_tdt + \sigma X_tdB_t\\V(t,x) = E_Q[e^{-r(T-t)}h(X_T)|X_t=x]</script><p>当设 $\mu(x)=rx,\sigma(x)=\sigma x,\lambda(x)=r$ , 得到PDE：</p><script type="math/tex; mode=display">rV = V_t + rxV_x+\frac{1}{2}\sigma^2x^2V_{xx} \ , \ V(T,x)=h(x)</script><h4 id="【第二版-格拉版】"><a href="#【第二版-格拉版】" class="headerlink" title="【第二版-格拉版】"></a>【第二版-格拉版】</h4><p>区别的地方是采用BM构建Process：</p><script type="math/tex; mode=display">\begin{align}V(t,x) &= E_Q[e^{-r(T-t)}h(X_T)|X_t=x]\\&\Downarrow\\V(t,x) &= E_Q[e^{-r(T-t)}h(B(T))|B(t)=f(t,x)] = u(t,f(t,x))\end{align}</script><p>其中<script type="math/tex">B(t)</script>的式子由：</p><script type="math/tex; mode=display">\begin{align}X_t &= X_0e^{(r-\frac{\sigma^2}{2})t+\sigma B(t) }= x\\B(t) &= \frac{ln(\frac{x}{X_0})-(r-\frac{\sigma^2}{2})t}{\sigma}=f(t,x)\end{align}</script><p>By the Feynman-Kac theorem with $\mu(x)=0,\sigma(x)=1$：</p><script type="math/tex; mode=display">ru = u_t+\frac{1}{2}u_{ff}</script><p>为了求解，得以下三个式子：</p><script type="math/tex; mode=display">\begin{align}V_t &= u_t + u_ff_t\\V_x &= u_ff_x\\V_{xx} &= u_{ff}(f_x)^2 + u_ff_{xx}\end{align}</script><p>依照之前的$f(t,x)$公式</p><script type="math/tex; mode=display">\begin{align}f &= \frac{ln(\frac{x}{X_0})-(r-\frac{\sigma^2}{2})t}{\sigma}\\f_t &= -\frac{1}{\sigma}(r-\frac{\sigma^2}{2})\\f_x &= \frac{1}{\sigma x} \ (lnax = lna + lnx)\\f_{xx} &= -\frac{1}{\sigma x^2}\end{align}</script><p>代入前一个式子并换位</p><script type="math/tex; mode=display">\begin{align}V_t + \frac{1}{\sigma}(r-\frac{\sigma^2}{2})u_f &= u_t \\\sigma xV_x &= u_f\\\sigma^2 x^2V_{xx} + \frac{\sigma^2 x^2}{\sigma x^2}u_f &= u_{ff}\end{align}</script><p>代入最开始的式子</p><script type="math/tex; mode=display">\begin{align}rV &= V_t +(r-\frac{\sigma^2}{2})xV_x +\frac{1}{2}(\sigma^2 x^2V_{xx} + \sigma^2 xV_x)\\ &= V_t +rxV_x-\frac{\sigma^2 x}{2}V_x +\frac{\sigma^2 x^2}{2}V_{xx} + \frac{\sigma^2 x}{2}V_x\\ &= V_t +rxV_x +\frac{\sigma^2 x^2}{2}V_{xx} \end{align}</script><h4 id="【第三版-参考书】"><a href="#【第三版-参考书】" class="headerlink" title="【第三版-参考书】"></a>【第三版-参考书】</h4><script type="math/tex; mode=display">\begin{align}V(t,x) &= E_Q[e^{-r(T-t)}V(X_T)|X_t=x]\\g(t,x) &= e^{-rt}V(t,x)\end{align}</script><p>By the Feynman-Kac theorem with time in [0,T]：</p><script type="math/tex; mode=display">g_t + rxg_x+\frac{1}{2}\sigma^2 x^2g_{xx}= 0</script><p>对g求导：</p><script type="math/tex; mode=display">\begin{align}g_t &= -re^{rt}V + e^{-rt}V_t\\g_x &= e^{-rt}V_x\\g_{xx} &= e^{-rt}V_{xx}\end{align}</script><p>代入：</p><script type="math/tex; mode=display">\begin{align}-re^{rt}V + e^{-rt}V_t + rxe^{-rt}V_x+\frac{1}{2}\sigma^2 x^2e^{-rt}V_{xx}= 0\\-rV + V_t + rxV_x+\frac{1}{2}\sigma^2 x^2V_{xx}= 0\\\end{align}</script><h3 id="2-对冲版推导"><a href="#2-对冲版推导" class="headerlink" title="2. 对冲版推导"></a>2. 对冲版推导</h3><h4 id="【第一版-Delta-对冲】"><a href="#【第一版-Delta-对冲】" class="headerlink" title="【第一版-Delta 对冲】"></a>【第一版-Delta 对冲】</h4><p>做一个Delta对冲的投资组合：</p><script type="math/tex; mode=display">\Pi = C(X,t) - \Delta X \ , \ \Delta = \frac{\partial C}{\partial X}</script><p> Ito formula：</p><script type="math/tex; mode=display">\begin{align}d\Pi &= \frac{\partial C}{\partial t}dt + \frac{\partial C}{\partial X}dX + \frac{1}{2}\sigma^2X^2\frac{\partial^2C}{\partial X^2}dt - \Delta dX\\&= \frac{\partial C}{\partial t}dt + \frac{1}{2}\sigma^2X^2\frac{\partial^2C}{\partial X^2}dt + (\frac{\partial C}{\partial X} - \Delta)dX\\&= \frac{\partial C}{\partial t}dt + \frac{1}{2}\sigma^2X^2\frac{\partial^2C}{\partial X^2}dt\end{align}</script><p>It should be equal to the same return as if we invested in riskless interest-bearing account：</p><script type="math/tex; mode=display">d\Pi = r\Pi dt = r(C(X,t) - \Delta X)dt = r(C(X,t) - X \frac{\partial C}{\partial X})dt</script><p>because of no arbitrage：</p><script type="math/tex; mode=display">\frac{\partial C}{\partial t}dt + \frac{1}{2}\sigma^2X^2\frac{\partial^2C}{\partial X^2}dt = r(C(X,t) - X \frac{\partial C}{\partial X})dt</script><p>so that：</p><script type="math/tex; mode=display">\frac{\partial C}{\partial t} + rX \frac{\partial C}{\partial X} + \frac{1}{2}\sigma^2X^2\frac{\partial^2C}{\partial X^2} = rC</script><h4 id="【第二版-Ito-公式】"><a href="#【第二版-Ito-公式】" class="headerlink" title="【第二版-Ito 公式】"></a>【第二版-Ito 公式】</h4><p>建立一个期权的复制组合</p><ul><li><p>$\Delta(t)$：持有股票数</p></li><li><p>$X(t)$：portfolio 价值</p></li><li><p>股票价值增量：$dS(t)=\alpha S(t)dt+\sigma S(t)dW(t)$</p></li><li><p>portfolio 价值增量：超额收益+无风险收益+风险</p><script type="math/tex; mode=display">\begin{align}dX(t)&=\Delta(t)dS(t)+r(X(t)-\Delta(t)S(t))dt\\&=\Delta(t)\alpha S(t)dt+\Delta(t)\sigma S(t)dW(t)+rX(t)dt-r\Delta(t)S(t)dt\\&=(\alpha-r)\Delta(t)S(t)dt+rX(t)dt+\Delta(t)\sigma S(t)dW(t)\end{align}</script></li></ul><p>股票价值的折现过程</p><script type="math/tex; mode=display">\begin{align}d(e^{-rt}S(t))&=S(t)de^{-rt}+e^{-rt}dS(t)+dS(t)de^{-rt}\\&=-re^{-rt}S(t)dt+e^{-rt}(\alpha S(t)dt+\sigma S(t)dW(t))\\&=(\alpha-r)e^{-rt}S(t)dt+e^{-rt}\sigma S(t)dW(t)\end{align}</script><p>组合价值的折现过程</p><script type="math/tex; mode=display">\begin{align}d(e^{-rt}X(t))&=X(t)de^{-rt}+e^{-rt}dX(t)+dX(t)de^{-rt}\\&=-re^{-rt}X(t)dt+e^{-rt}(\alpha-r)\Delta(t)S(t)dt...\\&...+e^{-rt}rX(t)dt+e^{-rt}\Delta(t)\sigma S(t)dW(t)\\&=\Delta(t)(e^{-rt}(\alpha-r)S(t)dt+e^{-rt}\sigma S(t)dW(t))\\&=\Delta(t)d(e^{-rt}S(t))\end{align}</script><ul><li>$C(t,x)$：Option price</li></ul><p>当复制成立时</p><script type="math/tex; mode=display">d(e^{-rt}C(t,S(t)))=d(e^{-rt}X(t))</script><p>先准备</p><script type="math/tex; mode=display">\begin{align}d(C(t,S(t)))&=C_tdt+C_xdS(t)+\frac12C_{xx}dS(t)dS(t)\\&=C_tdt+C_x(\alpha S(t)dt+\sigma S(t)dW(t))...\\&...+\frac12C_{xx}\sigma^2S(t)^2dt\\&=(C_t+C_x\alpha S(t)+\frac12C_{xx}\sigma^2S(t)^2)dt+C_x\sigma S(t)dW(t)\end{align}</script><p>代入</p><script type="math/tex; mode=display">\begin{align}d(e^{-rt}C(t,S(t)))&=Cde^{-rt}+e^{-rt}dC\\&=-re^{-rt}Cdt+e^{-rt}C_x\sigma S(t)dW(t)...\\&...+e^{-rt}(C_t+C_x\alpha S(t)+\frac12C_{xx}\sigma^2S(t)^2)dt\\&=e^{-rt}(C_t+C_x\alpha S(t)+\frac12C_{xx}\sigma^2S(t)^2-rC)dt...\\&...+e^{-rt}C_x\sigma S(t)dW(t)\end{align}</script><p>与组合价值的折现过程对比</p><script type="math/tex; mode=display">\Delta(t)(e^{-rt}(\alpha-r)S(t)dt+e^{-rt}\sigma S(t)dW(t))</script><p>得出</p><script type="math/tex; mode=display">\Delta(t)=C_x</script><script type="math/tex; mode=display">rC=C_t+\frac12C_{xx}\sigma^2S(t)^2+rC_xS(t)</script><h3 id="【附加资料】"><a href="#【附加资料】" class="headerlink" title="【附加资料】"></a>【附加资料】</h3><p>Black-Scholes equation is written in the form ：</p><script type="math/tex; mode=display">\frac{\partial C}{\partial t} + bX \frac{\partial C}{\partial X} + \frac{1}{2}\sigma^2X^2\frac{\partial^2C}{\partial X^2} - rC = 0</script><p>where：</p><div class="table-container"><table><thead><tr><th>Asset with on dividend</th><th>$b = r$</th></tr></thead><tbody><tr><td><strong>Asset with dividend $D$</strong></td><td>$b = r - D$</td></tr><tr><td><strong>Foreign currency with return $r_f$</strong></td><td>$b = r - r_f$</td></tr><tr><td><strong>Commodity with storage cost $q$</strong></td><td>$b = r + q$</td></tr><tr><td><strong>Futures</strong></td><td>$b = 0$</td></tr></tbody></table></div><hr><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol><li><p><a href="https://www.bilibili.com/video/av542948966">金融数学课程</a></p></li><li><p>孙健 《金融衍生品定价模型—数理金融引论 》中国经济出版社</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Black Scholes Model</tag>
      
      <tag>Feynman-Kac</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【代码】Financial Toolbox:Portfolio Optimization</title>
    <link href="/2021/03/11/Financial_Toolbox-Portfolio_Optimization/"/>
    <url>/2021/03/11/Financial_Toolbox-Portfolio_Optimization/</url>
    
    <content type="html"><![CDATA[<blockquote><p>对Matlab金融工具箱内的Portfolio_Optimization_Example代码的阅读笔记；</p><p>【Example】</p></blockquote><span id="more"></span><h3 id="打开文档"><a href="#打开文档" class="headerlink" title="打开文档"></a>打开文档</h3><p>打开Matlab，在command中输入：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">openExample(<span class="hljs-string">&#x27;finance/portfolioexamples&#x27;</span>)<br></code></pre></td></tr></table></figure><p>可打开文档</p><p><img src="/2021/03/11/Financial_Toolbox-Portfolio_Optimization/fig1.jpg" alt></p><h3 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs matlab">load BlueChipStockMoments <span class="hljs-comment">% 加载官方给的example</span><br><br>mret = MarketMean; <span class="hljs-comment">% mret = market_return</span><br>mrsk = <span class="hljs-built_in">sqrt</span>(MarketVar); <span class="hljs-comment">% mrsk = market_risk</span><br>cret = CashMean; <span class="hljs-comment">% cret = cash_return</span><br>crsk = <span class="hljs-built_in">sqrt</span>(CashVar); <span class="hljs-comment">% cret = cash_risk</span><br></code></pre></td></tr></table></figure><h3 id="初始化一个Portfolio对象"><a href="#初始化一个Portfolio对象" class="headerlink" title="初始化一个Portfolio对象"></a>初始化一个Portfolio对象</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs matlab">p = Portfolio(<span class="hljs-string">&#x27;AssetList&#x27;</span>,AssetList,<span class="hljs-string">&#x27;RiskFreeRate&#x27;</span>,CashMean);<br>p = setAssetMoments(p,AssetMean,AssetCovar); <span class="hljs-comment">% 加载数据</span><br><span class="hljs-comment">% [m, cov] = getAssetMoments(p); % 提取数据</span><br></code></pre></td></tr></table></figure><p><strong>AssetList</strong>：Asset名称的List，如果自己导入data，可采用：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs matlab">data = <span class="hljs-built_in">readtable</span>(<span class="hljs-string">&#x27;data.xlsx&#x27;</span>);<br>AssetList = data.Properties.VariableNames&#x27;;<br></code></pre></td></tr></table></figure><h4 id="【可选步骤】"><a href="#【可选步骤】" class="headerlink" title="【可选步骤】"></a>【可选步骤】</h4><h5 id="1-初始化一个-equal-weight-portfolio"><a href="#1-初始化一个-equal-weight-portfolio" class="headerlink" title="1.初始化一个 equal-weight portfolio"></a>1.初始化一个 equal-weight portfolio</h5><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs matlab">p = setInitPort(p,<span class="hljs-number">1</span>/p.NumAssets); <br>[ersk,eret] = estimatePortMoments(p,p.InitPort); <span class="hljs-comment">% 给出对应的equal-weight risk，return</span><br></code></pre></td></tr></table></figure><h5 id="2-画一个所有Asset在risk-return上的分布图"><a href="#2-画一个所有Asset在risk-return上的分布图" class="headerlink" title="2.画一个所有Asset在risk-return上的分布图"></a>2.画一个所有Asset在risk-return上的分布图</h5><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs matlab">clf; <span class="hljs-comment">% 删除所有figure</span><br>portfolioexamples_plot(<span class="hljs-string">&#x27;Asset Risks and Returns&#x27;</span>, ... <span class="hljs-comment">% title</span><br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, mrsk, mret, &#123;<span class="hljs-string">&#x27;Market&#x27;</span>&#125;&#125;, ... <span class="hljs-comment">% 点状图，x坐标，y坐标，名称</span><br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, crsk, cret, &#123;<span class="hljs-string">&#x27;Cash&#x27;</span>&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, ersk, eret, &#123;<span class="hljs-string">&#x27;Equal&#x27;</span>&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, <span class="hljs-built_in">sqrt</span>(<span class="hljs-built_in">diag</span>(p.AssetCovar)), p.AssetMean, p.AssetList, <span class="hljs-string">&#x27;.r&#x27;</span>&#125;); <br><span class="hljs-comment">% diag取对角矩阵；‘.r’图形样式</span><br></code></pre></td></tr></table></figure><p><img src="/2021/03/11/Financial_Toolbox-Portfolio_Optimization/fig2.jpg" alt></p><h3 id="在各种约束下的投资组合优化"><a href="#在各种约束下的投资组合优化" class="headerlink" title="在各种约束下的投资组合优化"></a>在各种约束下的投资组合优化</h3><h4 id="1-初始化一个long-only-portfolios"><a href="#1-初始化一个long-only-portfolios" class="headerlink" title="1.初始化一个long only portfolios"></a>1.初始化一个long only portfolios</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs matlab">p = setDefaultConstraints(p);<br><br>pwgt = estimateFrontier(p,<span class="hljs-number">20</span>); <span class="hljs-comment">% 为Frontier输出weight，第二个值确定个数</span><br>[prsk,pret] = estimatePortMoments(p,pwgt); <span class="hljs-comment">% 输出对应risk和return</span><br><span class="hljs-comment">% 或者直接使用 plotFrontier(p,20);</span><br><br><span class="hljs-comment">% Plot efficient frontier</span><br>clf;<br>portfolioexamples_plot(<span class="hljs-string">&#x27;Efficient Frontier&#x27;</span>, ...<br>&#123;<span class="hljs-string">&#x27;line&#x27;</span>, prsk, pret&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, [mrsk, crsk, ersk], [mret, cret, eret], &#123;<span class="hljs-string">&#x27;Market&#x27;</span>, <span class="hljs-string">&#x27;Cash&#x27;</span>, <span class="hljs-string">&#x27;Equal&#x27;</span>&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, <span class="hljs-built_in">sqrt</span>(<span class="hljs-built_in">diag</span>(p.AssetCovar)), p.AssetMean, p.AssetList, <span class="hljs-string">&#x27;.r&#x27;</span>&#125;);<br></code></pre></td></tr></table></figure><p><img src="/2021/03/11/Financial_Toolbox-Portfolio_Optimization/fig3.jpg" alt></p><h4 id="2-初始化一个portfolios-with-budget-constraint"><a href="#2-初始化一个portfolios-with-budget-constraint" class="headerlink" title="2.初始化一个portfolios with budget constraint"></a>2.初始化一个portfolios with budget constraint</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs matlab">q = setBudget(p, <span class="hljs-number">0</span>, <span class="hljs-number">0.8</span>); <span class="hljs-comment">% cash in [0,80%]</span><br><br>qwgt = estimateFrontier(q,<span class="hljs-number">20</span>);<br>[qrsk,qret] = estimatePortMoments(q,qwgt);<br><br><span class="hljs-comment">% Plot efficient frontier with tangent line (0 to 0.8 cash)</span><br>clf;<br>portfolioexamples_plot(<span class="hljs-string">&#x27;Efficient Frontier with Tangent Line&#x27;</span>, ...<br>&#123;<span class="hljs-string">&#x27;line&#x27;</span>, prsk, pret&#125;, ...<br>&#123;<span class="hljs-string">&#x27;line&#x27;</span>, qrsk, qret, [], <span class="hljs-string">&#x27;r&#x27;</span>, <span class="hljs-number">0.5</span>&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, [mrsk, crsk, ersk], [mret, cret, eret], &#123;<span class="hljs-string">&#x27;Market&#x27;</span>, <span class="hljs-string">&#x27;Cash&#x27;</span>, <span class="hljs-string">&#x27;Equal&#x27;</span>&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, <span class="hljs-built_in">sqrt</span>(<span class="hljs-built_in">diag</span>(p.AssetCovar)), p.AssetMean, p.AssetList, <span class="hljs-string">&#x27;.r&#x27;</span>&#125;);<br></code></pre></td></tr></table></figure><p><img src="/2021/03/11/Financial_Toolbox-Portfolio_Optimization/fig4.jpg" alt></p><h4 id="3-初始化一个portfolios其交易包含Transactions-Costs"><a href="#3-初始化一个portfolios其交易包含Transactions-Costs" class="headerlink" title="3.初始化一个portfolios其交易包含Transactions Costs"></a>3.初始化一个portfolios其交易包含Transactions Costs</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs matlab">BuyCost = <span class="hljs-number">0.0020</span>;<br>SellCost = <span class="hljs-number">0.0020</span>;<br><br>q = setCosts(p,BuyCost,SellCost);<br><br>qwgt = estimateFrontier(q,<span class="hljs-number">20</span>);<br>[qrsk,qret] = estimatePortMoments(q,qwgt);<br><br><span class="hljs-comment">% Plot efficient frontiers with gross and net returns</span><br>clf;<br>portfolioexamples_plot(<span class="hljs-string">&#x27;Efficient Frontier with and without Transaction Costs&#x27;</span>, ...<br>&#123;<span class="hljs-string">&#x27;line&#x27;</span>, prsk, pret, &#123;<span class="hljs-string">&#x27;Gross&#x27;</span>&#125;, <span class="hljs-string">&#x27;:b&#x27;</span>&#125;, ...<br>&#123;<span class="hljs-string">&#x27;line&#x27;</span>, qrsk, qret, &#123;<span class="hljs-string">&#x27;Net&#x27;</span>&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, [mrsk, crsk, ersk], [mret, cret, eret], &#123;<span class="hljs-string">&#x27;Market&#x27;</span>, <span class="hljs-string">&#x27;Cash&#x27;</span>, <span class="hljs-string">&#x27;Equal&#x27;</span>&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, <span class="hljs-built_in">sqrt</span>(<span class="hljs-built_in">diag</span>(p.AssetCovar)), p.AssetMean, p.AssetList, <span class="hljs-string">&#x27;.r&#x27;</span>&#125;);<br></code></pre></td></tr></table></figure><p><img src="/2021/03/11/Financial_Toolbox-Portfolio_Optimization/fig6.jpg" alt></p><h4 id="4-初始化一个portfolios其交易加入了Turnover-Constraint"><a href="#4-初始化一个portfolios其交易加入了Turnover-Constraint" class="headerlink" title="4.初始化一个portfolios其交易加入了Turnover Constraint"></a>4.初始化一个portfolios其交易加入了Turnover Constraint</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs matlab">BuyCost = <span class="hljs-number">0.0020</span>;<br>SellCost = <span class="hljs-number">0.0020</span>;<br>Turnover = <span class="hljs-number">0.2</span>;<br><br>q = setCosts(p, BuyCost,SellCost);<br>q = setTurnover(q,Turnover);<br><br>[qwgt,qbuy,qsell] = estimateFrontier(q,<span class="hljs-number">20</span>);<br>[qrsk,qret] = estimatePortMoments(q,qwgt);<br><br><span class="hljs-comment">% Plot efficient frontier with turnover constraint</span><br><br>clf;<br>portfolioexamples_plot(<span class="hljs-string">&#x27;Efficient Frontier with Turnover Constraint&#x27;</span>, ...<br>&#123;<span class="hljs-string">&#x27;line&#x27;</span>, prsk, pret, &#123;<span class="hljs-string">&#x27;Unconstrained&#x27;</span>&#125;, <span class="hljs-string">&#x27;:b&#x27;</span>&#125;, ...<br>&#123;<span class="hljs-string">&#x27;line&#x27;</span>, qrsk, qret, &#123;sprintf(<span class="hljs-string">&#x27;%g%% Turnover&#x27;</span>, <span class="hljs-number">100</span>*Turnover)&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, [mrsk, crsk, ersk], [mret, cret, eret], &#123;<span class="hljs-string">&#x27;Market&#x27;</span>, <span class="hljs-string">&#x27;Cash&#x27;</span>, <span class="hljs-string">&#x27;Equal&#x27;</span>&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, <span class="hljs-built_in">sqrt</span>(<span class="hljs-built_in">diag</span>(p.AssetCovar)), p.AssetMean, p.AssetList, <span class="hljs-string">&#x27;.r&#x27;</span>&#125;);<br>displaySumOfTransactions(Turnover, qbuy, qsell)<br></code></pre></td></tr></table></figure><p><img src="/2021/03/11/Financial_Toolbox-Portfolio_Optimization/fig7.jpg" alt></p><h4 id="5-依照最大夏普比率得到最优组合"><a href="#5-依照最大夏普比率得到最优组合" class="headerlink" title="5.依照最大夏普比率得到最优组合"></a>5.依照最大夏普比率得到最优组合</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs matlab">p = setInitPort(p, <span class="hljs-number">0</span>);<br><br>swgt = estimateMaxSharpeRatio(p);<br>[srsk,sret] = estimatePortMoments(p,swgt);<br><br><span class="hljs-comment">% Plot efficient frontier with portfolio that attains maximum Sharpe ratio</span><br><br>clf;<br>portfolioexamples_plot(<span class="hljs-string">&#x27;Efficient Frontier with Maximum Sharpe Ratio Portfolio&#x27;</span>, ...<br>&#123;<span class="hljs-string">&#x27;line&#x27;</span>, prsk, pret&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, srsk, sret, &#123;<span class="hljs-string">&#x27;Sharpe&#x27;</span>&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, [mrsk, crsk, ersk], [mret, cret, eret], &#123;<span class="hljs-string">&#x27;Market&#x27;</span>, <span class="hljs-string">&#x27;Cash&#x27;</span>, <span class="hljs-string">&#x27;Equal&#x27;</span>&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, <span class="hljs-built_in">sqrt</span>(<span class="hljs-built_in">diag</span>(p.AssetCovar)), p.AssetMean, p.AssetList, <span class="hljs-string">&#x27;.r&#x27;</span>&#125;);<br></code></pre></td></tr></table></figure><p><img src="/2021/03/11/Financial_Toolbox-Portfolio_Optimization/fig8.jpg" alt></p><h5 id="并与切线结合"><a href="#并与切线结合" class="headerlink" title="并与切线结合"></a>并与切线结合</h5><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs matlab">q = setBudget(p, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>);<br><br>qwgt = estimateFrontier(q,<span class="hljs-number">20</span>);<br>[qrsk,qret] = estimatePortMoments(q,qwgt);<br><br><span class="hljs-comment">% Plot that shows Sharpe ratio portfolio is the tangency portfolio</span><br><br>clf;<br>portfolioexamples_plot(<span class="hljs-string">&#x27;Efficient Frontier with Maximum Sharpe Ratio Portfolio&#x27;</span>, ...<br>&#123;<span class="hljs-string">&#x27;line&#x27;</span>, prsk, pret&#125;, ...<br>&#123;<span class="hljs-string">&#x27;line&#x27;</span>, qrsk, qret, [], [], <span class="hljs-number">1</span>&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, srsk, sret, &#123;<span class="hljs-string">&#x27;Sharpe&#x27;</span>&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, [mrsk, crsk, ersk], [mret, cret, eret], &#123;<span class="hljs-string">&#x27;Market&#x27;</span>, <span class="hljs-string">&#x27;Cash&#x27;</span>, <span class="hljs-string">&#x27;Equal&#x27;</span>&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, <span class="hljs-built_in">sqrt</span>(<span class="hljs-built_in">diag</span>(p.AssetCovar)), p.AssetMean, p.AssetList, <span class="hljs-string">&#x27;.r&#x27;</span>&#125;);<br></code></pre></td></tr></table></figure><p><img src="/2021/03/11/Financial_Toolbox-Portfolio_Optimization/fig9.jpg" alt></p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><h5 id="1-获得risk和return的范围"><a href="#1-获得risk和return的范围" class="headerlink" title="1.获得risk和return的范围"></a>1.获得risk和return的范围</h5><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs matlab">[rsk,ret] = estimatePortMoments(p,estimateFrontierLimits(p));<br><br>display(rsk);<br>display(ret);<br></code></pre></td></tr></table></figure><h5 id="2-利用固定return或risk得到值"><a href="#2-利用固定return或risk得到值" class="headerlink" title="2.利用固定return或risk得到值"></a>2.利用固定return或risk得到值</h5><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs matlab">TargetReturn = <span class="hljs-number">0.20</span>;<br>TargetRisk = <span class="hljs-number">0.15</span>;<br><br>awgt = estimateFrontierByReturn(p,TargetReturn/<span class="hljs-number">12</span>); <span class="hljs-comment">% 按月度数据/12</span><br>[arsk,aret] = estimatePortMoments(p,awgt);<br><br>bwgt = estimateFrontierByRisk(p,TargetRisk/<span class="hljs-built_in">sqrt</span>(<span class="hljs-number">12</span>));<br>[brsk,bret] = estimatePortMoments(p,bwgt);<br><br><span class="hljs-comment">% Plot efficient frontier with targeted portfolios</span><br>clf;<br>portfolioexamples_plot(<span class="hljs-string">&#x27;Efficient Frontier with Targeted Portfolios&#x27;</span>, ...<br>&#123;<span class="hljs-string">&#x27;line&#x27;</span>, prsk, pret&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, [mrsk, crsk, ersk], [mret, cret, eret], &#123;<span class="hljs-string">&#x27;Market&#x27;</span>, <span class="hljs-string">&#x27;Cash&#x27;</span>, <span class="hljs-string">&#x27;Equal&#x27;</span>&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, arsk, aret, &#123;sprintf(<span class="hljs-string">&#x27;%g%% Return&#x27;</span>,<span class="hljs-number">100</span>*TargetReturn)&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, brsk, bret, &#123;sprintf(<span class="hljs-string">&#x27;%g%% Risk&#x27;</span>,<span class="hljs-number">100</span>*TargetRisk)&#125;&#125;, ...<br>&#123;<span class="hljs-string">&#x27;scatter&#x27;</span>, <span class="hljs-built_in">sqrt</span>(<span class="hljs-built_in">diag</span>(p.AssetCovar)), p.AssetMean, p.AssetList, <span class="hljs-string">&#x27;.r&#x27;</span>&#125;);<br></code></pre></td></tr></table></figure><p><img src="/2021/03/11/Financial_Toolbox-Portfolio_Optimization/fig5.jpg" alt></p><h5 id="3-显示portfolio的包含的Assets和weight占比"><a href="#3-显示portfolio的包含的Assets和weight占比" class="headerlink" title="3.显示portfolio的包含的Assets和weight占比"></a>3.显示portfolio的包含的Assets和weight占比</h5><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs matlab">aBlotter = dataset(&#123;<span class="hljs-number">100</span>*awgt(awgt &gt; <span class="hljs-number">0</span>),<span class="hljs-string">&#x27;Weight&#x27;</span>&#125;, <span class="hljs-string">&#x27;obsnames&#x27;</span>, p.AssetList(awgt &gt; <span class="hljs-number">0</span>));<br><br>displayPortfolio(sprintf(<span class="hljs-string">&#x27;Portfolio with %g%% Target Return&#x27;</span>, <span class="hljs-number">100</span>*TargetReturn), aBlotter, <span class="hljs-built_in">false</span>);<br><br>bBlotter = dataset(&#123;<span class="hljs-number">100</span>*bwgt(bwgt &gt; <span class="hljs-number">0</span>),<span class="hljs-string">&#x27;Weight&#x27;</span>&#125;, <span class="hljs-string">&#x27;obsnames&#x27;</span>, p.AssetList(bwgt &gt; <span class="hljs-number">0</span>));<br><br>displayPortfolio(sprintf(<span class="hljs-string">&#x27;Portfolio with %g%% Target Risk&#x27;</span>, <span class="hljs-number">100</span>*TargetRisk), bBlotter, <span class="hljs-built_in">false</span>);<br></code></pre></td></tr></table></figure><hr><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol><li><a href="https://ww2.mathworks.cn/help/finance/portfolio-optimization-examples.html"><strong>MathWork</strong> - Help Center</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Matlab</tag>
      
      <tag>Portfolio Optimization</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】Option Greeks</title>
    <link href="/2021/03/05/Option_Greeks/"/>
    <url>/2021/03/05/Option_Greeks/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于格拉ECON5009课件的笔记；</p></blockquote><span id="more"></span><h4 id="Without-dividend"><a href="#Without-dividend" class="headerlink" title="Without dividend"></a>Without dividend</h4><p><img src="/2021/03/05/Option_Greeks/pic1-1.jpg" alt></p><blockquote><p>红线是在到期日之前的 Value，蓝线是到期日的 Intrinsic Value，差距是 Time Value</p></blockquote><p>We have:</p><script type="math/tex; mode=display">\begin{align}c &= S_tN(d_1)- e^{-r (T-t)}KN(d_2)\\p &= e^{-r (T-t)}KN(-d_2)- S_tN(-d_1)\end{align}</script><p>with:</p><script type="math/tex; mode=display">\begin{align}d_1&=\frac{1}{\sigma \sqrt{T-t}}(ln\frac{S_t}{K}+(r+\frac{1}{2}\sigma^2)(T-t))\\d_2&=\frac{1}{\sigma \sqrt{T-t}}(ln\frac{S_t}{K}+(r-\frac{1}{2}\sigma^2)(T-t))\\&=d1 - \sigma \sqrt{T-t}\end{align}</script><p>and:</p><script type="math/tex; mode=display">N'(d_1)=\frac{1}{\sqrt{2\pi}}e^{-\frac{d_1^2}{2}}\ ,\ N'(d_2)=\frac{1}{\sqrt{2\pi}}e^{-\frac{d_1^2}{2}}\frac{S_t}{K}e^{r(T-t)}</script><p><strong>Delta</strong></p><p><img src="/2021/03/05/Option_Greeks/pic1-2.jpg" alt></p><ul><li><strong>Delta</strong> of a call is always positive(+); <strong>Delta</strong> of a put is always negative(-).<script type="math/tex; mode=display">\begin{align}&\Delta = \frac{\partial \Pi}{\partial S}\\&\Delta_C = N(d_1)，\Delta_P = N(d_1)-1\\&\Delta_C \to 1，deep\ in\ the\ money\ (S_t \to +\infty)\\&\Delta_P \to -1，deep\ in\ the\ money\ (S_t \to 0)\end{align}</script></li></ul><p><strong>Gamma</strong></p><p><img src="/2021/03/05/Option_Greeks/pic1-3.jpg" alt></p><script type="math/tex; mode=display">\begin{align}&\Gamma = \frac{\partial^2 \Pi}{\partial S^2}\\&\Gamma_C = \Gamma_P = \frac{N'(d_1)}{S_t\sigma\sqrt{T-t}}\end{align}</script><p><strong>Theta (When is measured in days, divided by 252)</strong></p><p><img src="/2021/03/05/Option_Greeks/pic1-4.jpg" alt></p><script type="math/tex; mode=display">\begin{align}&\Theta = \frac{\partial \Pi}{\partial (T-t)}\\&\Theta_C = -rKe^{-r(T-t)}N(d_2)-S_tN'(d_1)\frac{\sigma}{2\sqrt{T-t}}\\&\Theta_P = rKe^{-r(T-t)}N(-d_2)-S_tN'(d_1)\frac{\sigma}{2\sqrt{T-t}}\\&\Theta_C \to (0, large\ and\ negative,-rKe^{-r(T-t)})\\&\Theta_P \to (rKe^{-r(T-t)}, large\ and\ negative,0)\end{align}</script><h4 id="With-BSM-PDE"><a href="#With-BSM-PDE" class="headerlink" title="With BSM PDE"></a>With BSM PDE</h4><script type="math/tex; mode=display">\Theta + rS\Delta + \frac{1}{2}\sigma^2S^2\Gamma = r\Pi</script><p><strong>Vega</strong></p><p><img src="/2021/03/05/Option_Greeks/pic1-5.jpg" alt></p><script type="math/tex; mode=display">\begin{align}&Vega = \frac{\partial \Pi}{\partial \sigma}\\&Vega = S_t\sqrt{T-t}N'(d_1)\\&Vega \to (0,+,0)\end{align}</script><p><strong>Rho</strong></p><p><img src="/2021/03/05/Option_Greeks/pic1-6.jpg" alt></p><script type="math/tex; mode=display">\begin{align}&Rho = \frac{\partial \Pi}{\partial r}\\&Rho_C = K(T-t)e^{-r(T-t)}N(d_2)\\&Rho_P = -K(T-t)e^{-r(T-t)}N(-d_2)\\&Rho_C \to (0,+),Rho_P \to (-,0)\end{align}</script>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Derivatives</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】LATEX基础语法</title>
    <link href="/2021/02/28/LATEX%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"/>
    <url>/2021/02/28/LATEX%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<blockquote><p>用于方便查找的Latex语法表；</p><p>Hexo有些Latex格式不好转化就忽略了；</p></blockquote><span id="more"></span><h2 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母"></a>希腊字母</h2><p><img src="/2021/02/28/LATEX%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/pic1.png" alt></p><h2 id="字符上加帽子，横线和波浪线"><a href="#字符上加帽子，横线和波浪线" class="headerlink" title="字符上加帽子，横线和波浪线"></a>字符上加帽子，横线和波浪线</h2><p>加帽子 输入\hat  或 \widehat，如果正文用\^{Z}即可</p><p>加横线 输入 \overline ，\bar</p><p>加波浪线 输入 \widetilde, \tilde</p><h2 id="箭头上面加字"><a href="#箭头上面加字" class="headerlink" title="箭头上面加字"></a>箭头上面加字</h2><p>（1）\stackrel{p}{\longrightarrow}</p><p>（2）\xrightarrow{p}</p><script type="math/tex; mode=display">\stackrel{p}{\longrightarrow}\quad \xrightarrow{p}</script><h2 id="符号加长"><a href="#符号加长" class="headerlink" title="符号加长"></a>符号加长</h2><p>（1）\left.\frac{dy}{dx}\right|_{x=0}</p><p>（2）\frac{dy}{dx}\bigg|_{x=0}</p><p><strong>\big，\bigg 区别示例</strong></p><script type="math/tex; mode=display">|_{x=0}\quad\big|_{x=0}\quad\bigg|_{x=0}</script><h2 id="其它特殊符号"><a href="#其它特殊符号" class="headerlink" title="其它特殊符号"></a>其它特殊符号</h2><h3 id="声调"><a href="#声调" class="headerlink" title="声调"></a>声调</h3><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\bar{x}</td><td style="text-align:left">$\bar{x}$</td><td style="text-align:left">\acute{\eta}</td><td style="text-align:left">$\acute{\eta}$</td><td style="text-align:left">\check{\alpha}</td><td style="text-align:left">$\check{\alpha}$</td></tr><tr><td style="text-align:left">\grave{\eta}</td><td style="text-align:left">$\grave{\eta}$</td><td style="text-align:left">\breve{a}</td><td style="text-align:left">$\breve{a}$</td><td style="text-align:left">\ddot{y}</td><td style="text-align:left">$\ddot{y}$</td></tr><tr><td style="text-align:left">\dot{x}</td><td style="text-align:left">$\dot{x}$</td><td style="text-align:left">\hat{\alpha}</td><td style="text-align:left">$\hat{\alpha}$</td><td style="text-align:left">\tilde{\iota}</td><td style="text-align:left">$\tilde{\iota}$</td></tr></tbody></table></div><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\sin\theta</td><td style="text-align:left">$\sin\theta$</td></tr><tr><td style="text-align:left">\cos\theta</td><td style="text-align:left">$\cos\theta$</td></tr><tr><td style="text-align:left">\tan\theta</td><td style="text-align:left">$\tan\theta$</td></tr><tr><td style="text-align:left">\arcsin\frac{L}{r}</td><td style="text-align:left">$\arcsin\frac{L}{r}$</td></tr><tr><td style="text-align:left">\arccos\frac{T}{r}</td><td style="text-align:left">$\arccos\frac{T}{r}$</td></tr><tr><td style="text-align:left">\arctan\frac{L}{T}</td><td style="text-align:left">$\arctan\frac{L}{T}$</td></tr><tr><td style="text-align:left">\sinh g</td><td style="text-align:left">$\sinh g$</td></tr><tr><td style="text-align:left">\cosh h</td><td style="text-align:left">$\cosh h$</td></tr><tr><td style="text-align:left">\tanh i</td><td style="text-align:left">$\tanh i$</td></tr><tr><td style="text-align:left">\operatorname{sh}j</td><td style="text-align:left">$\operatorname{sh}j$</td></tr><tr><td style="text-align:left">\operatorname{argsh}k</td><td style="text-align:left">$\operatorname{argsh}k$</td></tr><tr><td style="text-align:left">\operatorname{ch}h</td><td style="text-align:left">$\operatorname{ch}h$</td></tr><tr><td style="text-align:left">\operatorname{argch}l</td><td style="text-align:left">$\operatorname{argch}l$</td></tr><tr><td style="text-align:left">\operatorname{th}i</td><td style="text-align:left">$\operatorname{th}i$</td></tr><tr><td style="text-align:left">\operatorname{argth}m</td><td style="text-align:left">$\operatorname{argth}m$</td></tr><tr><td style="text-align:left">k’(x)=\lim_{\Delta x\to 0}\frac{k(x)-k(x-\Delta x)}{\Delta x}</td><td style="text-align:left">$k’(x)=\lim_{\Delta x\to 0}\frac{k(x)-k(x-\Delta x)}{\Delta x}$</td></tr><tr><td style="text-align:left">\limsup S</td><td style="text-align:left">$\limsup S$</td></tr><tr><td style="text-align:left">\liminf I</td><td style="text-align:left">$\liminf I$</td></tr><tr><td style="text-align:left">\max H</td><td style="text-align:left">$\max H$</td></tr><tr><td style="text-align:left">\min L</td><td style="text-align:left">$\min L$</td></tr><tr><td style="text-align:left">\inf s</td><td style="text-align:left">$\inf s$</td></tr><tr><td style="text-align:left">\sup t</td><td style="text-align:left">$\sup t$</td></tr><tr><td style="text-align:left">\exp!t</td><td style="text-align:left">$\exp!t$</td></tr><tr><td style="text-align:left">\ln X</td><td style="text-align:left">$\ln X$</td></tr><tr><td style="text-align:left">\lg X</td><td style="text-align:left">$\lg X$</td></tr><tr><td style="text-align:left">\log X</td><td style="text-align:left">$\log X$</td></tr><tr><td style="text-align:left">\log_\alpha X</td><td style="text-align:left">$\log_\alpha X$</td></tr><tr><td style="text-align:left">\ker x</td><td style="text-align:left">$\ker x$</td></tr><tr><td style="text-align:left">\deg x</td><td style="text-align:left">$\deg x$</td></tr><tr><td style="text-align:left">\gcd(T,U,V,W,X)</td><td style="text-align:left">$\gcd(T,U,V,W,X)$</td></tr><tr><td style="text-align:left">\Pr x</td><td style="text-align:left">$\Pr x$</td></tr><tr><td style="text-align:left">\det x</td><td style="text-align:left">$\det x$</td></tr><tr><td style="text-align:left">\hom x</td><td style="text-align:left">$\hom x$</td></tr><tr><td style="text-align:left">\arg x</td><td style="text-align:left">$\arg x$</td></tr><tr><td style="text-align:left">\dim x</td><td style="text-align:left">$\dim x$</td></tr><tr><td style="text-align:left">\lim_{t\to n}T</td><td style="text-align:left">$\lim_{t\to n}T$</td></tr></tbody></table></div><h3 id="同余"><a href="#同余" class="headerlink" title="同余"></a>同余</h3><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\pmod{m}</td><td style="text-align:left">$\pmod{m}$</td><td style="text-align:left">a \bmod b</td><td style="text-align:left">$a \bmod b$</td></tr></tbody></table></div><h3 id="微分"><a href="#微分" class="headerlink" title="微分"></a>微分</h3><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\nabla</td><td style="text-align:left">$\nabla$</td><td style="text-align:left">\partial x</td><td style="text-align:left">$\partial x$</td><td style="text-align:left">\mathrm{d}x</td><td style="text-align:left">$\mathrm{d}x$</td></tr><tr><td style="text-align:left">\dot x</td><td style="text-align:left">$\dot x$</td><td style="text-align:left">\ddot y</td><td style="text-align:left">$\ddot y$</td><td style="text-align:left"></td></tr></tbody></table></div><h3 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h3><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\forall</td><td style="text-align:left">$\forall$</td><td style="text-align:left">\exists</td><td style="text-align:left">$\exists$</td><td style="text-align:left">\empty</td><td style="text-align:left">$\empty$</td><td style="text-align:left">\emptyset</td><td style="text-align:left">$\emptyset$</td><td style="text-align:left">\varnothing</td><td style="text-align:left">$\varnothing$</td></tr><tr><td style="text-align:left">\in</td><td style="text-align:left">$\in$</td><td style="text-align:left">\ni</td><td style="text-align:left">$\ni$</td><td style="text-align:left">\not\in</td><td style="text-align:left">$\not\in$</td><td style="text-align:left">\notin</td><td style="text-align:left">$\notin$</td><td style="text-align:left">\subset</td><td style="text-align:left">$\subset$</td></tr><tr><td style="text-align:left">\subseteq</td><td style="text-align:left">$\subseteq$</td><td style="text-align:left">\supset</td><td style="text-align:left">$\supset$</td><td style="text-align:left">\supseteq</td><td style="text-align:left">$\supseteq$</td><td style="text-align:left">\cap</td><td style="text-align:left">$\cap$</td><td style="text-align:left">\bigcap</td><td style="text-align:left">$\bigcap$</td></tr><tr><td style="text-align:left">\cup</td><td style="text-align:left">$\cup$</td><td style="text-align:left">\bigcup</td><td style="text-align:left">$\bigcup$</td><td style="text-align:left">\biguplus</td><td style="text-align:left">$\biguplus$</td><td style="text-align:left">\sqsubset</td><td style="text-align:left">$\sqsubset$</td><td style="text-align:left">\sqsubseteq</td><td style="text-align:left">$\sqsubseteq$</td></tr><tr><td style="text-align:left">\sqsupset</td><td style="text-align:left">$\sqsupset$</td><td style="text-align:left">\sqsupseteq</td><td style="text-align:left">$\sqsupseteq$</td><td style="text-align:left">\sqcap</td><td style="text-align:left">$\sqcap$</td><td style="text-align:left">\sqcup</td><td style="text-align:left">$\sqcup$</td><td style="text-align:left">\bigsqcup</td><td style="text-align:left">$\bigsqcup$</td></tr></tbody></table></div><h3 id="逻辑"><a href="#逻辑" class="headerlink" title="逻辑"></a>逻辑</h3><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">p</td><td style="text-align:left">$p$</td><td style="text-align:left">\land</td><td style="text-align:left">$\land$</td><td style="text-align:left">\wedge</td><td style="text-align:left">$\wedge$</td><td style="text-align:left">\bigwedge</td><td style="text-align:left">$\bigwedge$</td></tr><tr><td style="text-align:left">\bar{q} \to p</td><td style="text-align:left">$\bar{q} \to p$</td><td style="text-align:left">\lor</td><td style="text-align:left">$\lor$</td><td style="text-align:left">\vee</td><td style="text-align:left">$\vee$</td><td style="text-align:left">\bigvee</td><td style="text-align:left">$\bigvee$</td></tr><tr><td style="text-align:left">\lnot</td><td style="text-align:left">$\lnot$</td><td style="text-align:left">\neg q</td><td style="text-align:left">$\neg q$</td><td style="text-align:left">\setminus</td><td style="text-align:left">$\setminus$</td><td style="text-align:left">\smallsetminus</td><td style="text-align:left">$\smallsetminus$</td></tr></tbody></table></div><h3 id="根号"><a href="#根号" class="headerlink" title="根号"></a>根号</h3><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\sqrt{3}</td><td style="text-align:left">$\sqrt{3}$</td><td style="text-align:left">\sqrt[n]{3}</td><td style="text-align:left">$\sqrt[n]{3}$</td></tr></tbody></table></div><h3 id="关系符号"><a href="#关系符号" class="headerlink" title="关系符号"></a>关系符号</h3><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\Delta ABC\sim\Delta XYZ</td><td style="text-align:left">$\Delta ABC\sim\Delta XYZ$</td></tr><tr><td style="text-align:left">\sqrt{3}\approx1.732050808\ldots</td><td style="text-align:left">$\sqrt{3}\approx1.732050808\ldots$</td></tr><tr><td style="text-align:left">\simeq</td><td style="text-align:left">$\simeq$</td></tr><tr><td style="text-align:left">\cong</td><td style="text-align:left">$\cong$</td></tr><tr><td style="text-align:left">\dot=</td><td style="text-align:left">$\dot=$</td></tr><tr><td style="text-align:left">\ggg</td><td style="text-align:left">$\ggg$</td></tr><tr><td style="text-align:left">\gg</td><td style="text-align:left">$\gg$</td></tr><tr><td style="text-align:left">&gt;</td><td style="text-align:left">$&gt;$</td></tr><tr><td style="text-align:left">\ge</td><td style="text-align:left">$\ge$</td></tr><tr><td style="text-align:left">\geqq</td><td style="text-align:left">$\geqq$</td></tr><tr><td style="text-align:left">=</td><td style="text-align:left">$=$</td></tr><tr><td style="text-align:left">\leq</td><td style="text-align:left">$\leq$</td></tr><tr><td style="text-align:left">\leqq</td><td style="text-align:left">$\leqq$</td></tr><tr><td style="text-align:left">&lt;</td><td style="text-align:left">$&lt;$</td></tr><tr><td style="text-align:left">\ll</td><td style="text-align:left">$\ll$</td></tr><tr><td style="text-align:left">\lll</td><td style="text-align:left">$\lll$</td></tr><tr><td style="text-align:left">(x-y)^2\equiv(-x+y)^2\equiv x^2-2xy+y^2</td><td style="text-align:left">$(x-y)^2\equiv(-x+y)^2\equiv x^2-2xy+y^2$</td></tr><tr><td style="text-align:left">x\not\equiv N</td><td style="text-align:left">$x\not\equiv N$</td></tr><tr><td style="text-align:left">x\ne A</td><td style="text-align:left">$x\ne A$</td></tr><tr><td style="text-align:left">x\neq C</td><td style="text-align:left">$x\neq C$</td></tr><tr><td style="text-align:left">t\propto v</td><td style="text-align:left">$t\propto v$</td></tr><tr><td style="text-align:left">\pm</td><td style="text-align:left">$\pm$</td></tr><tr><td style="text-align:left">\mp</td><td style="text-align:left">$\mp$</td></tr><tr><td style="text-align:left">\succeq</td><td style="text-align:left">$\succeq$</td></tr><tr><td style="text-align:left">\triangleq</td><td style="text-align:left">$\triangleq$</td></tr></tbody></table></div><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\begin</span>&#123;align&#125;<br><span class="hljs-keyword">\because</span><span class="hljs-keyword">\begin</span>&#123;cases&#125;<br><span class="hljs-keyword">\acute</span>&#123;a&#125;x<span class="hljs-built_in">^</span>2+bx<span class="hljs-built_in">^</span>2+c<span class="hljs-keyword">\gtrless</span>0<span class="hljs-keyword">\gtrless</span><span class="hljs-keyword">\grave</span>&#123;a&#125;x<span class="hljs-built_in">^</span>2+bx<span class="hljs-built_in">^</span>2+c<span class="hljs-keyword">\\</span><br><span class="hljs-keyword">\acute</span>&#123;a&#125;&gt;0&gt;<span class="hljs-keyword">\grave</span>&#123;a&#125;<br><span class="hljs-keyword">\end</span>&#123;cases&#125;<span class="hljs-keyword">\\</span><br><span class="hljs-keyword">\therefore</span><span class="hljs-keyword">\frac</span>&#123;-b<span class="hljs-keyword">\pm</span><span class="hljs-keyword">\sqrt</span>&#123;b<span class="hljs-built_in">^</span>2-4<span class="hljs-keyword">\acute</span>&#123;a&#125;c&#125;&#125;&#123;2<span class="hljs-keyword">\acute</span>&#123;a&#125;&#125;&#123;&#125;<span class="hljs-built_in">_</span><span class="hljs-keyword">\lessgtr</span><span class="hljs-built_in">^</span><span class="hljs-keyword">\gtrless</span> x<span class="hljs-built_in">_</span><span class="hljs-keyword">\lessgtr</span><span class="hljs-built_in">^</span><span class="hljs-keyword">\gtrless</span><span class="hljs-keyword">\frac</span>&#123;-b<span class="hljs-keyword">\pm</span><span class="hljs-keyword">\sqrt</span>&#123;b<span class="hljs-built_in">^</span>2-4<span class="hljs-keyword">\grave</span>&#123;a&#125;c&#125;&#125;&#123;2<span class="hljs-keyword">\grave</span>&#123;a&#125;&#125;<br><span class="hljs-keyword">\end</span>&#123;align&#125;<br></code></pre></td></tr></table></figure><script type="math/tex; mode=display">\begin{align}\because\begin{cases}\acute{a}x^2+bx^2+c\gtrless0\gtrless\grave{a}x^2+bx^2+c\\\acute{a}>0>\grave{a}\end{cases}\\\therefore\frac{-b\pm\sqrt{b^2-4\acute{a}c}}{2\acute{a}}{}_\lessgtr^\gtrless x_\lessgtr^\gtrless\frac{-b\pm\sqrt{b^2-4\grave{a}c}}{2\grave{a}}\end{align}</script><h3 id="几何符号"><a href="#几何符号" class="headerlink" title="几何符号"></a>几何符号</h3><div class="table-container"><table><thead><tr><th style="text-align:left">特征</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">菱形</td><td style="text-align:left">\Diamond</td><td style="text-align:left">$\Diamond$</td></tr><tr><td style="text-align:left">正方形</td><td style="text-align:left">\Box</td><td style="text-align:left">$\Box$</td></tr><tr><td style="text-align:left">Delta</td><td style="text-align:left">\Delta</td><td style="text-align:left">$\Delta$</td></tr><tr><td style="text-align:left">三角形</td><td style="text-align:left">\triangle</td><td style="text-align:left">$\triangle$</td></tr><tr><td style="text-align:left">角名</td><td style="text-align:left">\angle\Alpha\Beta\Gamma</td><td style="text-align:left">$\angle\Alpha\Beta\Gamma$</td></tr><tr><td style="text-align:left">角度</td><td style="text-align:left">sin\frac{\pi}{3}=sin60^{\operatorname{\omicron}}=\frac{\sqrt{3}}{2}</td><td style="text-align:left">$sin\frac{\pi}{3}=sin60^{\operatorname{\omicron}}=\frac{\sqrt{3}}{2}$</td></tr><tr><td style="text-align:left">垂直</td><td style="text-align:left">\perp</td><td style="text-align:left">$\perp$</td></tr></tbody></table></div><h3 id="箭头符号"><a href="#箭头符号" class="headerlink" title="箭头符号"></a>箭头符号</h3><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\leftarrow</td><td style="text-align:left">$\leftarrow$</td><td style="text-align:left">\gets</td><td style="text-align:left">$\gets$</td><td style="text-align:left">\longleftarrow</td><td style="text-align:left">$\longleftarrow$</td></tr><tr><td style="text-align:left">\rightarrow</td><td style="text-align:left">$\rightarrow$</td><td style="text-align:left">\to</td><td style="text-align:left">$\to$</td><td style="text-align:left">\longrightarrow</td><td style="text-align:left">$\longrightarrow$</td></tr><tr><td style="text-align:left">\mapsto</td><td style="text-align:left">$\mapsto$</td><td style="text-align:left">\longmapsto</td><td style="text-align:left">$\longmapsto$</td><td style="text-align:left">\hookrightarrow</td><td style="text-align:left">$\hookrightarrow$</td></tr><tr><td style="text-align:left">\nearrow</td><td style="text-align:left">$\nearrow$</td><td style="text-align:left">\nwarrow</td><td style="text-align:left">$\nwarrow$</td><td style="text-align:left">\uparrow</td><td style="text-align:left">$\uparrow$</td></tr><tr><td style="text-align:left">\searrow</td><td style="text-align:left">$\searrow$</td><td style="text-align:left">\swarrow</td><td style="text-align:left">$\swarrow$</td><td style="text-align:left">\downarrow</td><td style="text-align:left">$\downarrow$</td></tr><tr><td style="text-align:left">\leftrightarrow</td><td style="text-align:left">$\leftrightarrow$</td><td style="text-align:left">\updownarrow</td><td style="text-align:left">$\updownarrow$</td><td style="text-align:left">\nleftrightarrow</td><td style="text-align:left">$\nleftrightarrow$</td></tr><tr><td style="text-align:left">\rightrightarrows</td><td style="text-align:left">$\rightrightarrows$</td><td style="text-align:left">\rightleftarrows</td><td style="text-align:left">$\rightleftarrows$</td><td style="text-align:left">\downdownarrows</td><td style="text-align:left">$\downdownarrows$</td></tr><tr><td style="text-align:left">\dashrightarrow</td><td style="text-align:left">$\dashrightarrow$</td><td style="text-align:left">\circlearrowleft</td><td style="text-align:left">$\circlearrowleft$</td><td style="text-align:left">\multimap</td><td style="text-align:left">$\multimap$</td></tr><tr><td style="text-align:left">\twoheadleftarrow</td><td style="text-align:left">$\twoheadleftarrow$</td><td style="text-align:left">\leftarrowtail</td><td style="text-align:left">$\leftarrowtail$</td><td style="text-align:left">\looparrowleft</td><td style="text-align:left">$\looparrowleft$</td></tr><tr><td style="text-align:left">\curvearrowleft</td><td style="text-align:left">$\curvearrowleft$</td><td style="text-align:left">\Lsh</td><td style="text-align:left">$\Lsh$</td><td style="text-align:left">\leftrightsquigarrow</td><td style="text-align:left">$\leftrightsquigarrow$</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\rightharpoonup</td><td style="text-align:left">$\rightharpoonup$</td><td style="text-align:left">\rightharpoondown</td><td style="text-align:left">$\rightharpoondown$</td></tr><tr><td style="text-align:left">\leftharpoonup</td><td style="text-align:left">$\leftharpoonup$</td><td style="text-align:left">\leftharpoondown</td><td style="text-align:left">$\leftharpoondown$</td></tr><tr><td style="text-align:left">\upharpoonleft</td><td style="text-align:left">$\upharpoonleft$</td><td style="text-align:left">\upharpoonright</td><td style="text-align:left">$\upharpoonright$</td></tr><tr><td style="text-align:left">\downharpoonleft</td><td style="text-align:left">$\downharpoonleft$</td><td style="text-align:left">\downharpoonright</td><td style="text-align:left">$\downharpoonright$</td></tr><tr><td style="text-align:left">\\rightleftharpoons</td><td style="text-align:left">$\rightleftharpoons$</td><td style="text-align:left">\leftrightharpoons</td><td style="text-align:left">$\leftrightharpoons$</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\Leftarrow</td><td style="text-align:left">$\Leftarrow$</td><td style="text-align:left">\Rightarrow</td><td style="text-align:left">$\Rightarrow$</td><td style="text-align:left">\Leftrightarrow</td><td style="text-align:left">$\Leftrightarrow$</td></tr><tr><td style="text-align:left">\Longleftarrow</td><td style="text-align:left">$\Longleftarrow$</td><td style="text-align:left">\Longrightarrow</td><td style="text-align:left">$\Longrightarrow$</td><td style="text-align:left">\Longleftrightarrow (or \iff)</td><td style="text-align:left">$\Longleftrightarrow$</td></tr><tr><td style="text-align:left">\Uparrow</td><td style="text-align:left">$\Uparrow$</td><td style="text-align:left">\Downarrow</td><td style="text-align:left">$\Downarrow$</td><td style="text-align:left">\Updownarrow</td><td style="text-align:left">$\Updownarrow$</td></tr><tr><td style="text-align:left">\nLeftarrow</td><td style="text-align:left">$\nLeftarrow$</td><td style="text-align:left">\nLeftrightarrow</td><td style="text-align:left">$\nLeftrightarrow$</td><td style="text-align:left">\Lleftarrow</td><td style="text-align:left">$\Lleftarrow$</td></tr></tbody></table></div><h3 id="特殊符号"><a href="#特殊符号" class="headerlink" title="特殊符号"></a>特殊符号</h3><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\eth</td><td style="text-align:left">$\eth$</td><td style="text-align:left">\S</td><td style="text-align:left">$\S$</td><td style="text-align:left">\P</td><td style="text-align:left">$\P$</td><td style="text-align:left">\%</td><td style="text-align:left">$\%$</td><td style="text-align:left">\dagger</td><td style="text-align:left">$\dagger$</td><td style="text-align:left">\ddagger</td><td style="text-align:left">$\ddagger$</td></tr><tr><td style="text-align:left">\star</td><td style="text-align:left">$\star$</td><td style="text-align:left">*</td><td style="text-align:left">$*$</td><td style="text-align:left">\ldots</td><td style="text-align:left">$\ldots$</td><td style="text-align:left">\smile</td><td style="text-align:left">$\smile$</td><td style="text-align:left">\frown</td><td style="text-align:left">$\frown$</td><td style="text-align:left">\wr</td><td style="text-align:left">$\wr$</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\oplus</td><td style="text-align:left">$\oplus$</td><td style="text-align:left">\bigoplus</td><td style="text-align:left">$\bigoplus$</td><td style="text-align:left">\otimes</td><td style="text-align:left">$\otimes$</td></tr><tr><td style="text-align:left">\bigotimes</td><td style="text-align:left">$\bigotimes$</td><td style="text-align:left">\times</td><td style="text-align:left">$\times$</td><td style="text-align:left">\cdot</td><td style="text-align:left">$\cdot$</td></tr><tr><td style="text-align:left">\div</td><td style="text-align:left">$\div$</td><td style="text-align:left">\circ</td><td style="text-align:left">$\circ$</td><td style="text-align:left">\bullet</td><td style="text-align:left">$\bullet$</td></tr><tr><td style="text-align:left">\bigodot</td><td style="text-align:left">$\bigodot$</td><td style="text-align:left">\boxtimes</td><td style="text-align:left">$\boxtimes$</td><td style="text-align:left">\boxplus</td><td style="text-align:left">$\boxplus$</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\triangleleft</td><td style="text-align:left">$\triangleleft$</td><td style="text-align:left">\triangleright</td><td style="text-align:left">$\triangleright$</td><td style="text-align:left">\infty</td><td style="text-align:left">$\infty$</td><td style="text-align:left">\bot</td><td style="text-align:left">$\bot$</td></tr><tr><td style="text-align:left">\top</td><td style="text-align:left">$\top$</td><td style="text-align:left">\vdash</td><td style="text-align:left">$\vdash$</td><td style="text-align:left">\vDash</td><td style="text-align:left">$\vDash$</td><td style="text-align:left">\Vdash</td><td style="text-align:left">$\Vdash$</td></tr><tr><td style="text-align:left">\models</td><td style="text-align:left">$\models$</td><td style="text-align:left">\lVert</td><td style="text-align:left">$\lVert$</td><td style="text-align:left">\rVert</td><td style="text-align:left">$\rVert$</td><td style="text-align:left"></td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\imath</td><td style="text-align:left">$\imath$</td><td style="text-align:left">\hbar</td><td style="text-align:left">$\hbar$</td><td style="text-align:left">\ell</td><td style="text-align:left">$\ell$</td></tr><tr><td style="text-align:left">\mho</td><td style="text-align:left">$\mho$</td><td style="text-align:left">\Finv</td><td style="text-align:left">$\Finv$</td><td style="text-align:left">\Re</td><td style="text-align:left">$\Re$</td></tr><tr><td style="text-align:left">\Im</td><td style="text-align:left">$\Im$</td><td style="text-align:left">\wp</td><td style="text-align:left">$\wp$</td><td style="text-align:left">\complement</td><td style="text-align:left">$\complement$</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">\diamondsuit</td><td style="text-align:left">$\diamondsuit$</td><td style="text-align:left">\heartsuit</td><td style="text-align:left">$\heartsuit$</td><td style="text-align:left">\clubsuit</td><td style="text-align:left">$\clubsuit$</td><td style="text-align:left">\spadesuit</td><td style="text-align:left">$\spadesuit$</td></tr><tr><td style="text-align:left">\Game</td><td style="text-align:left">$\Game$</td><td style="text-align:left">\flat</td><td style="text-align:left">$\flat$</td><td style="text-align:left">\natural</td><td style="text-align:left">$\natural$</td><td style="text-align:left">\sharp</td><td style="text-align:left">$\sharp$</td></tr></tbody></table></div><h2 id="上标、下标及积分等"><a href="#上标、下标及积分等" class="headerlink" title="上标、下标及积分等"></a>上标、下标及积分等</h2><div class="table-container"><table><thead><tr><th style="text-align:left">功能</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">上标</td><td style="text-align:left">a^2</td><td style="text-align:left">$a^2$</td></tr><tr><td style="text-align:left">下标</td><td style="text-align:left">a_2</td><td style="text-align:left">$a_2$</td></tr><tr><td style="text-align:left">组合</td><td style="text-align:left">a^{2+2}</td><td style="text-align:left">$a^{2+2}$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">a_{i,j}</td><td style="text-align:left">$a_{i,j}$</td></tr><tr><td style="text-align:left">结合上下标</td><td style="text-align:left">x_2^3</td><td style="text-align:left">$x_2^3$</td></tr><tr><td style="text-align:left">前置上下标</td><td style="text-align:left">{}_1^2!X_3^4</td><td style="text-align:left">${}_1^2!X_3^4$</td></tr><tr><td style="text-align:left">导数 （<strong>HTML</strong>）</td><td style="text-align:left">x’</td><td style="text-align:left">$x’$</td></tr><tr><td style="text-align:left">导数 （<strong>PNG</strong>）</td><td style="text-align:left">x^\prime</td><td style="text-align:left">$x^\prime$</td></tr><tr><td style="text-align:left">导数 （<strong>错误</strong>）</td><td style="text-align:left">x\prime</td><td style="text-align:left">$x\prime$</td></tr><tr><td style="text-align:left">导数点</td><td style="text-align:left">\dot{x}</td><td style="text-align:left">$\dot{x}$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">\ddot{y}</td><td style="text-align:left">$\ddot{y}$</td></tr><tr><td style="text-align:left">向量</td><td style="text-align:left">\vec{c}</td><td style="text-align:left">$\vec{c}$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">\overleftarrow{a b}</td><td style="text-align:left">$\overleftarrow{a b}$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">\overrightarrow{c d}</td><td style="text-align:left">$\overrightarrow{c d}$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">\widehat{e f g}</td><td style="text-align:left">$\widehat{e f g}$</td></tr><tr><td style="text-align:left">上弧</td><td style="text-align:left">\overset{\frown} {AB}</td><td style="text-align:left">$\overset{\frown} {AB}$</td></tr><tr><td style="text-align:left">上划线</td><td style="text-align:left">\overline{h i j}</td><td style="text-align:left">$\overline{h i j}$</td></tr><tr><td style="text-align:left">下划线</td><td style="text-align:left">\underline{k l m}</td><td style="text-align:left">$\underline{k l m}$</td></tr><tr><td style="text-align:left">上括号</td><td style="text-align:left">\overbrace{1+2+\cdots+100}</td><td style="text-align:left">$\overbrace{1+2+\cdots+100}$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"> begin{matrix} 5050 \ \overbrace{ 1+2+\cdots+100 } \end{matrix}</td><td style="text-align:left">$\begin{matrix} 5050 \ \overbrace{ 1+2+\cdots+100 } \end{matrix}$</td></tr><tr><td style="text-align:left">下括号</td><td style="text-align:left">\underbrace{a+b+\cdots+z}</td><td style="text-align:left">$\underbrace{a+b+\cdots+z}$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"> begin{matrix} \underbrace{ a+b+\cdots+z } \ 26 \end{matrix}</td><td style="text-align:left">$\begin{matrix} \underbrace{ a+b+\cdots+z } \ 26 \end{matrix}$</td></tr><tr><td style="text-align:left">求和</td><td style="text-align:left">\sum_{k=1}^N k^2</td><td style="text-align:left">$\sum_{k=1}^N k^2$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"> begin{matrix} \sum_{k=1}^N k^2 \end{matrix}</td><td style="text-align:left">$\begin{matrix} \sum_{k=1}^N k^2 \end{matrix}$</td></tr><tr><td style="text-align:left">求积</td><td style="text-align:left">\prod_{i=1}^N x_i</td><td style="text-align:left">$\prod_{i=1}^N x_i$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"> begin{matrix} \prod_{i=1}^N x_i \end{matrix}</td><td style="text-align:left">$\begin{matrix} \prod_{i=1}^N x_i \end{matrix}$</td></tr><tr><td style="text-align:left">上积</td><td style="text-align:left">\coprod_{i=1}^N x_i</td><td style="text-align:left">$\coprod_{i=1}^N x_i$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"> begin{matrix} \coprod_{i=1}^N x_i \end{matrix}</td><td style="text-align:left">$\begin{matrix} \coprod_{i=1}^N x_i \end{matrix}$</td></tr><tr><td style="text-align:left">极限</td><td style="text-align:left">\lim_{n \to \infty}x_n</td><td style="text-align:left">$\lim_{n \to \infty}x_n$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"> begin{matrix} \lim_{n \to \infty}x_n \end{matrix}</td><td style="text-align:left">$\begin{matrix} \lim_{n \to \infty}x_n \end{matrix}$</td></tr><tr><td style="text-align:left">积分</td><td style="text-align:left">\int_{-N}^{N} e^x\, dx</td><td style="text-align:left">$\int_{-N}^{N} e^x\, dx$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"> begin{matrix} \int_{-N}^{N} e^x\, dx \end{matrix}</td><td style="text-align:left">$\begin{matrix} \int_{-N}^{N} e^x\, dx \end{matrix}$</td></tr><tr><td style="text-align:left">双重积分</td><td style="text-align:left">\iint_{D}^{W} \, dx\,dy</td><td style="text-align:left">$\iint_{D}^{W} \, dx\,dy$</td></tr><tr><td style="text-align:left">三重积分</td><td style="text-align:left">\iiint_{E}^{V} \, dx\,dy\,dz</td><td style="text-align:left">$\iiint_{E}^{V} \, dx\,dy\,dz$</td></tr><tr><td style="text-align:left">四重积分</td><td style="text-align:left">\iiiint_{F}^{U} \, dx\,dy\,dz\,dt</td><td style="text-align:left">$\iiiint_{F}^{U} \, dx\,dy\,dz\,dt$</td></tr><tr><td style="text-align:left">闭合的曲线,曲面积分</td><td style="text-align:left">\oint_{C} x^3\, dx + 4y^2\, dy</td><td style="text-align:left">$\oint_{C} x^3\, dx + 4y^2\, dy$</td></tr><tr><td style="text-align:left">交集</td><td style="text-align:left">\bigcap_1^{n} p</td><td style="text-align:left">$\bigcap_1^{n} p$</td></tr><tr><td style="text-align:left">并集</td><td style="text-align:left">\bigcup_1^{k} p</td><td style="text-align:left">$\bigcup_1^{k} p$</td></tr></tbody></table></div><h2 id="分数、矩阵和多行列式"><a href="#分数、矩阵和多行列式" class="headerlink" title="分数、矩阵和多行列式"></a>分数、矩阵和多行列式</h2><div class="table-container"><table><thead><tr><th style="text-align:left">功能</th><th style="text-align:left">语法</th><th style="text-align:left">效果</th></tr></thead><tbody><tr><td style="text-align:left">分数</td><td style="text-align:left">\frac{2}{4}=0.5</td><td style="text-align:left">$\frac{2}{4}=0.5$</td></tr><tr><td style="text-align:left">小型分数</td><td style="text-align:left">\tfrac{2}{4} = 0.5</td><td style="text-align:left">$\tfrac{2}{4} = 0.5$</td></tr><tr><td style="text-align:left">大型分数（嵌套）</td><td style="text-align:left">\cfrac{2}{c + \cfrac{2}{d + \cfrac{2}{4}}} = a</td><td style="text-align:left">$\cfrac{2}{c + \cfrac{2}{d + \cfrac{2}{4}}} = a$</td></tr><tr><td style="text-align:left">大型分数（不嵌套）</td><td style="text-align:left">\dfrac{2}{4} = 0.5 \qquad \dfrac{2}{c + \dfrac{2}{d + \dfrac{2}{4}}} = a</td><td style="text-align:left">$\dfrac{2}{4} = 0.5 \qquad \dfrac{2}{c + \dfrac{2}{d + \dfrac{2}{4}}} = a$</td></tr><tr><td style="text-align:left">二项式系数</td><td style="text-align:left">\dbinom{n}{r}=\binom{n}{n-r}=C^n_r=C^n_{n-r}</td><td style="text-align:left">$\dbinom{n}{r}=\binom{n}{n-r}=C^n_r=C^n_{n-r}$</td></tr><tr><td style="text-align:left">小型二项式系数</td><td style="text-align:left">\tbinom{n}{r}=\tbinom{n}{n-r}=C^n_r=C^n_{n-r}</td><td style="text-align:left">$\tbinom{n}{r}=\tbinom{n}{n-r}=C^n_r=C^n_{n-r}$</td></tr><tr><td style="text-align:left">大型二项式系数</td><td style="text-align:left">\binom{n}{r}=\dbinom{n}{n-r}=C^n_r=C^n_{n-r}</td><td style="text-align:left">$\binom{n}{r}=\dbinom{n}{n-r}=C^n_r=C^n_{n-r}$</td></tr><tr><td style="text-align:left">矩阵</td><td style="text-align:left"> begin{matrix} x &amp; y \ z &amp; v \end{matrix}</td><td style="text-align:left">$\begin{matrix} x &amp; y \ z &amp; v \end{matrix}$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"> begin{vmatrix} x &amp; y \ z &amp; v \end{vmatrix}</td><td style="text-align:left">$\begin{vmatrix} x &amp; y \ z &amp; v \end{vmatrix}$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"> begin{Vmatrix} x &amp; y \ z &amp; v \end{Vmatrix}</td><td style="text-align:left">$\begin{Vmatrix} x &amp; y \ z &amp; v \end{Vmatrix}$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"> begin{bmatrix} 0 &amp; \cdots &amp; 0 \ \vdots &amp; \ddots &amp; \vdots \ 0 &amp; \cdots &amp; 0 \end{bmatrix}</td><td style="text-align:left">$\begin{bmatrix} 0 &amp; \cdots &amp; 0 \ \vdots &amp; \ddots &amp; \vdots \ 0 &amp; \cdots &amp; 0 \end{bmatrix}$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"> begin{Bmatrix} x &amp; y \ z &amp; v \end{Bmatrix}</td><td style="text-align:left">$\begin{Bmatrix} x &amp; y \ z &amp; v \end{Bmatrix}$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"> begin{pmatrix} x &amp; y \ z &amp; v \end{pmatrix}</td><td style="text-align:left">$\begin{pmatrix} x &amp; y \ z &amp; v \end{pmatrix}$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"> bigl(  begin{smallmatrix} a&amp;b\ c&amp;d \end{smallmatrix} \bigr)</td><td style="text-align:left">$\bigl( \begin{smallmatrix} a&amp;b\ c&amp;d \end{smallmatrix} \bigr)$</td></tr><tr><td style="text-align:left">条件定义</td><td style="text-align:left">f(n) =  begin{cases} n/2, &amp; \mbox{if }n\mbox{ is even} \ 3n+1, &amp; \mbox{if }n\mbox{ is odd} \end{cases}</td><td style="text-align:left">$f(n) = \begin{cases} n/2, &amp; \mbox{if }n\mbox{ is even} \ 3n+1, &amp; \mbox{if }n\mbox{ is odd} \end{cases}$</td></tr><tr><td style="text-align:left">多行等式</td><td style="text-align:left"> begin{align} f(x) &amp; = (m+n)^2 \ &amp; = m^ 2+2mn+n^2 \ \end{align}</td><td style="text-align:left">$\begin{align} f(x) &amp; = (m+n)^2 \ &amp; = m^2+2mn+n^2 \ \end{align}$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left"> begin{alignat}{2} f(x) &amp; = (m-n)^2 \ f(x) &amp; = (-m+n)^2 \ &amp; = m^ 2-2mn+n^2 \ \end{alignat}</td><td style="text-align:left">$\begin{alignat}{2} f(x) &amp; = (m-n)^2 \ f(x) &amp; = (-m+n)^2 \ &amp; = m^2-2mn+n^2 \ \end{alignat}$</td></tr><tr><td style="text-align:left">多行等式（左对齐）</td><td style="text-align:left"> begin{array}{lcl} z &amp; = &amp; a \ f(x,y,z) &amp; = &amp; x + y + z \end{array}</td><td style="text-align:left">$\begin{array}{lcl} z &amp; = &amp; a \ f(x,y,z) &amp; = &amp; x + y + z \end{array}$</td></tr><tr><td style="text-align:left">多行等式（右对齐）</td><td style="text-align:left"> begin{array}{lcr} z &amp; = &amp; a \ f(x,y,z) &amp; = &amp; x + y + z \end{array}</td><td style="text-align:left">$\begin{array}{lcr} z &amp; = &amp; a \ f(x,y,z) &amp; = &amp; x + y + z \end{array}$</td></tr><tr><td style="text-align:left">方程组</td><td style="text-align:left"> begin{cases} 3x + 5y + z \ 7x - 2y + 4z \ -6x + 3y + 2z \end{cases}</td><td style="text-align:left">$\begin{cases} 3x + 5y + z \ 7x - 2y + 4z \ -6x + 3y + 2z \end{cases}$</td></tr><tr><td style="text-align:left">数组</td><td style="text-align:left"> begin{array}{lclclcl} a &amp; b &amp; S \ \hline 0&amp;0&amp;1\ 0&amp;1&amp;1\ 1&amp;0&amp;1\ 1&amp;1&amp;0\ \end{array}</td><td style="text-align:left">$\begin{array}{lclclcl} a &amp; b &amp; S \ \hline 0&amp;0&amp;1\ 0&amp;1&amp;1\ 1&amp;0&amp;1\ 1&amp;1&amp;0 \end{array}$</td></tr></tbody></table></div><h2 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h2><h3 id="希腊字母-1"><a href="#希腊字母-1" class="headerlink" title="希腊字母"></a>希腊字母</h3><p>斜体小写希腊字母一般用于在方程中显示变量。</p><div class="table-container"><table><thead><tr><th style="text-align:left">正体希腊字母</th><th style="text-align:left"></th></tr></thead><tbody><tr><td style="text-align:left">特征</td><td style="text-align:left">效果</td></tr><tr><td style="text-align:left">\Alpha \Beta \Gamma \Delta \Epsilon \Zeta \Eta \Theta</td><td style="text-align:left">$\Alpha \Beta \Gamma \Delta \Epsilon \Zeta \Eta \Theta$</td></tr><tr><td style="text-align:left">\Iota \Kappa \Lambda \Mu \Nu \Xi \Omicron \Pi</td><td style="text-align:left">$\Iota \Kappa \Lambda \Mu \Nu \Xi \Omicron \Pi$</td></tr><tr><td style="text-align:left">\Rho \Sigma \Tau \Upsilon \Phi \Chi \Psi \Omega</td><td style="text-align:left">$\Rho \Sigma \Tau \Upsilon \Phi \Chi \Psi \Omega$</td></tr><tr><td style="text-align:left">\alpha \beta \gamma \delta \epsilon \zeta \eta \theta</td><td style="text-align:left">$\alpha \beta \gamma \delta \epsilon \zeta \eta \theta$</td></tr><tr><td style="text-align:left">\iota \kappa\varkappa \lambda \mu \nu \xi \omicron \pi</td><td style="text-align:left">$\iota \kappa\varkappa \lambda \mu \nu \xi \omicron \pi$</td></tr><tr><td style="text-align:left">\rho \sigma \tau \upsilon \phi \chi \psi \omega</td><td style="text-align:left">$\rho \sigma \tau \upsilon \phi \chi \psi \omega$</td></tr><tr><td style="text-align:left">\Epsilon\epsilon\varepsilon</td><td style="text-align:left">$\Epsilon\epsilon\varepsilon$</td></tr><tr><td style="text-align:left">\Theta\theta\vartheta</td><td style="text-align:left">$\Theta\theta\vartheta$</td></tr><tr><td style="text-align:left">\Kappa\kappa\varkappa</td><td style="text-align:left">$\Kappa\kappa\varkappa$</td></tr><tr><td style="text-align:left">\Pi\pi\varpi</td><td style="text-align:left">$\Pi\pi\varpi$</td></tr><tr><td style="text-align:left">\Rho\rho\varrho</td><td style="text-align:left">$\Rho\rho\varrho$</td></tr><tr><td style="text-align:left">\Sigma\sigma\varsigma</td><td style="text-align:left">$\Sigma\sigma\varsigma$</td></tr><tr><td style="text-align:left">\Phi\phi\varphi</td><td style="text-align:left">$\Phi\phi\varphi$</td></tr><tr><td style="text-align:left">\digamma</td><td style="text-align:left">$\digamma$</td></tr></tbody></table></div><h3 id="黑板粗体"><a href="#黑板粗体" class="headerlink" title="黑板粗体"></a>黑板粗体</h3><p>语法</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\mathbb</span>&#123;ABCDEFGHIJKLMNOPQRSTUVWXYZ&#125;<br></code></pre></td></tr></table></figure><p>效果</p><p>$\mathbb{ABCDEFGHIJKLMNOPQRSTUVWXYZ}$</p><p>黑板粗体（Blackboard bold）一般用于表示数学和物理学中的向量或集合的符号。</p><h3 id="正粗体"><a href="#正粗体" class="headerlink" title="正粗体"></a>正粗体</h3><p>语法1</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\mathbf</span>&#123;012…abc…ABC…&#125;<br></code></pre></td></tr></table></figure><p>效果1</p><p>$\mathbf{012…abc…ABC…}$</p><p>语法2</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\boldsymbol</span>&#123;012…abc…ABC…<span class="hljs-keyword">\alpha</span> <span class="hljs-keyword">\beta</span> <span class="hljs-keyword">\gamma</span>…&#125;<br></code></pre></td></tr></table></figure><p>效果2</p><p>$\boldsymbol{012…abc…ABC…\alpha \beta \gamma…}$</p><p>备注</p><p>使用<code>\boldsymbol&#123;&#125;</code>可以加粗所有合法的符号。</p><h3 id="斜体数字"><a href="#斜体数字" class="headerlink" title="斜体数字"></a>斜体数字</h3><p>语法</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\mathit</span>&#123;0123456789&#125;<br></code></pre></td></tr></table></figure><p>效果</p><p>$\mathit{0123456789}$</p><h3 id="罗马体"><a href="#罗马体" class="headerlink" title="罗马体"></a>罗马体</h3><p>语法</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\mathrm</span>&#123;012…abc…ABC…&#125;或<span class="hljs-keyword">\mbox</span>&#123;&#125;或<span class="hljs-keyword">\operatorname</span>&#123;&#125;<br></code></pre></td></tr></table></figure><p>效果</p><p>$\mathrm{012…abc…ABC…}$</p><h3 id="花体"><a href="#花体" class="headerlink" title="花体"></a>花体</h3><p>语法</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\mathscr</span>&#123;012…abc…ABC…&#125;<br></code></pre></td></tr></table></figure><p>效果</p><p>$\mathscr{012…abc…ABC…}$</p><blockquote><p>通常使用的是大写</p></blockquote><h3 id="哥特体"><a href="#哥特体" class="headerlink" title="哥特体"></a>哥特体</h3><p>语法</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\mathfrak</span>&#123;012…abc…ABC…&#125;<br></code></pre></td></tr></table></figure><p>效果</p><p>$\mathfrak{012…abc…ABC…}$</p><h3 id="手写体"><a href="#手写体" class="headerlink" title="手写体"></a>手写体</h3><p>语法</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\mathcal</span>&#123;ABC…&#125;<br></code></pre></td></tr></table></figure><p>效果</p><p>$\mathcal{ABC…}$</p><h3 id="希伯来字母"><a href="#希伯来字母" class="headerlink" title="希伯来字母"></a>希伯来字母</h3><p>语法</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\aleph</span><span class="hljs-keyword">\beth</span><span class="hljs-keyword">\gimel</span><span class="hljs-keyword">\daleth</span><br></code></pre></td></tr></table></figure><p>效果</p><p>$\aleph\beth\gimel\daleth$</p><h2 id="括号"><a href="#括号" class="headerlink" title="括号"></a>括号</h2><div class="table-container"><table><thead><tr><th style="text-align:left">功能</th><th style="text-align:left">语法</th><th style="text-align:left">显示</th></tr></thead><tbody><tr><td style="text-align:left">不好看</td><td style="text-align:left">( \frac{1}{2} )</td><td style="text-align:left">$\frac{1}{2}$</td></tr><tr><td style="text-align:left">好看了</td><td style="text-align:left">\left( \frac{1}{2} \right)</td><td style="text-align:left">$\left( \frac{1}{2} \right)$</td></tr></tbody></table></div><p>您可以使用 <code>\left</code> 和 <code>\right</code> 来显示不同的括号：</p><div class="table-container"><table><thead><tr><th style="text-align:left">功能</th><th style="text-align:left">语法</th><th style="text-align:left">显示</th></tr></thead><tbody><tr><td style="text-align:left">圆括号，小括号</td><td style="text-align:left">\left<strong>(</strong> \frac{a}{b} \right<strong>)</strong></td><td style="text-align:left">$\left( \frac{a}{b} \right)$</td></tr><tr><td style="text-align:left">方括号，中括号</td><td style="text-align:left">\left<strong>[</strong> \frac{a}{b} \right<strong>]</strong></td><td style="text-align:left">$\left[ \frac{a}{b} \right]$</td></tr><tr><td style="text-align:left">花括号，大括号</td><td style="text-align:left">\left<strong>\{</strong> \frac{a}{b} \right<strong>\}</strong></td><td style="text-align:left">$\left\{ \frac{a}{b} \right\}$</td></tr><tr><td style="text-align:left">角括号</td><td style="text-align:left">\left <strong>\langle</strong> \frac{a}{b} \right <strong>\rangle</strong></td><td style="text-align:left">$\left \langle \frac{a}{b} \right \rangle$</td></tr><tr><td style="text-align:left">单竖线，绝对值</td><td style="text-align:left">\left<strong>l</strong> \frac{a}{b} \right<strong>l</strong></td><td style="text-align:left"><img src="/2021/02/28/LATEX%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/pic1-2.jpg" alt></td></tr><tr><td style="text-align:left">双竖线，范</td><td style="text-align:left">\left <strong>\l</strong> \frac{a}{b} \right <strong>\l</strong></td><td style="text-align:left"><img src="/2021/02/28/LATEX%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/pic1-3.jpg" alt></td></tr><tr><td style="text-align:left">取整函数</td><td style="text-align:left">\left <strong>\lfloor</strong> \frac{a}{b} \right <strong>\rfloor</strong></td><td style="text-align:left">$\left \lfloor \frac{a}{b} \right \rfloor$</td></tr><tr><td style="text-align:left">取顶函数</td><td style="text-align:left">\left <strong>\lceil</strong> \frac{c}{d} \right <strong>\rceil</strong></td><td style="text-align:left">$\left \lceil \frac{c}{d} \right \rceil$</td></tr><tr><td style="text-align:left">斜线与反斜线</td><td style="text-align:left">\left <strong>/</strong> \frac{a}{b} \right <strong>\backslash</strong></td><td style="text-align:left">$\left / \frac{a}{b} \right \backslash$</td></tr><tr><td style="text-align:left">上下箭头</td><td style="text-align:left">\left <strong>\uparrow</strong> \frac{a}{b} \right <strong>\downarrow</strong></td><td style="text-align:left">$\left \uparrow \frac{a}{b} \right \downarrow$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">\left <strong>\Uparrow</strong> \frac{a}{b} \right <strong>\Downarrow</strong></td><td style="text-align:left">$\left \Uparrow \frac{a}{b} \right \Downarrow$</td></tr><tr><td style="text-align:left"></td><td style="text-align:left">\left <strong>\updownarrow</strong> \frac{a}{b} \right <strong>\Updownarrow</strong></td><td style="text-align:left">$\left \updownarrow \frac{a}{b} \right \Updownarrow$</td></tr><tr><td style="text-align:left">混合括号</td><td style="text-align:left">\left [ 0,1 \right ) \left \langle \psi \right l</td><td style="text-align:left"><img src="/2021/02/28/LATEX%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/pic1-1.jpg" alt></td></tr><tr><td style="text-align:left">单左括号</td><td style="text-align:left">\left \{ \frac{a}{b} <strong>\right .</strong></td><td style="text-align:left">$\left \{ \frac{a}{b} \right .$</td></tr><tr><td style="text-align:left">单右括号</td><td style="text-align:left"><strong>\left .</strong> \frac{a}{b} \right \}</td><td style="text-align:left">$\left . \frac{a}{b} \right \}$</td></tr></tbody></table></div><p>备注：</p><ul><li>可以使用 <code>\big, \Big, \bigg, \Bigg</code> 控制括号的大小，比如代码</li></ul><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\Bigg</span> ( <span class="hljs-keyword">\bigg</span> [ <span class="hljs-keyword">\Big</span> <span class="hljs-keyword">\&#123;</span> <span class="hljs-keyword">\big</span> <span class="hljs-keyword">\langle</span> <span class="hljs-keyword">\left</span> | <span class="hljs-keyword">\|</span> <span class="hljs-keyword">\frac</span>&#123;a&#125;&#123;b&#125; <span class="hljs-keyword">\|</span> <span class="hljs-keyword">\right</span> | <span class="hljs-keyword">\big</span> <span class="hljs-keyword">\rangle</span> <span class="hljs-keyword">\Big</span> <span class="hljs-keyword">\&#125;</span> <span class="hljs-keyword">\bigg</span> ] <span class="hljs-keyword">\Bigg</span> )<br></code></pre></td></tr></table></figure><p>显示︰</p><script type="math/tex; mode=display">\Bigg ( \bigg [ \Big \{ \big \langle \left | \| \frac{a}{b} \| \right | \big\rangle \Big \} \bigg ] \Bigg )</script><h2 id="空格"><a href="#空格" class="headerlink" title="空格"></a>空格</h2><p>注意TEX能够自动处理大多数的空格，但是您有时候需要自己来控制。</p><div class="table-container"><table><thead><tr><th style="text-align:left">功能</th><th style="text-align:left">语法</th><th style="text-align:left">显示</th><th style="text-align:left">宽度</th></tr></thead><tbody><tr><td style="text-align:left">2个quad空格</td><td style="text-align:left">\alpha\qquad\beta</td><td style="text-align:left">$\alpha\qquad\beta$</td><td style="text-align:left">$2m$</td></tr><tr><td style="text-align:left">quad空格</td><td style="text-align:left">\alpha\quad\beta</td><td style="text-align:left">$\alpha\quad\beta$</td><td style="text-align:left">$m$</td></tr><tr><td style="text-align:left">大空格</td><td style="text-align:left">\alpha \beta</td><td style="text-align:left">$\alpha \beta$</td><td style="text-align:left">$\frac{m}{3}$</td></tr><tr><td style="text-align:left">中等空格</td><td style="text-align:left">\alpha\;\beta</td><td style="text-align:left">$\alpha\;\beta$</td><td style="text-align:left">$\frac{2m}{7}$</td></tr><tr><td style="text-align:left">小空格</td><td style="text-align:left">\alpha\,\beta</td><td style="text-align:left">$\alpha\,\beta$</td><td style="text-align:left">$\frac{m}{6}$</td></tr><tr><td style="text-align:left">没有空格</td><td style="text-align:left">\alpha\beta</td><td style="text-align:left">$\alpha\beta$</td><td style="text-align:left">$0$</td></tr><tr><td style="text-align:left">紧贴</td><td style="text-align:left">\alpha!\beta</td><td style="text-align:left">$\alpha!\beta$</td><td style="text-align:left">$\frac{m}{6}$</td></tr></tbody></table></div><h2 id="颜色"><a href="#颜色" class="headerlink" title="颜色"></a>颜色</h2><p>语法</p><ul><li>字体颜色︰<code>&#123;\color&#123;色调&#125;表达式&#125;</code></li><li>背景颜色︰<code>&#123;\pagecolor&#123;色调&#125;表达式&#125;</code></li></ul><p>支援色调表</p><div class="table-container"><table><thead><tr><th>${\color{Apricot}Apricot}$</th><th>${\color{Aquamarine}Aquamarine}$</th><th>${\color{Bittersweet}Bittersweet}$</th><th>${\color{Black}Black}$</th></tr></thead><tbody><tr><td>${\color{Blue}Blue}$</td><td>${\color{BlueGreen}BlueGreen}$</td><td>${\color{BlueViolet}BlueViolet}$</td><td>${\color{BrickRed}BrickRed}$</td></tr><tr><td>${\color{Brown}Brown}$</td><td>${\color{BurntOrange}BurntOrange}$</td><td>${\color{CadetBlue}CadetBlue}$</td><td>${\color{CarnationPink}CarnationPink}$</td></tr><tr><td>${\color{Cerulean}Cerulean}$</td><td>${\color{CornflowerBlue}CornflowerBlue}$</td><td>${\color{Cyan}Cyan}$</td><td>${\color{Dandelion}Dandelion}$</td></tr><tr><td>${\color{DarkOrchid}DarkOrchid}$</td><td>${\color{Emerald}Emerald}$</td><td>${\color{ForestGreen}ForestGreen}$</td><td>${\color{Fuchsia}Fuchsia}$</td></tr><tr><td>${\color{Goldenrod}Goldenrod}$</td><td>${\color{Gray}Gray}$</td><td>${\color{Green}Green}$</td><td>${\color{GreenYellow}GreenYellow}$</td></tr><tr><td>${\color{JungleGreen}JungleGreen}$</td><td>${\color{Lavender}Lavender}$</td><td>${\color{LimeGreen}LimeGreen}$</td><td>${\color{Magenta}Magenta}$</td></tr><tr><td>${\color{Mahogany}Mahogany}$</td><td>${\color{Maroon}Maroon}$</td><td>${\color{Melon}Melon}$</td><td>${\color{MidnightBlue}MidnightBlue}$</td></tr><tr><td>${\color{Mulberry}Mulberry}$</td><td>${\color{NavyBlue}NavyBlue}$</td><td>${\color{OliveGreen}OliveGreen}$</td><td>${\color{Orange}Orange}$</td></tr><tr><td>${\color{OrangeRed}OrangeRed}$</td><td>${\color{Orchid}Orchid}$</td><td>${\color{Peach}Peach}$</td><td>${\color{Periwinkle}Periwinkle}$</td></tr><tr><td>${\color{PineGreen}PineGreen}$</td><td>${\color{Plum}Plum}$</td><td>${\color{ProcessBlue}ProcessBlue}$</td><td>${\color{Purple}Purple}$</td></tr><tr><td>${\color{RawSienna}RawSienna}$</td><td>${\color{Red}Red}$</td><td>${\color{RedOrange}RedOrange}$</td><td>${\color{RedViolet}RedViolet}$</td></tr><tr><td>${\color{Rhodamine}Rhodamine}$</td><td>${\color{RoyalBlue}RoyalBlue}$</td><td>${\color{RoyalPurple}RoyalPurple}$</td><td>${\color{RubineRed}RubineRed}$</td></tr><tr><td>${\color{Salmon}Salmon}$</td><td>${\color{SeaGreen}SeaGreen}$</td><td>${\color{Sepia}Sepia}$</td><td>${\color{SkyBlue}SkyBlue}$</td></tr><tr><td>${\color{SpringGreen}SpringGreen}$</td><td>${\color{Tan}Tan}$</td><td>${\color{TealBlue}TealBlue}$</td><td>${\color{Thistle}Thistle}$</td></tr><tr><td>${\color{Turquoise}Turquoise}$</td><td>${\color{Violet}Violet}$</td><td>${\color{VioletRed}VioletRed}$</td><td>${\color{White}White}$</td></tr><tr><td>${\color{WildStrawberry}WildStrawberry}$</td><td>${\color{Yellow}Yellow}$</td><td>${\color{YellowGreen}YellowGreen}$</td><td>${\color{YellowOrange}YellowOrange}$</td></tr></tbody></table></div><p>注︰输入时第一个字母必需以大写输入，如<code>\color&#123;OliveGreen&#125;</code></p><p>例子</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs latex">- &#123;<span class="hljs-keyword">\color</span>&#123;Blue&#125;x<span class="hljs-built_in">^</span>2&#125;+&#123;<span class="hljs-keyword">\color</span>&#123;Brown&#125;2x&#125; - &#123;<span class="hljs-keyword">\color</span>&#123;OliveGreen&#125;1&#125;<br><br>- x<span class="hljs-built_in">_</span>&#123;<span class="hljs-keyword">\color</span>&#123;Maroon&#125;1,2&#125;=<span class="hljs-keyword">\frac</span>&#123;-b<span class="hljs-keyword">\pm</span><span class="hljs-keyword">\sqrt</span>&#123;&#123;<span class="hljs-keyword">\color</span>&#123;Maroon&#125;b<span class="hljs-built_in">^</span>2-4ac&#125;&#125;&#125;&#123;2a&#125;<br></code></pre></td></tr></table></figure><h2 id="小型数学公式"><a href="#小型数学公式" class="headerlink" title="小型数学公式"></a>小型数学公式</h2><p>当要把分数等公式放进文字中的时候，我们需要使用小型的数学公式。</p><p>可以使用：</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\begin</span>&#123;smallmatrix&#125;...<span class="hljs-keyword">\end</span>&#123;smallmatrix&#125;<br></code></pre></td></tr></table></figure><p>或直接使用<a href="http://zh.wikipedia.org/wiki/Template:Smallmath">Smallmath</a>模板。</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex">&#123;&#123;Smallmath|f= f(x)=5+<span class="hljs-keyword">\frac</span>&#123;1&#125;&#123;5&#125; &#125;&#125;<br></code></pre></td></tr></table></figure><h2 id="强制使用PNG"><a href="#强制使用PNG" class="headerlink" title="强制使用PNG"></a>强制使用PNG</h2><p>若你需要强制输出一个PNG图的数学公式的话，你可于公式的最后加上 <code>\,</code>（小空格，但于公式的最后是不会显示出来）。</p><p>输入 <code>2x=1 \,</code>的话以PNG图输出。</p><p>你也可以使用 <code>\,\!</code>，这个亦能强制使用PNG图像。</p><p>阅读更多︰<a href="http://en.wikipedia.org/wiki/Help:Displaying_a_formula#Forced_PNG_rendering">Help:Displaying a formula#Forced PNG rendering</a></p><h2 id="免费Latex识别-图片转换器"><a href="#免费Latex识别-图片转换器" class="headerlink" title="免费Latex识别+图片转换器"></a>免费Latex识别+图片转换器</h2><p><a href="https://latexlive.com/help">https://latexlive.com/help</a></p><hr><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><p><a href="https://blog.csdn.net/qq_17528659/article/details/82152530">夕若幽兰的Blog</a></p></li><li><p><a href="https://anorien.csc.warwick.ac.uk/mirrors/CTAN/info/symbols/comprehensive/symbols-a4.pdf">官方Symbol List</a></p></li><li><p><a href="https://blog.csdn.net/zgj926503/article/details/52757631/">Zhao-Pace的CSDN</a></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Latex</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【推导】Black Scholes Model</title>
    <link href="/2021/02/28/Black_Scholes_Model%E6%8E%A8%E5%AF%BC/"/>
    <url>/2021/02/28/Black_Scholes_Model%E6%8E%A8%E5%AF%BC/</url>
    
    <content type="html"><![CDATA[<blockquote><p> 基于格拉ECO5009课件；</p><p> 省略了关于测度变换的部分，直接求解；</p><p> 是比较早的笔记，完整的可以看进阶版；</p></blockquote><span id="more"></span><h3 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h3><ul><li>stock price 基于GBM：</li></ul><script type="math/tex; mode=display">dS = \mu Sdt + \sigma SdW</script><ul><li>Ito’s lemma：</li></ul><script type="math/tex; mode=display">df = (\frac{\partial f}{\partial S}\mu S + \frac{\partial f}{\partial t} + \frac{1}{2}\frac{\partial^2 f}{\partial S^2}\sigma^2S^2)dt + \frac{\partial f}{\partial S}\sigma SdW</script><h3 id="推导"><a href="#推导" class="headerlink" title="推导"></a>推导</h3><ul><li>let f = lnS, we have：</li></ul><script type="math/tex; mode=display">\frac{\partial f}{\partial S} = \frac{1}{S}, \frac{\partial^2 f}{\partial S^2} = \frac{1}{S^2}, \frac{\partial f}{\partial t} = 0</script><ul><li>so ：</li></ul><script type="math/tex; mode=display">dlnS_t = (\mu - \frac{\sigma^2}{2})dt +\sigma dW_t</script><ul><li>Integrating equation from time 0 to t and taking the exponential：</li></ul><script type="math/tex; mode=display">S_t = S_0exp((\mu - \frac{\sigma^2}{2})t +\sigma W_t)</script><ul><li>In the distribution $W_t  \sim \epsilon \sqrt{t}$</li></ul><script type="math/tex; mode=display">S_t = S_0exp((\mu - \frac{\sigma^2}{2})t +\sigma \epsilon \sqrt{t})</script><ul><li>With the risk-neutral valuation, where $\tau = T-t$：</li></ul><script type="math/tex; mode=display">c = e^{-r \tau}\widetilde{E}_t((S_T-K)^+)</script><ul><li>代入$S_T$（老师写的是$-\sigma \epsilon \sqrt{\tau}$ ,但说不影响EXP），$y \sim N(0,1)$</li></ul><script type="math/tex; mode=display">\begin{align}c &= e^{-r \tau}\widetilde{E}_t((S_texp((r - \frac{\sigma^2}{2})\tau +\sigma \sqrt{\tau}y)-K)^+)\\&(对y求积分)\\&= \int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}y^2} e^{-r \tau}(S_texp((r - \frac{\sigma^2}{2})\tau +\sigma \sqrt{\tau}y)-K)^+dy\end{align}</script><ul><li>分析，存在某一个点使$()^+$部分从正数到0</li></ul><script type="math/tex; mode=display">\begin{align}S_texp((r - \frac{\sigma^2}{2})\tau +\sigma \sqrt{\tau}y) &> K\\y &> (ln\frac{K}{S_t}-(r - \frac{\sigma^2}{2})\tau)\frac{1}{\sigma \sqrt{\tau}}\\y &< (ln\frac{S_t}{K}+(r - \frac{\sigma^2}{2})\tau)\frac{1}{\sigma \sqrt{\tau}}=d2\end{align}</script><ul><li>代入前一个式子：</li></ul><script type="math/tex; mode=display">\begin{align}c &= \int_{-\infty}^{d2} \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}y^2} e^{-r \tau}(S_texp((r - \frac{\sigma^2}{2})\tau +\sigma \sqrt{\tau}y)-K)dy\\&= \int_{-\infty}^{d2} \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}y^2} e^{-r \tau}(S_texp(r - \frac{\sigma^2}{2})\tau +\sigma \sqrt{\tau}y)dy- \int_{-\infty}^{d2} \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}y^2} e^{-r \tau}Kdy\\&= \frac{1}{\sqrt{2\pi}}S_t\int_{-\infty}^{d2} e^{-r \tau}e^{-\frac{1}{2}y^2} e^{(r - \frac{\sigma^2}{2})\tau +\sigma \sqrt{\tau}y}dy- e^{-r \tau}KN(d2)\\&= \frac{1}{\sqrt{2\pi}}S_t\int_{-\infty}^{d2}e^{-\frac{1}{2}(y-\sigma \sqrt{\tau})^2}dy- e^{-r \tau}KN(d2)\\\end{align}</script><ul><li>第一部分去掉$S_T$相当于：</li></ul><script type="math/tex; mode=display">\begin{align}N(y-\sigma \sqrt{\tau}<d2) &= N(y<d2+\sigma \sqrt{\tau}) = N(d1)\\d1 &= (ln\frac{S_t}{K}+(r + \frac{\sigma^2}{2})\tau)\frac{1}{\sigma \sqrt{\tau}}\end{align}</script><ul><li>得到最终结果：</li></ul><script type="math/tex; mode=display">c = S_tN(d1)- e^{-r \tau}KN(d2)\\</script><h3 id="MATLAB公式"><a href="#MATLAB公式" class="headerlink" title="MATLAB公式"></a>MATLAB公式</h3><p><code>[Call,Put] = blsprice(Price,Strike,Rate,Time,Volatility)</code></p>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Black Scholes Model</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【代码】Asian arithmetic Option</title>
    <link href="/2021/02/17/Asian_arithmetic_Option_With_MatlabCode/"/>
    <url>/2021/02/17/Asian_arithmetic_Option_With_MatlabCode/</url>
    
    <content type="html"><![CDATA[<blockquote><p> 对算术平均亚式期权Matlab代码的阅读；</p></blockquote><span id="more"></span><h4 id="Payoff-of-Asian-arithmetic’s-is"><a href="#Payoff-of-Asian-arithmetic’s-is" class="headerlink" title="Payoff of Asian arithmetic’s is"></a>Payoff of Asian arithmetic’s is</h4><script type="math/tex; mode=display">call : max(\frac{1}{n}\sum_i^nS_i-K_i,0)</script><h4 id="输入参数"><a href="#输入参数" class="headerlink" title="输入参数"></a>输入参数</h4><ul><li>r = risk free rate</li><li>u , d : $S_1(up)=S_0<em>u, S_1(down)=S_0</em>d$</li><li>strike = strike price (K)</li><li>s0 = $S_0$</li><li>imax = T or periods</li></ul><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs matlab">r = <span class="hljs-number">0.03</span>; u = <span class="hljs-number">1.1</span>; d = <span class="hljs-number">0.9</span>; <br>strike = <span class="hljs-number">9.5</span>; S0 = <span class="hljs-number">9</span>;<br>imax = <span class="hljs-number">3</span>;<br></code></pre></td></tr></table></figure><h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><ul><li>rnp = $\frac{1+r-d}{u-d}$ , risk neutral probability</li><li>SS : 初始化价格树，因为不同于欧式需要记录每一步，即$S_0ud$和$S_0du$的平均价格不等，因此需要$2^{imax}$种情况</li></ul><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs matlab">rnp = (<span class="hljs-number">1</span>+r-d)/(u-d);<br>SS = <span class="hljs-built_in">zeros</span>(<span class="hljs-number">2</span>^imax,imax+<span class="hljs-number">1</span>);<br>SS(:,<span class="hljs-number">1</span>) = S0;<br></code></pre></td></tr></table></figure><h5 id="output："><a href="#output：" class="headerlink" title="output："></a>output：</h5><p>​    SS =  (2^imax,imax+1)</p><script type="math/tex; mode=display">\begin{bmatrix} 9 & 0 & 0 & 0 \\\vdots&\vdots&\vdots&\vdots \\ 9 & 0 & 0 & 0 \\\end{bmatrix} \tag{8 x 4}</script><h4 id="建立up-down组合表"><a href="#建立up-down组合表" class="headerlink" title="建立up-down组合表"></a>建立up-down组合表</h4><ul><li>matr : 将所有可能排成$2^{imax}$行</li></ul><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs matlab">matr=[];<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:imax<br>    v1 = <span class="hljs-built_in">ones</span>(<span class="hljs-number">2</span>^(<span class="hljs-built_in">i</span><span class="hljs-number">-1</span>),<span class="hljs-number">1</span>);<br>    v2 = -v1;<br>    vc = <span class="hljs-built_in">repmat</span>([v1;v2],<span class="hljs-number">2</span>^(imax-<span class="hljs-built_in">i</span>),<span class="hljs-number">1</span>);<br>    <span class="hljs-comment">% repmat : 将矩阵[v1;v2]重复到2^(imax)×1块排列中</span><br>    matr = [vc,matr]; <span class="hljs-comment">%类似+=,从左加</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><h5 id="output：-1"><a href="#output：-1" class="headerlink" title="output："></a>output：</h5><p>​    matr = （2^imax,imax）</p><script type="math/tex; mode=display">\begin{bmatrix} 1 \\-1 \\1 \\-1 \\1 \\-1 \\1 \\-1 \\\end{bmatrix} =>\begin{bmatrix} 1 & 1 \\1 & -1 \\-1 & 1 \\-1 & -1 \\1 & 1 \\1 & -1 \\-1 & 1 \\-1 & -1 \\\end{bmatrix} =>\begin{bmatrix} 1 & 1 & 1 \\1 & 1 & -1 \\1 & -1 & 1 \\1 & -1 & -1 \\-1 & 1 & 1 \\-1 & 1 & -1 \\-1 & -1 & 1 \\-1 & -1 & -1 \\\end{bmatrix} \tag{8 x 3}</script><h4 id="补充价格树"><a href="#补充价格树" class="headerlink" title="补充价格树"></a>补充价格树</h4><ul><li>按照matr的组合对SS进行补充</li></ul><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-keyword">for</span> z = <span class="hljs-number">1</span>:<span class="hljs-number">2</span>^imax<br>    <span class="hljs-keyword">for</span> k = <span class="hljs-number">2</span>:imax+<span class="hljs-number">1</span><br>        SS(z,k)=SS(z,k<span class="hljs-number">-1</span>)*u;<br>        <span class="hljs-keyword">if</span> matr(z,k<span class="hljs-number">-1</span>)&lt;<span class="hljs-number">0</span><br>            SS(z,k)=SS(z,k<span class="hljs-number">-1</span>)*d;<br>        <span class="hljs-keyword">end</span><br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><h5 id="output：-2"><a href="#output：-2" class="headerlink" title="output："></a>output：</h5><p>​    SS = （2^imax,imax+1）</p><script type="math/tex; mode=display">\begin{bmatrix}     9&9.9&10.89&11.979\\    9&9.9&10.89&9.8010\\    9&9.9&8.91&9.8010\\    9&9.9&8.91&8.0190\\    9&8.1&8.91&9.8010\\    9&8.1&8.91&8.0190\\    9&8.1&7.29&8.0190\\    9&8.1&7.29&6.5610\\\end{bmatrix} \tag{8 x 4}</script><h4 id="计算收益"><a href="#计算收益" class="headerlink" title="计算收益"></a>计算收益</h4><ul><li>按照公式计算收益</li></ul><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs matlab">payoff = <span class="hljs-built_in">max</span>(sum(SS,<span class="hljs-number">2</span>)/(imax+<span class="hljs-number">1</span>)-strike,<span class="hljs-number">0</span>); <span class="hljs-comment">% Asian arithmetic&#x27;s</span><br><span class="hljs-comment">%payoff = max(prod(SS,2)^(imax+1)-strike,0); % Asian geometric&#x27;s</span><br></code></pre></td></tr></table></figure><h5 id="output：-3"><a href="#output：-3" class="headerlink" title="output："></a>output：</h5><p>​    payoff = （2^imax,1）</p><script type="math/tex; mode=display">\begin{bmatrix}0.9422\\0.3978\\     0\\     0\\     0\\     0\\     0\\     0\end{bmatrix} \tag{8 x 1}</script><h4 id="计算每个up-down组合up的次数"><a href="#计算每个up-down组合up的次数" class="headerlink" title="计算每个up-down组合up的次数"></a>计算每个up-down组合up的次数</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>:<span class="hljs-number">2</span>^imax<br>    ind1 = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span> =<span class="hljs-number">1</span>:imax<br>        <span class="hljs-keyword">if</span> matr(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span>)&gt;<span class="hljs-number">0</span><br>            ind1=ind1+<span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">end</span><br>    <span class="hljs-keyword">end</span><br>    pp(<span class="hljs-built_in">i</span>)=ind1;<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><h5 id="output：-4"><a href="#output：-4" class="headerlink" title="output："></a>output：</h5><p>​    pp = （1,2^imax）</p><script type="math/tex; mode=display">\begin{bmatrix}3&     2&     2&     1&     2&     1&     1&     0\end{bmatrix} \tag{1 x 8}</script><h4 id="计算期望值"><a href="#计算期望值" class="headerlink" title="计算期望值"></a>计算期望值</h4><ul><li>rnp_payoff = $rnp ^{pp}*(1-rnp)^{imax-pp}$</li><li>option_price = $\frac{E_{rnp}[payoff]}{(1+r)^{imax}}$</li></ul><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs matlab">rnp_payoff=(rnp.^pp).*(<span class="hljs-number">1</span>-rnp).^(imax-pp);<br>option_price=sum(payoff.*rnp_payoff&#x27;)/((<span class="hljs-number">1</span>+r)^imax);<br></code></pre></td></tr></table></figure><h5 id="output：-5"><a href="#output：-5" class="headerlink" title="output："></a>output：</h5><p>​    rnp_payoff = （1,2^imax）</p><script type="math/tex; mode=display">\begin{bmatrix}0.2746&    0.1479&    0.1479&    0.0796&    0.1479&    0.0796&    0.0796&    0.0429\end{bmatrix} \tag{1 x 8}</script><p>​    rnp_payoff = （1,1）</p><script type="math/tex; mode=display">0.2906 \tag{1 x 1}</script>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Matlab</tag>
      
      <tag>Asian arithmetic Option</tag>
      
      <tag>Option Pricing</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【定义】多时期离散时间模型</title>
    <link href="/2021/02/16/%E6%95%B0%E7%90%86%E9%87%91%E8%9E%8D_2/"/>
    <url>/2021/02/16/%E6%95%B0%E7%90%86%E9%87%91%E8%9E%8D_2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于《数理金融学引论—离散时间模型》；</p><p>第二部分笔记：多时期市场；</p></blockquote><span id="more"></span><ul><li>在有限样本空间 $\Omega$ 中，$\omega$ 为某一时间 $t$ 的一种可能状态，P($\omega_k$) 为状态 k 发生的概率<ul><li>拥有子集$A_n$ ，且$A_{n-1}\supseteq A_n$ </li><li>$A_n$ 的子集 $\{A_{n+1}\}$ 集合形成一个分割（Partition）$\mathscr{P}$ （不相交的子集集合）</li></ul></li></ul><script type="math/tex; mode=display">\Omega = \{\omega_1,\omega_2,...,\omega_K\}</script><ul><li><p>域流（Filtration）$\mathbb{F}$ = $\{\mathscr{F}_t: t = 0,1…,T\}$ </p><ul><li>描述/揭示价格信息/事件</li><li>$\mathscr{F}$ 称为 $\Omega$ 上的一个代数（Algebra），$F \in  \mathscr{F}$ =&gt; $F^c = \Omega\setminus F \in  \mathscr{F}$</li><li>$\mathscr{F}_0 = \{\empty , \Omega\}$ , $\mathscr{F}_T = 2^\Omega$</li></ul></li><li><p>银行账户过程（Bank Account Process）B</p></li><li><p>价格过程（Price Process）S</p></li><li><p>价值过程（Value Process）V</p></li></ul><script type="math/tex; mode=display">V_t = H_0(t)B_t + \sum_{n=1}^NH_n(t)S_n(t)</script><ul><li>增益过程（Gains Process）G</li></ul><script type="math/tex; mode=display">\begin{aligned}\Delta S_n &\equiv S_n(t)-S_n(t-1)\\G_t &\equiv \sum_{u=1}^t H_0(u)\Delta B_u + \sum_{n=1}^N\sum_{u=1}^t H_n(u) \Delta S_n(u)\end{aligned}</script><ul><li>自融资（Self-financing）在交易发生前的价值恰好等于发生之后的价值</li></ul><script type="math/tex; mode=display">V_t=H_0(t+1)B_t+\sum_{n=1}^NH_n(t+1)S_n(t)</script><ul><li>折现价格过程（Discounted Price Process）S^*^</li></ul><script type="math/tex; mode=display">S_n^*(t) \equiv S_n(t)/B_t</script><ul><li>折现价值过程（Discounted Value Process）V^*^</li></ul><script type="math/tex; mode=display">V_t^* \equiv H_0(t) + \sum_{n=1}^N H_n(t)S_n^*(t)</script><ul><li>折现增益过程（Discounted Gains Process）G^*^</li></ul><script type="math/tex; mode=display">G_t^* \equiv \sum_{n=1}^N\sum_{u=1}^t H_n(u) \Delta S_n^*(u)</script><ul><li><p>随机过程 $z$ 中的鞅（Martingale）: $E[Z_{t+s}|\mathscr{F}_t]=Z_t$</p><ul><li>上鞅（Super martingale）: $E[Z_{t+s}|\mathscr{F}_t]\leq Z_t$</li><li>下鞅（Sub martingale）: $E[Z_{t+s}|\mathscr{F}_t]\ge Z_t$</li></ul></li><li><p>风险中性概率测度（Risk Neutral Probability）Q</p><ul><li>也称为鞅测度（Martingale Measure）</li></ul></li></ul><script type="math/tex; mode=display">E_Q[S_n^*(t+s)|\mathscr{F}_t]=S_n^*(t)</script><ul><li>线性定价测度（Linear Pricing Measure）$\pi$</li></ul><script type="math/tex; mode=display">\sum_{\omega}\pi(\omega)G_T^*(\omega) = 0</script>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Financial Mathematics</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【代码】基于超额收益的资产组合优化</title>
    <link href="/2021/02/15/%E5%9F%BA%E4%BA%8E%E8%B6%85%E9%A2%9D%E6%94%B6%E7%9B%8A%E7%9A%84%E8%B5%84%E4%BA%A7%E7%BB%84%E5%90%88%E4%BC%98%E5%8C%96/"/>
    <url>/2021/02/15/%E5%9F%BA%E4%BA%8E%E8%B6%85%E9%A2%9D%E6%94%B6%E7%9B%8A%E7%9A%84%E8%B5%84%E4%BA%A7%E7%BB%84%E5%90%88%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<blockquote><p> 基于《现代投资组合理论与投资分析 9th》第九章；</p><p> 仅包含MATLAB代码，原理请查看原书；</p></blockquote><span id="more"></span><p>输入：</p><ul><li>Mean: 期望收益矩阵</li><li>Beta: 市场收益变动1%时，期望变动率矩阵</li><li>Sigma: 证券收益标准差</li><li>Sigma_m: 市场指数标准差</li><li>Rf: 无风险资产收益</li></ul><p>输出：</p><div class="table-container"><table><thead><tr><th style="text-align:center">1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th><th>15</th></tr></thead><tbody><tr><td style="text-align:center">证券编号</td><td>收益均值</td><td>超额收益</td><td>贝塔</td><td>超额收益/贝塔</td><td>证券收益标准差</td><td>非系统风险</td><td>超额收益*贝塔/非系统风险2</td><td>8的累加</td><td>贝塔/非系统风险2</td><td>贝塔2/非系统风险2</td><td>11的累加</td><td>截止率候选值</td><td>未调整比率</td><td>调整后比率</td></tr><tr><td style="text-align:center">$i$</td><td>$R_i$</td><td>$R_i-R_f$</td><td>$\beta_i$</td><td>$\frac{R_i-R_f}{\beta_i}$</td><td>$\sigma_i$</td><td>$\sigma_{ei}$</td><td>$\frac{(R_i-R_f)\beta_i}{\sigma_{ei}^2}$</td><td>sum(8)</td><td>$\frac{\beta_i}{\sigma_{ei}^2}$</td><td>$\frac{\beta_i^2}{\sigma_{ei}^2}$</td><td>sum(11)</td><td>$c_i$</td><td>$z_i$</td><td>$x_i$</td></tr></tbody></table></div><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-params">[matrix]</span> = <span class="hljs-title">portfolio_optimization_c</span><span class="hljs-params">(mean,beta,sigma,sigma_m,rf)</span></span><br><span class="hljs-comment">% mean|excess return|beta|excess return over beta|sigma_i|sigma_ei|(ri-rf)beta/sigma_ei^2|sum(8)|betai/sigma_ei^2|betai^2/sigma_ei^2|sum(11)|C*|Z|X</span><br>n = <span class="hljs-built_in">length</span>(<span class="hljs-built_in">mean</span>);<br>matrix = <span class="hljs-built_in">zeros</span>(n,<span class="hljs-number">15</span>);<br>matrix(:,<span class="hljs-number">1</span>) = <span class="hljs-number">1</span>:<span class="hljs-number">1</span>:n;<br>matrix(:,<span class="hljs-number">2</span>) = <span class="hljs-built_in">mean</span>;<br>matrix(:,<span class="hljs-number">3</span>) = <span class="hljs-built_in">mean</span>-rf;<br>matrix(:,<span class="hljs-number">4</span>) = <span class="hljs-built_in">beta</span>;<br>matrix(:,<span class="hljs-number">5</span>) = matrix(:,<span class="hljs-number">3</span>)./matrix(:,<span class="hljs-number">4</span>);<br>matrix(:,<span class="hljs-number">6</span>) = sigma;<br>matrix(:,<span class="hljs-number">7</span>) = <span class="hljs-built_in">sqrt</span>(matrix(:,<span class="hljs-number">6</span>).^<span class="hljs-number">2</span>-sigma_m^<span class="hljs-number">2</span>*matrix(:,<span class="hljs-number">4</span>).^<span class="hljs-number">2</span>);<br>matrix(:,<span class="hljs-number">8</span>) = matrix(:,<span class="hljs-number">3</span>).*matrix(:,<span class="hljs-number">4</span>)./matrix(:,<span class="hljs-number">7</span>).^<span class="hljs-number">2</span>;<br>matrix(:,<span class="hljs-number">10</span>) = matrix(:,<span class="hljs-number">4</span>)./matrix(:,<span class="hljs-number">7</span>).^<span class="hljs-number">2</span>;<br>matrix(:,<span class="hljs-number">11</span>) = matrix(:,<span class="hljs-number">4</span>).^<span class="hljs-number">2.</span>/matrix(:,<span class="hljs-number">7</span>).^<span class="hljs-number">2</span>;<br>matrix = <span class="hljs-built_in">sortrows</span>(matrix,<span class="hljs-number">5</span>,<span class="hljs-string">&#x27;descend&#x27;</span>);<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:<span class="hljs-number">1</span>:n<br>    matrix(<span class="hljs-built_in">i</span>,<span class="hljs-number">9</span>) = sum(matrix(<span class="hljs-number">1</span>:<span class="hljs-built_in">i</span>,<span class="hljs-number">8</span>));<br>    matrix(<span class="hljs-built_in">i</span>,<span class="hljs-number">12</span>) = sum(matrix(<span class="hljs-number">1</span>:<span class="hljs-built_in">i</span>,<span class="hljs-number">11</span>));<br><span class="hljs-keyword">end</span><br>matrix(:,<span class="hljs-number">13</span>) = sigma_m^<span class="hljs-number">2</span>*matrix(:,<span class="hljs-number">9</span>)./(<span class="hljs-number">1</span>+sigma_m^<span class="hljs-number">2</span>*matrix(:,<span class="hljs-number">12</span>));<br>C = matrix(<span class="hljs-number">1</span>,<span class="hljs-number">13</span>);<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:<span class="hljs-number">1</span>:n<br>    <span class="hljs-keyword">if</span> matrix(<span class="hljs-built_in">i</span>,<span class="hljs-number">13</span>) &gt; matrix(<span class="hljs-built_in">i</span>,<span class="hljs-number">5</span>)<br>        <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">else</span><br>        C = matrix(<span class="hljs-built_in">i</span>,<span class="hljs-number">13</span>);<br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br>matrix(:,<span class="hljs-number">14</span>) = matrix(:,<span class="hljs-number">10</span>).*(matrix(:,<span class="hljs-number">5</span>)-C);<br>matrix(:,<span class="hljs-number">15</span>) = matrix(:,<span class="hljs-number">14</span>)/sum(matrix(:,<span class="hljs-number">14</span>));<br>name = &#123;<span class="hljs-string">&#x27;index&#x27;</span>,<span class="hljs-string">&#x27;mean&#x27;</span>,<span class="hljs-string">&#x27;excess_return&#x27;</span>,<span class="hljs-string">&#x27;beta&#x27;</span>,<span class="hljs-string">&#x27;excess_return_over_beta&#x27;</span>,<span class="hljs-string">&#x27;sigma&#x27;</span>,<span class="hljs-string">&#x27;sigma_e&#x27;</span>,<span class="hljs-string">&#x27;excess_return_time_beta_by_sigma_e2&#x27;</span>,<span class="hljs-string">&#x27;sum_of_8&#x27;</span>,<span class="hljs-string">&#x27;beta_by_sigma_e2&#x27;</span>,<span class="hljs-string">&#x27;beta2_by_sigma_e2&#x27;</span>,<span class="hljs-string">&#x27;sum_of_11&#x27;</span>,<span class="hljs-string">&#x27;C&#x27;</span>,<span class="hljs-string">&#x27;Z&#x27;</span>,<span class="hljs-string">&#x27;X&#x27;</span>&#125;;<br>matrix = array2table(matrix, <span class="hljs-string">&#x27;VariableNames&#x27;</span>, name);<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Matlab</tag>
      
      <tag>Portfolio Optimization</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【推导】Modern Portfolio Theory</title>
    <link href="/2021/02/15/Modern_Portfolio_Theory/"/>
    <url>/2021/02/15/Modern_Portfolio_Theory/</url>
    
    <content type="html"><![CDATA[<blockquote><p>构造拉格朗日函数公式研究马科维茨投资模型；</p><p>目前包含：</p><ol><li><p>求最小 sigma_p；</p></li><li><p>最优组合下每个资产的权重；</p></li><li><p>加入 risk free security 后的权重；</p></li></ol></blockquote><span id="more"></span><h4 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h4><p>原模型等价于固定预期收益率为常数、权重之和为1的限制条件下求最小方差的线性规划问题如下：</p><script type="math/tex; mode=display">\begin{align}目标函数：&min\sum_{i=1}^n\sum_{j=1}^nw_iw_jCov(r_i,r_j)\\&s.t.\begin{cases}\sum_{i=1}^nr_iw_i=E(R)\\\sum_{i=1}^nw_i=1\end{cases}\\\end{align}</script><h4 id="Part-1："><a href="#Part-1：" class="headerlink" title="Part 1："></a>Part 1：</h4><p>构造的拉格朗日函数公式如下：</p><script type="math/tex; mode=display">\mathcal{L}(w,\lambda_1,\lambda_2)=\sum_{i=1}^n\sum_{j=1}^nw_iw_jCov(r_i,r_j)-\lambda_1(\sum_{i=1}^nr_iw_i-E(R))-\lambda_2(\sum_{i=1}^nw_i-1)</script><p>对$w_i,\lambda_1,\lambda_2$分别求导取0，满足条件如下:</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial \mathcal{L}}{\partial w_i}&=\sum_{j=1}^nw_jCov(r_i,r_j)-\lambda_1r_i-\lambda_2=0\\\frac{\partial \mathcal{L}}{\partial \lambda_1}&=\sum_{i=1}^nr_iw_i-E(R)=0\\\frac{\partial \mathcal{L}}{\partial \lambda_2}&=\sum_{i=1}^nw_i-1=0\\\end{aligned}</script><p>整合$w_j =&gt; w,r_i =&gt; R,Cov(r_i,r_j)=&gt;\Sigma$</p><script type="math/tex; mode=display">\begin{cases}&2\Sigma w -\lambda_1R-\lambda_21_n=0\\&w^TR-E(R)=0\\&e^T1_n-1=0\end{cases}</script><p>假设收益率协方差可逆</p><script type="math/tex; mode=display">w =\frac{1}{2}\Sigma^{-1}(\lambda_1R+\lambda_21_n) \tag{1}</script><script type="math/tex; mode=display">E(R)=w^TR \tag{2}</script><script type="math/tex; mode=display">e^T1_n=1 \tag{3}</script><p>将(2),(3)代入(1)</p><script type="math/tex; mode=display">\begin{cases}E(R)=\frac{1}{2}(\lambda_1R^T\Sigma^{-1}R+\lambda_21_n^T\Sigma^{-1}R)\\1 = \frac{1}{2}(\lambda_1R^T\Sigma^{-1}1_n+\lambda_21_n^T\Sigma^{-1}1_n)\end{cases}</script><p>转为矩阵格式</p><script type="math/tex; mode=display">\begin{bmatrix}E(R)\\1\end{bmatrix}=\frac{1}{2}\begin{bmatrix}R^T\Sigma^{-1}R&1_n^T\Sigma^{-1}R\\R^T\Sigma^{-1}1_n&1_n^T\Sigma^{-1}1_n\end{bmatrix}\begin{bmatrix}\lambda_1\\\lambda_2\end{bmatrix}\tag{4}</script><p>由于目标函数$=&gt;min\quad\sigma_p^2$</p><script type="math/tex; mode=display">\begin{aligned}\sigma_p^2&=w^T\Sigma w\\&=\frac{1}{4}(\lambda_1R^T\Sigma^{-1}+\lambda_21_n^T\Sigma^{-1})\Sigma\Sigma^{-1}(\lambda_1R+\lambda_21_n) \\&=\frac{1}{4}(\lambda_1^2R^T\Sigma^{-1}R+2\lambda_1\lambda_2R^T\Sigma^{-1}1_n+\lambda_2^21_n^T\Sigma^{-1}1_n)\\&=\frac{1}{4}\begin{bmatrix}\lambda_1&\lambda_2 \end{bmatrix}\begin{bmatrix}R^T\Sigma^{-1}R&1_n^T\Sigma^{-1}R\\R^T\Sigma^{-1}1_n&1_n^T\Sigma^{-1}1_n\end{bmatrix}\begin{bmatrix}\lambda_1\\\lambda_2\end{bmatrix}\end{aligned}\tag{5}</script><p>联立(4),(5)得</p><script type="math/tex; mode=display">\begin{bmatrix}E(R)&1\end{bmatrix}\begin{bmatrix}R^T\Sigma^{-1}R&1_n^T\Sigma^{-1}R\\R^T\Sigma^{-1}1_n&1_n^T\Sigma^{-1}1_n\end{bmatrix}^{-1}\begin{bmatrix}E(R)\\1\end{bmatrix}=\sigma_p^2</script><p>设  $a = R^T\Sigma^{-1}R,b = R^T\Sigma^{-1}1_n,c = 1_n^T\Sigma^{-1}1_n$ , 化简得</p><script type="math/tex; mode=display">\sigma_p^2=\frac{cE(R)^2-2bE(R)+a}{ac-b^2}</script><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-params">[P_return]</span> = <span class="hljs-title">optimal_portfolio_e</span><span class="hljs-params">(mu,Sigma,sigma)</span></span><br>n = <span class="hljs-built_in">size</span>(Sigma,<span class="hljs-number">1</span>); <br>V = Sigma^(<span class="hljs-number">-1</span>); <br>e = <span class="hljs-built_in">ones</span>(n,<span class="hljs-number">1</span>); <br>A = mu&#x27;*V*mu;<br>B = e&#x27;*V*mu;<br>C = e&#x27;*V*e;<br>P_return = fzero(@(x) C*x^<span class="hljs-number">2</span><span class="hljs-number">-2</span>*B*x+A-sigma^<span class="hljs-number">2</span>*(A*C-B^<span class="hljs-number">2</span>),<span class="hljs-number">1</span>);<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><h4 id="Part-2："><a href="#Part-2：" class="headerlink" title="Part 2："></a>Part 2：</h4><p>从矩阵形式得到</p><script type="math/tex; mode=display">\begin{align}\begin{bmatrix}2\\2E(R)\end{bmatrix}&=\begin{bmatrix}1_n^T\Sigma^{-1}R&1_n^T\Sigma^{-1}1_n\\ R^T\Sigma^{-1}R&R^T\Sigma^{-1}1_n\end{bmatrix}\begin{bmatrix}\lambda_1\\ \lambda_2\end{bmatrix}\\\begin{bmatrix}\lambda_1\\ \lambda_2\end{bmatrix}&=\begin{bmatrix}1_n^T\Sigma^{-1}R&1_n^T\Sigma^{-1}1_n\\R^T\Sigma^{-1}R&R^T\Sigma^{-1}1_n\end{bmatrix}^{-1}\begin{bmatrix}2\\2E(R)\end{bmatrix}\end{align}</script><p>代入$w$得</p><script type="math/tex; mode=display">w = \begin{bmatrix} \Sigma^{-1}R&\Sigma^{-1}1_n\end{bmatrix}\begin{bmatrix}1_n^T\Sigma^{-1}R&1_n^T\Sigma^{-1}1_n\\R^T\Sigma^{-1}R&R^T\Sigma^{-1}1_n\end{bmatrix}^{-1}\begin{bmatrix}1\\E(R)\end{bmatrix}</script><p>求得$w^T\Sigma w$</p><h4 id="Part-3："><a href="#Part-3：" class="headerlink" title="Part 3："></a>Part 3：</h4><p>加入收益率是 $r_f$ 的  risk free security 之后</p><script type="math/tex; mode=display">\begin{align}&目标函数：min\quad w^T\Sigma w\\&s.t.\quad (1-\sum_{i=1}^n)r_f+w^TR=E(R)\end{align}</script><p>Solution</p><script type="math/tex; mode=display">\sigma_p^2=\frac{(E(R)-r_f)^2}{(R-r_f1_n)^T\Sigma^{-1}(R-r_f1_n)}</script><script type="math/tex; mode=display">\xi=\frac{\sigma_p^2}{E(R)-r_f}</script><script type="math/tex; mode=display">w=\xi\Sigma^{-1}(E(R)-r_f1_n)</script><hr><h4 id="MATLAB代码："><a href="#MATLAB代码：" class="headerlink" title="MATLAB代码："></a>MATLAB代码：</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">[w]</span> = <span class="hljs-title">optimal_portfolio_1</span><span class="hljs-params">(R,Sigma,ER)</span></span><br><span class="hljs-comment">% no risk-free asset</span><br>n = <span class="hljs-built_in">size</span>(Sigma,<span class="hljs-number">1</span>); <span class="hljs-comment">% the number of risky shares</span><br>V = Sigma^(<span class="hljs-number">-1</span>); <span class="hljs-comment">%inverse of  variance-covariance matrix</span><br>e = <span class="hljs-built_in">ones</span>(n,<span class="hljs-number">1</span>); <span class="hljs-comment">% unit vector, column</span><br>A = e&#x27;*V*R;<br>B = R&#x27;*V*R;<br>C = e&#x27;*V*e;<br>K = [A C;  B A];<br>LM = K^(<span class="hljs-number">-1</span>)*[<span class="hljs-number">1</span>; ER];<br>w = [V*R, V*e]*LM; <span class="hljs-comment">% optimal weight</span><br></code></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">[w]</span> = <span class="hljs-title">optimal_portfolio_2</span><span class="hljs-params">(mu,Sigma,rf,p)</span></span><br><span class="hljs-comment">% with risk free asset</span><br>n = <span class="hljs-built_in">size</span>(Sigma,<span class="hljs-number">1</span>); <span class="hljs-comment">% the number of risky shares</span><br>V = Sigma^(<span class="hljs-number">-1</span>); <span class="hljs-comment">%inverse of  variance-covariance matrix</span><br>e = <span class="hljs-built_in">ones</span>(n,<span class="hljs-number">1</span>); <span class="hljs-comment">% unit vector, column</span><br><br>sigma2min = (p - rf)^<span class="hljs-number">2</span>/((mu-rf*e)&#x27;*V*(mu-rf*e));<br>xi = sigma2min/(p - rf);<span class="hljs-comment">% tangency</span><br><br>w = xi*V*(mu-rf*e); <span class="hljs-comment">% optimal weight</span><br></code></pre></td></tr></table></figure><hr><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol><li><a href="https://xueqiu.com/1985849148/145570290">投资组合理论学习之马科维茨投资模型（一）</a></li><li><a href="https://zhuanlan.zhihu.com/p/273729929">矩阵求导公式的数学推导（矩阵求导——基础篇）</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Markowitz</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】Inner product and Cross Product</title>
    <link href="/2021/02/15/Inner_product_and_Cross_Product/"/>
    <url>/2021/02/15/Inner_product_and_Cross_Product/</url>
    
    <content type="html"><![CDATA[<blockquote><p>对内积与外积基础性质进行简要陈述；</p></blockquote><span id="more"></span><h2 id="内积（Inner-product，点乘）"><a href="#内积（Inner-product，点乘）" class="headerlink" title="内积（Inner product，点乘）"></a>内积（Inner product，点乘）</h2><script type="math/tex; mode=display">a = [a_1,a_2,...,a_n] \qquad b = [b_1,b_2,...,b_n]</script><script type="math/tex; mode=display">a·b = |a||b|Cos\angle(a,b)</script><p><img src="/2021/02/15/Inner_product_and_Cross_Product/pic1-1.jpg" alt></p><ul><li>在几何中这个结果为b在a方向上的<strong>投影</strong>，若a与b正交，$a·b=0$</li><li>Scalar projrction of x onto y ：$\alpha=\frac{x^Ty}{||y||}$</li><li>Vector projection of x onto y : $P=\alpha\frac1{||y||}y=\frac{x^Ty}{y^Ty}y$</li></ul><p><img src="/2021/02/15/Inner_product_and_Cross_Product/pic1-8.jpg" alt></p><ul><li><p>If $a=(a_1,a_2,a_3)$ and $b=(b_1,b_2,b_3)$.  Then $a·b=a_1b_1+a_2b_2+a_3b_3$</p><p>证明：</p><ul><li><p>$|a-b|^2=|a|^2+|b|^2-2|a||b|Cos\angle(a,b)$</p></li><li><p>$|a|^2=a_q^2+a_2^2+a_3^2,|b|^2=b_q^2+b_2^2+b_3^2$</p></li><li><p>$|a-b|^2=(a_1-b_1)^2+(a_2-b_2)^2+(a_3-b_3)^2$</p><script type="math/tex; mode=display">\begin{aligned}a·b&=|a||b|Cos\angle(a,b)\\&=\frac12(|a|^2+|b|^2-|a-b|^2)\\&=\frac12(a_q^2+a_2^2+a_3^2+b_q^2+b_2^2+b_3^2-(a_1-b_1)^2-(a_2-b_2)^2-(a_3-b_3)^2)\\&=a_1b_1+a_2b_2+a_3b_3\end{aligned}</script></li></ul></li></ul><h2 id="外积（Cross-Product，叉乘）"><a href="#外积（Cross-Product，叉乘）" class="headerlink" title="外积（Cross Product，叉乘）"></a>外积（Cross Product，叉乘）</h2><script type="math/tex; mode=display">a = (x_1,y_1,z_1) \qquad b = (x_2,y_2,z_2)</script><script type="math/tex; mode=display">a \times b = \begin{vmatrix} i & j & k \\ x_1 & y_1 & z_1 \\x_2 & y_2 & z_2 \end{vmatrix} = (y_1z_2-y_2z_1)i-(x_1z_2-x_2z_1)j+(x_1y_2-x_2y_1)k</script><p>其中</p><script type="math/tex; mode=display">i = (1,0,0) \ j = (0,1,0) \ k = (0,0,1)</script><p>得到结果向量</p><script type="math/tex; mode=display">a \times b = (y_1z_2-y_2z_1,-(x_1z_2-x_2z_1),x_1y_2-x_2y_1)</script><p><img src="/2021/02/15/Inner_product_and_Cross_Product/pic1-2.jpg" alt></p><p>在几何中这个结果称为<strong>法向量</strong>，该向量垂直于a和b向量构成的平面</p><p>叉乘同时拥有其它基本性质：</p><ol><li>$a \times a = 0$</li><li>$a \times b = -( b \times a)$</li><li>$(a + b)\times c = a \times c + b \times c$</li><li>$(a\times b)\times c\ne a\times(b\times c)$</li><li>$(a\times b)·c=a·(b\times c)$</li></ol><p>可得到叉乘公式推导：</p><script type="math/tex; mode=display">\begin{aligned}u \times v =& (u_1i+u_2j+u_3k)\times(v_1i+v_2j+v_3k)\\=&u_1v_1(i \times i)+u_1v_2(i \times j)+u_1v_3(i \times k)+\\&u_2v_1(j \times i)+u_2v_2(j \times j)+u_2v_3(j \times k)+\\&u_3v_1(k \times i)+u_3v_2(k \times j)+u_3v_3(k \times k)+\end{aligned}</script><p>同时因为</p><script type="math/tex; mode=display">i\times i = j\times j = k\times k = 0</script><script type="math/tex; mode=display">\begin{cases}i\times j = k\\j\times k = i\\k\times i = j\end{cases}\\begin{cases}j\times i = -k\\k\times j = -i\\i\times k = -j\end{cases}</script><p>得到</p><script type="math/tex; mode=display">\begin{aligned}u\times v =& (u_2v_3-u_3v_2)i+(u_3v_1-u_1v_3)j+(u_1v_2-u_2v_1)k\\=& \begin{vmatrix} u_2 & u_3 \\v_2 & v_3 \end{vmatrix}i -\begin{vmatrix} u_1 & u_3 \\v_1 & v_3 \end{vmatrix}j +\begin{vmatrix} u_1 & u_2 \\v_1 & v_2 \end{vmatrix}k\\=& \begin{vmatrix} i & j & k\\u_1 & u_2 & u_3\\v_1 & v_2 & v_3 \end{vmatrix}\end{aligned}</script><ul><li><p>证明垂直：</p><script type="math/tex; mode=display">\begin{aligned}(u\times v)·w =& (u_2v_3-u_3v_2)w_1+(u_3v_1-u_1v_3)w_2+(u_1v_2-u_2v_1)w_3\\=& \begin{vmatrix} w_1 & w_2 & w_3\\u_1 & u_2 & u_3\\v_1 & v_2 & v_3 \end{vmatrix}\end{aligned}</script><script type="math/tex; mode=display">(u\times v)·u = \begin{vmatrix} u_1 & u_2 & u_3\\u_1 & u_2 & u_3\\v_1 & v_2 & v_3 \end{vmatrix}=u_1u_2v_3+u_2u_3v_1+u_3u_1v_2-u_3u_2v_1-u_2u_1v_3-u_1u_3v_2=0</script><script type="math/tex; mode=display">(u\times v)·v = \begin{vmatrix} v_1 & v_2 & v_3\\u_1 & u_2 & u_3\\v_1 & v_2 & v_3 \end{vmatrix}=v_1u_2v_3+v_2u_3v_1+v_3u_1v_2-v_3u_2v_1-v_2u_1v_3-v_1u_3v_2=0</script><p>$u$  $v$  is perpendicular to both $u$ and $v$.</p></li></ul><p><img src="/2021/02/15/Inner_product_and_Cross_Product/pic1-3.jpg" alt></p><h2 id="扩充"><a href="#扩充" class="headerlink" title="扩充"></a>扩充</h2><ul><li><p>If $u=(u_1,u_2,u_3)$ and $v=(v_1,v_2,v_3)$.  Then $|u\times v|=|u||v|Sin\angle(a,b)$</p><p>证明：</p><script type="math/tex; mode=display">\begin{aligned}|u\times v|^{2} &=(u_{2} v_{3}-u_{3} v_{2})^{2}+(u_{3} v_{1}-u_{1} v_{3})^{2}+(u_{1} v_{2}-u_{2} v_{1})^{2} \\&=(u_{2} v_{3})^{2}-2(u_{2} v_{3})(u_{3} v_{2})+(u_{3} v_{2})^{2} \\&+(u_{3} v_{1})^{2}-2(u_{3} v_{1})(u_{1} v_{3})+(u_{1} v_{3})^{2} \\&+(u_{1} v_{2})^{2}-2(u_{1} v_{2})(u_{2} v_{1})+(u_{2} v_{1})^{2} \\&=(u_{1} v_{1})^{2}+(u_{1} v_{2})^{2}+(u_{1} v_{3})^{2}+(u_{2} v_{1})^{2}+(u_{2} v_{2})^{2}+(u_{2} v_{3})^{2}+(u_{3} v_{1})^{2}+(u_{3} v_{2})^{2}+(u_{3} v_{3})^{2} \\&-[(u_{1} v_{1})^{2}+(u_{2} v_{2})^{2}+(u_{3} v_{3})^{2}+2(u_{1} v_{1})(u_{2} v_{2})+2(u_{2} v_{2})(u_{3} v_{3})+2(u_{1} v_{1})(u_{3} v_{3})] \\&=(u_{1}^{2}+u_{2}^{2}+u_{3}^{2})(v_{1}^{2}+v_{2}^{2}+v_{3}^{2})-(u_{1} v_{1}+u_{2} v_{2}+u_{3} v_{3})^{2} \\&=|u|^{2}|v|^{2}-(u \cdot v)^{2} \\&=|u|^{2}|v|^{2}-|u|^{2}|v|^{2}Cos^2\angle(a,b)\\&=|u|^{2}|v|^{2}Sin^2\angle(a,b)\end{aligned}</script></li></ul><p><img src="/2021/02/15/Inner_product_and_Cross_Product/pic1-4.jpg" alt></p><ul><li>$|v\times w||u|Cos\angle(a,b)=u·(v\times w)=\begin{vmatrix}u_1 &amp; u_2 &amp; u_3\\v_1 &amp; v_2 &amp; v_3\ w_1 &amp; w_2 &amp; w_3\end{vmatrix}$</li></ul><p><img src="/2021/02/15/Inner_product_and_Cross_Product/pic1-5.jpg" alt></p><ul><li>The area of the parallelogram generated by the vectors $(a, b)$ and $(c, d)$ is $det\left(\matrix{a&amp;b\\c&amp;d}\right)$</li></ul><p><img src="/2021/02/15/Inner_product_and_Cross_Product/pic1-6.jpg" alt></p><ul><li>$\left\{\matrix{ax+by=e\\cx+dy=f}\right.$ ，只有在 $det\left(\matrix{a&amp;b\\c&amp;d}\right)\ne0$ 时才有解，解为 $\left(\matrix{a&amp;b\\c&amp;d}\right)^{-1}\left(\matrix{e\\f}\right)$</li></ul><p><img src="/2021/02/15/Inner_product_and_Cross_Product/pic1-7.jpg" alt></p><hr><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://www.cnblogs.com/lzhu/p/10405091.html"><strong>向量的内积（点乘）</strong></a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Math</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Inner product＆Cross Product</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【定义】单时期离散时间模型</title>
    <link href="/2021/02/13/%E6%95%B0%E7%90%86%E9%87%91%E8%9E%8D_1/"/>
    <url>/2021/02/13/%E6%95%B0%E7%90%86%E9%87%91%E8%9E%8D_1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于《数理金融学引论—离散时间模型》；</p><p>第一部分笔记：单时期市场；</p></blockquote><span id="more"></span><ul><li>在有限样本空间 $\Omega$ 中，$\omega$ 为某一时间的一种可能状态，P($\omega_k$) 为状态 k 发生的概率。</li></ul><script type="math/tex; mode=display">\begin{aligned}\Omega = \{\omega_1,\omega_2,...,\omega_K\}\\P(\omega_k)>0 \ , \ \sum_{k=1}^K p(\omega_k)=1\end{aligned}</script><ul><li>银行账户过程（Bank Account Process）B</li><li>价格过程（Price Process）S</li><li>交易策略（Trading Strategy）H</li></ul><script type="math/tex; mode=display">H_0 = x-\sum_{i=1}^{n}H_nS_n(0)</script><ul><li>价值过程（Value Process）V</li></ul><script type="math/tex; mode=display">V_t \equiv H_0B_t + \sum_{n=1}^N H_nS_n(t) \ , \ t = 0,1</script><ul><li>增益过程（Gains Process）G</li></ul><script type="math/tex; mode=display">\begin{aligned}\Delta S_n &\equiv S_n(1)-S_n(0)\\G &\equiv V_1-V_0 \equiv H_0r + \sum_{n=1}^N H_n \Delta S_n\end{aligned}</script><ul><li>折现价格过程（Discounted Price Process）S^*^</li></ul><script type="math/tex; mode=display">S_n^*(t) \equiv S_n(t)/B_t \ , \ t = 0,1</script><ul><li>折现价值过程（Discounted Value Process）V^*^</li></ul><script type="math/tex; mode=display">V_t^* \equiv V_t/B_t \equiv H_0 + \sum_{n=1}^N H_nS_n^*(t) \ , \ t = 0,1</script><ul><li>折现增益过程（Discounted Gains Process）G^*^</li></ul><script type="math/tex; mode=display">\begin{aligned}G^* &\equiv V_1^*-V_0^* \equiv \sum_{n=1}^N H_n \Delta S_n^*\\G^* &\not\equiv G/B_t  \ (\ V_0,V_1除的B_t不一样\ )\end{aligned}</script><ul><li>线性定价测度（Linear Pricing Measure）$\pi$</li></ul><script type="math/tex; mode=display">\begin{aligned}V_0^* &= \sum_\omega \pi(\omega)V_1^*(\omega) = \sum_\omega \pi(\omega)V_1(\omega)/B_1(\omega)\\H_0 +& \sum_{n=1}^N H_nS_n^*(0) = \sum_\omega \pi(\omega)[H_0 + \sum_{n=1}^N H_nS_n^*(1)(\omega)]\end{aligned}</script><blockquote><p>为满足线性条件使$\sum_\omega \pi(\omega)=1$ , 这样人们把 $\pi$ 解释成样本空间 $\Omega$ 上的一个概率测度</p></blockquote><script type="math/tex; mode=display">S_n^*(0) = \sum_\omega \pi(\omega)S_n^*(1)(\omega)</script><ul><li>风险中性概率测度（Risk Neutral Probability）Q</li></ul><script type="math/tex; mode=display">\begin{aligned}&Q(\omega)>0 \ , \ E_Q[\Delta S_n^*]=0\\E_Q[\Delta S_n^*] = &E_Q[S_n^*(1)-S_n^*(0)] = E_Q[S_n^*(1)]-S_n^*(0)\end{aligned}</script><blockquote><p>与$\pi(\omega)$等价</p></blockquote><script type="math/tex; mode=display">\begin{aligned}\mathbb{W} &\equiv \{X\in \mathbb{R}^K:X = G^* 对于某一个交易策略H\}\\\mathbb{A} &\equiv \{X\in \mathbb{R}^K:X \geqq0 ,X\not=0 \}\\\mathbb{W} \cap \mathbb{A}&\not= \empty \ :\mathbb{W}的非负象限\\\mathbb{W}^\perp &\equiv \{Y\in \mathbb{R}^K:X·Y=0 \ 对于所有X\in \mathbb{W}\}\\\mathbb{P}^+ &\equiv \{X\in \mathbb{R}^K:X_1+...+X_K=1 ,X_1>0,...,X_K>0\}\end{aligned}</script><p><img src="/2021/02/13/%E6%95%B0%E7%90%86%E9%87%91%E8%9E%8D_1/pic1-1.jpg" alt></p><script type="math/tex; mode=display">\begin{aligned}Q\in &\mathbb{W}^\perp \cap \mathbb{P}^+\\Where \ E_Q[G^*]&=\sum_{n=1}^NH_nE_Q[S_n^*]=0\end{aligned}</script><ul><li>超平面分离定理（Separating hyperplane theorem）: 若 C , D为非空凸集，且  $C \cap D = \empty$，则存在  $a \not= 0 , b $ 使得<script type="math/tex; mode=display">\begin{aligned}a^Tx&\leqq b \ for \ x\in C\\a^Tx&\geqq b \ for \ x\in D\\inf_{x\in D}a^Tx&\geqq sup_{x\in C}a^Tx\end{aligned}</script></li></ul><blockquote><p>可推导当$\mathbb{W}\cap\mathbb{A} = \empty$, 必有$\mathbb{W}^\perp\cap\mathbb{P}^+\not=\empty$, 且$\mathbb{W}^\perp=\lambda a$</p></blockquote><p><img src="/2021/02/13/%E6%95%B0%E7%90%86%E9%87%91%E8%9E%8D_1/pic1-2.jpg" alt></p>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Financial Mathematics</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【笔记】基于斜率最大的资产组合优化</title>
    <link href="/2021/02/13/%E5%9F%BA%E4%BA%8E%E6%96%9C%E7%8E%87%E6%9C%80%E5%A4%A7%E7%9A%84%E8%B5%84%E4%BA%A7%E7%BB%84%E5%90%88%E4%BC%98%E5%8C%96/"/>
    <url>/2021/02/13/%E5%9F%BA%E4%BA%8E%E6%96%9C%E7%8E%87%E6%9C%80%E5%A4%A7%E7%9A%84%E8%B5%84%E4%BA%A7%E7%BB%84%E5%90%88%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<blockquote><p> 基于《现代投资组合理论与投资分析 9th》；</p><p>对基于斜率的资产组合优化的推导，包含MATLAB代码；</p></blockquote><span id="more"></span><h4 id="基础定义"><a href="#基础定义" class="headerlink" title="基础定义"></a>基础定义</h4><script type="math/tex; mode=display">\begin{aligned}x_i&:分配给项目i的比率\\ \bar{r}_i&:项目i的平均回报率\\ r_f&:无风险回报率\\ \sigma_i&: 项目i的风险\\  p&:投资组合\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}\bar{r}_p &= \sum_{i=1}^n x_i\bar{r}_i\\\sigma_p^2 &= \sum_{i=1}^n x_i^2\sigma_i^2 + \sum_{i=1}^n\sum_{j=1\\j\ne i}^nx_ix_j\sigma_{ij}\end{aligned}</script><h4 id="推导过程"><a href="#推导过程" class="headerlink" title="推导过程"></a>推导过程</h4><p>基于斜率最大，得出目标函数：</p><script type="math/tex; mode=display">\begin{aligned}MAX\ \theta &= \frac{\bar{r}_p-r_f}{\sigma_p}\\\sum_{i=1}^nx_i&=1\end{aligned}</script><p>带入基础定义得：</p><script type="math/tex; mode=display">\theta = \frac{\sum_{i=1}^n x_i(\bar{r}_i-r_f)}{\sqrt{\sum_{i=1}^n x_i^2\sigma_i^2 + \sum_{i=1}^n\sum_{j=1\\j\ne i}^nx_ix_j\sigma_{ij}}}</script><p>求最大值即对所有x求导等于0：</p><script type="math/tex; mode=display">\begin{aligned}Set \ \lambda &= \sum_{i=1}^n x_i^2\sigma_i^2 + \sum_{i=1}^n\sum_{j=1\\j\ne i}^nx_ix_j\sigma_{ij}\\\frac{d\theta}{dx_i}&=\frac{(\bar{r}_i-r_f)\lambda^{\frac{1}{2}}-(\sum_{i=1}^n x_i(\bar{r}_i-r_f))·\frac{1}{2}\lambda^{-\frac{1}{2}}·(2x_i\sigma_i^2+2\sum_{j=1\\j\ne i}^nx_j\sigma_{ij})}{\lambda}=0\\&\Rightarrow (\bar{r}_i-r_f)-(\sum_{i=1}^n x_i(\bar{r}_i-r_f))·\lambda^{-1}·(x_i\sigma_i^2+\sum_{j=1\\j\ne i}^nx_j\sigma_{ij})=0\\&\Rightarrow (\bar{r}_i-r_f)-(\bar{r}_p-r_f)·\lambda^{-1}·(x_i\sigma_i^2+\sum_{j=1\\j\ne i}^nx_j\sigma_{ij})=0\\&\Rightarrow (\bar{r}_i-r_f)-\lambda_{new}·(\sum_{j=1}^nx_j\sigma_{ij})=0\\&\Rightarrow (\bar{r}_i-r_f)=\lambda_{new}·(\sum_{j=1}^nx_j\sigma_{ij})\\&Set\ \ \lambda_{new}x_i=z_i \\&\Rightarrow (\bar{r}_i-r_f)=\sum_{j=1}^nz_j\sigma_{ij}\end{aligned}</script><p>当用于矩阵求解时：</p><script type="math/tex; mode=display">R=\left[\begin{matrix}\bar{r}_1\\\bar{r}_2\\\vdots\\ \bar{r}_n\\\end{matrix}\right],Z=\left[\begin{matrix}z_1\\z_2\\\vdots\\z_n\\\end{matrix}\right]</script><script type="math/tex; mode=display">H=\left[\begin{matrix}\sigma_1^2&\sigma_{12}&\cdots&\sigma_{1n}\\\sigma_{21}&\sigma_2^2&\cdots&\sigma_{2n}\\\vdots & \vdots & \ddots & \vdots \\\sigma_{n1}&\sigma_{n2}&\cdots&\sigma_n^2\\\end{matrix}\right]</script><script type="math/tex; mode=display">\begin{aligned}R-r_f&=HZ\\Z &= H^{-1}(R-r_f)\\x_i &= \frac{z_i}{\sum_{i=1}^nz_i}\end{aligned}</script><hr><h4 id="【MATLAB-代码】"><a href="#【MATLAB-代码】" class="headerlink" title="【MATLAB 代码】"></a>【MATLAB 代码】</h4><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-params">[X]</span> = <span class="hljs-title">portfolio_optimization</span><span class="hljs-params">(R,H,rf)</span></span><br><span class="hljs-comment">% Z = H^(-1)(R-rf)</span><br>n = <span class="hljs-built_in">length</span>(R);<br>X = <span class="hljs-built_in">zeros</span>(n,<span class="hljs-number">1</span>);<br>Z = inv(H)*(R-rf);<br>Z_sum = sum(Z);<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:<span class="hljs-number">1</span>:n<br>    X(<span class="hljs-built_in">i</span>)=Z(<span class="hljs-built_in">i</span>)/Z_sum;<br><span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Portfolio Optimization</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
